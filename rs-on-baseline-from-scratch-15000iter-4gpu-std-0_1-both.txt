Running experiment
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0 15  282M   15 44.2M    0     0  88.7M      0  0:00:03 --:--:--  0:00:03 88.6M 92  282M   92  260M    0     0   173M      0  0:00:01  0:00:01 --:--:--  173M100  282M  100  282M    0     0   175M      0  0:00:01  0:00:01 --:--:--  175M
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0 44  282M   44  126M    0     0   144M      0  0:00:01 --:--:--  0:00:01  144M100  282M  100  282M    0     0   178M      0  0:00:01  0:00:01 --:--:--  178M
W0311 19:49:23.650000 12 torch/distributed/run.py:792] 
W0311 19:49:23.650000 12 torch/distributed/run.py:792] *****************************************
W0311 19:49:23.650000 12 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0311 19:49:23.650000 12 torch/distributed/run.py:792] *****************************************
2025-03-11 19:49:30 - ===== Input Parameters =====
2025-03-11 19:49:30 - {'alpha_values_pgd': '0.01',
 'attack_batch_size_pgd': 10,
 'attack_type': 'base_baseline',
 'batch_size': 8,
 'batch_size_surr': 16,
 'compute_fid': False,
 'decoder_model_path': 'decoder_model.pth',
 'finetune_batch_size': 16,
 'finetune_decoder': False,
 'finetune_epochs': 10,
 'finetune_lr': 0.0001,
 'finetune_pgd_alpha': 0.01,
 'finetune_pgd_steps': 200,
 'finetune_surrogate': False,
 'flip_key_type': 'none',
 'image_attack_size': 1000,
 'initial_channels': 64,
 'initial_channels_surr': 64,
 'key_type': 'none',
 'local_rank': 0,
 'lr_D': 0.0002,
 'lr_M_hat': 0.0002,
 'mask_switch_on': False,
 'max_delta': 0.05,
 'mode': 'train',
 'momentum_pgd': 0.9,
 'n_iterations': 15000,
 'num_conv_layers': 7,
 'num_conv_layers_surr': 5,
 'num_eval_samples': 1000,
 'num_pool_layers': 7,
 'num_pool_layers_surr': 5,
 'num_steps_pgd': 200,
 'plotting': False,
 'random_smooth': True,
 'random_smooth_std': 0.1,
 'random_smooth_type': 'both',
 'rank': 0,
 'resume_checkpoint': None,
 'run_eval': True,
 'saving_path': 'results',
 'seed_key': 2024,
 'self_trained': False,
 'self_trained_latent_dim': 128,
 'self_trained_model_path': 'generator.pth',
 'stylegan2_url': 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/paper-fig7c-training-set-sweeps/ffhq70k-paper256-ada.pkl',
 'surrogate_decoder_folder': None,
 'surrogate_training_only': False,
 'train_size': 100000,
 'watermarked_model_path': 'watermarked_model.pkl',
 'world_size': 4}
2025-03-11 19:49:30 - ============================

GPU(s) available: NVIDIA A100-SXM4-40GB
NVIDIA A100-SXM4-40GB
NVIDIA A100-SXM4-40GB
NVIDIA A100-SXM4-40GB
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:77 [0] NCCL INFO Bootstrap : Using eth0:10.42.64.225<0>
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:77 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:77 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:77 [0] NCCL INFO NET/Plugin: Using internal network plugin.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:77 [0] NCCL INFO cudaDriverVersion 12060
NCCL version 2.21.5+cuda12.4
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:77 [0] NCCL INFO Comm config Blocking set to 1
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:80 [3] NCCL INFO cudaDriverVersion 12060
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:80 [3] NCCL INFO Bootstrap : Using eth0:10.42.64.225<0>
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:80 [3] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:80 [3] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:80 [3] NCCL INFO NET/Plugin: Using internal network plugin.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:78 [1] NCCL INFO cudaDriverVersion 12060
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:78 [1] NCCL INFO Bootstrap : Using eth0:10.42.64.225<0>
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:80 [3] NCCL INFO Comm config Blocking set to 1
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:78 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:78 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:78 [1] NCCL INFO NET/Plugin: Using internal network plugin.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:79 [2] NCCL INFO cudaDriverVersion 12060
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:78 [1] NCCL INFO Comm config Blocking set to 1
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:79 [2] NCCL INFO Bootstrap : Using eth0:10.42.64.225<0>
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:79 [2] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:79 [2] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:79 [2] NCCL INFO NET/Plugin: Using internal network plugin.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:79 [2] NCCL INFO Comm config Blocking set to 1
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO NET/Socket : Using [0]eth0:10.42.64.225<0>
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Using non-device net plugin version 0
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Using network Socket
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO NET/Socket : Using [0]eth0:10.42.64.225<0>
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Using non-device net plugin version 0
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Using network Socket
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO NET/Socket : Using [0]eth0:10.42.64.225<0>
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Using non-device net plugin version 0
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Using network Socket
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO NET/Socket : Using [0]eth0:10.42.64.225<0>
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Using non-device net plugin version 0
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Using network Socket
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO ncclCommInitRank comm 0x5af2a09a5d40 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 7000 commId 0xfc230b0f1e1d0e53 - Init START
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO ncclCommInitRank comm 0x577004599980 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 9000 commId 0xfc230b0f1e1d0e53 - Init START
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO ncclCommInitRank comm 0x6304621c72d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 6000 commId 0xfc230b0f1e1d0e53 - Init START
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO ncclCommInitRank comm 0x5b0398c15f10 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8000 commId 0xfc230b0f1e1d0e53 - Init START
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO NVLS multicast support is not available on dev 3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO NVLS multicast support is not available on dev 0
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO NVLS multicast support is not available on dev 2
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO NVLS multicast support is not available on dev 1
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO comm 0x6304621c72d0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO comm 0x577004599980 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO comm 0x5af2a09a5d40 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO comm 0x5b0398c15f10 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 00/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 01/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 02/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 03/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 04/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 05/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 06/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 07/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 08/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->2 [5] -1/-1/-1->3->2 [6] -1/-1/-1->3->2 [7] -1/-1/-1->3->2 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] -1/-1/-1->3->2 [11] -1/-1/-1->3->2 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->2 [17] -1/-1/-1->3->2 [18] -1/-1/-1->3->2 [19] -1/-1/-1->3->2 [20] -1/-1/-1->3->2 [21] -1/-1/-1->3->2 [22] -1/-1/-1->3->2 [23] -1/-1/-1->3->2
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 09/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO P2P Chunksize set to 524288
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 10/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO P2P Chunksize set to 524288
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO P2P Chunksize set to 524288
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 11/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 12/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 13/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 14/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 15/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 16/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 17/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 18/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 19/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 20/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 21/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 22/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 23/24 :    0   1   2   3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO P2P Chunksize set to 524288
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 01/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 02/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 04/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 05/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 07/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 08/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 08/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 09/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 09/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 10/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 11/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 11/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 13/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 13/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 14/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 14/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 09/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 15/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 16/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 16/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 11/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 17/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 17/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 17/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 13/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 19/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 19/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 20/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 20/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 20/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 15/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 21/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 21/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 16/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 22/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 22/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 17/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 23/0 : 3[3] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 23/0 : 1[1] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Channel 23/0 : 0[0] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 19/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 21/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 22/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 23/0 : 2[2] -> 3[3] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Connected all rings
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Connected all rings
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Connected all rings
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Connected all rings
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 08/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 09/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 12/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 14/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 15/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 16/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 18/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 08/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 20/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 10/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 21/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 16/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 12/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 13/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 22/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 18/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 14/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 19/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 16/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 21/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 22/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 18/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 19/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 20/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 22/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO Connected all trees
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO Connected all trees
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO Connected all trees
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO Connected all trees
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:112 [2] NCCL INFO ncclCommInitRank comm 0x5b0398c15f10 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8000 commId 0xfc230b0f1e1d0e53 - Init COMPLETE
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:109 [0] NCCL INFO ncclCommInitRank comm 0x6304621c72d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 6000 commId 0xfc230b0f1e1d0e53 - Init COMPLETE
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:110 [3] NCCL INFO ncclCommInitRank comm 0x577004599980 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 9000 commId 0xfc230b0f1e1d0e53 - Init COMPLETE
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:111 [1] NCCL INFO ncclCommInitRank comm 0x5af2a09a5d40 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 7000 commId 0xfc230b0f1e1d0e53 - Init COMPLETE
2025-03-11 19:49:34 - World size: 4
2025-03-11 19:49:34 - max_delta = 0.05
2025-03-11 19:49:34 - time_string = 20250311194930239004
2025-03-11 19:49:34 - mask_switch_on = False
2025-03-11 19:49:34 - key_type = none
2025-03-11 19:49:34 - flip_key_type = none
2025-03-11 19:49:34 - Random smoothing enabled with type 'both' and std 0.1
2025-03-11 19:49:34 - Decoder structure:
FlexibleDecoder(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): ReLU(inplace=True)
    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (12): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (15): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (16): ReLU(inplace=True)
    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (18): Conv2d(2048, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (19): ReLU(inplace=True)
    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (21): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (classifier): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=4096, out_features=1, bias=True)
    (2): Sigmoid()
  )
)
2025-03-11 19:49:34 - Decoder parameters: 100652673
/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Setting up PyTorch plugin "bias_act_plugin"... Setting up PyTorch plugin "bias_act_plugin"... Setting up PyTorch plugin "bias_act_plugin"... Setting up PyTorch plugin "bias_act_plugin"... Done.
Done.
Done.
Done.
/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Setting up PyTorch plugin "upfirdn2d_plugin"... Setting up PyTorch plugin "upfirdn2d_plugin"... Setting up PyTorch plugin "upfirdn2d_plugin"... Setting up PyTorch plugin "upfirdn2d_plugin"... Done.
Done.
Done.
Done.
2025-03-11 19:50:30 - Train Iteration 1: loss: 1.0000, d_k_M range: [0.5010, 0.5013], d_k_M_hat range: [0.5010, 0.5013]
2025-03-11 19:50:30 - Train Iteration 2: loss: 1.0000, d_k_M range: [0.5026, 0.5028], d_k_M_hat range: [0.5026, 0.5028]
2025-03-11 19:50:31 - Train Iteration 3: loss: 0.9999, d_k_M range: [0.5243, 0.5329], d_k_M_hat range: [0.5244, 0.5331]
2025-03-11 19:50:31 - Train Iteration 4: loss: 0.9994, d_k_M range: [0.5480, 0.5590], d_k_M_hat range: [0.5483, 0.5596]
2025-03-11 19:50:31 - Train Iteration 5: loss: 0.9951, d_k_M range: [0.6557, 0.6796], d_k_M_hat range: [0.6584, 0.6827]
2025-03-11 19:50:32 - Train Iteration 6: loss: 0.9958, d_k_M range: [0.9182, 0.9535], d_k_M_hat range: [0.9209, 0.9556]
2025-03-11 19:50:32 - Train Iteration 7: loss: 0.9946, d_k_M range: [0.5785, 0.6179], d_k_M_hat range: [0.5812, 0.6220]
2025-03-11 19:50:33 - Train Iteration 8: loss: 0.9892, d_k_M range: [0.7952, 0.8529], d_k_M_hat range: [0.8056, 0.8610]
2025-03-11 19:50:33 - Train Iteration 9: loss: 0.9829, d_k_M range: [0.7055, 0.7764], d_k_M_hat range: [0.7185, 0.7882]
2025-03-11 19:50:33 - Train Iteration 10: loss: 0.9791, d_k_M range: [0.8269, 0.9222], d_k_M_hat range: [0.8428, 0.9349]
2025-03-11 19:50:34 - Train Iteration 11: loss: 0.9994, d_k_M range: [0.4879, 0.5161], d_k_M_hat range: [0.4882, 0.5205]
2025-03-11 19:50:34 - Train Iteration 12: loss: 0.9875, d_k_M range: [0.5458, 0.6004], d_k_M_hat range: [0.5520, 0.6082]
2025-03-11 19:50:35 - Train Iteration 13: loss: 0.9721, d_k_M range: [0.7187, 0.8426], d_k_M_hat range: [0.7409, 0.8596]
2025-03-11 19:50:35 - Train Iteration 14: loss: 0.9727, d_k_M range: [0.5772, 0.8237], d_k_M_hat range: [0.5943, 0.8441]
2025-03-11 19:50:36 - Train Iteration 15: loss: 0.9827, d_k_M range: [0.6034, 0.8236], d_k_M_hat range: [0.6121, 0.8426]
2025-03-11 19:50:36 - Train Iteration 16: loss: 0.9504, d_k_M range: [0.6396, 0.8370], d_k_M_hat range: [0.6877, 0.8621]
2025-03-11 19:50:37 - Train Iteration 17: loss: 0.9968, d_k_M range: [0.4539, 0.9439], d_k_M_hat range: [0.4555, 0.9619]
2025-03-11 19:50:37 - Train Iteration 18: loss: 0.9970, d_k_M range: [0.9834, 0.9956], d_k_M_hat range: [0.9879, 0.9971]
2025-03-11 19:50:37 - Train Iteration 19: loss: 0.9923, d_k_M range: [0.8850, 0.9874], d_k_M_hat range: [0.9115, 0.9913]
2025-03-11 19:50:38 - Train Iteration 20: loss: 0.9599, d_k_M range: [0.6122, 0.8544], d_k_M_hat range: [0.6373, 0.8746]
2025-03-11 19:50:38 - Train Iteration 21: loss: 0.9835, d_k_M range: [0.4533, 0.5977], d_k_M_hat range: [0.4616, 0.6276]
2025-03-11 19:50:39 - Train Iteration 22: loss: 0.9956, d_k_M range: [0.8194, 0.9932], d_k_M_hat range: [0.8505, 0.9954]
2025-03-11 19:50:39 - Train Iteration 23: loss: 0.9732, d_k_M range: [0.7976, 0.9333], d_k_M_hat range: [0.8293, 0.9468]
2025-03-11 19:50:40 - Train Iteration 24: loss: 0.9588, d_k_M range: [0.4962, 0.6298], d_k_M_hat range: [0.5170, 0.6561]
2025-03-11 19:50:40 - Train Iteration 25: loss: 0.9504, d_k_M range: [0.6256, 0.8175], d_k_M_hat range: [0.6749, 0.8521]
2025-03-11 19:50:40 - Train Iteration 26: loss: 0.9756, d_k_M range: [0.4085, 0.6223], d_k_M_hat range: [0.4207, 0.6676]
2025-03-11 19:50:41 - Train Iteration 27: loss: 0.9965, d_k_M range: [0.9128, 0.9958], d_k_M_hat range: [0.9443, 0.9975]
2025-03-11 19:50:41 - Train Iteration 28: loss: 0.9932, d_k_M range: [0.9148, 0.9905], d_k_M_hat range: [0.9368, 0.9939]
2025-03-11 19:50:42 - Train Iteration 29: loss: 0.9670, d_k_M range: [0.8696, 0.9399], d_k_M_hat range: [0.8996, 0.9567]
2025-03-11 19:50:42 - Train Iteration 30: loss: 0.9528, d_k_M range: [0.4788, 0.7262], d_k_M_hat range: [0.5139, 0.7567]
2025-03-11 19:50:42 - Train Iteration 31: loss: 0.9608, d_k_M range: [0.6249, 0.8619], d_k_M_hat range: [0.6592, 0.8849]
2025-03-11 19:50:43 - Train Iteration 32: loss: 0.9331, d_k_M range: [0.5019, 0.7263], d_k_M_hat range: [0.5392, 0.7618]
2025-03-11 19:50:43 - Train Iteration 33: loss: 0.9359, d_k_M range: [0.4716, 0.8048], d_k_M_hat range: [0.5444, 0.8479]
2025-03-11 19:50:44 - Train Iteration 34: loss: 0.9717, d_k_M range: [0.3079, 0.4156], d_k_M_hat range: [0.3221, 0.4706]
2025-03-11 19:50:44 - Train Iteration 35: loss: 0.9536, d_k_M range: [0.5577, 0.8960], d_k_M_hat range: [0.6153, 0.9195]
2025-03-11 19:50:44 - Train Iteration 36: loss: 0.9633, d_k_M range: [0.3145, 0.5221], d_k_M_hat range: [0.3330, 0.5685]
2025-03-11 19:50:45 - Train Iteration 37: loss: 0.9228, d_k_M range: [0.5491, 0.8086], d_k_M_hat range: [0.6031, 0.8479]
2025-03-11 19:50:45 - Train Iteration 38: loss: 0.9051, d_k_M range: [0.4001, 0.6614], d_k_M_hat range: [0.4553, 0.7225]
2025-03-11 19:50:46 - Train Iteration 39: loss: 0.9636, d_k_M range: [0.4902, 0.9280], d_k_M_hat range: [0.5841, 0.9464]
2025-03-11 19:50:46 - Train Iteration 40: loss: 0.9800, d_k_M range: [0.1554, 0.2448], d_k_M_hat range: [0.1722, 0.2813]
2025-03-11 19:50:46 - Train Iteration 41: loss: 0.9100, d_k_M range: [0.2726, 0.6762], d_k_M_hat range: [0.3186, 0.7403]
2025-03-11 19:50:47 - Train Iteration 42: loss: 0.9744, d_k_M range: [0.8161, 0.9558], d_k_M_hat range: [0.8633, 0.9687]
2025-03-11 19:50:47 - Train Iteration 43: loss: 0.9368, d_k_M range: [0.6009, 0.8134], d_k_M_hat range: [0.6506, 0.8465]
2025-03-11 19:50:48 - Train Iteration 44: loss: 0.9161, d_k_M range: [0.4900, 0.7076], d_k_M_hat range: [0.5429, 0.7527]
2025-03-11 19:50:48 - Train Iteration 45: loss: 0.8717, d_k_M range: [0.2974, 0.6651], d_k_M_hat range: [0.3665, 0.7364]
2025-03-11 19:50:48 - Train Iteration 46: loss: 0.9057, d_k_M range: [0.1347, 0.4649], d_k_M_hat range: [0.1830, 0.5615]
2025-03-11 19:50:49 - Train Iteration 47: loss: 0.9870, d_k_M range: [0.6708, 0.9835], d_k_M_hat range: [0.7587, 0.9900]
2025-03-11 19:50:49 - Train Iteration 48: loss: 0.9248, d_k_M range: [0.5681, 0.8375], d_k_M_hat range: [0.6487, 0.8759]
2025-03-11 19:50:49 - Train Iteration 49: loss: 0.8968, d_k_M range: [0.1818, 0.5139], d_k_M_hat range: [0.2348, 0.5862]
2025-03-11 19:50:50 - Train Iteration 50: loss: 0.9143, d_k_M range: [0.3610, 0.8316], d_k_M_hat range: [0.4452, 0.8754]
2025-03-11 19:50:50 - Train Iteration 51: loss: 0.8623, d_k_M range: [0.2303, 0.4956], d_k_M_hat range: [0.3214, 0.5870]
2025-03-11 19:50:50 - Train Iteration 52: loss: 0.9575, d_k_M range: [0.0557, 0.3425], d_k_M_hat range: [0.0772, 0.4758]
2025-03-11 19:50:51 - Train Iteration 53: loss: 0.9496, d_k_M range: [0.2981, 0.9229], d_k_M_hat range: [0.3931, 0.9484]
2025-03-11 19:50:51 - Train Iteration 54: loss: 0.9957, d_k_M range: [0.0494, 0.2056], d_k_M_hat range: [0.0516, 0.2948]
2025-03-11 19:50:52 - Train Iteration 55: loss: 0.8685, d_k_M range: [0.2413, 0.4691], d_k_M_hat range: [0.3269, 0.5606]
2025-03-11 19:50:52 - Train Iteration 56: loss: 0.8870, d_k_M range: [0.2252, 0.8168], d_k_M_hat range: [0.3147, 0.8750]
2025-03-11 19:50:53 - Train Iteration 57: loss: 0.8769, d_k_M range: [0.2756, 0.6917], d_k_M_hat range: [0.3720, 0.7553]
2025-03-11 19:50:53 - Train Iteration 58: loss: 0.8485, d_k_M range: [0.1993, 0.6691], d_k_M_hat range: [0.2782, 0.7737]
2025-03-11 19:50:53 - Train Iteration 59: loss: 0.8639, d_k_M range: [0.1356, 0.6815], d_k_M_hat range: [0.2062, 0.7674]
2025-03-11 19:50:54 - Train Iteration 60: loss: 0.9402, d_k_M range: [0.5533, 0.9209], d_k_M_hat range: [0.6678, 0.9513]
2025-03-11 19:50:54 - Train Iteration 61: loss: 0.8942, d_k_M range: [0.2491, 0.7970], d_k_M_hat range: [0.3297, 0.8514]
2025-03-11 19:50:54 - Train Iteration 62: loss: 0.9207, d_k_M range: [0.1076, 0.3744], d_k_M_hat range: [0.1481, 0.4697]
2025-03-11 19:50:55 - Train Iteration 63: loss: 0.9448, d_k_M range: [0.5668, 0.9247], d_k_M_hat range: [0.6559, 0.9527]
2025-03-11 19:50:55 - Train Iteration 64: loss: 0.8749, d_k_M range: [0.2234, 0.6908], d_k_M_hat range: [0.3034, 0.7580]
2025-03-11 19:50:56 - Train Iteration 65: loss: 0.8958, d_k_M range: [0.2352, 0.4814], d_k_M_hat range: [0.3072, 0.5761]
2025-03-11 19:50:56 - Train Iteration 66: loss: 0.8140, d_k_M range: [0.1858, 0.5769], d_k_M_hat range: [0.2963, 0.6885]
2025-03-11 19:50:57 - Train Iteration 67: loss: 0.9577, d_k_M range: [0.7500, 0.9508], d_k_M_hat range: [0.8498, 0.9722]
2025-03-11 19:50:57 - Train Iteration 68: loss: 0.8168, d_k_M range: [0.1845, 0.4912], d_k_M_hat range: [0.2974, 0.6171]
2025-03-11 19:50:58 - Train Iteration 69: loss: 0.8193, d_k_M range: [0.1883, 0.7357], d_k_M_hat range: [0.2880, 0.8319]
2025-03-11 19:50:58 - Train Iteration 70: loss: 0.9595, d_k_M range: [0.4980, 0.9581], d_k_M_hat range: [0.6592, 0.9786]
2025-03-11 19:50:59 - Train Iteration 71: loss: 0.8288, d_k_M range: [0.3921, 0.7504], d_k_M_hat range: [0.5330, 0.8400]
2025-03-11 19:50:59 - Train Iteration 72: loss: 0.9817, d_k_M range: [0.0413, 0.2861], d_k_M_hat range: [0.0504, 0.3895]
2025-03-11 19:51:00 - Train Iteration 73: loss: 0.8456, d_k_M range: [0.3745, 0.7543], d_k_M_hat range: [0.4882, 0.8421]
2025-03-11 19:51:00 - Train Iteration 74: loss: 0.9226, d_k_M range: [0.0825, 0.4348], d_k_M_hat range: [0.1219, 0.5250]
2025-03-11 19:51:00 - Train Iteration 75: loss: 0.8851, d_k_M range: [0.1506, 0.7442], d_k_M_hat range: [0.2098, 0.8333]
2025-03-11 19:51:01 - Train Iteration 76: loss: 0.9379, d_k_M range: [0.5084, 0.9363], d_k_M_hat range: [0.6419, 0.9678]
2025-03-11 19:51:01 - Train Iteration 77: loss: 0.8586, d_k_M range: [0.1086, 0.4605], d_k_M_hat range: [0.1861, 0.5746]
2025-03-11 19:51:02 - Train Iteration 78: loss: 0.8039, d_k_M range: [0.1805, 0.6910], d_k_M_hat range: [0.2978, 0.7988]
2025-03-11 19:51:02 - Train Iteration 79: loss: 0.9335, d_k_M range: [0.4745, 0.9250], d_k_M_hat range: [0.5953, 0.9588]
2025-03-11 19:51:02 - Train Iteration 80: loss: 0.9372, d_k_M range: [0.0542, 0.4024], d_k_M_hat range: [0.0861, 0.5086]
2025-03-11 19:51:03 - Train Iteration 81: loss: 0.9479, d_k_M range: [0.5105, 0.9344], d_k_M_hat range: [0.5992, 0.9608]
2025-03-11 19:51:03 - Train Iteration 82: loss: 0.8512, d_k_M range: [0.3846, 0.5799], d_k_M_hat range: [0.4669, 0.6650]
2025-03-11 19:51:04 - Train Iteration 83: loss: 0.8489, d_k_M range: [0.1885, 0.6924], d_k_M_hat range: [0.2811, 0.7844]
2025-03-11 19:51:04 - Train Iteration 84: loss: 0.8181, d_k_M range: [0.2716, 0.7742], d_k_M_hat range: [0.4003, 0.8697]
2025-03-11 19:51:05 - Train Iteration 85: loss: 0.8542, d_k_M range: [0.2116, 0.8078], d_k_M_hat range: [0.3022, 0.8835]
2025-03-11 19:51:05 - Train Iteration 86: loss: 0.8452, d_k_M range: [0.3034, 0.8175], d_k_M_hat range: [0.4140, 0.8982]
2025-03-11 19:51:05 - Train Iteration 87: loss: 0.8744, d_k_M range: [0.0935, 0.4161], d_k_M_hat range: [0.1584, 0.5226]
2025-03-11 19:51:06 - Train Iteration 88: loss: 0.8419, d_k_M range: [0.2369, 0.6806], d_k_M_hat range: [0.3550, 0.7823]
2025-03-11 19:51:06 - Train Iteration 89: loss: 0.8697, d_k_M range: [0.0754, 0.6125], d_k_M_hat range: [0.1429, 0.7376]
2025-03-11 19:51:07 - Train Iteration 90: loss: 0.8865, d_k_M range: [0.3326, 0.8713], d_k_M_hat range: [0.4619, 0.9298]
2025-03-11 19:51:07 - Train Iteration 91: loss: 0.8224, d_k_M range: [0.3251, 0.6293], d_k_M_hat range: [0.4235, 0.7233]
2025-03-11 19:51:07 - Train Iteration 92: loss: 0.8452, d_k_M range: [0.4103, 0.7936], d_k_M_hat range: [0.5297, 0.8743]
2025-03-11 19:51:08 - Train Iteration 93: loss: 0.8851, d_k_M range: [0.0791, 0.5608], d_k_M_hat range: [0.1383, 0.6901]
2025-03-11 19:51:08 - Train Iteration 94: loss: 0.8871, d_k_M range: [0.5094, 0.8664], d_k_M_hat range: [0.6100, 0.9245]
2025-03-11 19:51:09 - Train Iteration 95: loss: 0.8707, d_k_M range: [0.2230, 0.8101], d_k_M_hat range: [0.3192, 0.8856]
2025-03-11 19:51:09 - Train Iteration 96: loss: 0.8239, d_k_M range: [0.3156, 0.5863], d_k_M_hat range: [0.4079, 0.6924]
2025-03-11 19:51:09 - Train Iteration 97: loss: 0.7987, d_k_M range: [0.3516, 0.7373], d_k_M_hat range: [0.4662, 0.8436]
2025-03-11 19:51:10 - Train Iteration 98: loss: 0.8386, d_k_M range: [0.0960, 0.6519], d_k_M_hat range: [0.1802, 0.7619]
2025-03-11 19:51:10 - Train Iteration 99: loss: 0.9291, d_k_M range: [0.5439, 0.9292], d_k_M_hat range: [0.6475, 0.9653]
2025-03-11 19:51:10 - Train Iteration 100: loss: 0.8378, d_k_M range: [0.2349, 0.6350], d_k_M_hat range: [0.3387, 0.7197]
2025-03-11 19:51:11 - Train Iteration 101: loss: 0.8968, d_k_M range: [0.0643, 0.5006], d_k_M_hat range: [0.1219, 0.6252]
2025-03-11 19:51:11 - Train Iteration 102: loss: 0.8456, d_k_M range: [0.0965, 0.6328], d_k_M_hat range: [0.1769, 0.7373]
2025-03-11 19:51:11 - Train Iteration 103: loss: 0.8101, d_k_M range: [0.2476, 0.5856], d_k_M_hat range: [0.3772, 0.6855]
2025-03-11 19:51:12 - Train Iteration 104: loss: 0.9130, d_k_M range: [0.3346, 0.9107], d_k_M_hat range: [0.4715, 0.9552]
2025-03-11 19:51:12 - Train Iteration 105: loss: 0.7956, d_k_M range: [0.1393, 0.6340], d_k_M_hat range: [0.2657, 0.7569]
2025-03-11 19:51:13 - Train Iteration 106: loss: 0.8839, d_k_M range: [0.5010, 0.8813], d_k_M_hat range: [0.6359, 0.9411]
2025-03-11 19:51:13 - Train Iteration 107: loss: 0.8721, d_k_M range: [0.0706, 0.6013], d_k_M_hat range: [0.1368, 0.7084]
2025-03-11 19:51:13 - Train Iteration 108: loss: 0.9385, d_k_M range: [0.1731, 0.9299], d_k_M_hat range: [0.2976, 0.9611]
2025-03-11 19:51:14 - Train Iteration 109: loss: 0.7865, d_k_M range: [0.1191, 0.5824], d_k_M_hat range: [0.2490, 0.7043]
2025-03-11 19:51:14 - Train Iteration 110: loss: 0.7894, d_k_M range: [0.1953, 0.6769], d_k_M_hat range: [0.3156, 0.7925]
2025-03-11 19:51:15 - Train Iteration 111: loss: 0.9848, d_k_M range: [0.6412, 0.9856], d_k_M_hat range: [0.7749, 0.9932]
2025-03-11 19:51:15 - Train Iteration 112: loss: 0.9676, d_k_M range: [0.3185, 0.9680], d_k_M_hat range: [0.4263, 0.9843]
2025-03-11 19:51:15 - Train Iteration 113: loss: 0.8289, d_k_M range: [0.1115, 0.7180], d_k_M_hat range: [0.2011, 0.8212]
2025-03-11 19:51:16 - Train Iteration 114: loss: 0.8124, d_k_M range: [0.3141, 0.7942], d_k_M_hat range: [0.4448, 0.8929]
2025-03-11 19:51:16 - Train Iteration 115: loss: 0.9004, d_k_M range: [0.0536, 0.4501], d_k_M_hat range: [0.1047, 0.5822]
2025-03-11 19:51:17 - Train Iteration 116: loss: 0.8559, d_k_M range: [0.4546, 0.8610], d_k_M_hat range: [0.5925, 0.9359]
2025-03-11 19:51:17 - Train Iteration 117: loss: 0.9810, d_k_M range: [0.0137, 0.1945], d_k_M_hat range: [0.0232, 0.2833]
2025-03-11 19:51:17 - Train Iteration 118: loss: 0.8421, d_k_M range: [0.1213, 0.5416], d_k_M_hat range: [0.2037, 0.6451]
2025-03-11 19:51:18 - Train Iteration 119: loss: 0.8463, d_k_M range: [0.2711, 0.7242], d_k_M_hat range: [0.3881, 0.8237]
2025-03-11 19:51:18 - Train Iteration 120: loss: 0.8406, d_k_M range: [0.4222, 0.6532], d_k_M_hat range: [0.5112, 0.7486]
2025-03-11 19:51:19 - Train Iteration 121: loss: 0.8065, d_k_M range: [0.2553, 0.7436], d_k_M_hat range: [0.3587, 0.8533]
2025-03-11 19:51:19 - Train Iteration 122: loss: 0.8198, d_k_M range: [0.1661, 0.7494], d_k_M_hat range: [0.2919, 0.8440]
2025-03-11 19:51:20 - Train Iteration 123: loss: 0.7665, d_k_M range: [0.2413, 0.6912], d_k_M_hat range: [0.3664, 0.8260]
2025-03-11 19:51:20 - Train Iteration 124: loss: 0.7747, d_k_M range: [0.1180, 0.6223], d_k_M_hat range: [0.2387, 0.7630]
2025-03-11 19:51:21 - Train Iteration 125: loss: 0.8575, d_k_M range: [0.0498, 0.4214], d_k_M_hat range: [0.1238, 0.5852]
2025-03-11 19:51:21 - Train Iteration 126: loss: 0.8416, d_k_M range: [0.3504, 0.8663], d_k_M_hat range: [0.5263, 0.9489]
2025-03-11 19:51:21 - Train Iteration 127: loss: 0.9022, d_k_M range: [0.2046, 0.9151], d_k_M_hat range: [0.3241, 0.9652]
2025-03-11 19:51:22 - Train Iteration 128: loss: 0.7813, d_k_M range: [0.3046, 0.6617], d_k_M_hat range: [0.4407, 0.7778]
2025-03-11 19:51:22 - Train Iteration 129: loss: 0.8102, d_k_M range: [0.1292, 0.7259], d_k_M_hat range: [0.2291, 0.8496]
2025-03-11 19:51:23 - Train Iteration 130: loss: 0.7988, d_k_M range: [0.1583, 0.6700], d_k_M_hat range: [0.2645, 0.7909]
2025-03-11 19:51:23 - Train Iteration 131: loss: 0.7952, d_k_M range: [0.3187, 0.7395], d_k_M_hat range: [0.4269, 0.8648]
2025-03-11 19:51:23 - Train Iteration 132: loss: 0.7730, d_k_M range: [0.1868, 0.7104], d_k_M_hat range: [0.3463, 0.8312]
2025-03-11 19:51:24 - Train Iteration 133: loss: 0.9465, d_k_M range: [0.0283, 0.7430], d_k_M_hat range: [0.0554, 0.8733]
2025-03-11 19:51:24 - Train Iteration 134: loss: 0.8132, d_k_M range: [0.3732, 0.8104], d_k_M_hat range: [0.4714, 0.9116]
2025-03-11 19:51:25 - Train Iteration 135: loss: 0.8132, d_k_M range: [0.1806, 0.7512], d_k_M_hat range: [0.3131, 0.8608]
2025-03-11 19:51:25 - Train Iteration 136: loss: 0.7544, d_k_M range: [0.1927, 0.6764], d_k_M_hat range: [0.3242, 0.8126]
2025-03-11 19:51:25 - Train Iteration 137: loss: 0.7844, d_k_M range: [0.1919, 0.6803], d_k_M_hat range: [0.3343, 0.8095]
2025-03-11 19:51:26 - Train Iteration 138: loss: 0.7371, d_k_M range: [0.1532, 0.6961], d_k_M_hat range: [0.3463, 0.8376]
2025-03-11 19:51:26 - Train Iteration 139: loss: 0.9528, d_k_M range: [0.2134, 0.9646], d_k_M_hat range: [0.4315, 0.9885]
2025-03-11 19:51:27 - Train Iteration 140: loss: 0.9644, d_k_M range: [0.0120, 0.1760], d_k_M_hat range: [0.0326, 0.3150]
2025-03-11 19:51:27 - Train Iteration 141: loss: 0.9494, d_k_M range: [0.0189, 0.5399], d_k_M_hat range: [0.0445, 0.6752]
2025-03-11 19:51:27 - Train Iteration 142: loss: 0.8867, d_k_M range: [0.0634, 0.6054], d_k_M_hat range: [0.1217, 0.7453]
2025-03-11 19:51:28 - Train Iteration 143: loss: 0.8362, d_k_M range: [0.3537, 0.8414], d_k_M_hat range: [0.4809, 0.9269]
2025-03-11 19:51:28 - Train Iteration 144: loss: 0.7768, d_k_M range: [0.2737, 0.5024], d_k_M_hat range: [0.3935, 0.6426]
2025-03-11 19:51:29 - Train Iteration 145: loss: 0.8157, d_k_M range: [0.0881, 0.6283], d_k_M_hat range: [0.1849, 0.7836]
2025-03-11 19:51:29 - Train Iteration 146: loss: 0.7610, d_k_M range: [0.2689, 0.6473], d_k_M_hat range: [0.3995, 0.7749]
2025-03-11 19:51:29 - Train Iteration 147: loss: 0.7927, d_k_M range: [0.2045, 0.7885], d_k_M_hat range: [0.3419, 0.8982]
2025-03-11 19:51:30 - Train Iteration 148: loss: 0.9318, d_k_M range: [0.0358, 0.2782], d_k_M_hat range: [0.0705, 0.3961]
2025-03-11 19:51:30 - Train Iteration 149: loss: 0.8022, d_k_M range: [0.2427, 0.6205], d_k_M_hat range: [0.3673, 0.7580]
2025-03-11 19:51:31 - Train Iteration 150: loss: 0.8286, d_k_M range: [0.3489, 0.8296], d_k_M_hat range: [0.4831, 0.9193]
2025-03-11 19:51:31 - Train Iteration 151: loss: 0.8080, d_k_M range: [0.1952, 0.3675], d_k_M_hat range: [0.3091, 0.4995]
2025-03-11 19:51:31 - Train Iteration 152: loss: 0.7988, d_k_M range: [0.2270, 0.7259], d_k_M_hat range: [0.3482, 0.8322]
2025-03-11 19:51:32 - Train Iteration 153: loss: 0.8035, d_k_M range: [0.2613, 0.6369], d_k_M_hat range: [0.3698, 0.7654]
2025-03-11 19:51:32 - Train Iteration 154: loss: 0.7968, d_k_M range: [0.4003, 0.7843], d_k_M_hat range: [0.5119, 0.8916]
2025-03-11 19:51:32 - Train Iteration 155: loss: 0.7861, d_k_M range: [0.1047, 0.6021], d_k_M_hat range: [0.2181, 0.7351]
2025-03-11 19:51:33 - Train Iteration 156: loss: 0.8076, d_k_M range: [0.0967, 0.7132], d_k_M_hat range: [0.1981, 0.8484]
2025-03-11 19:51:33 - Train Iteration 157: loss: 0.8794, d_k_M range: [0.3657, 0.9041], d_k_M_hat range: [0.4855, 0.9663]
2025-03-11 19:51:34 - Train Iteration 158: loss: 0.8046, d_k_M range: [0.3135, 0.6028], d_k_M_hat range: [0.4262, 0.7169]
2025-03-11 19:51:34 - Train Iteration 159: loss: 0.7845, d_k_M range: [0.3362, 0.6430], d_k_M_hat range: [0.4663, 0.7602]
2025-03-11 19:51:34 - Train Iteration 160: loss: 0.9306, d_k_M range: [0.3168, 0.9388], d_k_M_hat range: [0.4689, 0.9741]
2025-03-11 19:51:35 - Train Iteration 161: loss: 0.7888, d_k_M range: [0.0762, 0.6333], d_k_M_hat range: [0.1962, 0.7576]
2025-03-11 19:51:35 - Train Iteration 162: loss: 0.7793, d_k_M range: [0.0923, 0.6702], d_k_M_hat range: [0.2095, 0.7939]
2025-03-11 19:51:36 - Train Iteration 163: loss: 0.7915, d_k_M range: [0.3112, 0.5866], d_k_M_hat range: [0.4215, 0.7116]
2025-03-11 19:51:36 - Train Iteration 164: loss: 0.7774, d_k_M range: [0.2130, 0.7785], d_k_M_hat range: [0.3616, 0.8968]
2025-03-11 19:51:36 - Train Iteration 165: loss: 0.8100, d_k_M range: [0.0914, 0.5089], d_k_M_hat range: [0.2040, 0.6363]
2025-03-11 19:51:37 - Train Iteration 166: loss: 0.7937, d_k_M range: [0.1472, 0.7167], d_k_M_hat range: [0.2805, 0.8360]
2025-03-11 19:51:37 - Train Iteration 167: loss: 0.7866, d_k_M range: [0.3390, 0.7073], d_k_M_hat range: [0.4550, 0.8276]
2025-03-11 19:51:38 - Train Iteration 168: loss: 0.7724, d_k_M range: [0.2569, 0.5375], d_k_M_hat range: [0.3890, 0.6748]
2025-03-11 19:51:38 - Train Iteration 169: loss: 0.7737, d_k_M range: [0.1027, 0.6376], d_k_M_hat range: [0.2231, 0.7793]
2025-03-11 19:51:38 - Train Iteration 170: loss: 0.8098, d_k_M range: [0.0904, 0.7601], d_k_M_hat range: [0.1905, 0.8949]
2025-03-11 19:51:39 - Train Iteration 171: loss: 0.9680, d_k_M range: [0.5000, 0.9768], d_k_M_hat range: [0.6347, 0.9929]
2025-03-11 19:51:39 - Train Iteration 172: loss: 0.9845, d_k_M range: [0.3474, 0.9878], d_k_M_hat range: [0.4843, 0.9956]
2025-03-11 19:51:40 - Train Iteration 173: loss: 0.7561, d_k_M range: [0.3207, 0.7204], d_k_M_hat range: [0.4649, 0.8508]
2025-03-11 19:51:40 - Train Iteration 174: loss: 0.7989, d_k_M range: [0.0592, 0.3075], d_k_M_hat range: [0.1671, 0.4485]
2025-03-11 19:51:41 - Train Iteration 175: loss: 0.8045, d_k_M range: [0.2611, 0.7999], d_k_M_hat range: [0.3841, 0.9030]
2025-03-11 19:51:41 - Train Iteration 176: loss: 0.7900, d_k_M range: [0.2149, 0.6393], d_k_M_hat range: [0.3341, 0.7524]
2025-03-11 19:51:41 - Train Iteration 177: loss: 0.7783, d_k_M range: [0.4621, 0.6925], d_k_M_hat range: [0.5929, 0.8173]
2025-03-11 19:51:42 - Train Iteration 178: loss: 0.7944, d_k_M range: [0.1305, 0.7589], d_k_M_hat range: [0.2392, 0.8763]
2025-03-11 19:51:42 - Train Iteration 179: loss: 0.8817, d_k_M range: [0.0408, 0.8305], d_k_M_hat range: [0.1018, 0.9186]
2025-03-11 19:51:43 - Train Iteration 180: loss: 0.8911, d_k_M range: [0.2411, 0.8971], d_k_M_hat range: [0.3823, 0.9531]
2025-03-11 19:51:43 - Train Iteration 181: loss: 0.7973, d_k_M range: [0.1804, 0.7705], d_k_M_hat range: [0.3124, 0.8776]
2025-03-11 19:51:43 - Train Iteration 182: loss: 0.8030, d_k_M range: [0.2325, 0.5919], d_k_M_hat range: [0.3488, 0.7157]
2025-03-11 19:51:44 - Train Iteration 183: loss: 0.7918, d_k_M range: [0.3544, 0.6911], d_k_M_hat range: [0.4771, 0.8013]
2025-03-11 19:51:44 - Train Iteration 184: loss: 0.8644, d_k_M range: [0.2945, 0.8809], d_k_M_hat range: [0.4189, 0.9512]
2025-03-11 19:51:45 - Train Iteration 185: loss: 0.7971, d_k_M range: [0.1622, 0.5817], d_k_M_hat range: [0.2797, 0.7034]
2025-03-11 19:51:45 - Train Iteration 186: loss: 0.7685, d_k_M range: [0.1110, 0.5307], d_k_M_hat range: [0.2506, 0.6559]
2025-03-11 19:51:45 - Train Iteration 187: loss: 0.7987, d_k_M range: [0.2106, 0.7470], d_k_M_hat range: [0.3284, 0.8616]
2025-03-11 19:51:46 - Train Iteration 188: loss: 0.7875, d_k_M range: [0.3393, 0.8134], d_k_M_hat range: [0.4914, 0.9260]
2025-03-11 19:51:46 - Train Iteration 189: loss: 0.8955, d_k_M range: [0.0242, 0.5195], d_k_M_hat range: [0.0778, 0.6869]
2025-03-11 19:51:47 - Train Iteration 190: loss: 0.7454, d_k_M range: [0.2702, 0.6750], d_k_M_hat range: [0.4333, 0.8117]
2025-03-11 19:51:47 - Train Iteration 191: loss: 0.7569, d_k_M range: [0.2559, 0.5316], d_k_M_hat range: [0.4191, 0.6752]
2025-03-11 19:51:48 - Train Iteration 192: loss: 0.7432, d_k_M range: [0.1863, 0.7793], d_k_M_hat range: [0.3627, 0.9172]
2025-03-11 19:51:48 - Train Iteration 193: loss: 0.7789, d_k_M range: [0.0528, 0.5321], d_k_M_hat range: [0.1703, 0.7382]
2025-03-11 19:51:48 - Train Iteration 194: loss: 0.9377, d_k_M range: [0.1956, 0.9545], d_k_M_hat range: [0.3961, 0.9862]
2025-03-11 19:51:49 - Train Iteration 195: loss: 0.7424, d_k_M range: [0.1012, 0.6705], d_k_M_hat range: [0.2478, 0.8088]
2025-03-11 19:51:49 - Train Iteration 196: loss: 0.8061, d_k_M range: [0.0512, 0.7265], d_k_M_hat range: [0.1533, 0.8773]
2025-03-11 19:51:50 - Train Iteration 197: loss: 0.7287, d_k_M range: [0.3174, 0.7166], d_k_M_hat range: [0.4638, 0.8694]
2025-03-11 19:51:50 - Train Iteration 198: loss: 0.7776, d_k_M range: [0.2826, 0.7662], d_k_M_hat range: [0.4221, 0.8843]
2025-03-11 19:51:50 - Train Iteration 199: loss: 0.7668, d_k_M range: [0.1461, 0.7403], d_k_M_hat range: [0.2833, 0.8670]
2025-03-11 19:51:51 - Train Iteration 200: loss: 0.9140, d_k_M range: [0.0230, 0.5654], d_k_M_hat range: [0.0670, 0.7106]
2025-03-11 19:51:51 - Train Iteration 201: loss: 0.7756, d_k_M range: [0.3953, 0.6680], d_k_M_hat range: [0.5268, 0.8108]
2025-03-11 19:51:52 - Train Iteration 202: loss: 0.7797, d_k_M range: [0.2226, 0.7029], d_k_M_hat range: [0.3396, 0.8230]
2025-03-11 19:51:52 - Train Iteration 203: loss: 0.7763, d_k_M range: [0.1637, 0.5853], d_k_M_hat range: [0.2902, 0.7383]
2025-03-11 19:51:52 - Train Iteration 204: loss: 0.9664, d_k_M range: [0.3470, 0.9745], d_k_M_hat range: [0.5065, 0.9915]
2025-03-11 19:51:53 - Train Iteration 205: loss: 0.7681, d_k_M range: [0.2003, 0.7969], d_k_M_hat range: [0.3479, 0.9205]
2025-03-11 19:51:53 - Train Iteration 206: loss: 0.7378, d_k_M range: [0.1068, 0.4761], d_k_M_hat range: [0.2479, 0.6195]
2025-03-11 19:51:54 - Train Iteration 207: loss: 0.8041, d_k_M range: [0.1243, 0.8214], d_k_M_hat range: [0.2379, 0.9247]
2025-03-11 19:51:54 - Train Iteration 208: loss: 0.8301, d_k_M range: [0.0633, 0.3815], d_k_M_hat range: [0.1522, 0.5234]
2025-03-11 19:51:54 - Train Iteration 209: loss: 0.7560, d_k_M range: [0.0914, 0.5219], d_k_M_hat range: [0.2593, 0.6525]
2025-03-11 19:51:55 - Train Iteration 210: loss: 0.8376, d_k_M range: [0.5684, 0.8686], d_k_M_hat range: [0.7129, 0.9533]
2025-03-11 19:51:55 - Train Iteration 211: loss: 0.7879, d_k_M range: [0.2710, 0.7848], d_k_M_hat range: [0.4222, 0.8972]
2025-03-11 19:51:56 - Train Iteration 212: loss: 0.7667, d_k_M range: [0.2639, 0.6164], d_k_M_hat range: [0.4070, 0.7517]
2025-03-11 19:51:56 - Train Iteration 213: loss: 0.7409, d_k_M range: [0.2744, 0.5904], d_k_M_hat range: [0.4343, 0.7447]
2025-03-11 19:51:57 - Train Iteration 214: loss: 0.8047, d_k_M range: [0.0401, 0.7622], d_k_M_hat range: [0.1431, 0.9036]
2025-03-11 19:51:57 - Train Iteration 215: loss: 0.8158, d_k_M range: [0.3223, 0.8456], d_k_M_hat range: [0.4877, 0.9423]
2025-03-11 19:51:58 - Train Iteration 216: loss: 0.7740, d_k_M range: [0.2418, 0.7170], d_k_M_hat range: [0.3715, 0.8372]
2025-03-11 19:51:58 - Train Iteration 217: loss: 0.7406, d_k_M range: [0.2421, 0.6239], d_k_M_hat range: [0.3875, 0.7667]
2025-03-11 19:51:59 - Train Iteration 218: loss: 0.8152, d_k_M range: [0.1369, 0.8499], d_k_M_hat range: [0.2570, 0.9470]
2025-03-11 19:51:59 - Train Iteration 219: loss: 0.7880, d_k_M range: [0.0710, 0.5128], d_k_M_hat range: [0.1833, 0.6697]
2025-03-11 19:51:59 - Train Iteration 220: loss: 0.7512, d_k_M range: [0.2206, 0.6168], d_k_M_hat range: [0.3553, 0.7615]
2025-03-11 19:52:00 - Train Iteration 221: loss: 0.7461, d_k_M range: [0.3196, 0.7300], d_k_M_hat range: [0.4826, 0.8869]
2025-03-11 19:52:00 - Train Iteration 222: loss: 0.7463, d_k_M range: [0.3064, 0.6083], d_k_M_hat range: [0.4559, 0.7875]
2025-03-11 19:52:01 - Train Iteration 223: loss: 0.7527, d_k_M range: [0.1673, 0.4970], d_k_M_hat range: [0.3192, 0.6438]
2025-03-11 19:52:01 - Train Iteration 224: loss: 0.8348, d_k_M range: [0.2278, 0.8605], d_k_M_hat range: [0.3772, 0.9468]
2025-03-11 19:52:02 - Train Iteration 225: loss: 0.8144, d_k_M range: [0.0548, 0.4989], d_k_M_hat range: [0.1524, 0.6308]
2025-03-11 19:52:02 - Train Iteration 226: loss: 0.8199, d_k_M range: [0.3555, 0.8226], d_k_M_hat range: [0.4879, 0.9171]
2025-03-11 19:52:03 - Train Iteration 227: loss: 0.7849, d_k_M range: [0.0666, 0.5849], d_k_M_hat range: [0.1806, 0.7176]
2025-03-11 19:52:03 - Train Iteration 228: loss: 0.8041, d_k_M range: [0.0594, 0.6248], d_k_M_hat range: [0.1626, 0.7648]
2025-03-11 19:52:04 - Train Iteration 229: loss: 0.7789, d_k_M range: [0.1459, 0.7556], d_k_M_hat range: [0.2968, 0.8797]
2025-03-11 19:52:04 - Train Iteration 230: loss: 0.7919, d_k_M range: [0.1519, 0.6934], d_k_M_hat range: [0.3182, 0.8282]
2025-03-11 19:52:04 - Train Iteration 231: loss: 0.7520, d_k_M range: [0.1439, 0.5805], d_k_M_hat range: [0.2806, 0.7290]
2025-03-11 19:52:05 - Train Iteration 232: loss: 0.8942, d_k_M range: [0.0212, 0.8118], d_k_M_hat range: [0.0755, 0.9248]
2025-03-11 19:52:05 - Train Iteration 233: loss: 0.9902, d_k_M range: [0.2185, 0.9931], d_k_M_hat range: [0.3798, 0.9980]
2025-03-11 19:52:06 - Train Iteration 234: loss: 0.7694, d_k_M range: [0.2084, 0.6886], d_k_M_hat range: [0.3523, 0.8115]
2025-03-11 19:52:06 - Train Iteration 235: loss: 0.7576, d_k_M range: [0.1191, 0.6284], d_k_M_hat range: [0.2566, 0.7621]
2025-03-11 19:52:07 - Train Iteration 236: loss: 0.9009, d_k_M range: [0.0137, 0.7385], d_k_M_hat range: [0.0645, 0.8647]
2025-03-11 19:52:07 - Train Iteration 237: loss: 0.8708, d_k_M range: [0.1130, 0.9069], d_k_M_hat range: [0.2795, 0.9738]
2025-03-11 19:52:07 - Train Iteration 238: loss: 0.7456, d_k_M range: [0.0717, 0.6243], d_k_M_hat range: [0.2082, 0.7718]
2025-03-11 19:52:08 - Train Iteration 239: loss: 0.8670, d_k_M range: [0.1966, 0.8965], d_k_M_hat range: [0.3351, 0.9654]
2025-03-11 19:52:08 - Train Iteration 240: loss: 0.7939, d_k_M range: [0.1007, 0.4191], d_k_M_hat range: [0.2215, 0.5540]
2025-03-11 19:52:09 - Train Iteration 241: loss: 0.7825, d_k_M range: [0.1005, 0.6018], d_k_M_hat range: [0.2159, 0.7294]
2025-03-11 19:52:09 - Train Iteration 242: loss: 0.7533, d_k_M range: [0.1323, 0.6219], d_k_M_hat range: [0.2848, 0.7540]
2025-03-11 19:52:10 - Train Iteration 243: loss: 0.7765, d_k_M range: [0.2551, 0.6219], d_k_M_hat range: [0.3971, 0.7476]
2025-03-11 19:52:10 - Train Iteration 244: loss: 0.7956, d_k_M range: [0.1487, 0.8195], d_k_M_hat range: [0.3233, 0.9348]
2025-03-11 19:52:11 - Train Iteration 245: loss: 0.7106, d_k_M range: [0.2746, 0.6601], d_k_M_hat range: [0.4371, 0.8315]
2025-03-11 19:52:11 - Train Iteration 246: loss: 0.7969, d_k_M range: [0.2575, 0.8445], d_k_M_hat range: [0.4279, 0.9518]
2025-03-11 19:52:12 - Train Iteration 247: loss: 0.7653, d_k_M range: [0.1071, 0.5885], d_k_M_hat range: [0.2324, 0.7660]
2025-03-11 19:52:12 - Train Iteration 248: loss: 0.9250, d_k_M range: [0.0199, 0.7277], d_k_M_hat range: [0.0581, 0.8683]
2025-03-11 19:52:13 - Train Iteration 249: loss: 0.8002, d_k_M range: [0.0461, 0.4741], d_k_M_hat range: [0.1516, 0.6340]
2025-03-11 19:52:13 - Train Iteration 250: loss: 0.7460, d_k_M range: [0.2571, 0.7698], d_k_M_hat range: [0.3945, 0.9061]
2025-03-11 19:52:14 - Train Iteration 251: loss: 0.7278, d_k_M range: [0.1941, 0.7053], d_k_M_hat range: [0.3679, 0.8523]
2025-03-11 19:52:14 - Train Iteration 252: loss: 0.7305, d_k_M range: [0.3150, 0.7097], d_k_M_hat range: [0.4765, 0.8550]
2025-03-11 19:52:15 - Train Iteration 253: loss: 0.9250, d_k_M range: [0.1586, 0.9463], d_k_M_hat range: [0.3215, 0.9845]
2025-03-11 19:52:15 - Train Iteration 254: loss: 0.7598, d_k_M range: [0.1976, 0.7981], d_k_M_hat range: [0.3564, 0.9265]
2025-03-11 19:52:16 - Train Iteration 255: loss: 0.8080, d_k_M range: [0.0586, 0.5271], d_k_M_hat range: [0.1615, 0.6833]
2025-03-11 19:52:16 - Train Iteration 256: loss: 0.7307, d_k_M range: [0.0946, 0.6012], d_k_M_hat range: [0.2398, 0.7645]
2025-03-11 19:52:17 - Train Iteration 257: loss: 0.7485, d_k_M range: [0.0731, 0.5212], d_k_M_hat range: [0.2403, 0.7017]
2025-03-11 19:52:17 - Train Iteration 258: loss: 0.7389, d_k_M range: [0.1117, 0.5085], d_k_M_hat range: [0.2840, 0.7189]
2025-03-11 19:52:18 - Train Iteration 259: loss: 0.7964, d_k_M range: [0.1274, 0.8551], d_k_M_hat range: [0.3133, 0.9627]
2025-03-11 19:52:18 - Train Iteration 260: loss: 0.8582, d_k_M range: [0.0308, 0.5689], d_k_M_hat range: [0.1045, 0.7346]
2025-03-11 19:52:19 - Train Iteration 261: loss: 0.7703, d_k_M range: [0.0624, 0.4784], d_k_M_hat range: [0.2140, 0.6397]
2025-03-11 19:52:19 - Train Iteration 262: loss: 0.7742, d_k_M range: [0.3706, 0.6430], d_k_M_hat range: [0.5177, 0.7702]
2025-03-11 19:52:20 - Train Iteration 263: loss: 0.7960, d_k_M range: [0.1304, 0.8472], d_k_M_hat range: [0.2886, 0.9550]
2025-03-11 19:52:21 - Train Iteration 264: loss: 0.7625, d_k_M range: [0.1233, 0.7988], d_k_M_hat range: [0.2754, 0.9256]
2025-03-11 19:52:21 - Train Iteration 265: loss: 0.7532, d_k_M range: [0.0618, 0.7136], d_k_M_hat range: [0.1939, 0.8474]
2025-03-11 19:52:22 - Train Iteration 266: loss: 0.7365, d_k_M range: [0.1717, 0.4406], d_k_M_hat range: [0.3418, 0.5975]
2025-03-11 19:52:22 - Train Iteration 267: loss: 0.7267, d_k_M range: [0.1164, 0.6995], d_k_M_hat range: [0.3085, 0.8489]
2025-03-11 19:52:22 - Train Iteration 268: loss: 0.7008, d_k_M range: [0.1230, 0.5015], d_k_M_hat range: [0.3022, 0.6925]
2025-03-11 19:52:23 - Train Iteration 269: loss: 0.7284, d_k_M range: [0.0507, 0.6658], d_k_M_hat range: [0.1987, 0.8390]
2025-03-11 19:52:23 - Train Iteration 270: loss: 0.9174, d_k_M range: [0.0095, 0.2948], d_k_M_hat range: [0.0517, 0.4768]
2025-03-11 19:52:24 - Train Iteration 271: loss: 0.7487, d_k_M range: [0.3209, 0.6663], d_k_M_hat range: [0.4556, 0.8117]
2025-03-11 19:52:24 - Train Iteration 272: loss: 0.7768, d_k_M range: [0.0625, 0.5360], d_k_M_hat range: [0.2159, 0.6864]
2025-03-11 19:52:25 - Train Iteration 273: loss: 0.7847, d_k_M range: [0.2304, 0.7885], d_k_M_hat range: [0.3719, 0.9026]
2025-03-11 19:52:25 - Train Iteration 274: loss: 0.7699, d_k_M range: [0.1506, 0.4915], d_k_M_hat range: [0.3002, 0.6141]
2025-03-11 19:52:26 - Train Iteration 275: loss: 0.8502, d_k_M range: [0.0239, 0.6342], d_k_M_hat range: [0.1019, 0.7752]
2025-03-11 19:52:26 - Train Iteration 276: loss: 0.9887, d_k_M range: [0.4906, 0.9921], d_k_M_hat range: [0.6245, 0.9978]
2025-03-11 19:52:27 - Train Iteration 277: loss: 0.9786, d_k_M range: [0.1981, 0.9845], d_k_M_hat range: [0.3161, 0.9952]
2025-03-11 19:52:27 - Train Iteration 278: loss: 0.7756, d_k_M range: [0.2604, 0.5338], d_k_M_hat range: [0.3977, 0.6798]
2025-03-11 19:52:28 - Train Iteration 279: loss: 0.7476, d_k_M range: [0.2785, 0.7168], d_k_M_hat range: [0.4139, 0.8624]
2025-03-11 19:52:28 - Train Iteration 280: loss: 0.7708, d_k_M range: [0.1745, 0.7225], d_k_M_hat range: [0.3217, 0.8445]
2025-03-11 19:52:29 - Train Iteration 281: loss: 0.7422, d_k_M range: [0.1829, 0.5683], d_k_M_hat range: [0.3412, 0.7068]
2025-03-11 19:52:29 - Train Iteration 282: loss: 0.8552, d_k_M range: [0.3425, 0.8904], d_k_M_hat range: [0.5000, 0.9657]
2025-03-11 19:52:30 - Train Iteration 283: loss: 0.7632, d_k_M range: [0.2005, 0.4331], d_k_M_hat range: [0.3271, 0.5678]
2025-03-11 19:52:30 - Train Iteration 284: loss: 0.7804, d_k_M range: [0.0995, 0.5416], d_k_M_hat range: [0.2161, 0.7126]
2025-03-11 19:52:31 - Train Iteration 285: loss: 0.8633, d_k_M range: [0.0269, 0.6310], d_k_M_hat range: [0.0977, 0.7767]
2025-03-11 19:52:31 - Train Iteration 286: loss: 0.9066, d_k_M range: [0.0191, 0.5088], d_k_M_hat range: [0.0669, 0.6674]
2025-03-11 19:52:32 - Train Iteration 287: loss: 0.8460, d_k_M range: [0.0292, 0.8259], d_k_M_hat range: [0.1094, 0.9283]
2025-03-11 19:52:32 - Train Iteration 288: loss: 0.7659, d_k_M range: [0.1701, 0.5284], d_k_M_hat range: [0.3729, 0.6760]
2025-03-11 19:52:33 - Train Iteration 289: loss: 0.7509, d_k_M range: [0.2049, 0.7678], d_k_M_hat range: [0.3610, 0.9012]
2025-03-11 19:52:33 - Train Iteration 290: loss: 0.7118, d_k_M range: [0.0589, 0.4490], d_k_M_hat range: [0.2284, 0.6287]
2025-03-11 19:52:34 - Train Iteration 291: loss: 0.7625, d_k_M range: [0.2831, 0.7937], d_k_M_hat range: [0.4452, 0.9205]
2025-03-11 19:52:34 - Train Iteration 292: loss: 0.7403, d_k_M range: [0.1211, 0.6803], d_k_M_hat range: [0.2817, 0.8265]
2025-03-11 19:52:35 - Train Iteration 293: loss: 0.7009, d_k_M range: [0.2397, 0.5716], d_k_M_hat range: [0.4133, 0.7405]
2025-03-11 19:52:35 - Train Iteration 294: loss: 0.9334, d_k_M range: [0.1118, 0.9570], d_k_M_hat range: [0.2607, 0.9909]
2025-03-11 19:52:36 - Train Iteration 295: loss: 0.7316, d_k_M range: [0.1234, 0.6919], d_k_M_hat range: [0.2680, 0.8534]
2025-03-11 19:52:36 - Train Iteration 296: loss: 0.7485, d_k_M range: [0.0618, 0.5923], d_k_M_hat range: [0.1967, 0.7454]
2025-03-11 19:52:37 - Train Iteration 297: loss: 0.7467, d_k_M range: [0.0962, 0.7018], d_k_M_hat range: [0.2866, 0.8377]
2025-03-11 19:52:37 - Train Iteration 298: loss: 0.8176, d_k_M range: [0.1749, 0.8499], d_k_M_hat range: [0.3762, 0.9457]
2025-03-11 19:52:38 - Train Iteration 299: loss: 0.8379, d_k_M range: [0.0237, 0.5015], d_k_M_hat range: [0.1083, 0.6371]
2025-03-11 19:52:38 - Train Iteration 300: loss: 0.7401, d_k_M range: [0.2957, 0.7061], d_k_M_hat range: [0.4549, 0.8647]
2025-03-11 19:52:39 - Train Iteration 301: loss: 0.7471, d_k_M range: [0.0733, 0.6449], d_k_M_hat range: [0.2273, 0.7877]
2025-03-11 19:52:39 - Train Iteration 302: loss: 0.7409, d_k_M range: [0.0673, 0.4882], d_k_M_hat range: [0.2065, 0.6577]
2025-03-11 19:52:40 - Train Iteration 303: loss: 0.7483, d_k_M range: [0.2404, 0.7958], d_k_M_hat range: [0.4285, 0.9308]
2025-03-11 19:52:40 - Train Iteration 304: loss: 0.7390, d_k_M range: [0.0703, 0.7799], d_k_M_hat range: [0.2242, 0.9202]
2025-03-11 19:52:41 - Train Iteration 305: loss: 0.8081, d_k_M range: [0.0370, 0.8066], d_k_M_hat range: [0.1380, 0.9482]
2025-03-11 19:52:41 - Train Iteration 306: loss: 0.9395, d_k_M range: [0.4324, 0.9579], d_k_M_hat range: [0.5943, 0.9886]
2025-03-11 19:52:42 - Train Iteration 307: loss: 0.7230, d_k_M range: [0.3731, 0.6255], d_k_M_hat range: [0.5245, 0.7898]
2025-03-11 19:52:42 - Train Iteration 308: loss: 0.9016, d_k_M range: [0.0161, 0.5266], d_k_M_hat range: [0.0665, 0.6656]
2025-03-11 19:52:43 - Train Iteration 309: loss: 0.7288, d_k_M range: [0.2965, 0.6908], d_k_M_hat range: [0.4491, 0.8400]
2025-03-11 19:52:43 - Train Iteration 310: loss: 0.7996, d_k_M range: [0.3514, 0.8326], d_k_M_hat range: [0.5226, 0.9384]
2025-03-11 19:52:44 - Train Iteration 311: loss: 0.7875, d_k_M range: [0.1026, 0.6366], d_k_M_hat range: [0.2152, 0.7939]
2025-03-11 19:52:44 - Train Iteration 312: loss: 0.9351, d_k_M range: [0.3591, 0.9561], d_k_M_hat range: [0.5187, 0.9891]
2025-03-11 19:52:45 - Train Iteration 313: loss: 0.8914, d_k_M range: [0.0234, 0.5354], d_k_M_hat range: [0.0793, 0.6716]
2025-03-11 19:52:45 - Train Iteration 314: loss: 0.7543, d_k_M range: [0.2983, 0.5264], d_k_M_hat range: [0.4298, 0.6698]
2025-03-11 19:52:46 - Train Iteration 315: loss: 0.7406, d_k_M range: [0.2999, 0.5948], d_k_M_hat range: [0.4556, 0.7788]
2025-03-11 19:52:46 - Train Iteration 316: loss: 0.7449, d_k_M range: [0.0795, 0.5952], d_k_M_hat range: [0.2347, 0.7465]
2025-03-11 19:52:47 - Train Iteration 317: loss: 0.7569, d_k_M range: [0.2006, 0.6928], d_k_M_hat range: [0.3509, 0.8652]
2025-03-11 19:52:47 - Train Iteration 318: loss: 0.7142, d_k_M range: [0.3322, 0.6779], d_k_M_hat range: [0.5018, 0.8328]
2025-03-11 19:52:48 - Train Iteration 319: loss: 0.7761, d_k_M range: [0.1005, 0.8181], d_k_M_hat range: [0.2667, 0.9372]
2025-03-11 19:52:48 - Train Iteration 320: loss: 0.7557, d_k_M range: [0.1941, 0.6705], d_k_M_hat range: [0.3248, 0.8562]
2025-03-11 19:52:49 - Train Iteration 321: loss: 0.7261, d_k_M range: [0.0632, 0.6473], d_k_M_hat range: [0.2243, 0.8304]
2025-03-11 19:52:50 - Train Iteration 322: loss: 0.7443, d_k_M range: [0.1296, 0.7603], d_k_M_hat range: [0.2669, 0.9138]
2025-03-11 19:52:50 - Train Iteration 323: loss: 0.7212, d_k_M range: [0.0560, 0.6388], d_k_M_hat range: [0.2068, 0.8271]
2025-03-11 19:52:51 - Train Iteration 324: loss: 0.8713, d_k_M range: [0.3434, 0.9149], d_k_M_hat range: [0.5470, 0.9815]
2025-03-11 19:52:51 - Train Iteration 325: loss: 0.7509, d_k_M range: [0.1667, 0.7623], d_k_M_hat range: [0.3509, 0.8957]
2025-03-11 19:52:52 - Train Iteration 326: loss: 0.8192, d_k_M range: [0.0198, 0.4779], d_k_M_hat range: [0.1147, 0.6587]
2025-03-11 19:52:52 - Train Iteration 327: loss: 0.8824, d_k_M range: [0.3760, 0.9152], d_k_M_hat range: [0.5821, 0.9758]
2025-03-11 19:52:53 - Train Iteration 328: loss: 0.7100, d_k_M range: [0.1880, 0.6469], d_k_M_hat range: [0.3641, 0.8241]
2025-03-11 19:52:53 - Train Iteration 329: loss: 0.8120, d_k_M range: [0.0389, 0.6403], d_k_M_hat range: [0.1378, 0.8282]
2025-03-11 19:52:54 - Train Iteration 330: loss: 0.7348, d_k_M range: [0.0672, 0.5650], d_k_M_hat range: [0.2252, 0.7339]
2025-03-11 19:52:54 - Train Iteration 331: loss: 0.7005, d_k_M range: [0.1805, 0.7202], d_k_M_hat range: [0.3552, 0.8832]
2025-03-11 19:52:55 - Train Iteration 332: loss: 0.7276, d_k_M range: [0.3054, 0.7120], d_k_M_hat range: [0.4523, 0.8693]
2025-03-11 19:52:55 - Train Iteration 333: loss: 0.7854, d_k_M range: [0.1917, 0.8182], d_k_M_hat range: [0.3584, 0.9320]
2025-03-11 19:52:56 - Train Iteration 334: loss: 0.9215, d_k_M range: [0.0142, 0.6426], d_k_M_hat range: [0.0542, 0.8107]
2025-03-11 19:52:56 - Train Iteration 335: loss: 0.7849, d_k_M range: [0.0674, 0.6230], d_k_M_hat range: [0.1815, 0.7809]
2025-03-11 19:52:57 - Train Iteration 336: loss: 0.7645, d_k_M range: [0.2996, 0.8215], d_k_M_hat range: [0.4698, 0.9472]
2025-03-11 19:52:57 - Train Iteration 337: loss: 0.8336, d_k_M range: [0.0367, 0.5204], d_k_M_hat range: [0.1236, 0.6676]
2025-03-11 19:52:58 - Train Iteration 338: loss: 0.7131, d_k_M range: [0.2137, 0.7281], d_k_M_hat range: [0.3818, 0.8841]
2025-03-11 19:52:58 - Train Iteration 339: loss: 0.7222, d_k_M range: [0.0962, 0.7819], d_k_M_hat range: [0.2589, 0.9321]
2025-03-11 19:52:58 - Train Iteration 340: loss: 0.9255, d_k_M range: [0.0229, 0.5763], d_k_M_hat range: [0.0609, 0.7241]
2025-03-11 19:52:59 - Train Iteration 341: loss: 0.7719, d_k_M range: [0.3069, 0.6951], d_k_M_hat range: [0.4421, 0.8554]
2025-03-11 19:52:59 - Train Iteration 342: loss: 0.7437, d_k_M range: [0.3019, 0.7736], d_k_M_hat range: [0.4744, 0.9112]
2025-03-11 19:53:00 - Train Iteration 343: loss: 0.9309, d_k_M range: [0.2856, 0.9527], d_k_M_hat range: [0.4926, 0.9879]
2025-03-11 19:53:00 - Train Iteration 344: loss: 0.7503, d_k_M range: [0.0748, 0.6833], d_k_M_hat range: [0.2086, 0.8584]
2025-03-11 19:53:01 - Train Iteration 345: loss: 0.7303, d_k_M range: [0.0520, 0.4810], d_k_M_hat range: [0.1975, 0.6643]
2025-03-11 19:53:01 - Train Iteration 346: loss: 0.7228, d_k_M range: [0.1692, 0.5312], d_k_M_hat range: [0.3281, 0.6961]
2025-03-11 19:53:02 - Train Iteration 347: loss: 0.8461, d_k_M range: [0.0201, 0.8422], d_k_M_hat range: [0.1003, 0.9510]
2025-03-11 19:53:02 - Train Iteration 348: loss: 0.8161, d_k_M range: [0.3289, 0.8720], d_k_M_hat range: [0.4968, 0.9686]
2025-03-11 19:53:02 - Train Iteration 349: loss: 0.8456, d_k_M range: [0.0385, 0.5968], d_k_M_hat range: [0.1189, 0.7684]
2025-03-11 19:53:03 - Train Iteration 350: loss: 0.8375, d_k_M range: [0.2059, 0.8636], d_k_M_hat range: [0.3492, 0.9485]
2025-03-11 19:53:03 - Train Iteration 351: loss: 0.8820, d_k_M range: [0.1811, 0.9177], d_k_M_hat range: [0.3311, 0.9785]
2025-03-11 19:53:04 - Train Iteration 352: loss: 0.7328, d_k_M range: [0.0900, 0.4340], d_k_M_hat range: [0.2421, 0.6115]
2025-03-11 19:53:04 - Train Iteration 353: loss: 0.7313, d_k_M range: [0.1806, 0.6454], d_k_M_hat range: [0.3384, 0.7903]
2025-03-11 19:53:05 - Train Iteration 354: loss: 0.8069, d_k_M range: [0.0530, 0.5416], d_k_M_hat range: [0.1548, 0.7164]
2025-03-11 19:53:05 - Train Iteration 355: loss: 0.7058, d_k_M range: [0.0559, 0.6894], d_k_M_hat range: [0.2464, 0.8493]
2025-03-11 19:53:05 - Train Iteration 356: loss: 0.7837, d_k_M range: [0.0310, 0.4462], d_k_M_hat range: [0.1551, 0.6322]
2025-03-11 19:53:06 - Train Iteration 357: loss: 0.7909, d_k_M range: [0.3212, 0.8505], d_k_M_hat range: [0.4974, 0.9611]
2025-03-11 19:53:06 - Train Iteration 358: loss: 0.7722, d_k_M range: [0.1001, 0.4489], d_k_M_hat range: [0.2336, 0.6103]
2025-03-11 19:53:07 - Train Iteration 359: loss: 0.7888, d_k_M range: [0.0263, 0.5618], d_k_M_hat range: [0.1381, 0.7155]
2025-03-11 19:53:07 - Train Iteration 360: loss: 0.7382, d_k_M range: [0.1740, 0.7113], d_k_M_hat range: [0.3516, 0.8604]
2025-03-11 19:53:08 - Train Iteration 361: loss: 0.7069, d_k_M range: [0.1323, 0.6645], d_k_M_hat range: [0.3142, 0.8415]
2025-03-11 19:53:08 - Train Iteration 362: loss: 0.9556, d_k_M range: [0.3470, 0.9721], d_k_M_hat range: [0.5243, 0.9946]
2025-03-11 19:53:08 - Train Iteration 363: loss: 0.8595, d_k_M range: [0.0760, 0.9039], d_k_M_hat range: [0.2265, 0.9768]
2025-03-11 19:53:09 - Train Iteration 364: loss: 0.7417, d_k_M range: [0.1719, 0.6051], d_k_M_hat range: [0.3312, 0.7858]
2025-03-11 19:53:09 - Train Iteration 365: loss: 0.7832, d_k_M range: [0.0651, 0.7924], d_k_M_hat range: [0.1800, 0.9250]
2025-03-11 19:53:10 - Train Iteration 366: loss: 0.7420, d_k_M range: [0.1835, 0.7770], d_k_M_hat range: [0.3512, 0.9156]
2025-03-11 19:53:10 - Train Iteration 367: loss: 0.7683, d_k_M range: [0.0464, 0.7296], d_k_M_hat range: [0.1720, 0.8711]
2025-03-11 19:53:10 - Train Iteration 368: loss: 0.7293, d_k_M range: [0.2523, 0.7382], d_k_M_hat range: [0.4071, 0.8842]
2025-03-11 19:53:11 - Train Iteration 369: loss: 0.7596, d_k_M range: [0.2145, 0.5561], d_k_M_hat range: [0.3509, 0.7076]
2025-03-11 19:53:11 - Train Iteration 370: loss: 0.7643, d_k_M range: [0.2130, 0.5000], d_k_M_hat range: [0.3958, 0.6654]
2025-03-11 19:53:12 - Train Iteration 371: loss: 0.7226, d_k_M range: [0.1653, 0.6739], d_k_M_hat range: [0.3165, 0.8359]
2025-03-11 19:53:12 - Train Iteration 372: loss: 0.9719, d_k_M range: [0.0066, 0.7638], d_k_M_hat range: [0.0207, 0.9081]
2025-03-11 19:53:13 - Train Iteration 373: loss: 0.7298, d_k_M range: [0.0444, 0.5428], d_k_M_hat range: [0.2051, 0.7134]
2025-03-11 19:53:13 - Train Iteration 374: loss: 0.8050, d_k_M range: [0.0582, 0.8319], d_k_M_hat range: [0.2149, 0.9347]
2025-03-11 19:53:13 - Train Iteration 375: loss: 0.9029, d_k_M range: [0.0745, 0.9326], d_k_M_hat range: [0.2333, 0.9824]
2025-03-11 19:53:14 - Train Iteration 376: loss: 0.7313, d_k_M range: [0.0528, 0.7200], d_k_M_hat range: [0.2086, 0.8649]
2025-03-11 19:53:14 - Train Iteration 377: loss: 0.9135, d_k_M range: [0.0097, 0.5785], d_k_M_hat range: [0.0539, 0.7541]
2025-03-11 19:53:15 - Train Iteration 378: loss: 0.7050, d_k_M range: [0.2275, 0.3733], d_k_M_hat range: [0.3945, 0.5380]
2025-03-11 19:53:15 - Train Iteration 379: loss: 0.8292, d_k_M range: [0.1379, 0.8736], d_k_M_hat range: [0.2971, 0.9630]
2025-03-11 19:53:16 - Train Iteration 380: loss: 0.9875, d_k_M range: [0.0040, 0.4979], d_k_M_hat range: [0.0103, 0.6620]
2025-03-11 19:53:16 - Train Iteration 381: loss: 0.6944, d_k_M range: [0.1691, 0.4592], d_k_M_hat range: [0.3421, 0.6669]
2025-03-11 19:53:17 - Train Iteration 382: loss: 0.6741, d_k_M range: [0.0953, 0.5429], d_k_M_hat range: [0.2743, 0.7409]
2025-03-11 19:53:17 - Train Iteration 383: loss: 0.9476, d_k_M range: [0.0628, 0.9671], d_k_M_hat range: [0.2211, 0.9936]
2025-03-11 19:53:18 - Train Iteration 384: loss: 0.7169, d_k_M range: [0.2003, 0.7155], d_k_M_hat range: [0.3635, 0.8698]
2025-03-11 19:53:18 - Train Iteration 385: loss: 0.7348, d_k_M range: [0.0983, 0.5610], d_k_M_hat range: [0.2619, 0.7038]
2025-03-11 19:53:18 - Train Iteration 386: loss: 0.7150, d_k_M range: [0.1539, 0.5266], d_k_M_hat range: [0.3107, 0.6970]
2025-03-11 19:53:19 - Train Iteration 387: loss: 0.7553, d_k_M range: [0.0250, 0.6752], d_k_M_hat range: [0.1589, 0.8455]
2025-03-11 19:53:19 - Train Iteration 388: loss: 0.7530, d_k_M range: [0.3225, 0.8249], d_k_M_hat range: [0.4958, 0.9572]
2025-03-11 19:53:20 - Train Iteration 389: loss: 0.7038, d_k_M range: [0.2798, 0.4894], d_k_M_hat range: [0.4694, 0.7014]
2025-03-11 19:53:20 - Train Iteration 390: loss: 0.7852, d_k_M range: [0.0186, 0.7807], d_k_M_hat range: [0.1325, 0.9230]
2025-03-11 19:53:20 - Train Iteration 391: loss: 0.7198, d_k_M range: [0.1919, 0.8010], d_k_M_hat range: [0.3867, 0.9544]
2025-03-11 19:53:21 - Train Iteration 392: loss: 0.6945, d_k_M range: [0.1627, 0.7361], d_k_M_hat range: [0.3426, 0.9032]
2025-03-11 19:53:21 - Train Iteration 393: loss: 0.7010, d_k_M range: [0.1963, 0.6838], d_k_M_hat range: [0.3819, 0.8554]
2025-03-11 19:53:22 - Train Iteration 394: loss: 0.7438, d_k_M range: [0.0596, 0.4644], d_k_M_hat range: [0.1972, 0.6404]
2025-03-11 19:53:22 - Train Iteration 395: loss: 0.7084, d_k_M range: [0.1274, 0.6706], d_k_M_hat range: [0.3069, 0.8521]
2025-03-11 19:53:23 - Train Iteration 396: loss: 0.8122, d_k_M range: [0.0408, 0.5687], d_k_M_hat range: [0.1396, 0.7273]
2025-03-11 19:53:23 - Train Iteration 397: loss: 0.7580, d_k_M range: [0.3190, 0.7963], d_k_M_hat range: [0.4906, 0.9431]
2025-03-11 19:53:23 - Train Iteration 398: loss: 0.7380, d_k_M range: [0.1830, 0.7601], d_k_M_hat range: [0.3390, 0.9010]
2025-03-11 19:53:24 - Train Iteration 399: loss: 0.7337, d_k_M range: [0.0756, 0.6140], d_k_M_hat range: [0.2190, 0.8043]
2025-03-11 19:53:24 - Train Iteration 400: loss: 0.7229, d_k_M range: [0.1350, 0.5573], d_k_M_hat range: [0.3000, 0.7365]
2025-03-11 19:53:25 - Train Iteration 401: loss: 0.8129, d_k_M range: [0.3071, 0.8720], d_k_M_hat range: [0.4924, 0.9704]
2025-03-11 19:53:25 - Train Iteration 402: loss: 0.6904, d_k_M range: [0.1289, 0.5330], d_k_M_hat range: [0.3150, 0.7363]
2025-03-11 19:53:26 - Train Iteration 403: loss: 0.8963, d_k_M range: [0.2948, 0.9286], d_k_M_hat range: [0.4819, 0.9819]
2025-03-11 19:53:26 - Train Iteration 404: loss: 0.8985, d_k_M range: [0.2869, 0.9369], d_k_M_hat range: [0.5073, 0.9890]
2025-03-11 19:53:26 - Train Iteration 405: loss: 0.7201, d_k_M range: [0.0908, 0.7398], d_k_M_hat range: [0.2600, 0.9177]
2025-03-11 19:53:27 - Train Iteration 406: loss: 0.8271, d_k_M range: [0.0315, 0.4368], d_k_M_hat range: [0.1221, 0.5771]
2025-03-11 19:53:27 - Train Iteration 407: loss: 0.7638, d_k_M range: [0.2784, 0.7964], d_k_M_hat range: [0.4551, 0.9360]
2025-03-11 19:53:28 - Train Iteration 408: loss: 0.7120, d_k_M range: [0.2136, 0.5663], d_k_M_hat range: [0.3939, 0.7308]
2025-03-11 19:53:28 - Train Iteration 409: loss: 0.7287, d_k_M range: [0.0918, 0.6347], d_k_M_hat range: [0.2628, 0.7810]
2025-03-11 19:53:29 - Train Iteration 410: loss: 0.8723, d_k_M range: [0.3107, 0.9130], d_k_M_hat range: [0.4777, 0.9790]
2025-03-11 19:53:29 - Train Iteration 411: loss: 0.8461, d_k_M range: [0.1853, 0.8987], d_k_M_hat range: [0.3629, 0.9789]
2025-03-11 19:53:29 - Train Iteration 412: loss: 0.8412, d_k_M range: [0.0188, 0.5735], d_k_M_hat range: [0.1016, 0.7085]
2025-03-11 19:53:30 - Train Iteration 413: loss: 0.9152, d_k_M range: [0.0711, 0.9426], d_k_M_hat range: [0.2103, 0.9859]
2025-03-11 19:53:30 - Train Iteration 414: loss: 0.8000, d_k_M range: [0.0354, 0.3305], d_k_M_hat range: [0.1409, 0.4823]
2025-03-11 19:53:31 - Train Iteration 415: loss: 0.7560, d_k_M range: [0.2656, 0.7564], d_k_M_hat range: [0.3962, 0.8955]
2025-03-11 19:53:31 - Train Iteration 416: loss: 0.8109, d_k_M range: [0.1373, 0.8444], d_k_M_hat range: [0.2974, 0.9439]
2025-03-11 19:53:31 - Train Iteration 417: loss: 0.7257, d_k_M range: [0.1387, 0.5354], d_k_M_hat range: [0.2982, 0.7182]
2025-03-11 19:53:32 - Train Iteration 418: loss: 0.7141, d_k_M range: [0.2843, 0.6916], d_k_M_hat range: [0.4677, 0.8510]
2025-03-11 19:53:32 - Train Iteration 419: loss: 0.7069, d_k_M range: [0.2754, 0.6853], d_k_M_hat range: [0.4599, 0.8621]
2025-03-11 19:53:33 - Train Iteration 420: loss: 0.7293, d_k_M range: [0.0567, 0.6902], d_k_M_hat range: [0.2451, 0.8451]
2025-03-11 19:53:33 - Train Iteration 421: loss: 0.7623, d_k_M range: [0.0772, 0.7979], d_k_M_hat range: [0.2443, 0.9248]
2025-03-11 19:53:33 - Train Iteration 422: loss: 0.7337, d_k_M range: [0.0975, 0.6257], d_k_M_hat range: [0.2409, 0.7857]
2025-03-11 19:53:34 - Train Iteration 423: loss: 0.7412, d_k_M range: [0.1545, 0.7496], d_k_M_hat range: [0.3812, 0.8887]
2025-03-11 19:53:34 - Train Iteration 424: loss: 0.7034, d_k_M range: [0.0486, 0.6327], d_k_M_hat range: [0.2366, 0.7939]
2025-03-11 19:53:35 - Train Iteration 425: loss: 0.6916, d_k_M range: [0.2438, 0.6988], d_k_M_hat range: [0.4188, 0.8672]
2025-03-11 19:53:35 - Train Iteration 426: loss: 0.7093, d_k_M range: [0.4223, 0.7799], d_k_M_hat range: [0.6086, 0.9377]
2025-03-11 19:53:36 - Train Iteration 427: loss: 0.6989, d_k_M range: [0.1888, 0.7456], d_k_M_hat range: [0.4152, 0.9096]
2025-03-11 19:53:36 - Train Iteration 428: loss: 0.8836, d_k_M range: [0.4506, 0.9211], d_k_M_hat range: [0.6475, 0.9811]
2025-03-11 19:53:36 - Train Iteration 429: loss: 0.9335, d_k_M range: [0.0099, 0.5864], d_k_M_hat range: [0.0437, 0.7779]
2025-03-11 19:53:37 - Train Iteration 430: loss: 0.7203, d_k_M range: [0.0991, 0.3957], d_k_M_hat range: [0.2661, 0.5742]
2025-03-11 19:53:37 - Train Iteration 431: loss: 0.7605, d_k_M range: [0.1228, 0.8179], d_k_M_hat range: [0.3303, 0.9458]
2025-03-11 19:53:38 - Train Iteration 432: loss: 0.7050, d_k_M range: [0.1616, 0.5689], d_k_M_hat range: [0.3257, 0.7584]
2025-03-11 19:53:38 - Train Iteration 433: loss: 0.7543, d_k_M range: [0.0525, 0.7392], d_k_M_hat range: [0.1839, 0.8997]
2025-03-11 19:53:39 - Train Iteration 434: loss: 0.8792, d_k_M range: [0.0111, 0.8331], d_k_M_hat range: [0.0735, 0.9467]
2025-03-11 19:53:39 - Train Iteration 435: loss: 0.7331, d_k_M range: [0.2328, 0.7517], d_k_M_hat range: [0.4623, 0.8954]
2025-03-11 19:53:40 - Train Iteration 436: loss: 0.7995, d_k_M range: [0.0110, 0.5640], d_k_M_hat range: [0.1168, 0.7352]
2025-03-11 19:53:40 - Train Iteration 437: loss: 0.9221, d_k_M range: [0.2636, 0.9489], d_k_M_hat range: [0.4912, 0.9887]
2025-03-11 19:53:40 - Train Iteration 438: loss: 0.7052, d_k_M range: [0.0671, 0.4033], d_k_M_hat range: [0.2424, 0.5687]
2025-03-11 19:53:41 - Train Iteration 439: loss: 0.6904, d_k_M range: [0.1685, 0.4781], d_k_M_hat range: [0.3504, 0.7126]
2025-03-11 19:53:41 - Train Iteration 440: loss: 0.6656, d_k_M range: [0.1893, 0.6225], d_k_M_hat range: [0.3837, 0.8260]
2025-03-11 19:53:42 - Train Iteration 441: loss: 0.9482, d_k_M range: [0.3582, 0.9673], d_k_M_hat range: [0.5809, 0.9936]
2025-03-11 19:53:42 - Train Iteration 442: loss: 0.6703, d_k_M range: [0.2129, 0.5727], d_k_M_hat range: [0.3949, 0.7540]
2025-03-11 19:53:43 - Train Iteration 443: loss: 0.6932, d_k_M range: [0.1096, 0.5132], d_k_M_hat range: [0.2914, 0.7195]
2025-03-11 19:53:43 - Train Iteration 444: loss: 0.7175, d_k_M range: [0.2798, 0.4686], d_k_M_hat range: [0.4328, 0.6625]
2025-03-11 19:53:43 - Train Iteration 445: loss: 0.7509, d_k_M range: [0.1895, 0.7957], d_k_M_hat range: [0.3928, 0.9291]
2025-03-11 19:53:44 - Train Iteration 446: loss: 0.7158, d_k_M range: [0.0589, 0.6220], d_k_M_hat range: [0.2128, 0.8147]
2025-03-11 19:53:44 - Train Iteration 447: loss: 0.7211, d_k_M range: [0.3753, 0.7630], d_k_M_hat range: [0.5635, 0.9156]
2025-03-11 19:53:45 - Train Iteration 448: loss: 0.7706, d_k_M range: [0.1136, 0.5506], d_k_M_hat range: [0.3007, 0.7194]
2025-03-11 19:53:45 - Train Iteration 449: loss: 0.7568, d_k_M range: [0.0374, 0.8101], d_k_M_hat range: [0.2431, 0.9401]
2025-03-11 19:53:46 - Train Iteration 450: loss: 0.7262, d_k_M range: [0.2700, 0.7086], d_k_M_hat range: [0.4511, 0.8854]
2025-03-11 19:53:46 - Train Iteration 451: loss: 0.7332, d_k_M range: [0.0341, 0.4628], d_k_M_hat range: [0.1778, 0.6407]
2025-03-11 19:53:46 - Train Iteration 452: loss: 0.7708, d_k_M range: [0.2703, 0.8230], d_k_M_hat range: [0.4347, 0.9451]
2025-03-11 19:53:47 - Train Iteration 453: loss: 0.8629, d_k_M range: [0.0172, 0.7004], d_k_M_hat range: [0.0882, 0.8797]
2025-03-11 19:53:47 - Train Iteration 454: loss: 0.7174, d_k_M range: [0.2822, 0.6747], d_k_M_hat range: [0.4585, 0.8425]
2025-03-11 19:53:48 - Train Iteration 455: loss: 0.8295, d_k_M range: [0.0293, 0.6581], d_k_M_hat range: [0.1186, 0.8235]
2025-03-11 19:53:48 - Train Iteration 456: loss: 0.7474, d_k_M range: [0.0854, 0.5030], d_k_M_hat range: [0.2208, 0.6823]
2025-03-11 19:53:48 - Train Iteration 457: loss: 0.7175, d_k_M range: [0.1534, 0.5149], d_k_M_hat range: [0.3284, 0.6679]
2025-03-11 19:53:49 - Train Iteration 458: loss: 0.7799, d_k_M range: [0.0404, 0.8392], d_k_M_hat range: [0.1716, 0.9561]
2025-03-11 19:53:49 - Train Iteration 459: loss: 0.8947, d_k_M range: [0.0107, 0.4716], d_k_M_hat range: [0.0648, 0.6356]
2025-03-11 19:53:50 - Train Iteration 460: loss: 0.7755, d_k_M range: [0.0434, 0.5368], d_k_M_hat range: [0.1780, 0.6856]
2025-03-11 19:53:50 - Train Iteration 461: loss: 0.7321, d_k_M range: [0.2848, 0.6837], d_k_M_hat range: [0.4426, 0.8294]
2025-03-11 19:53:51 - Train Iteration 462: loss: 0.7227, d_k_M range: [0.2414, 0.5181], d_k_M_hat range: [0.4028, 0.7187]
2025-03-11 19:53:51 - Train Iteration 463: loss: 0.6587, d_k_M range: [0.0621, 0.4798], d_k_M_hat range: [0.2705, 0.6755]
2025-03-11 19:53:51 - Train Iteration 464: loss: 0.7892, d_k_M range: [0.0267, 0.6492], d_k_M_hat range: [0.1383, 0.8351]
2025-03-11 19:53:52 - Train Iteration 465: loss: 0.8192, d_k_M range: [0.3316, 0.8659], d_k_M_hat range: [0.5442, 0.9608]
2025-03-11 19:53:52 - Train Iteration 466: loss: 0.6987, d_k_M range: [0.0532, 0.5253], d_k_M_hat range: [0.2242, 0.7106]
2025-03-11 19:53:53 - Train Iteration 467: loss: 0.9349, d_k_M range: [0.2812, 0.9568], d_k_M_hat range: [0.4543, 0.9899]
2025-03-11 19:53:53 - Train Iteration 468: loss: 0.7266, d_k_M range: [0.0778, 0.5714], d_k_M_hat range: [0.2606, 0.7493]
2025-03-11 19:53:53 - Train Iteration 469: loss: 0.7773, d_k_M range: [0.0606, 0.6298], d_k_M_hat range: [0.1790, 0.7792]
2025-03-11 19:53:54 - Train Iteration 470: loss: 0.7241, d_k_M range: [0.1596, 0.7283], d_k_M_hat range: [0.3243, 0.8774]
2025-03-11 19:53:54 - Train Iteration 471: loss: 0.7610, d_k_M range: [0.0477, 0.6720], d_k_M_hat range: [0.1753, 0.8488]
2025-03-11 19:53:55 - Train Iteration 472: loss: 0.6937, d_k_M range: [0.1138, 0.5091], d_k_M_hat range: [0.2850, 0.6888]
2025-03-11 19:53:55 - Train Iteration 473: loss: 0.8830, d_k_M range: [0.0228, 0.4031], d_k_M_hat range: [0.0832, 0.5691]
2025-03-11 19:53:55 - Train Iteration 474: loss: 0.7007, d_k_M range: [0.0445, 0.7718], d_k_M_hat range: [0.2219, 0.9348]
2025-03-11 19:53:56 - Train Iteration 475: loss: 0.7888, d_k_M range: [0.0251, 0.5817], d_k_M_hat range: [0.1369, 0.7847]
2025-03-11 19:53:56 - Train Iteration 476: loss: 0.7222, d_k_M range: [0.1143, 0.7836], d_k_M_hat range: [0.3148, 0.9338]
2025-03-11 19:53:57 - Train Iteration 477: loss: 0.7570, d_k_M range: [0.0797, 0.6861], d_k_M_hat range: [0.2097, 0.8698]
2025-03-11 19:53:57 - Train Iteration 478: loss: 0.7082, d_k_M range: [0.2488, 0.7591], d_k_M_hat range: [0.4314, 0.9175]
2025-03-11 19:53:58 - Train Iteration 479: loss: 0.6968, d_k_M range: [0.0465, 0.6998], d_k_M_hat range: [0.2251, 0.8965]
2025-03-11 19:53:58 - Train Iteration 480: loss: 0.8298, d_k_M range: [0.0216, 0.7653], d_k_M_hat range: [0.1106, 0.9219]
2025-03-11 19:53:58 - Train Iteration 481: loss: 0.6776, d_k_M range: [0.2941, 0.6451], d_k_M_hat range: [0.4886, 0.8385]
2025-03-11 19:53:59 - Train Iteration 482: loss: 0.8370, d_k_M range: [0.0130, 0.6290], d_k_M_hat range: [0.0981, 0.8229]
2025-03-11 19:53:59 - Train Iteration 483: loss: 0.7136, d_k_M range: [0.0623, 0.7739], d_k_M_hat range: [0.2305, 0.9309]
2025-03-11 19:54:00 - Train Iteration 484: loss: 0.7485, d_k_M range: [0.0309, 0.5092], d_k_M_hat range: [0.1657, 0.6716]
2025-03-11 19:54:00 - Train Iteration 485: loss: 0.7429, d_k_M range: [0.0602, 0.6834], d_k_M_hat range: [0.1983, 0.8434]
2025-03-11 19:54:01 - Train Iteration 486: loss: 0.7048, d_k_M range: [0.1686, 0.5388], d_k_M_hat range: [0.3547, 0.7157]
2025-03-11 19:54:01 - Train Iteration 487: loss: 0.9591, d_k_M range: [0.0285, 0.9733], d_k_M_hat range: [0.2133, 0.9940]
2025-03-11 19:54:02 - Train Iteration 488: loss: 0.7233, d_k_M range: [0.1148, 0.5513], d_k_M_hat range: [0.2833, 0.7295]
2025-03-11 19:54:02 - Train Iteration 489: loss: 0.7281, d_k_M range: [0.2818, 0.7560], d_k_M_hat range: [0.4546, 0.9027]
2025-03-11 19:54:02 - Train Iteration 490: loss: 0.7370, d_k_M range: [0.0697, 0.8198], d_k_M_hat range: [0.2311, 0.9613]
2025-03-11 19:54:03 - Train Iteration 491: loss: 0.9521, d_k_M range: [0.0085, 0.6076], d_k_M_hat range: [0.0327, 0.7879]
2025-03-11 19:54:03 - Train Iteration 492: loss: 0.6937, d_k_M range: [0.0840, 0.5014], d_k_M_hat range: [0.2775, 0.6885]
2025-03-11 19:54:04 - Train Iteration 493: loss: 0.7320, d_k_M range: [0.1375, 0.7982], d_k_M_hat range: [0.3385, 0.9427]
2025-03-11 19:54:04 - Train Iteration 494: loss: 0.7114, d_k_M range: [0.1538, 0.6450], d_k_M_hat range: [0.3359, 0.8015]
2025-03-11 19:54:05 - Train Iteration 495: loss: 0.7412, d_k_M range: [0.1225, 0.4756], d_k_M_hat range: [0.2615, 0.6422]
2025-03-11 19:54:05 - Train Iteration 496: loss: 0.7164, d_k_M range: [0.0356, 0.4109], d_k_M_hat range: [0.1891, 0.5824]
2025-03-11 19:54:05 - Train Iteration 497: loss: 0.8797, d_k_M range: [0.0085, 0.4765], d_k_M_hat range: [0.0705, 0.6229]
2025-03-11 19:54:06 - Train Iteration 498: loss: 0.7103, d_k_M range: [0.1081, 0.7317], d_k_M_hat range: [0.3358, 0.8949]
2025-03-11 19:54:06 - Train Iteration 499: loss: 0.8753, d_k_M range: [0.0220, 0.6139], d_k_M_hat range: [0.0864, 0.7985]
2025-03-11 19:54:07 - Train Iteration 500: loss: 0.8150, d_k_M range: [0.3096, 0.8638], d_k_M_hat range: [0.4879, 0.9611]
2025-03-11 19:54:07 - Train Iteration 501: loss: 0.7141, d_k_M range: [0.1027, 0.7373], d_k_M_hat range: [0.2635, 0.8922]
2025-03-11 19:54:08 - Train Iteration 502: loss: 0.8345, d_k_M range: [0.0126, 0.3386], d_k_M_hat range: [0.0991, 0.5021]
2025-03-11 19:54:08 - Train Iteration 503: loss: 0.7431, d_k_M range: [0.1696, 0.8080], d_k_M_hat range: [0.3277, 0.9460]
2025-03-11 19:54:08 - Train Iteration 504: loss: 0.7418, d_k_M range: [0.3461, 0.6238], d_k_M_hat range: [0.5105, 0.7878]
2025-03-11 19:54:09 - Train Iteration 505: loss: 0.7341, d_k_M range: [0.2901, 0.6339], d_k_M_hat range: [0.4395, 0.8045]
2025-03-11 19:54:09 - Train Iteration 506: loss: 0.7291, d_k_M range: [0.1643, 0.6699], d_k_M_hat range: [0.3466, 0.8508]
2025-03-11 19:54:10 - Train Iteration 507: loss: 0.7131, d_k_M range: [0.1427, 0.7237], d_k_M_hat range: [0.3139, 0.8793]
2025-03-11 19:54:10 - Train Iteration 508: loss: 0.7052, d_k_M range: [0.1815, 0.6282], d_k_M_hat range: [0.3680, 0.8382]
2025-03-11 19:54:10 - Train Iteration 509: loss: 0.8399, d_k_M range: [0.1705, 0.8961], d_k_M_hat range: [0.3655, 0.9796]
2025-03-11 19:54:11 - Train Iteration 510: loss: 0.7390, d_k_M range: [0.0309, 0.5589], d_k_M_hat range: [0.1713, 0.7317]
2025-03-11 19:54:11 - Train Iteration 511: loss: 0.9656, d_k_M range: [0.1700, 0.9787], d_k_M_hat range: [0.3489, 0.9961]
2025-03-11 19:54:12 - Train Iteration 512: loss: 0.6827, d_k_M range: [0.2289, 0.6353], d_k_M_hat range: [0.4614, 0.8090]
2025-03-11 19:54:12 - Train Iteration 513: loss: 0.7074, d_k_M range: [0.2073, 0.5375], d_k_M_hat range: [0.4119, 0.7356]
2025-03-11 19:54:12 - Train Iteration 514: loss: 0.7260, d_k_M range: [0.1734, 0.7167], d_k_M_hat range: [0.3669, 0.8700]
2025-03-11 19:54:13 - Train Iteration 515: loss: 0.7461, d_k_M range: [0.0330, 0.4722], d_k_M_hat range: [0.1692, 0.6810]
2025-03-11 19:54:13 - Train Iteration 516: loss: 0.6825, d_k_M range: [0.1516, 0.4495], d_k_M_hat range: [0.3433, 0.6363]
2025-03-11 19:54:14 - Train Iteration 517: loss: 0.7006, d_k_M range: [0.0597, 0.5591], d_k_M_hat range: [0.2227, 0.7485]
2025-03-11 19:54:14 - Train Iteration 518: loss: 0.6681, d_k_M range: [0.2439, 0.7150], d_k_M_hat range: [0.4347, 0.8977]
2025-03-11 19:54:14 - Train Iteration 519: loss: 0.6665, d_k_M range: [0.1156, 0.6540], d_k_M_hat range: [0.3265, 0.8529]
2025-03-11 19:54:15 - Train Iteration 520: loss: 0.6741, d_k_M range: [0.0306, 0.6696], d_k_M_hat range: [0.2209, 0.8710]
2025-03-11 19:54:15 - Train Iteration 521: loss: 0.7709, d_k_M range: [0.0283, 0.3140], d_k_M_hat range: [0.1503, 0.4948]
2025-03-11 19:54:16 - Train Iteration 522: loss: 0.6851, d_k_M range: [0.2058, 0.6360], d_k_M_hat range: [0.4021, 0.8082]
2025-03-11 19:54:16 - Train Iteration 523: loss: 0.6849, d_k_M range: [0.0919, 0.5766], d_k_M_hat range: [0.3022, 0.7674]
2025-03-11 19:54:17 - Train Iteration 524: loss: 0.8584, d_k_M range: [0.2358, 0.9075], d_k_M_hat range: [0.4367, 0.9810]
2025-03-11 19:54:17 - Train Iteration 525: loss: 0.7112, d_k_M range: [0.3278, 0.6762], d_k_M_hat range: [0.5229, 0.8504]
2025-03-11 19:54:17 - Train Iteration 526: loss: 0.9173, d_k_M range: [0.0059, 0.5566], d_k_M_hat range: [0.0482, 0.7461]
2025-03-11 19:54:18 - Train Iteration 527: loss: 0.6940, d_k_M range: [0.2927, 0.7734], d_k_M_hat range: [0.4748, 0.9403]
2025-03-11 19:54:18 - Train Iteration 528: loss: 0.9621, d_k_M range: [0.2071, 0.9757], d_k_M_hat range: [0.3854, 0.9949]
2025-03-11 19:54:19 - Train Iteration 529: loss: 0.7155, d_k_M range: [0.0518, 0.4888], d_k_M_hat range: [0.2180, 0.6871]
2025-03-11 19:54:19 - Train Iteration 530: loss: 0.7701, d_k_M range: [0.3321, 0.8451], d_k_M_hat range: [0.5387, 0.9675]
2025-03-11 19:54:19 - Train Iteration 531: loss: 0.7833, d_k_M range: [0.0295, 0.5503], d_k_M_hat range: [0.1563, 0.7097]
2025-03-11 19:54:20 - Train Iteration 532: loss: 0.7328, d_k_M range: [0.2801, 0.6368], d_k_M_hat range: [0.4797, 0.7808]
2025-03-11 19:54:20 - Train Iteration 533: loss: 0.7028, d_k_M range: [0.2555, 0.7703], d_k_M_hat range: [0.4597, 0.9365]
2025-03-11 19:54:21 - Train Iteration 534: loss: 0.7057, d_k_M range: [0.1090, 0.5317], d_k_M_hat range: [0.2690, 0.7197]
2025-03-11 19:54:21 - Train Iteration 535: loss: 0.6998, d_k_M range: [0.1426, 0.6769], d_k_M_hat range: [0.3305, 0.8610]
2025-03-11 19:54:22 - Train Iteration 536: loss: 0.7341, d_k_M range: [0.2024, 0.8088], d_k_M_hat range: [0.4418, 0.9520]
2025-03-11 19:54:22 - Train Iteration 537: loss: 0.7921, d_k_M range: [0.0288, 0.6822], d_k_M_hat range: [0.1388, 0.8701]
2025-03-11 19:54:23 - Train Iteration 538: loss: 0.6847, d_k_M range: [0.2081, 0.6510], d_k_M_hat range: [0.3846, 0.8520]
2025-03-11 19:54:23 - Train Iteration 539: loss: 0.6876, d_k_M range: [0.0546, 0.4203], d_k_M_hat range: [0.2400, 0.5910]
2025-03-11 19:54:23 - Train Iteration 540: loss: 0.7992, d_k_M range: [0.0131, 0.6524], d_k_M_hat range: [0.1192, 0.8557]
2025-03-11 19:54:24 - Train Iteration 541: loss: 0.6811, d_k_M range: [0.3367, 0.7411], d_k_M_hat range: [0.5216, 0.9178]
2025-03-11 19:54:24 - Train Iteration 542: loss: 0.6784, d_k_M range: [0.0757, 0.6201], d_k_M_hat range: [0.2521, 0.8157]
2025-03-11 19:54:25 - Train Iteration 543: loss: 0.7339, d_k_M range: [0.0534, 0.7525], d_k_M_hat range: [0.2644, 0.9004]
2025-03-11 19:54:25 - Train Iteration 544: loss: 0.6704, d_k_M range: [0.2026, 0.6067], d_k_M_hat range: [0.3996, 0.7928]
2025-03-11 19:54:26 - Train Iteration 545: loss: 0.7124, d_k_M range: [0.2391, 0.6687], d_k_M_hat range: [0.4335, 0.8247]
2025-03-11 19:54:26 - Train Iteration 546: loss: 0.8168, d_k_M range: [0.0140, 0.5485], d_k_M_hat range: [0.1103, 0.7458]
2025-03-11 19:54:26 - Train Iteration 547: loss: 0.6716, d_k_M range: [0.2220, 0.6874], d_k_M_hat range: [0.4045, 0.8679]
2025-03-11 19:54:27 - Train Iteration 548: loss: 0.6935, d_k_M range: [0.0736, 0.5770], d_k_M_hat range: [0.2408, 0.7641]
2025-03-11 19:54:27 - Train Iteration 549: loss: 0.7217, d_k_M range: [0.1774, 0.7712], d_k_M_hat range: [0.3279, 0.9305]
2025-03-11 19:54:28 - Train Iteration 550: loss: 0.6984, d_k_M range: [0.0639, 0.5240], d_k_M_hat range: [0.2282, 0.7152]
2025-03-11 19:54:28 - Train Iteration 551: loss: 0.7475, d_k_M range: [0.2109, 0.7878], d_k_M_hat range: [0.3812, 0.9232]
2025-03-11 19:54:29 - Train Iteration 552: loss: 0.7715, d_k_M range: [0.2019, 0.8341], d_k_M_hat range: [0.3842, 0.9557]
2025-03-11 19:54:29 - Train Iteration 553: loss: 0.7236, d_k_M range: [0.0520, 0.6877], d_k_M_hat range: [0.2014, 0.8632]
2025-03-11 19:54:30 - Train Iteration 554: loss: 0.9264, d_k_M range: [0.3987, 0.9527], d_k_M_hat range: [0.5637, 0.9902]
2025-03-11 19:54:30 - Train Iteration 555: loss: 0.7441, d_k_M range: [0.1287, 0.7804], d_k_M_hat range: [0.2967, 0.9221]
2025-03-11 19:54:30 - Train Iteration 556: loss: 0.7214, d_k_M range: [0.0683, 0.7174], d_k_M_hat range: [0.2380, 0.8767]
2025-03-11 19:54:31 - Train Iteration 557: loss: 0.7680, d_k_M range: [0.1587, 0.8180], d_k_M_hat range: [0.3267, 0.9417]
2025-03-11 19:54:31 - Train Iteration 558: loss: 0.6965, d_k_M range: [0.0781, 0.4825], d_k_M_hat range: [0.2712, 0.6479]
2025-03-11 19:54:32 - Train Iteration 559: loss: 0.7034, d_k_M range: [0.1024, 0.6475], d_k_M_hat range: [0.3003, 0.8548]
2025-03-11 19:54:32 - Train Iteration 560: loss: 0.8739, d_k_M range: [0.0083, 0.4996], d_k_M_hat range: [0.0796, 0.6934]
2025-03-11 19:54:32 - Train Iteration 561: loss: 0.6952, d_k_M range: [0.2863, 0.6521], d_k_M_hat range: [0.4716, 0.8274]
2025-03-11 19:54:33 - Train Iteration 562: loss: 0.7165, d_k_M range: [0.0489, 0.6386], d_k_M_hat range: [0.2071, 0.8049]
2025-03-11 19:54:33 - Train Iteration 563: loss: 0.8049, d_k_M range: [0.3022, 0.8678], d_k_M_hat range: [0.5069, 0.9706]
2025-03-11 19:54:34 - Train Iteration 564: loss: 0.7713, d_k_M range: [0.0426, 0.4876], d_k_M_hat range: [0.1861, 0.6965]
2025-03-11 19:54:34 - Train Iteration 565: loss: 0.7003, d_k_M range: [0.0698, 0.5362], d_k_M_hat range: [0.2491, 0.7211]
2025-03-11 19:54:34 - Train Iteration 566: loss: 0.6835, d_k_M range: [0.1550, 0.4866], d_k_M_hat range: [0.3423, 0.7151]
2025-03-11 19:54:35 - Train Iteration 567: loss: 0.7006, d_k_M range: [0.2159, 0.7493], d_k_M_hat range: [0.4005, 0.9123]
2025-03-11 19:54:35 - Train Iteration 568: loss: 0.7134, d_k_M range: [0.1394, 0.4575], d_k_M_hat range: [0.3038, 0.6467]
2025-03-11 19:54:36 - Train Iteration 569: loss: 0.7152, d_k_M range: [0.0216, 0.7313], d_k_M_hat range: [0.1759, 0.9080]
2025-03-11 19:54:36 - Train Iteration 570: loss: 0.6741, d_k_M range: [0.2151, 0.6155], d_k_M_hat range: [0.4332, 0.8449]
2025-03-11 19:54:36 - Train Iteration 571: loss: 0.7646, d_k_M range: [0.0175, 0.3371], d_k_M_hat range: [0.1431, 0.5353]
2025-03-11 19:54:37 - Train Iteration 572: loss: 0.6478, d_k_M range: [0.1756, 0.6827], d_k_M_hat range: [0.3863, 0.8874]
2025-03-11 19:54:37 - Train Iteration 573: loss: 0.7132, d_k_M range: [0.1355, 0.5952], d_k_M_hat range: [0.3205, 0.7928]
2025-03-11 19:54:38 - Train Iteration 574: loss: 0.7028, d_k_M range: [0.1462, 0.7447], d_k_M_hat range: [0.3244, 0.9112]
2025-03-11 19:54:38 - Train Iteration 575: loss: 0.6873, d_k_M range: [0.1839, 0.5876], d_k_M_hat range: [0.3673, 0.7790]
2025-03-11 19:54:39 - Train Iteration 576: loss: 0.8116, d_k_M range: [0.0333, 0.8830], d_k_M_hat range: [0.1666, 0.9821]
2025-03-11 19:54:39 - Train Iteration 577: loss: 0.7336, d_k_M range: [0.0405, 0.7780], d_k_M_hat range: [0.1839, 0.9313]
2025-03-11 19:54:39 - Train Iteration 578: loss: 0.8219, d_k_M range: [0.2805, 0.8801], d_k_M_hat range: [0.4760, 0.9735]
2025-03-11 19:54:40 - Train Iteration 579: loss: 0.7114, d_k_M range: [0.0356, 0.5501], d_k_M_hat range: [0.1946, 0.7244]
2025-03-11 19:54:40 - Train Iteration 580: loss: 0.7316, d_k_M range: [0.0891, 0.7242], d_k_M_hat range: [0.2663, 0.9164]
2025-03-11 19:54:41 - Train Iteration 581: loss: 0.6673, d_k_M range: [0.1560, 0.6786], d_k_M_hat range: [0.3392, 0.8733]
2025-03-11 19:54:41 - Train Iteration 582: loss: 0.8983, d_k_M range: [0.0076, 0.5068], d_k_M_hat range: [0.0598, 0.6969]
2025-03-11 19:54:41 - Train Iteration 583: loss: 0.7231, d_k_M range: [0.0976, 0.6874], d_k_M_hat range: [0.3067, 0.8625]
2025-03-11 19:54:42 - Train Iteration 584: loss: 0.7201, d_k_M range: [0.3123, 0.7482], d_k_M_hat range: [0.4793, 0.8996]
2025-03-11 19:54:42 - Train Iteration 585: loss: 0.7009, d_k_M range: [0.0295, 0.7333], d_k_M_hat range: [0.2205, 0.9217]
2025-03-11 19:54:43 - Train Iteration 586: loss: 0.6723, d_k_M range: [0.1855, 0.7299], d_k_M_hat range: [0.4228, 0.9292]
2025-03-11 19:54:43 - Train Iteration 587: loss: 0.7401, d_k_M range: [0.0240, 0.4968], d_k_M_hat range: [0.1637, 0.6672]
2025-03-11 19:54:44 - Train Iteration 588: loss: 0.7102, d_k_M range: [0.2692, 0.6510], d_k_M_hat range: [0.5062, 0.8562]
2025-03-11 19:54:44 - Train Iteration 589: loss: 0.7965, d_k_M range: [0.2578, 0.8520], d_k_M_hat range: [0.4686, 0.9595]
2025-03-11 19:54:44 - Train Iteration 590: loss: 0.7187, d_k_M range: [0.2864, 0.6887], d_k_M_hat range: [0.4747, 0.8865]
2025-03-11 19:54:45 - Train Iteration 591: loss: 0.6864, d_k_M range: [0.0253, 0.7055], d_k_M_hat range: [0.2014, 0.8936]
2025-03-11 19:54:45 - Train Iteration 592: loss: 0.8528, d_k_M range: [0.2130, 0.9024], d_k_M_hat range: [0.4316, 0.9789]
2025-03-11 19:54:46 - Train Iteration 593: loss: 0.7266, d_k_M range: [0.2237, 0.6694], d_k_M_hat range: [0.4327, 0.8367]
2025-03-11 19:54:46 - Train Iteration 594: loss: 0.6713, d_k_M range: [0.1296, 0.4357], d_k_M_hat range: [0.3324, 0.6356]
2025-03-11 19:54:47 - Train Iteration 595: loss: 0.7160, d_k_M range: [0.0492, 0.6497], d_k_M_hat range: [0.2030, 0.8308]
2025-03-11 19:54:47 - Train Iteration 596: loss: 0.8787, d_k_M range: [0.0165, 0.7109], d_k_M_hat range: [0.0791, 0.8932]
2025-03-11 19:54:47 - Train Iteration 597: loss: 0.7717, d_k_M range: [0.3093, 0.8345], d_k_M_hat range: [0.4681, 0.9561]
2025-03-11 19:54:48 - Train Iteration 598: loss: 0.6923, d_k_M range: [0.3059, 0.6160], d_k_M_hat range: [0.4738, 0.8055]
2025-03-11 19:54:48 - Train Iteration 599: loss: 0.7062, d_k_M range: [0.1243, 0.4663], d_k_M_hat range: [0.3191, 0.6554]
2025-03-11 19:54:49 - Train Iteration 600: loss: 0.7087, d_k_M range: [0.1334, 0.5925], d_k_M_hat range: [0.3193, 0.8121]
2025-03-11 19:54:49 - Train Iteration 601: loss: 0.7397, d_k_M range: [0.1822, 0.7321], d_k_M_hat range: [0.3661, 0.8933]
2025-03-11 19:54:49 - Train Iteration 602: loss: 0.7536, d_k_M range: [0.0696, 0.7608], d_k_M_hat range: [0.3107, 0.9219]
2025-03-11 19:54:50 - Train Iteration 603: loss: 0.7809, d_k_M range: [0.1705, 0.8191], d_k_M_hat range: [0.3655, 0.9354]
2025-03-11 19:54:50 - Train Iteration 604: loss: 0.7036, d_k_M range: [0.2165, 0.6527], d_k_M_hat range: [0.3814, 0.8139]
2025-03-11 19:54:51 - Train Iteration 605: loss: 0.7610, d_k_M range: [0.2214, 0.8182], d_k_M_hat range: [0.4342, 0.9458]
2025-03-11 19:54:51 - Train Iteration 606: loss: 0.7150, d_k_M range: [0.1095, 0.6848], d_k_M_hat range: [0.2735, 0.8393]
2025-03-11 19:54:51 - Train Iteration 607: loss: 0.8618, d_k_M range: [0.0079, 0.4962], d_k_M_hat range: [0.0796, 0.6979]
2025-03-11 19:54:52 - Train Iteration 608: loss: 0.6866, d_k_M range: [0.3131, 0.6705], d_k_M_hat range: [0.5034, 0.8512]
2025-03-11 19:54:52 - Train Iteration 609: loss: 0.7441, d_k_M range: [0.2011, 0.6368], d_k_M_hat range: [0.3534, 0.8209]
2025-03-11 19:54:53 - Train Iteration 610: loss: 0.7257, d_k_M range: [0.0651, 0.3533], d_k_M_hat range: [0.2668, 0.5505]
2025-03-11 19:54:53 - Train Iteration 611: loss: 0.7534, d_k_M range: [0.0950, 0.7814], d_k_M_hat range: [0.3125, 0.9134]
2025-03-11 19:54:54 - Train Iteration 612: loss: 0.7242, d_k_M range: [0.1924, 0.7999], d_k_M_hat range: [0.3759, 0.9489]
2025-03-11 19:54:54 - Train Iteration 613: loss: 0.6534, d_k_M range: [0.0446, 0.3846], d_k_M_hat range: [0.2363, 0.6079]
2025-03-11 19:54:54 - Train Iteration 614: loss: 0.8820, d_k_M range: [0.0869, 0.9285], d_k_M_hat range: [0.2718, 0.9893]
2025-03-11 19:54:55 - Train Iteration 615: loss: 0.6768, d_k_M range: [0.2889, 0.7519], d_k_M_hat range: [0.4865, 0.9292]
2025-03-11 19:54:55 - Train Iteration 616: loss: 0.6956, d_k_M range: [0.0269, 0.7059], d_k_M_hat range: [0.2034, 0.8718]
2025-03-11 19:54:56 - Train Iteration 617: loss: 0.8023, d_k_M range: [0.0570, 0.8721], d_k_M_hat range: [0.2690, 0.9763]
2025-03-11 19:54:56 - Train Iteration 618: loss: 0.7905, d_k_M range: [0.0276, 0.3095], d_k_M_hat range: [0.1385, 0.5124]
2025-03-11 19:54:56 - Train Iteration 619: loss: 0.6630, d_k_M range: [0.2430, 0.7040], d_k_M_hat range: [0.4441, 0.8954]
2025-03-11 19:54:57 - Train Iteration 620: loss: 0.8476, d_k_M range: [0.0489, 0.9022], d_k_M_hat range: [0.2264, 0.9815]
2025-03-11 19:54:57 - Train Iteration 621: loss: 0.6748, d_k_M range: [0.1427, 0.6963], d_k_M_hat range: [0.3561, 0.8748]
2025-03-11 19:54:58 - Train Iteration 622: loss: 0.8452, d_k_M range: [0.0144, 0.7332], d_k_M_hat range: [0.0951, 0.9421]
2025-03-11 19:54:58 - Train Iteration 623: loss: 0.9202, d_k_M range: [0.1459, 0.9509], d_k_M_hat range: [0.4081, 0.9916]
2025-03-11 19:54:59 - Train Iteration 624: loss: 0.7096, d_k_M range: [0.0371, 0.6781], d_k_M_hat range: [0.1947, 0.8856]
2025-03-11 19:54:59 - Train Iteration 625: loss: 0.9274, d_k_M range: [0.0997, 0.9530], d_k_M_hat range: [0.3142, 0.9900]
2025-03-11 19:54:59 - Train Iteration 626: loss: 0.6862, d_k_M range: [0.0562, 0.5140], d_k_M_hat range: [0.2303, 0.7274]
2025-03-11 19:55:00 - Train Iteration 627: loss: 0.6812, d_k_M range: [0.1721, 0.5709], d_k_M_hat range: [0.3714, 0.7580]
2025-03-11 19:55:00 - Train Iteration 628: loss: 0.6865, d_k_M range: [0.1159, 0.5460], d_k_M_hat range: [0.3098, 0.7338]
2025-03-11 19:55:01 - Train Iteration 629: loss: 0.8520, d_k_M range: [0.0112, 0.9028], d_k_M_hat range: [0.1047, 0.9797]
2025-03-11 19:55:01 - Train Iteration 630: loss: 0.9562, d_k_M range: [0.0026, 0.3354], d_k_M_hat range: [0.0248, 0.5278]
2025-03-11 19:55:02 - Train Iteration 631: loss: 0.7871, d_k_M range: [0.0172, 0.8345], d_k_M_hat range: [0.1428, 0.9474]
2025-03-11 19:55:02 - Train Iteration 632: loss: 0.7981, d_k_M range: [0.0117, 0.3854], d_k_M_hat range: [0.1184, 0.5613]
2025-03-11 19:55:02 - Train Iteration 633: loss: 0.7101, d_k_M range: [0.3545, 0.7489], d_k_M_hat range: [0.5503, 0.9140]
2025-03-11 19:55:03 - Train Iteration 634: loss: 0.7664, d_k_M range: [0.2302, 0.8350], d_k_M_hat range: [0.4429, 0.9596]
2025-03-11 19:55:03 - Train Iteration 635: loss: 0.7003, d_k_M range: [0.1388, 0.5665], d_k_M_hat range: [0.3119, 0.7386]
2025-03-11 19:55:04 - Train Iteration 636: loss: 0.6814, d_k_M range: [0.0340, 0.5532], d_k_M_hat range: [0.2102, 0.7515]
2025-03-11 19:55:04 - Train Iteration 637: loss: 0.7374, d_k_M range: [0.1023, 0.3807], d_k_M_hat range: [0.2436, 0.5744]
2025-03-11 19:55:04 - Train Iteration 638: loss: 0.6807, d_k_M range: [0.0819, 0.4280], d_k_M_hat range: [0.2785, 0.6081]
2025-03-11 19:55:05 - Train Iteration 639: loss: 0.7590, d_k_M range: [0.0620, 0.8307], d_k_M_hat range: [0.2823, 0.9595]
2025-03-11 19:55:05 - Train Iteration 640: loss: 0.8447, d_k_M range: [0.0057, 0.4579], d_k_M_hat range: [0.0866, 0.6566]
2025-03-11 19:55:06 - Train Iteration 641: loss: 0.8097, d_k_M range: [0.1753, 0.8766], d_k_M_hat range: [0.3754, 0.9768]
2025-03-11 19:55:06 - Train Iteration 642: loss: 0.6739, d_k_M range: [0.1008, 0.4199], d_k_M_hat range: [0.2978, 0.6314]
2025-03-11 19:55:07 - Train Iteration 643: loss: 0.8016, d_k_M range: [0.1105, 0.8686], d_k_M_hat range: [0.3286, 0.9733]
2025-03-11 19:55:07 - Train Iteration 644: loss: 0.7092, d_k_M range: [0.1300, 0.5340], d_k_M_hat range: [0.3040, 0.7670]
2025-03-11 19:55:08 - Train Iteration 645: loss: 0.6850, d_k_M range: [0.2538, 0.6979], d_k_M_hat range: [0.4791, 0.8703]
2025-03-11 19:55:08 - Train Iteration 646: loss: 0.8557, d_k_M range: [0.0095, 0.7142], d_k_M_hat range: [0.0845, 0.8990]
2025-03-11 19:55:09 - Train Iteration 647: loss: 0.6738, d_k_M range: [0.3388, 0.4864], d_k_M_hat range: [0.5397, 0.7004]
2025-03-11 19:55:09 - Train Iteration 648: loss: 0.6714, d_k_M range: [0.1491, 0.5518], d_k_M_hat range: [0.3496, 0.7324]
2025-03-11 19:55:09 - Train Iteration 649: loss: 0.7286, d_k_M range: [0.3290, 0.7852], d_k_M_hat range: [0.5070, 0.9316]
2025-03-11 19:55:10 - Train Iteration 650: loss: 0.7101, d_k_M range: [0.1458, 0.5689], d_k_M_hat range: [0.3421, 0.7687]
2025-03-11 19:55:10 - Train Iteration 651: loss: 0.6458, d_k_M range: [0.1157, 0.5010], d_k_M_hat range: [0.3484, 0.7156]
2025-03-11 19:55:11 - Train Iteration 652: loss: 0.7119, d_k_M range: [0.2129, 0.4435], d_k_M_hat range: [0.3691, 0.6398]
2025-03-11 19:55:11 - Train Iteration 653: loss: 0.6745, d_k_M range: [0.1446, 0.7190], d_k_M_hat range: [0.4204, 0.9114]
2025-03-11 19:55:12 - Train Iteration 654: loss: 0.7322, d_k_M range: [0.0076, 0.5741], d_k_M_hat range: [0.1519, 0.8046]
2025-03-11 19:55:12 - Train Iteration 655: loss: 0.8202, d_k_M range: [0.3782, 0.8890], d_k_M_hat range: [0.5849, 0.9834]
2025-03-11 19:55:12 - Train Iteration 656: loss: 0.6904, d_k_M range: [0.2091, 0.7254], d_k_M_hat range: [0.4026, 0.8944]
2025-03-11 19:55:13 - Train Iteration 657: loss: 0.6345, d_k_M range: [0.1853, 0.6089], d_k_M_hat range: [0.3887, 0.8393]
2025-03-11 19:55:14 - Train Iteration 658: loss: 0.6467, d_k_M range: [0.2833, 0.6825], d_k_M_hat range: [0.5083, 0.8905]
2025-03-11 19:55:14 - Train Iteration 659: loss: 0.7372, d_k_M range: [0.0148, 0.4495], d_k_M_hat range: [0.1562, 0.6872]
2025-03-11 19:55:14 - Train Iteration 660: loss: 0.6716, d_k_M range: [0.0876, 0.7143], d_k_M_hat range: [0.2717, 0.8948]
2025-03-11 19:55:15 - Train Iteration 661: loss: 0.6191, d_k_M range: [0.2232, 0.6311], d_k_M_hat range: [0.4699, 0.8507]
2025-03-11 19:55:15 - Train Iteration 662: loss: 0.9375, d_k_M range: [0.0032, 0.4485], d_k_M_hat range: [0.0349, 0.7472]
2025-03-11 19:55:16 - Train Iteration 663: loss: 0.8409, d_k_M range: [0.3096, 0.9026], d_k_M_hat range: [0.5030, 0.9855]
2025-03-11 19:55:16 - Train Iteration 664: loss: 0.6818, d_k_M range: [0.1041, 0.7369], d_k_M_hat range: [0.3017, 0.9274]
2025-03-11 19:55:16 - Train Iteration 665: loss: 0.6753, d_k_M range: [0.2431, 0.7303], d_k_M_hat range: [0.4401, 0.9085]
2025-03-11 19:55:17 - Train Iteration 666: loss: 0.7011, d_k_M range: [0.0356, 0.4450], d_k_M_hat range: [0.2207, 0.6168]
2025-03-11 19:55:17 - Train Iteration 667: loss: 0.6778, d_k_M range: [0.0812, 0.6041], d_k_M_hat range: [0.2921, 0.7998]
2025-03-11 19:55:18 - Train Iteration 668: loss: 0.6803, d_k_M range: [0.0226, 0.4681], d_k_M_hat range: [0.2173, 0.6695]
2025-03-11 19:55:18 - Train Iteration 669: loss: 0.6811, d_k_M range: [0.0315, 0.6151], d_k_M_hat range: [0.2321, 0.8014]
2025-03-11 19:55:19 - Train Iteration 670: loss: 0.6605, d_k_M range: [0.1691, 0.5711], d_k_M_hat range: [0.3563, 0.7664]
2025-03-11 19:55:19 - Train Iteration 671: loss: 0.6594, d_k_M range: [0.1243, 0.6463], d_k_M_hat range: [0.3365, 0.8343]
2025-03-11 19:55:19 - Train Iteration 672: loss: 0.8144, d_k_M range: [0.0171, 0.5359], d_k_M_hat range: [0.1147, 0.7513]
2025-03-11 19:55:20 - Train Iteration 673: loss: 0.6858, d_k_M range: [0.3203, 0.5395], d_k_M_hat range: [0.5030, 0.7203]
2025-03-11 19:55:20 - Train Iteration 674: loss: 0.6678, d_k_M range: [0.0775, 0.6812], d_k_M_hat range: [0.3071, 0.8721]
2025-03-11 19:55:21 - Train Iteration 675: loss: 0.7055, d_k_M range: [0.2647, 0.6465], d_k_M_hat range: [0.4555, 0.8420]
2025-03-11 19:55:21 - Train Iteration 676: loss: 0.6788, d_k_M range: [0.3122, 0.5598], d_k_M_hat range: [0.5180, 0.7838]
2025-03-11 19:55:22 - Train Iteration 677: loss: 0.6662, d_k_M range: [0.0546, 0.7497], d_k_M_hat range: [0.2759, 0.9335]
2025-03-11 19:55:22 - Train Iteration 678: loss: 0.9225, d_k_M range: [0.0075, 0.6567], d_k_M_hat range: [0.0470, 0.8661]
2025-03-11 19:55:22 - Train Iteration 679: loss: 0.6815, d_k_M range: [0.2823, 0.6039], d_k_M_hat range: [0.4567, 0.8403]
2025-03-11 19:55:23 - Train Iteration 680: loss: 0.6977, d_k_M range: [0.0243, 0.6537], d_k_M_hat range: [0.1890, 0.8408]
2025-03-11 19:55:23 - Train Iteration 681: loss: 0.6731, d_k_M range: [0.2558, 0.7231], d_k_M_hat range: [0.4617, 0.9150]
2025-03-11 19:55:24 - Train Iteration 682: loss: 0.8948, d_k_M range: [0.1898, 0.9366], d_k_M_hat range: [0.3741, 0.9907]
2025-03-11 19:55:24 - Train Iteration 683: loss: 0.7375, d_k_M range: [0.0376, 0.3474], d_k_M_hat range: [0.1788, 0.5617]
2025-03-11 19:55:24 - Train Iteration 684: loss: 0.9578, d_k_M range: [0.2683, 0.9756], d_k_M_hat range: [0.4648, 0.9969]
2025-03-11 19:55:25 - Train Iteration 685: loss: 0.6616, d_k_M range: [0.2486, 0.6593], d_k_M_hat range: [0.4486, 0.8492]
2025-03-11 19:55:25 - Train Iteration 686: loss: 0.7508, d_k_M range: [0.2674, 0.8109], d_k_M_hat range: [0.4850, 0.9444]
2025-03-11 19:55:26 - Train Iteration 687: loss: 0.6998, d_k_M range: [0.0378, 0.5375], d_k_M_hat range: [0.2012, 0.7445]
2025-03-11 19:55:26 - Train Iteration 688: loss: 0.6977, d_k_M range: [0.2844, 0.6317], d_k_M_hat range: [0.4823, 0.8185]
2025-03-11 19:55:27 - Train Iteration 689: loss: 0.7151, d_k_M range: [0.2653, 0.7565], d_k_M_hat range: [0.4330, 0.9109]
2025-03-11 19:55:27 - Train Iteration 690: loss: 0.7630, d_k_M range: [0.3759, 0.8313], d_k_M_hat range: [0.6238, 0.9691]
2025-03-11 19:55:27 - Train Iteration 691: loss: 0.9093, d_k_M range: [0.2204, 0.9410], d_k_M_hat range: [0.4145, 0.9875]
2025-03-11 19:55:28 - Train Iteration 692: loss: 0.7204, d_k_M range: [0.2119, 0.4460], d_k_M_hat range: [0.3635, 0.6357]
2025-03-11 19:55:28 - Train Iteration 693: loss: 0.7167, d_k_M range: [0.0521, 0.3425], d_k_M_hat range: [0.2450, 0.5069]
2025-03-11 19:55:29 - Train Iteration 694: loss: 0.6710, d_k_M range: [0.1334, 0.6113], d_k_M_hat range: [0.3738, 0.7922]
2025-03-11 19:55:29 - Train Iteration 695: loss: 0.6838, d_k_M range: [0.3729, 0.7067], d_k_M_hat range: [0.5936, 0.9162]
2025-03-11 19:55:30 - Train Iteration 696: loss: 0.6900, d_k_M range: [0.0418, 0.5083], d_k_M_hat range: [0.2141, 0.7354]
2025-03-11 19:55:30 - Train Iteration 697: loss: 0.6480, d_k_M range: [0.2135, 0.6907], d_k_M_hat range: [0.4384, 0.9090]
2025-03-11 19:55:31 - Train Iteration 698: loss: 0.6669, d_k_M range: [0.1218, 0.6685], d_k_M_hat range: [0.3328, 0.8829]
2025-03-11 19:55:31 - Train Iteration 699: loss: 0.6928, d_k_M range: [0.0241, 0.7489], d_k_M_hat range: [0.1970, 0.9374]
2025-03-11 19:55:32 - Train Iteration 700: loss: 0.7257, d_k_M range: [0.2011, 0.7967], d_k_M_hat range: [0.4118, 0.9549]
2025-03-11 19:55:32 - Train Iteration 701: loss: 0.6829, d_k_M range: [0.0986, 0.6373], d_k_M_hat range: [0.3146, 0.8546]
2025-03-11 19:55:32 - Train Iteration 702: loss: 0.6555, d_k_M range: [0.2346, 0.5073], d_k_M_hat range: [0.4250, 0.7080]
2025-03-11 19:55:33 - Train Iteration 703: loss: 0.8930, d_k_M range: [0.0042, 0.8608], d_k_M_hat range: [0.0592, 0.9784]
2025-03-11 19:55:33 - Train Iteration 704: loss: 0.6322, d_k_M range: [0.3120, 0.6498], d_k_M_hat range: [0.5408, 0.8725]
2025-03-11 19:55:34 - Train Iteration 705: loss: 0.6347, d_k_M range: [0.1104, 0.6079], d_k_M_hat range: [0.3218, 0.8500]
2025-03-11 19:55:34 - Train Iteration 706: loss: 0.6885, d_k_M range: [0.0548, 0.6413], d_k_M_hat range: [0.2326, 0.8640]
2025-03-11 19:55:35 - Train Iteration 707: loss: 0.6316, d_k_M range: [0.1240, 0.5797], d_k_M_hat range: [0.3433, 0.8315]
2025-03-11 19:55:35 - Train Iteration 708: loss: 0.9727, d_k_M range: [0.0669, 0.9846], d_k_M_hat range: [0.3361, 0.9983]
2025-03-11 19:55:36 - Train Iteration 709: loss: 0.6973, d_k_M range: [0.2250, 0.7774], d_k_M_hat range: [0.4433, 0.9424]
2025-03-11 19:55:36 - Train Iteration 710: loss: 0.7763, d_k_M range: [0.0054, 0.6600], d_k_M_hat range: [0.1243, 0.8937]
2025-03-11 19:55:37 - Train Iteration 711: loss: 0.9157, d_k_M range: [0.4897, 0.9488], d_k_M_hat range: [0.7133, 0.9919]
2025-03-11 19:55:37 - Train Iteration 712: loss: 0.6836, d_k_M range: [0.2342, 0.7359], d_k_M_hat range: [0.4248, 0.9091]
2025-03-11 19:55:37 - Train Iteration 713: loss: 0.7547, d_k_M range: [0.0288, 0.5217], d_k_M_hat range: [0.1601, 0.7017]
2025-03-11 19:55:38 - Train Iteration 714: loss: 0.8351, d_k_M range: [0.0685, 0.8936], d_k_M_hat range: [0.1573, 0.9798]
2025-03-11 19:55:38 - Train Iteration 715: loss: 0.7253, d_k_M range: [0.1625, 0.4949], d_k_M_hat range: [0.3108, 0.6761]
2025-03-11 19:55:39 - Train Iteration 716: loss: 0.6868, d_k_M range: [0.0920, 0.5914], d_k_M_hat range: [0.2884, 0.7720]
2025-03-11 19:55:39 - Train Iteration 717: loss: 0.6827, d_k_M range: [0.2375, 0.6602], d_k_M_hat range: [0.4614, 0.8340]
2025-03-11 19:55:39 - Train Iteration 718: loss: 0.6857, d_k_M range: [0.1539, 0.7654], d_k_M_hat range: [0.3290, 0.9374]
2025-03-11 19:55:40 - Train Iteration 719: loss: 0.7160, d_k_M range: [0.1778, 0.7799], d_k_M_hat range: [0.3530, 0.9337]
2025-03-11 19:55:40 - Train Iteration 720: loss: 0.7218, d_k_M range: [0.0917, 0.3592], d_k_M_hat range: [0.2741, 0.5623]
2025-03-11 19:55:41 - Train Iteration 721: loss: 0.7624, d_k_M range: [0.0260, 0.5500], d_k_M_hat range: [0.1528, 0.7522]
2025-03-11 19:55:41 - Train Iteration 722: loss: 0.7900, d_k_M range: [0.0368, 0.5313], d_k_M_hat range: [0.1480, 0.7442]
2025-03-11 19:55:42 - Train Iteration 723: loss: 0.9528, d_k_M range: [0.4621, 0.9725], d_k_M_hat range: [0.6727, 0.9964]
2025-03-11 19:55:42 - Train Iteration 724: loss: 0.7450, d_k_M range: [0.2986, 0.8277], d_k_M_hat range: [0.4827, 0.9645]
2025-03-11 19:55:42 - Train Iteration 725: loss: 0.7213, d_k_M range: [0.0291, 0.4258], d_k_M_hat range: [0.1854, 0.6444]
2025-03-11 19:55:43 - Train Iteration 726: loss: 0.7346, d_k_M range: [0.0464, 0.4158], d_k_M_hat range: [0.1893, 0.5958]
2025-03-11 19:55:43 - Train Iteration 727: loss: 0.6943, d_k_M range: [0.2060, 0.7274], d_k_M_hat range: [0.3901, 0.8941]
2025-03-11 19:55:44 - Train Iteration 728: loss: 0.8018, d_k_M range: [0.0919, 0.8719], d_k_M_hat range: [0.2394, 0.9765]
2025-03-11 19:55:44 - Train Iteration 729: loss: 0.6437, d_k_M range: [0.1472, 0.6100], d_k_M_hat range: [0.3573, 0.8122]
2025-03-11 19:55:44 - Train Iteration 730: loss: 0.9851, d_k_M range: [0.0314, 0.9910], d_k_M_hat range: [0.2125, 0.9984]
2025-03-11 19:55:45 - Train Iteration 731: loss: 0.6911, d_k_M range: [0.2131, 0.7905], d_k_M_hat range: [0.4330, 0.9592]
2025-03-11 19:55:45 - Train Iteration 732: loss: 0.6887, d_k_M range: [0.0633, 0.7477], d_k_M_hat range: [0.2918, 0.9178]
2025-03-11 19:55:46 - Train Iteration 733: loss: 0.6865, d_k_M range: [0.2162, 0.6308], d_k_M_hat range: [0.4291, 0.8151]
2025-03-11 19:55:46 - Train Iteration 734: loss: 0.7161, d_k_M range: [0.0155, 0.5223], d_k_M_hat range: [0.1693, 0.7148]
2025-03-11 19:55:47 - Train Iteration 735: loss: 0.6808, d_k_M range: [0.2179, 0.6059], d_k_M_hat range: [0.4090, 0.7925]
2025-03-11 19:55:47 - Train Iteration 736: loss: 0.7604, d_k_M range: [0.1453, 0.8505], d_k_M_hat range: [0.3578, 0.9785]
2025-03-11 19:55:47 - Train Iteration 737: loss: 0.7922, d_k_M range: [0.0549, 0.8555], d_k_M_hat range: [0.1742, 0.9655]
2025-03-11 19:55:48 - Train Iteration 738: loss: 0.7291, d_k_M range: [0.0628, 0.4519], d_k_M_hat range: [0.2345, 0.6365]
2025-03-11 19:55:48 - Train Iteration 739: loss: 0.7372, d_k_M range: [0.3338, 0.7079], d_k_M_hat range: [0.4751, 0.8777]
2025-03-11 19:55:49 - Train Iteration 740: loss: 0.7257, d_k_M range: [0.2706, 0.6880], d_k_M_hat range: [0.4720, 0.8712]
2025-03-11 19:55:49 - Train Iteration 741: loss: 0.6927, d_k_M range: [0.1419, 0.4319], d_k_M_hat range: [0.3184, 0.6352]
2025-03-11 19:55:49 - Train Iteration 742: loss: 0.6707, d_k_M range: [0.0801, 0.5642], d_k_M_hat range: [0.3032, 0.7520]
2025-03-11 19:55:50 - Train Iteration 743: loss: 0.6719, d_k_M range: [0.0462, 0.4388], d_k_M_hat range: [0.2402, 0.6190]
2025-03-11 19:55:50 - Train Iteration 744: loss: 0.6805, d_k_M range: [0.2314, 0.7055], d_k_M_hat range: [0.4225, 0.8981]
2025-03-11 19:55:51 - Train Iteration 745: loss: 0.6750, d_k_M range: [0.2145, 0.6843], d_k_M_hat range: [0.4033, 0.8627]
2025-03-11 19:55:51 - Train Iteration 746: loss: 0.6562, d_k_M range: [0.2360, 0.5946], d_k_M_hat range: [0.4414, 0.8158]
2025-03-11 19:55:52 - Train Iteration 747: loss: 0.6790, d_k_M range: [0.2392, 0.6555], d_k_M_hat range: [0.4519, 0.8359]
2025-03-11 19:55:52 - Train Iteration 748: loss: 0.7245, d_k_M range: [0.0142, 0.4994], d_k_M_hat range: [0.1630, 0.7400]
2025-03-11 19:55:53 - Train Iteration 749: loss: 0.6445, d_k_M range: [0.1403, 0.7509], d_k_M_hat range: [0.3619, 0.9481]
2025-03-11 19:55:53 - Train Iteration 750: loss: 0.8571, d_k_M range: [0.0309, 0.4497], d_k_M_hat range: [0.1051, 0.6597]
2025-03-11 19:55:54 - Train Iteration 751: loss: 0.6558, d_k_M range: [0.1257, 0.5530], d_k_M_hat range: [0.3159, 0.7640]
2025-03-11 19:55:54 - Train Iteration 752: loss: 0.6569, d_k_M range: [0.0604, 0.5355], d_k_M_hat range: [0.2574, 0.7443]
2025-03-11 19:55:54 - Train Iteration 753: loss: 0.6677, d_k_M range: [0.0992, 0.6514], d_k_M_hat range: [0.2930, 0.8342]
2025-03-11 19:55:55 - Train Iteration 754: loss: 0.8449, d_k_M range: [0.0078, 0.6730], d_k_M_hat range: [0.0886, 0.8769]
2025-03-11 19:55:55 - Train Iteration 755: loss: 0.6361, d_k_M range: [0.1762, 0.6455], d_k_M_hat range: [0.3883, 0.8479]
2025-03-11 19:55:56 - Train Iteration 756: loss: 0.6378, d_k_M range: [0.1376, 0.7382], d_k_M_hat range: [0.3390, 0.9453]
2025-03-11 19:55:56 - Train Iteration 757: loss: 0.7460, d_k_M range: [0.2323, 0.8335], d_k_M_hat range: [0.4572, 0.9698]
2025-03-11 19:55:57 - Train Iteration 758: loss: 0.6916, d_k_M range: [0.1410, 0.5385], d_k_M_hat range: [0.3719, 0.7756]
2025-03-11 19:55:57 - Train Iteration 759: loss: 0.6736, d_k_M range: [0.1959, 0.6873], d_k_M_hat range: [0.3807, 0.8846]
2025-03-11 19:55:58 - Train Iteration 760: loss: 0.7950, d_k_M range: [0.3743, 0.8683], d_k_M_hat range: [0.5908, 0.9766]
2025-03-11 19:55:58 - Train Iteration 761: loss: 0.6750, d_k_M range: [0.1202, 0.4758], d_k_M_hat range: [0.3454, 0.6543]
2025-03-11 19:55:58 - Train Iteration 762: loss: 0.6417, d_k_M range: [0.0523, 0.4537], d_k_M_hat range: [0.2513, 0.6667]
2025-03-11 19:55:59 - Train Iteration 763: loss: 0.6692, d_k_M range: [0.2500, 0.6940], d_k_M_hat range: [0.4527, 0.8801]
2025-03-11 19:55:59 - Train Iteration 764: loss: 0.7299, d_k_M range: [0.1191, 0.6805], d_k_M_hat range: [0.2648, 0.9019]
2025-03-11 19:56:00 - Train Iteration 765: loss: 0.7480, d_k_M range: [0.2582, 0.8433], d_k_M_hat range: [0.4859, 0.9785]
2025-03-11 19:56:00 - Train Iteration 766: loss: 0.7041, d_k_M range: [0.0327, 0.4116], d_k_M_hat range: [0.1936, 0.6617]
2025-03-11 19:56:00 - Train Iteration 767: loss: 0.9069, d_k_M range: [0.4040, 0.9419], d_k_M_hat range: [0.6117, 0.9897]
2025-03-11 19:56:01 - Train Iteration 768: loss: 0.6706, d_k_M range: [0.1759, 0.6205], d_k_M_hat range: [0.3863, 0.8386]
2025-03-11 19:56:01 - Train Iteration 769: loss: 0.7300, d_k_M range: [0.0493, 0.8290], d_k_M_hat range: [0.2587, 0.9746]
2025-03-11 19:56:02 - Train Iteration 770: loss: 0.6508, d_k_M range: [0.1627, 0.6468], d_k_M_hat range: [0.3636, 0.8400]
2025-03-11 19:56:02 - Train Iteration 771: loss: 0.6587, d_k_M range: [0.0821, 0.6115], d_k_M_hat range: [0.2705, 0.8339]
2025-03-11 19:56:02 - Train Iteration 772: loss: 0.7222, d_k_M range: [0.0589, 0.6178], d_k_M_hat range: [0.2091, 0.8511]
2025-03-11 19:56:03 - Train Iteration 773: loss: 0.6622, d_k_M range: [0.0900, 0.5614], d_k_M_hat range: [0.2762, 0.7489]
2025-03-11 19:56:03 - Train Iteration 774: loss: 0.7966, d_k_M range: [0.0102, 0.6335], d_k_M_hat range: [0.1176, 0.8458]
2025-03-11 19:56:04 - Train Iteration 775: loss: 0.6545, d_k_M range: [0.1007, 0.6342], d_k_M_hat range: [0.2917, 0.8655]
2025-03-11 19:56:04 - Train Iteration 776: loss: 0.6231, d_k_M range: [0.0407, 0.5845], d_k_M_hat range: [0.2514, 0.8113]
2025-03-11 19:56:05 - Train Iteration 777: loss: 0.8495, d_k_M range: [0.1893, 0.9087], d_k_M_hat range: [0.4146, 0.9870]
2025-03-11 19:56:05 - Train Iteration 778: loss: 0.9098, d_k_M range: [0.0019, 0.7810], d_k_M_hat range: [0.0480, 0.9514]
2025-03-11 19:56:06 - Train Iteration 779: loss: 0.7327, d_k_M range: [0.2922, 0.8108], d_k_M_hat range: [0.4994, 0.9548]
2025-03-11 19:56:06 - Train Iteration 780: loss: 0.6832, d_k_M range: [0.2217, 0.6258], d_k_M_hat range: [0.4113, 0.8303]
2025-03-11 19:56:07 - Train Iteration 781: loss: 0.9957, d_k_M range: [0.0011, 0.3574], d_k_M_hat range: [0.0033, 0.5702]
2025-03-11 19:56:07 - Train Iteration 782: loss: 0.8374, d_k_M range: [0.0727, 0.8924], d_k_M_hat range: [0.2336, 0.9773]
2025-03-11 19:56:08 - Train Iteration 783: loss: 0.7209, d_k_M range: [0.0161, 0.7050], d_k_M_hat range: [0.1671, 0.8869]
2025-03-11 19:56:08 - Train Iteration 784: loss: 0.7230, d_k_M range: [0.2910, 0.7888], d_k_M_hat range: [0.4629, 0.9385]
2025-03-11 19:56:08 - Train Iteration 785: loss: 0.7091, d_k_M range: [0.2189, 0.6701], d_k_M_hat range: [0.4206, 0.8639]
2025-03-11 19:56:09 - Train Iteration 786: loss: 0.8798, d_k_M range: [0.2326, 0.9277], d_k_M_hat range: [0.4358, 0.9897]
2025-03-11 19:56:09 - Train Iteration 787: loss: 0.7241, d_k_M range: [0.0566, 0.6286], d_k_M_hat range: [0.2056, 0.8369]
2025-03-11 19:56:10 - Train Iteration 788: loss: 0.6691, d_k_M range: [0.1306, 0.5820], d_k_M_hat range: [0.3419, 0.7640]
2025-03-11 19:56:10 - Train Iteration 789: loss: 0.7159, d_k_M range: [0.3018, 0.8086], d_k_M_hat range: [0.5002, 0.9625]
2025-03-11 19:56:10 - Train Iteration 790: loss: 0.6808, d_k_M range: [0.2139, 0.7840], d_k_M_hat range: [0.4204, 0.9589]
2025-03-11 19:56:11 - Train Iteration 791: loss: 0.6887, d_k_M range: [0.2946, 0.6251], d_k_M_hat range: [0.5251, 0.8260]
2025-03-11 19:56:11 - Train Iteration 792: loss: 0.6799, d_k_M range: [0.2786, 0.4536], d_k_M_hat range: [0.4834, 0.6559]
2025-03-11 19:56:12 - Train Iteration 793: loss: 0.6293, d_k_M range: [0.1343, 0.6891], d_k_M_hat range: [0.3718, 0.9185]
2025-03-11 19:56:12 - Train Iteration 794: loss: 0.6764, d_k_M range: [0.2267, 0.6961], d_k_M_hat range: [0.4042, 0.9060]
2025-03-11 19:56:13 - Train Iteration 795: loss: 0.6148, d_k_M range: [0.2022, 0.6158], d_k_M_hat range: [0.4181, 0.8323]
2025-03-11 19:56:13 - Train Iteration 796: loss: 0.7141, d_k_M range: [0.1387, 0.8172], d_k_M_hat range: [0.3421, 0.9722]
2025-03-11 19:56:14 - Train Iteration 797: loss: 0.6903, d_k_M range: [0.0488, 0.4516], d_k_M_hat range: [0.2180, 0.7048]
2025-03-11 19:56:14 - Train Iteration 798: loss: 0.6777, d_k_M range: [0.0513, 0.6154], d_k_M_hat range: [0.2933, 0.8582]
2025-03-11 19:56:15 - Train Iteration 799: loss: 0.7240, d_k_M range: [0.0095, 0.3372], d_k_M_hat range: [0.1586, 0.5774]
2025-03-11 19:56:15 - Train Iteration 800: loss: 0.6742, d_k_M range: [0.2294, 0.7452], d_k_M_hat range: [0.4121, 0.9250]
2025-03-11 19:56:16 - Train Iteration 801: loss: 0.6737, d_k_M range: [0.1856, 0.6332], d_k_M_hat range: [0.4041, 0.8245]
2025-03-11 19:56:16 - Train Iteration 802: loss: 0.6572, d_k_M range: [0.2312, 0.4249], d_k_M_hat range: [0.4564, 0.6467]
2025-03-11 19:56:16 - Train Iteration 803: loss: 0.6335, d_k_M range: [0.0908, 0.3980], d_k_M_hat range: [0.3154, 0.6020]
2025-03-11 19:56:17 - Train Iteration 804: loss: 0.6621, d_k_M range: [0.1606, 0.7614], d_k_M_hat range: [0.4133, 0.9477]
2025-03-11 19:56:17 - Train Iteration 805: loss: 0.9664, d_k_M range: [0.0043, 0.4860], d_k_M_hat range: [0.0212, 0.6834]
2025-03-11 19:56:18 - Train Iteration 806: loss: 0.6293, d_k_M range: [0.2165, 0.4237], d_k_M_hat range: [0.4279, 0.6786]
2025-03-11 19:56:18 - Train Iteration 807: loss: 0.6731, d_k_M range: [0.0644, 0.5313], d_k_M_hat range: [0.2952, 0.7211]
2025-03-11 19:56:19 - Train Iteration 808: loss: 0.7509, d_k_M range: [0.1325, 0.8260], d_k_M_hat range: [0.3586, 0.9595]
2025-03-11 19:56:19 - Train Iteration 809: loss: 0.6584, d_k_M range: [0.1366, 0.6618], d_k_M_hat range: [0.3295, 0.8508]
2025-03-11 19:56:19 - Train Iteration 810: loss: 0.6883, d_k_M range: [0.2359, 0.7745], d_k_M_hat range: [0.4547, 0.9448]
2025-03-11 19:56:20 - Train Iteration 811: loss: 0.6794, d_k_M range: [0.0778, 0.6214], d_k_M_hat range: [0.2713, 0.8225]
2025-03-11 19:56:20 - Train Iteration 812: loss: 0.7185, d_k_M range: [0.0188, 0.3898], d_k_M_hat range: [0.1712, 0.6083]
2025-03-11 19:56:21 - Train Iteration 813: loss: 0.7246, d_k_M range: [0.2415, 0.8075], d_k_M_hat range: [0.4492, 0.9562]
2025-03-11 19:56:21 - Train Iteration 814: loss: 0.6916, d_k_M range: [0.2461, 0.7807], d_k_M_hat range: [0.4680, 0.9491]
2025-03-11 19:56:22 - Train Iteration 815: loss: 0.6897, d_k_M range: [0.1304, 0.5068], d_k_M_hat range: [0.3005, 0.6999]
2025-03-11 19:56:22 - Train Iteration 816: loss: 0.6996, d_k_M range: [0.0852, 0.7472], d_k_M_hat range: [0.2608, 0.9376]
2025-03-11 19:56:23 - Train Iteration 817: loss: 0.6829, d_k_M range: [0.1866, 0.7476], d_k_M_hat range: [0.3602, 0.9504]
2025-03-11 19:56:23 - Train Iteration 818: loss: 0.6509, d_k_M range: [0.1258, 0.6978], d_k_M_hat range: [0.3312, 0.9143]
2025-03-11 19:56:23 - Train Iteration 819: loss: 0.6693, d_k_M range: [0.1920, 0.7052], d_k_M_hat range: [0.4034, 0.9008]
2025-03-11 19:56:24 - Train Iteration 820: loss: 0.6955, d_k_M range: [0.0638, 0.7683], d_k_M_hat range: [0.2390, 0.9487]
2025-03-11 19:56:24 - Train Iteration 821: loss: 0.7504, d_k_M range: [0.0298, 0.6375], d_k_M_hat range: [0.1635, 0.8444]
2025-03-11 19:56:25 - Train Iteration 822: loss: 0.6221, d_k_M range: [0.0773, 0.5499], d_k_M_hat range: [0.2966, 0.7828]
2025-03-11 19:56:25 - Train Iteration 823: loss: 0.7767, d_k_M range: [0.0106, 0.8633], d_k_M_hat range: [0.1552, 0.9819]
2025-03-11 19:56:26 - Train Iteration 824: loss: 0.6471, d_k_M range: [0.0821, 0.4731], d_k_M_hat range: [0.3051, 0.6688]
2025-03-11 19:56:26 - Train Iteration 825: loss: 0.6524, d_k_M range: [0.0611, 0.5251], d_k_M_hat range: [0.2534, 0.7307]
2025-03-11 19:56:27 - Train Iteration 826: loss: 0.6565, d_k_M range: [0.2251, 0.6001], d_k_M_hat range: [0.4218, 0.7974]
2025-03-11 19:56:27 - Train Iteration 827: loss: 0.6478, d_k_M range: [0.2983, 0.7531], d_k_M_hat range: [0.5088, 0.9483]
2025-03-11 19:56:28 - Train Iteration 828: loss: 0.8887, d_k_M range: [0.0774, 0.9330], d_k_M_hat range: [0.3212, 0.9902]
2025-03-11 19:56:28 - Train Iteration 829: loss: 0.6549, d_k_M range: [0.0456, 0.6171], d_k_M_hat range: [0.2364, 0.8277]
2025-03-11 19:56:29 - Train Iteration 830: loss: 0.6408, d_k_M range: [0.0791, 0.6963], d_k_M_hat range: [0.3011, 0.9109]
2025-03-11 19:56:29 - Train Iteration 831: loss: 0.8066, d_k_M range: [0.1432, 0.8748], d_k_M_hat range: [0.3613, 0.9767]
2025-03-11 19:56:29 - Train Iteration 832: loss: 0.7802, d_k_M range: [0.0114, 0.4880], d_k_M_hat range: [0.1281, 0.7391]
2025-03-11 19:56:30 - Train Iteration 833: loss: 0.6519, d_k_M range: [0.0616, 0.6529], d_k_M_hat range: [0.2715, 0.8547]
2025-03-11 19:56:30 - Train Iteration 834: loss: 0.7212, d_k_M range: [0.0203, 0.5370], d_k_M_hat range: [0.1711, 0.7409]
2025-03-11 19:56:31 - Train Iteration 835: loss: 0.9716, d_k_M range: [0.3194, 0.9832], d_k_M_hat range: [0.5699, 0.9975]
2025-03-11 19:56:31 - Train Iteration 836: loss: 0.6829, d_k_M range: [0.2696, 0.6547], d_k_M_hat range: [0.4904, 0.8462]
2025-03-11 19:56:32 - Train Iteration 837: loss: 0.6932, d_k_M range: [0.1140, 0.6559], d_k_M_hat range: [0.3386, 0.8356]
2025-03-11 19:56:32 - Train Iteration 838: loss: 0.6955, d_k_M range: [0.0412, 0.6289], d_k_M_hat range: [0.2072, 0.8178]
2025-03-11 19:56:32 - Train Iteration 839: loss: 0.6573, d_k_M range: [0.0451, 0.5228], d_k_M_hat range: [0.2564, 0.7201]
2025-03-11 19:56:33 - Train Iteration 840: loss: 0.8306, d_k_M range: [0.0659, 0.8814], d_k_M_hat range: [0.2770, 0.9700]
2025-03-11 19:56:33 - Train Iteration 841: loss: 0.6597, d_k_M range: [0.2957, 0.5955], d_k_M_hat range: [0.4835, 0.8339]
2025-03-11 19:56:34 - Train Iteration 842: loss: 0.7226, d_k_M range: [0.1787, 0.8160], d_k_M_hat range: [0.3637, 0.9660]
2025-03-11 19:56:34 - Train Iteration 843: loss: 0.7644, d_k_M range: [0.2805, 0.8428], d_k_M_hat range: [0.4897, 0.9685]
2025-03-11 19:56:35 - Train Iteration 844: loss: 0.6890, d_k_M range: [0.1391, 0.5664], d_k_M_hat range: [0.3576, 0.7443]
2025-03-11 19:56:35 - Train Iteration 845: loss: 0.6864, d_k_M range: [0.0300, 0.7152], d_k_M_hat range: [0.2025, 0.9280]
2025-03-11 19:56:36 - Train Iteration 846: loss: 0.7645, d_k_M range: [0.0262, 0.5654], d_k_M_hat range: [0.1519, 0.7884]
2025-03-11 19:56:36 - Train Iteration 847: loss: 0.6875, d_k_M range: [0.2526, 0.6879], d_k_M_hat range: [0.4441, 0.8820]
2025-03-11 19:56:37 - Train Iteration 848: loss: 0.7605, d_k_M range: [0.0392, 0.5502], d_k_M_hat range: [0.2024, 0.7443]
2025-03-11 19:56:37 - Train Iteration 849: loss: 0.8152, d_k_M range: [0.0062, 0.4188], d_k_M_hat range: [0.1034, 0.6377]
2025-03-11 19:56:37 - Train Iteration 850: loss: 0.6736, d_k_M range: [0.0887, 0.5651], d_k_M_hat range: [0.2995, 0.7736]
2025-03-11 19:56:38 - Train Iteration 851: loss: 0.7164, d_k_M range: [0.1057, 0.8103], d_k_M_hat range: [0.3261, 0.9639]
2025-03-11 19:56:38 - Train Iteration 852: loss: 0.6744, d_k_M range: [0.0431, 0.4913], d_k_M_hat range: [0.2218, 0.6988]
2025-03-11 19:56:39 - Train Iteration 853: loss: 0.6669, d_k_M range: [0.1162, 0.7534], d_k_M_hat range: [0.3074, 0.9368]
2025-03-11 19:56:39 - Train Iteration 854: loss: 0.6403, d_k_M range: [0.0675, 0.5474], d_k_M_hat range: [0.3091, 0.8019]
2025-03-11 19:56:40 - Train Iteration 855: loss: 0.8576, d_k_M range: [0.1837, 0.9161], d_k_M_hat range: [0.4235, 0.9900]
2025-03-11 19:56:40 - Train Iteration 856: loss: 0.6302, d_k_M range: [0.1064, 0.4321], d_k_M_hat range: [0.3127, 0.6441]
2025-03-11 19:56:41 - Train Iteration 857: loss: 0.6372, d_k_M range: [0.1462, 0.6932], d_k_M_hat range: [0.4338, 0.8995]
2025-03-11 19:56:41 - Train Iteration 858: loss: 0.6538, d_k_M range: [0.1300, 0.6785], d_k_M_hat range: [0.3214, 0.8982]
2025-03-11 19:56:42 - Train Iteration 859: loss: 0.9236, d_k_M range: [0.0016, 0.5147], d_k_M_hat range: [0.0406, 0.7526]
2025-03-11 19:56:42 - Train Iteration 860: loss: 0.6937, d_k_M range: [0.2777, 0.7632], d_k_M_hat range: [0.4968, 0.9423]
2025-03-11 19:56:42 - Train Iteration 861: loss: 0.6413, d_k_M range: [0.3423, 0.6863], d_k_M_hat range: [0.5502, 0.8855]
2025-03-11 19:56:43 - Train Iteration 862: loss: 0.6927, d_k_M range: [0.0352, 0.7496], d_k_M_hat range: [0.2426, 0.9319]
2025-03-11 19:56:43 - Train Iteration 863: loss: 0.7820, d_k_M range: [0.2351, 0.8576], d_k_M_hat range: [0.5045, 0.9733]
2025-03-11 19:56:44 - Train Iteration 864: loss: 0.7596, d_k_M range: [0.0145, 0.8208], d_k_M_hat range: [0.1601, 0.9493]
2025-03-11 19:56:44 - Train Iteration 865: loss: 0.6493, d_k_M range: [0.2623, 0.4604], d_k_M_hat range: [0.4823, 0.6642]
2025-03-11 19:56:44 - Train Iteration 866: loss: 0.7080, d_k_M range: [0.0418, 0.5666], d_k_M_hat range: [0.2004, 0.8164]
2025-03-11 19:56:45 - Train Iteration 867: loss: 0.8744, d_k_M range: [0.0058, 0.5035], d_k_M_hat range: [0.0707, 0.7449]
2025-03-11 19:56:45 - Train Iteration 868: loss: 0.7783, d_k_M range: [0.2512, 0.8591], d_k_M_hat range: [0.4604, 0.9769]
2025-03-11 19:56:46 - Train Iteration 869: loss: 0.6490, d_k_M range: [0.0520, 0.7128], d_k_M_hat range: [0.2556, 0.9099]
2025-03-11 19:56:46 - Train Iteration 870: loss: 0.9685, d_k_M range: [0.2092, 0.9820], d_k_M_hat range: [0.4500, 0.9979]
2025-03-11 19:56:47 - Train Iteration 871: loss: 0.7259, d_k_M range: [0.0148, 0.5384], d_k_M_hat range: [0.1628, 0.8110]
2025-03-11 19:56:47 - Train Iteration 872: loss: 0.6041, d_k_M range: [0.2022, 0.6349], d_k_M_hat range: [0.4668, 0.8584]
2025-03-11 19:56:48 - Train Iteration 873: loss: 0.7295, d_k_M range: [0.0095, 0.6036], d_k_M_hat range: [0.1554, 0.8281]
2025-03-11 19:56:48 - Train Iteration 874: loss: 0.6626, d_k_M range: [0.0731, 0.7179], d_k_M_hat range: [0.2945, 0.9039]
2025-03-11 19:56:48 - Train Iteration 875: loss: 0.7433, d_k_M range: [0.1167, 0.8150], d_k_M_hat range: [0.3591, 0.9528]
2025-03-11 19:56:49 - Train Iteration 876: loss: 0.7949, d_k_M range: [0.2640, 0.8670], d_k_M_hat range: [0.4871, 0.9796]
2025-03-11 19:56:49 - Train Iteration 877: loss: 0.6265, d_k_M range: [0.2106, 0.4572], d_k_M_hat range: [0.4220, 0.6842]
2025-03-11 19:56:50 - Train Iteration 878: loss: 0.6748, d_k_M range: [0.0149, 0.5241], d_k_M_hat range: [0.1934, 0.7511]
2025-03-11 19:56:50 - Train Iteration 879: loss: 0.9337, d_k_M range: [0.1838, 0.9615], d_k_M_hat range: [0.4539, 0.9953]
2025-03-11 19:56:50 - Train Iteration 880: loss: 0.6287, d_k_M range: [0.1423, 0.4474], d_k_M_hat range: [0.3611, 0.6612]
2025-03-11 19:56:51 - Train Iteration 881: loss: 0.8642, d_k_M range: [0.0137, 0.4375], d_k_M_hat range: [0.0841, 0.6483]
2025-03-11 19:56:51 - Train Iteration 882: loss: 0.6626, d_k_M range: [0.2592, 0.6939], d_k_M_hat range: [0.4452, 0.9170]
2025-03-11 19:56:52 - Train Iteration 883: loss: 0.7504, d_k_M range: [0.2886, 0.8371], d_k_M_hat range: [0.4873, 0.9708]
2025-03-11 19:56:52 - Train Iteration 884: loss: 0.6968, d_k_M range: [0.3196, 0.7684], d_k_M_hat range: [0.5240, 0.9409]
2025-03-11 19:56:53 - Train Iteration 885: loss: 0.6453, d_k_M range: [0.2570, 0.4047], d_k_M_hat range: [0.4630, 0.6222]
2025-03-11 19:56:53 - Train Iteration 886: loss: 0.6625, d_k_M range: [0.1127, 0.4718], d_k_M_hat range: [0.3314, 0.6679]
2025-03-11 19:56:53 - Train Iteration 887: loss: 0.6506, d_k_M range: [0.0487, 0.5570], d_k_M_hat range: [0.2820, 0.7505]
2025-03-11 19:56:54 - Train Iteration 888: loss: 0.7035, d_k_M range: [0.2753, 0.7167], d_k_M_hat range: [0.5318, 0.9258]
2025-03-11 19:56:54 - Train Iteration 889: loss: 0.6975, d_k_M range: [0.0482, 0.7927], d_k_M_hat range: [0.2509, 0.9576]
2025-03-11 19:56:55 - Train Iteration 890: loss: 0.9287, d_k_M range: [0.0020, 0.2123], d_k_M_hat range: [0.0383, 0.4780]
2025-03-11 19:56:55 - Train Iteration 891: loss: 0.8688, d_k_M range: [0.2485, 0.9158], d_k_M_hat range: [0.4836, 0.9837]
2025-03-11 19:56:55 - Train Iteration 892: loss: 0.6486, d_k_M range: [0.1270, 0.5687], d_k_M_hat range: [0.3216, 0.7754]
2025-03-11 19:56:56 - Train Iteration 893: loss: 0.6861, d_k_M range: [0.1291, 0.7720], d_k_M_hat range: [0.3664, 0.9437]
2025-03-11 19:56:56 - Train Iteration 894: loss: 0.6775, d_k_M range: [0.0869, 0.5050], d_k_M_hat range: [0.2948, 0.7054]
2025-03-11 19:56:57 - Train Iteration 895: loss: 0.8547, d_k_M range: [0.1683, 0.9112], d_k_M_hat range: [0.4348, 0.9867]
2025-03-11 19:56:57 - Train Iteration 896: loss: 0.6487, d_k_M range: [0.1309, 0.5937], d_k_M_hat range: [0.3668, 0.8220]
2025-03-11 19:56:58 - Train Iteration 897: loss: 0.6667, d_k_M range: [0.0524, 0.6282], d_k_M_hat range: [0.2423, 0.8458]
2025-03-11 19:56:58 - Train Iteration 898: loss: 0.6728, d_k_M range: [0.2216, 0.7772], d_k_M_hat range: [0.4385, 0.9570]
2025-03-11 19:56:58 - Train Iteration 899: loss: 0.6513, d_k_M range: [0.0886, 0.4246], d_k_M_hat range: [0.3090, 0.6642]
2025-03-11 19:56:59 - Train Iteration 900: loss: 0.6184, d_k_M range: [0.0663, 0.4162], d_k_M_hat range: [0.3090, 0.6427]
2025-03-11 19:56:59 - Train Iteration 901: loss: 0.6997, d_k_M range: [0.2655, 0.8011], d_k_M_hat range: [0.5190, 0.9647]
2025-03-11 19:57:00 - Train Iteration 902: loss: 0.6118, d_k_M range: [0.1552, 0.4286], d_k_M_hat range: [0.4083, 0.6822]
2025-03-11 19:57:00 - Train Iteration 903: loss: 0.8176, d_k_M range: [0.0356, 0.8911], d_k_M_hat range: [0.2526, 0.9869]
2025-03-11 19:57:01 - Train Iteration 904: loss: 0.6640, d_k_M range: [0.0166, 0.7478], d_k_M_hat range: [0.2017, 0.9353]
2025-03-11 19:57:01 - Train Iteration 905: loss: 0.7432, d_k_M range: [0.5621, 0.8411], d_k_M_hat range: [0.7825, 0.9791]
2025-03-11 19:57:02 - Train Iteration 906: loss: 0.6776, d_k_M range: [0.1128, 0.5656], d_k_M_hat range: [0.2927, 0.7669]
2025-03-11 19:57:02 - Train Iteration 907: loss: 0.6722, d_k_M range: [0.1074, 0.5680], d_k_M_hat range: [0.3185, 0.7884]
2025-03-11 19:57:02 - Train Iteration 908: loss: 0.6530, d_k_M range: [0.0880, 0.5095], d_k_M_hat range: [0.2800, 0.7171]
2025-03-11 19:57:03 - Train Iteration 909: loss: 0.6323, d_k_M range: [0.1762, 0.5945], d_k_M_hat range: [0.4039, 0.8118]
2025-03-11 19:57:03 - Train Iteration 910: loss: 0.6534, d_k_M range: [0.2884, 0.6504], d_k_M_hat range: [0.5091, 0.8798]
2025-03-11 19:57:04 - Train Iteration 911: loss: 0.6146, d_k_M range: [0.1370, 0.6853], d_k_M_hat range: [0.3530, 0.9046]
2025-03-11 19:57:04 - Train Iteration 912: loss: 0.7092, d_k_M range: [0.0088, 0.4878], d_k_M_hat range: [0.1667, 0.7124]
2025-03-11 19:57:04 - Train Iteration 913: loss: 0.7897, d_k_M range: [0.2783, 0.8709], d_k_M_hat range: [0.5460, 0.9822]
2025-03-11 19:57:05 - Train Iteration 914: loss: 0.6767, d_k_M range: [0.0146, 0.7383], d_k_M_hat range: [0.1920, 0.9201]
2025-03-11 19:57:05 - Train Iteration 915: loss: 0.7559, d_k_M range: [0.0059, 0.6498], d_k_M_hat range: [0.1364, 0.8705]
2025-03-11 19:57:06 - Train Iteration 916: loss: 0.9696, d_k_M range: [0.0119, 0.9830], d_k_M_hat range: [0.0948, 0.9983]
2025-03-11 19:57:06 - Train Iteration 917: loss: 0.6617, d_k_M range: [0.0316, 0.6407], d_k_M_hat range: [0.2325, 0.8741]
2025-03-11 19:57:07 - Train Iteration 918: loss: 0.6683, d_k_M range: [0.3072, 0.6945], d_k_M_hat range: [0.5204, 0.9093]
2025-03-11 19:57:07 - Train Iteration 919: loss: 0.6249, d_k_M range: [0.1904, 0.5857], d_k_M_hat range: [0.4124, 0.8009]
2025-03-11 19:57:08 - Train Iteration 920: loss: 0.7550, d_k_M range: [0.0145, 0.6272], d_k_M_hat range: [0.1455, 0.8661]
2025-03-11 19:57:08 - Train Iteration 921: loss: 0.6683, d_k_M range: [0.0685, 0.7551], d_k_M_hat range: [0.2943, 0.9376]
2025-03-11 19:57:08 - Train Iteration 922: loss: 0.6423, d_k_M range: [0.1691, 0.4985], d_k_M_hat range: [0.3677, 0.7039]
2025-03-11 19:57:09 - Train Iteration 923: loss: 0.8250, d_k_M range: [0.0103, 0.4057], d_k_M_hat range: [0.1020, 0.6173]
2025-03-11 19:57:09 - Train Iteration 924: loss: 0.6529, d_k_M range: [0.3027, 0.5358], d_k_M_hat range: [0.5188, 0.7550]
2025-03-11 19:57:10 - Train Iteration 925: loss: 0.6612, d_k_M range: [0.0393, 0.2699], d_k_M_hat range: [0.2386, 0.4741]
2025-03-11 19:57:10 - Train Iteration 926: loss: 0.6863, d_k_M range: [0.1633, 0.6121], d_k_M_hat range: [0.3798, 0.8099]
2025-03-11 19:57:10 - Train Iteration 927: loss: 0.7462, d_k_M range: [0.0443, 0.8369], d_k_M_hat range: [0.2374, 0.9731]
2025-03-11 19:57:11 - Train Iteration 928: loss: 0.7296, d_k_M range: [0.0248, 0.5323], d_k_M_hat range: [0.1707, 0.7463]
2025-03-11 19:57:11 - Train Iteration 929: loss: 0.8003, d_k_M range: [0.0253, 0.5974], d_k_M_hat range: [0.1307, 0.7867]
2025-03-11 19:57:12 - Train Iteration 930: loss: 0.6794, d_k_M range: [0.0934, 0.6627], d_k_M_hat range: [0.2896, 0.8528]
2025-03-11 19:57:12 - Train Iteration 931: loss: 0.6876, d_k_M range: [0.1452, 0.5849], d_k_M_hat range: [0.3435, 0.7955]
2025-03-11 19:57:13 - Train Iteration 932: loss: 0.6804, d_k_M range: [0.3116, 0.5537], d_k_M_hat range: [0.5031, 0.7477]
2025-03-11 19:57:13 - Train Iteration 933: loss: 0.7058, d_k_M range: [0.1913, 0.7747], d_k_M_hat range: [0.3885, 0.9346]
2025-03-11 19:57:13 - Train Iteration 934: loss: 0.6811, d_k_M range: [0.2103, 0.4604], d_k_M_hat range: [0.4253, 0.6514]
2025-03-11 19:57:14 - Train Iteration 935: loss: 0.6614, d_k_M range: [0.1701, 0.6561], d_k_M_hat range: [0.3569, 0.8722]
2025-03-11 19:57:14 - Train Iteration 936: loss: 0.6607, d_k_M range: [0.1612, 0.7322], d_k_M_hat range: [0.3563, 0.9193]
2025-03-11 19:57:15 - Train Iteration 937: loss: 0.6671, d_k_M range: [0.1539, 0.7252], d_k_M_hat range: [0.3714, 0.9084]
2025-03-11 19:57:15 - Train Iteration 938: loss: 0.8028, d_k_M range: [0.2083, 0.8744], d_k_M_hat range: [0.4311, 0.9784]
2025-03-11 19:57:15 - Train Iteration 939: loss: 0.6511, d_k_M range: [0.1783, 0.5424], d_k_M_hat range: [0.3859, 0.7834]
2025-03-11 19:57:16 - Train Iteration 940: loss: 0.6144, d_k_M range: [0.0627, 0.6201], d_k_M_hat range: [0.2789, 0.8698]
2025-03-11 19:57:16 - Train Iteration 941: loss: 0.6728, d_k_M range: [0.1208, 0.7470], d_k_M_hat range: [0.3184, 0.9267]
2025-03-11 19:57:17 - Train Iteration 942: loss: 0.6510, d_k_M range: [0.0441, 0.4421], d_k_M_hat range: [0.2530, 0.6508]
2025-03-11 19:57:17 - Train Iteration 943: loss: 0.6567, d_k_M range: [0.0606, 0.3735], d_k_M_hat range: [0.2503, 0.6378]
2025-03-11 19:57:18 - Train Iteration 944: loss: 0.6524, d_k_M range: [0.1453, 0.7315], d_k_M_hat range: [0.3668, 0.9238]
2025-03-11 19:57:18 - Train Iteration 945: loss: 0.7361, d_k_M range: [0.0113, 0.4975], d_k_M_hat range: [0.1554, 0.6903]
2025-03-11 19:57:19 - Train Iteration 946: loss: 0.6584, d_k_M range: [0.2100, 0.6667], d_k_M_hat range: [0.4353, 0.8980]
2025-03-11 19:57:19 - Train Iteration 947: loss: 0.7926, d_k_M range: [0.0450, 0.8671], d_k_M_hat range: [0.2303, 0.9768]
2025-03-11 19:57:20 - Train Iteration 948: loss: 0.6645, d_k_M range: [0.0697, 0.5951], d_k_M_hat range: [0.2883, 0.8345]
2025-03-11 19:57:20 - Train Iteration 949: loss: 0.9867, d_k_M range: [0.0006, 0.5707], d_k_M_hat range: [0.0072, 0.7796]
2025-03-11 19:57:20 - Train Iteration 950: loss: 0.6197, d_k_M range: [0.0936, 0.6704], d_k_M_hat range: [0.3208, 0.9198]
2025-03-11 19:57:21 - Train Iteration 951: loss: 0.7694, d_k_M range: [0.1890, 0.8342], d_k_M_hat range: [0.4260, 0.9570]
2025-03-11 19:57:21 - Train Iteration 952: loss: 0.6152, d_k_M range: [0.1646, 0.6241], d_k_M_hat range: [0.4081, 0.8854]
2025-03-11 19:57:22 - Train Iteration 953: loss: 0.7205, d_k_M range: [0.0103, 0.4340], d_k_M_hat range: [0.1615, 0.6851]
2025-03-11 19:57:22 - Train Iteration 954: loss: 0.7657, d_k_M range: [0.0250, 0.7446], d_k_M_hat range: [0.1500, 0.9004]
2025-03-11 19:57:23 - Train Iteration 955: loss: 0.7291, d_k_M range: [0.2423, 0.8295], d_k_M_hat range: [0.4789, 0.9756]
2025-03-11 19:57:23 - Train Iteration 956: loss: 0.7071, d_k_M range: [0.0082, 0.4530], d_k_M_hat range: [0.1673, 0.6639]
2025-03-11 19:57:24 - Train Iteration 957: loss: 0.8243, d_k_M range: [0.1400, 0.8844], d_k_M_hat range: [0.3760, 0.9765]
2025-03-11 19:57:24 - Train Iteration 958: loss: 0.6922, d_k_M range: [0.0327, 0.5680], d_k_M_hat range: [0.2349, 0.7527]
2025-03-11 19:57:25 - Train Iteration 959: loss: 0.6762, d_k_M range: [0.0199, 0.4720], d_k_M_hat range: [0.2177, 0.6793]
2025-03-11 19:57:25 - Train Iteration 960: loss: 0.6661, d_k_M range: [0.2884, 0.7455], d_k_M_hat range: [0.5211, 0.9294]
2025-03-11 19:57:25 - Train Iteration 961: loss: 0.6555, d_k_M range: [0.0963, 0.5526], d_k_M_hat range: [0.3562, 0.7473]
2025-03-11 19:57:26 - Train Iteration 962: loss: 0.6828, d_k_M range: [0.1418, 0.7686], d_k_M_hat range: [0.3977, 0.9423]
2025-03-11 19:57:26 - Train Iteration 963: loss: 0.6368, d_k_M range: [0.0560, 0.6726], d_k_M_hat range: [0.2840, 0.8746]
2025-03-11 19:57:27 - Train Iteration 964: loss: 0.6569, d_k_M range: [0.1088, 0.4677], d_k_M_hat range: [0.3264, 0.6904]
2025-03-11 19:57:27 - Train Iteration 965: loss: 0.6684, d_k_M range: [0.1499, 0.7799], d_k_M_hat range: [0.4268, 0.9624]
2025-03-11 19:57:27 - Train Iteration 966: loss: 0.8365, d_k_M range: [0.0057, 0.5497], d_k_M_hat range: [0.0911, 0.7734]
2025-03-11 19:57:28 - Train Iteration 967: loss: 0.6598, d_k_M range: [0.1150, 0.5631], d_k_M_hat range: [0.3336, 0.7703]
2025-03-11 19:57:28 - Train Iteration 968: loss: 0.9792, d_k_M range: [0.0013, 0.5391], d_k_M_hat range: [0.0117, 0.7949]
2025-03-11 19:57:29 - Train Iteration 969: loss: 0.6428, d_k_M range: [0.0472, 0.6292], d_k_M_hat range: [0.2462, 0.8464]
2025-03-11 19:57:29 - Train Iteration 970: loss: 0.8134, d_k_M range: [0.0373, 0.8862], d_k_M_hat range: [0.2829, 0.9843]
2025-03-11 19:57:29 - Train Iteration 971: loss: 0.6230, d_k_M range: [0.0599, 0.5539], d_k_M_hat range: [0.2769, 0.8150]
2025-03-11 19:57:30 - Train Iteration 972: loss: 0.6224, d_k_M range: [0.0403, 0.6300], d_k_M_hat range: [0.2593, 0.8719]
2025-03-11 19:57:30 - Train Iteration 973: loss: 0.5959, d_k_M range: [0.1316, 0.6725], d_k_M_hat range: [0.4163, 0.9006]
2025-03-11 19:57:31 - Train Iteration 974: loss: 0.6582, d_k_M range: [0.0198, 0.5550], d_k_M_hat range: [0.2085, 0.8057]
2025-03-11 19:57:31 - Train Iteration 975: loss: 0.6360, d_k_M range: [0.1719, 0.5595], d_k_M_hat range: [0.3900, 0.8071]
2025-03-11 19:57:32 - Train Iteration 976: loss: 0.9461, d_k_M range: [0.0582, 0.9695], d_k_M_hat range: [0.2688, 0.9969]
2025-03-11 19:57:32 - Train Iteration 977: loss: 0.6211, d_k_M range: [0.1931, 0.7460], d_k_M_hat range: [0.4196, 0.9611]
2025-03-11 19:57:33 - Train Iteration 978: loss: 0.7097, d_k_M range: [0.1587, 0.8153], d_k_M_hat range: [0.3382, 0.9729]
2025-03-11 19:57:33 - Train Iteration 979: loss: 0.7073, d_k_M range: [0.1921, 0.7984], d_k_M_hat range: [0.4060, 0.9618]
2025-03-11 19:57:33 - Train Iteration 980: loss: 0.8765, d_k_M range: [0.0042, 0.4759], d_k_M_hat range: [0.0680, 0.6953]
2025-03-11 19:57:34 - Train Iteration 981: loss: 0.7069, d_k_M range: [0.0677, 0.4740], d_k_M_hat range: [0.2269, 0.6609]
2025-03-11 19:57:34 - Train Iteration 982: loss: 0.6510, d_k_M range: [0.2579, 0.5439], d_k_M_hat range: [0.4840, 0.7445]
2025-03-11 19:57:35 - Train Iteration 983: loss: 0.6691, d_k_M range: [0.2381, 0.5553], d_k_M_hat range: [0.4628, 0.7373]
2025-03-11 19:57:35 - Train Iteration 984: loss: 0.6081, d_k_M range: [0.0822, 0.5840], d_k_M_hat range: [0.3223, 0.8074]
2025-03-11 19:57:35 - Train Iteration 985: loss: 0.6352, d_k_M range: [0.0646, 0.6778], d_k_M_hat range: [0.2687, 0.8997]
2025-03-11 19:57:36 - Train Iteration 986: loss: 0.6656, d_k_M range: [0.0868, 0.6648], d_k_M_hat range: [0.3139, 0.8712]
2025-03-11 19:57:36 - Train Iteration 987: loss: 0.5808, d_k_M range: [0.2129, 0.5969], d_k_M_hat range: [0.4716, 0.8430]
2025-03-11 19:57:37 - Train Iteration 988: loss: 0.9625, d_k_M range: [0.0013, 0.5950], d_k_M_hat range: [0.0202, 0.8132]
2025-03-11 19:57:37 - Train Iteration 989: loss: 0.7192, d_k_M range: [0.1066, 0.8160], d_k_M_hat range: [0.3611, 0.9679]
2025-03-11 19:57:37 - Train Iteration 990: loss: 0.6392, d_k_M range: [0.0391, 0.5283], d_k_M_hat range: [0.2508, 0.7592]
2025-03-11 19:57:38 - Train Iteration 991: loss: 0.6685, d_k_M range: [0.0353, 0.7393], d_k_M_hat range: [0.2913, 0.9216]
2025-03-11 19:57:38 - Train Iteration 992: loss: 0.6363, d_k_M range: [0.0543, 0.3964], d_k_M_hat range: [0.2566, 0.6233]
2025-03-11 19:57:39 - Train Iteration 993: loss: 0.7070, d_k_M range: [0.1354, 0.7917], d_k_M_hat range: [0.3977, 0.9509]
2025-03-11 19:57:39 - Train Iteration 994: loss: 0.6007, d_k_M range: [0.0474, 0.4389], d_k_M_hat range: [0.3134, 0.6819]
2025-03-11 19:57:40 - Train Iteration 995: loss: 0.7305, d_k_M range: [0.0095, 0.8098], d_k_M_hat range: [0.1748, 0.9550]
2025-03-11 19:57:40 - Train Iteration 996: loss: 0.7280, d_k_M range: [0.0283, 0.8257], d_k_M_hat range: [0.2476, 0.9725]
2025-03-11 19:57:41 - Train Iteration 997: loss: 0.6307, d_k_M range: [0.1600, 0.6647], d_k_M_hat range: [0.3669, 0.8705]
2025-03-11 19:57:41 - Train Iteration 998: loss: 0.6265, d_k_M range: [0.1128, 0.3631], d_k_M_hat range: [0.3706, 0.6096]
2025-03-11 19:57:42 - Train Iteration 999: loss: 0.6209, d_k_M range: [0.0235, 0.5004], d_k_M_hat range: [0.2410, 0.7282]
2025-03-11 19:57:42 - Train Iteration 1000: loss: 0.6830, d_k_M range: [0.0340, 0.3027], d_k_M_hat range: [0.2076, 0.5394]
2025-03-11 19:57:43 - Train Iteration 1001: loss: 0.8531, d_k_M range: [0.1862, 0.9066], d_k_M_hat range: [0.4159, 0.9830]
2025-03-11 19:57:43 - Train Iteration 1002: loss: 0.6497, d_k_M range: [0.1980, 0.7183], d_k_M_hat range: [0.4211, 0.9123]
2025-03-11 19:57:43 - Train Iteration 1003: loss: 0.6493, d_k_M range: [0.0173, 0.5833], d_k_M_hat range: [0.2236, 0.7814]
2025-03-11 19:57:44 - Train Iteration 1004: loss: 0.7789, d_k_M range: [0.0042, 0.5834], d_k_M_hat range: [0.1216, 0.8213]
2025-03-11 19:57:44 - Train Iteration 1005: loss: 0.8405, d_k_M range: [0.4511, 0.9076], d_k_M_hat range: [0.6896, 0.9908]
2025-03-11 19:57:45 - Train Iteration 1006: loss: 0.6752, d_k_M range: [0.2875, 0.5804], d_k_M_hat range: [0.5225, 0.7901]
2025-03-11 19:57:45 - Train Iteration 1007: loss: 0.6621, d_k_M range: [0.2054, 0.6131], d_k_M_hat range: [0.4184, 0.8407]
2025-03-11 19:57:46 - Train Iteration 1008: loss: 0.6136, d_k_M range: [0.1665, 0.5243], d_k_M_hat range: [0.3996, 0.7624]
2025-03-11 19:57:46 - Train Iteration 1009: loss: 0.7202, d_k_M range: [0.0465, 0.8161], d_k_M_hat range: [0.2590, 0.9675]
2025-03-11 19:57:47 - Train Iteration 1010: loss: 0.6520, d_k_M range: [0.1130, 0.5977], d_k_M_hat range: [0.3144, 0.8062]
2025-03-11 19:57:47 - Train Iteration 1011: loss: 0.6746, d_k_M range: [0.1855, 0.6444], d_k_M_hat range: [0.4854, 0.8231]
2025-03-11 19:57:47 - Train Iteration 1012: loss: 0.6109, d_k_M range: [0.2933, 0.6997], d_k_M_hat range: [0.5700, 0.9181]
2025-03-11 19:57:48 - Train Iteration 1013: loss: 0.8098, d_k_M range: [0.0117, 0.7133], d_k_M_hat range: [0.1118, 0.9151]
2025-03-11 19:57:48 - Train Iteration 1014: loss: 0.6546, d_k_M range: [0.0201, 0.4484], d_k_M_hat range: [0.2111, 0.6701]
2025-03-11 19:57:49 - Train Iteration 1015: loss: 0.6988, d_k_M range: [0.2253, 0.7388], d_k_M_hat range: [0.5046, 0.9029]
2025-03-11 19:57:49 - Train Iteration 1016: loss: 0.8258, d_k_M range: [0.0197, 0.4263], d_k_M_hat range: [0.1109, 0.6790]
2025-03-11 19:57:50 - Train Iteration 1017: loss: 0.6398, d_k_M range: [0.0881, 0.5620], d_k_M_hat range: [0.2883, 0.7974]
2025-03-11 19:57:50 - Train Iteration 1018: loss: 0.8070, d_k_M range: [0.0169, 0.8840], d_k_M_hat range: [0.1654, 0.9857]
2025-03-11 19:57:50 - Train Iteration 1019: loss: 0.8653, d_k_M range: [0.0099, 0.4416], d_k_M_hat range: [0.0797, 0.6466]
2025-03-11 19:57:51 - Train Iteration 1020: loss: 0.6492, d_k_M range: [0.2295, 0.6611], d_k_M_hat range: [0.4536, 0.8828]
2025-03-11 19:57:51 - Train Iteration 1021: loss: 0.8740, d_k_M range: [0.0866, 0.9196], d_k_M_hat range: [0.2763, 0.9847]
2025-03-11 19:57:52 - Train Iteration 1022: loss: 0.6906, d_k_M range: [0.1758, 0.5947], d_k_M_hat range: [0.3448, 0.8158]
2025-03-11 19:57:52 - Train Iteration 1023: loss: 0.6726, d_k_M range: [0.0358, 0.7380], d_k_M_hat range: [0.2608, 0.9179]
2025-03-11 19:57:53 - Train Iteration 1024: loss: 0.6266, d_k_M range: [0.1186, 0.4575], d_k_M_hat range: [0.3636, 0.7133]
2025-03-11 19:57:53 - Train Iteration 1025: loss: 0.6548, d_k_M range: [0.1682, 0.6050], d_k_M_hat range: [0.3965, 0.8326]
2025-03-11 19:57:54 - Train Iteration 1026: loss: 0.6680, d_k_M range: [0.2304, 0.7972], d_k_M_hat range: [0.4804, 0.9823]
2025-03-11 19:57:54 - Train Iteration 1027: loss: 0.5946, d_k_M range: [0.0255, 0.3701], d_k_M_hat range: [0.2543, 0.6782]
2025-03-11 19:57:54 - Train Iteration 1028: loss: 0.5982, d_k_M range: [0.0750, 0.5134], d_k_M_hat range: [0.3303, 0.7746]
2025-03-11 19:57:55 - Train Iteration 1029: loss: 0.6018, d_k_M range: [0.0569, 0.6510], d_k_M_hat range: [0.2811, 0.9040]
2025-03-11 19:57:55 - Train Iteration 1030: loss: 0.8408, d_k_M range: [0.0129, 0.7706], d_k_M_hat range: [0.0960, 0.9603]
2025-03-11 19:57:56 - Train Iteration 1031: loss: 0.5770, d_k_M range: [0.1486, 0.5320], d_k_M_hat range: [0.3959, 0.8295]
2025-03-11 19:57:56 - Train Iteration 1032: loss: 0.6738, d_k_M range: [0.0869, 0.7668], d_k_M_hat range: [0.3473, 0.9459]
2025-03-11 19:57:57 - Train Iteration 1033: loss: 0.6979, d_k_M range: [0.0088, 0.5658], d_k_M_hat range: [0.1734, 0.8317]
2025-03-11 19:57:57 - Train Iteration 1034: loss: 0.7994, d_k_M range: [0.2186, 0.8822], d_k_M_hat range: [0.5076, 0.9881]
2025-03-11 19:57:57 - Train Iteration 1035: loss: 0.6206, d_k_M range: [0.0542, 0.4192], d_k_M_hat range: [0.2854, 0.6314]
2025-03-11 19:57:58 - Train Iteration 1036: loss: 0.6049, d_k_M range: [0.1352, 0.4056], d_k_M_hat range: [0.3574, 0.6979]
2025-03-11 19:57:58 - Train Iteration 1037: loss: 0.6062, d_k_M range: [0.1827, 0.4730], d_k_M_hat range: [0.4041, 0.7545]
2025-03-11 19:57:59 - Train Iteration 1038: loss: 0.6258, d_k_M range: [0.0870, 0.5781], d_k_M_hat range: [0.3080, 0.8073]
2025-03-11 19:57:59 - Train Iteration 1039: loss: 0.6496, d_k_M range: [0.1305, 0.3787], d_k_M_hat range: [0.3537, 0.6421]
2025-03-11 19:57:59 - Train Iteration 1040: loss: 0.6320, d_k_M range: [0.0253, 0.5479], d_k_M_hat range: [0.2303, 0.8162]
2025-03-11 19:58:00 - Train Iteration 1041: loss: 0.9675, d_k_M range: [0.1513, 0.9823], d_k_M_hat range: [0.3789, 0.9987]
2025-03-11 19:58:00 - Train Iteration 1042: loss: 0.6403, d_k_M range: [0.1910, 0.7537], d_k_M_hat range: [0.4265, 0.9535]
2025-03-11 19:58:01 - Train Iteration 1043: loss: 0.7461, d_k_M range: [0.0082, 0.8377], d_k_M_hat range: [0.1916, 0.9739]
2025-03-11 19:58:01 - Train Iteration 1044: loss: 0.6131, d_k_M range: [0.0336, 0.4685], d_k_M_hat range: [0.2506, 0.6975]
2025-03-11 19:58:02 - Train Iteration 1045: loss: 0.6752, d_k_M range: [0.1344, 0.7897], d_k_M_hat range: [0.3957, 0.9680]
2025-03-11 19:58:02 - Train Iteration 1046: loss: 0.6155, d_k_M range: [0.2416, 0.5860], d_k_M_hat range: [0.4719, 0.8130]
2025-03-11 19:58:03 - Train Iteration 1047: loss: 0.7532, d_k_M range: [0.0150, 0.4344], d_k_M_hat range: [0.1472, 0.6695]
2025-03-11 19:58:03 - Train Iteration 1048: loss: 0.8044, d_k_M range: [0.0998, 0.8844], d_k_M_hat range: [0.3521, 0.9875]
2025-03-11 19:58:03 - Train Iteration 1049: loss: 0.7013, d_k_M range: [0.0383, 0.7588], d_k_M_hat range: [0.2269, 0.9214]
2025-03-11 19:58:04 - Train Iteration 1050: loss: 0.6633, d_k_M range: [0.1008, 0.3342], d_k_M_hat range: [0.3302, 0.5611]
2025-03-11 19:58:04 - Train Iteration 1051: loss: 0.7071, d_k_M range: [0.0125, 0.5624], d_k_M_hat range: [0.1716, 0.7472]
2025-03-11 19:58:05 - Train Iteration 1052: loss: 0.6825, d_k_M range: [0.1592, 0.7448], d_k_M_hat range: [0.3672, 0.9235]
2025-03-11 19:58:05 - Train Iteration 1053: loss: 0.6897, d_k_M range: [0.2677, 0.6359], d_k_M_hat range: [0.4769, 0.8670]
2025-03-11 19:58:06 - Train Iteration 1054: loss: 0.6608, d_k_M range: [0.2338, 0.6935], d_k_M_hat range: [0.4715, 0.9060]
2025-03-11 19:58:06 - Train Iteration 1055: loss: 0.6320, d_k_M range: [0.0870, 0.7185], d_k_M_hat range: [0.3236, 0.9235]
2025-03-11 19:58:06 - Train Iteration 1056: loss: 0.6391, d_k_M range: [0.0655, 0.6953], d_k_M_hat range: [0.2747, 0.9168]
2025-03-11 19:58:07 - Train Iteration 1057: loss: 0.6783, d_k_M range: [0.3105, 0.7851], d_k_M_hat range: [0.5025, 0.9615]
2025-03-11 19:58:07 - Train Iteration 1058: loss: 0.6456, d_k_M range: [0.1494, 0.4649], d_k_M_hat range: [0.3459, 0.6770]
2025-03-11 19:58:08 - Train Iteration 1059: loss: 0.6614, d_k_M range: [0.0728, 0.7461], d_k_M_hat range: [0.3482, 0.9328]
2025-03-11 19:58:08 - Train Iteration 1060: loss: 0.5978, d_k_M range: [0.0300, 0.4312], d_k_M_hat range: [0.2935, 0.6580]
2025-03-11 19:58:08 - Train Iteration 1061: loss: 0.7710, d_k_M range: [0.0052, 0.8048], d_k_M_hat range: [0.1271, 0.9679]
2025-03-11 19:58:09 - Train Iteration 1062: loss: 0.6090, d_k_M range: [0.0787, 0.7251], d_k_M_hat range: [0.2983, 0.9609]
2025-03-11 19:58:09 - Train Iteration 1063: loss: 0.5712, d_k_M range: [0.0496, 0.6127], d_k_M_hat range: [0.3311, 0.8812]
2025-03-11 19:58:10 - Train Iteration 1064: loss: 0.6744, d_k_M range: [0.2469, 0.7833], d_k_M_hat range: [0.5178, 0.9621]
2025-03-11 19:58:10 - Train Iteration 1065: loss: 0.9371, d_k_M range: [0.0045, 0.6221], d_k_M_hat range: [0.0364, 0.8566]
2025-03-11 19:58:11 - Train Iteration 1066: loss: 0.6421, d_k_M range: [0.2856, 0.7090], d_k_M_hat range: [0.5465, 0.9077]
2025-03-11 19:58:11 - Train Iteration 1067: loss: 0.8081, d_k_M range: [0.0836, 0.8799], d_k_M_hat range: [0.3059, 0.9809]
2025-03-11 19:58:11 - Train Iteration 1068: loss: 0.6473, d_k_M range: [0.0423, 0.2948], d_k_M_hat range: [0.2444, 0.5227]
2025-03-11 19:58:12 - Train Iteration 1069: loss: 0.6976, d_k_M range: [0.2183, 0.5526], d_k_M_hat range: [0.4320, 0.7655]
2025-03-11 19:58:12 - Train Iteration 1070: loss: 0.6510, d_k_M range: [0.2528, 0.6756], d_k_M_hat range: [0.4656, 0.8688]
2025-03-11 19:58:13 - Train Iteration 1071: loss: 0.6501, d_k_M range: [0.2345, 0.5242], d_k_M_hat range: [0.4299, 0.7492]
2025-03-11 19:58:13 - Train Iteration 1072: loss: 0.6597, d_k_M range: [0.0832, 0.5086], d_k_M_hat range: [0.3158, 0.7303]
2025-03-11 19:58:14 - Train Iteration 1073: loss: 0.6703, d_k_M range: [0.1702, 0.6315], d_k_M_hat range: [0.3909, 0.8650]
2025-03-11 19:58:14 - Train Iteration 1074: loss: 0.6521, d_k_M range: [0.2268, 0.6793], d_k_M_hat range: [0.4384, 0.9031]
2025-03-11 19:58:15 - Train Iteration 1075: loss: 0.8210, d_k_M range: [0.0126, 0.8891], d_k_M_hat range: [0.2097, 0.9830]
2025-03-11 19:58:15 - Train Iteration 1076: loss: 0.6306, d_k_M range: [0.0973, 0.5119], d_k_M_hat range: [0.3601, 0.7488]
2025-03-11 19:58:16 - Train Iteration 1077: loss: 0.7657, d_k_M range: [0.0049, 0.6359], d_k_M_hat range: [0.1299, 0.8157]
2025-03-11 19:58:16 - Train Iteration 1078: loss: 0.6758, d_k_M range: [0.2168, 0.6350], d_k_M_hat range: [0.4376, 0.8412]
2025-03-11 19:58:16 - Train Iteration 1079: loss: 0.6605, d_k_M range: [0.1165, 0.7138], d_k_M_hat range: [0.3038, 0.9019]
2025-03-11 19:58:17 - Train Iteration 1080: loss: 0.6886, d_k_M range: [0.2521, 0.7127], d_k_M_hat range: [0.5004, 0.8958]
2025-03-11 19:58:17 - Train Iteration 1081: loss: 0.6829, d_k_M range: [0.1999, 0.7820], d_k_M_hat range: [0.4604, 0.9556]
2025-03-11 19:58:18 - Train Iteration 1082: loss: 0.7465, d_k_M range: [0.0085, 0.5477], d_k_M_hat range: [0.1445, 0.7538]
2025-03-11 19:58:18 - Train Iteration 1083: loss: 0.6444, d_k_M range: [0.0834, 0.4694], d_k_M_hat range: [0.2807, 0.7075]
2025-03-11 19:58:19 - Train Iteration 1084: loss: 0.6821, d_k_M range: [0.1854, 0.6158], d_k_M_hat range: [0.4384, 0.8007]
2025-03-11 19:58:19 - Train Iteration 1085: loss: 0.6517, d_k_M range: [0.2522, 0.5321], d_k_M_hat range: [0.5228, 0.7764]
2025-03-11 19:58:19 - Train Iteration 1086: loss: 0.6070, d_k_M range: [0.1167, 0.5947], d_k_M_hat range: [0.3512, 0.8367]
2025-03-11 19:58:20 - Train Iteration 1087: loss: 0.9101, d_k_M range: [0.0503, 0.9448], d_k_M_hat range: [0.2497, 0.9908]
2025-03-11 19:58:20 - Train Iteration 1088: loss: 0.6474, d_k_M range: [0.1443, 0.6346], d_k_M_hat range: [0.4146, 0.8585]
2025-03-11 19:58:21 - Train Iteration 1089: loss: 0.5927, d_k_M range: [0.0860, 0.5265], d_k_M_hat range: [0.3412, 0.7566]
2025-03-11 19:58:21 - Train Iteration 1090: loss: 0.7325, d_k_M range: [0.0076, 0.3320], d_k_M_hat range: [0.1518, 0.6101]
2025-03-11 19:58:22 - Train Iteration 1091: loss: 0.8813, d_k_M range: [0.1373, 0.9350], d_k_M_hat range: [0.3605, 0.9962]
2025-03-11 19:58:22 - Train Iteration 1092: loss: 0.6326, d_k_M range: [0.0151, 0.6140], d_k_M_hat range: [0.2282, 0.8349]
2025-03-11 19:58:23 - Train Iteration 1093: loss: 0.6434, d_k_M range: [0.1515, 0.4529], d_k_M_hat range: [0.3869, 0.6901]
2025-03-11 19:58:23 - Train Iteration 1094: loss: 0.7093, d_k_M range: [0.1665, 0.8005], d_k_M_hat range: [0.4304, 0.9583]
2025-03-11 19:58:23 - Train Iteration 1095: loss: 0.6198, d_k_M range: [0.0259, 0.5930], d_k_M_hat range: [0.2527, 0.8057]
2025-03-11 19:58:24 - Train Iteration 1096: loss: 0.6673, d_k_M range: [0.0624, 0.4339], d_k_M_hat range: [0.2818, 0.6758]
2025-03-11 19:58:24 - Train Iteration 1097: loss: 0.7043, d_k_M range: [0.0143, 0.6022], d_k_M_hat range: [0.1751, 0.8473]
2025-03-11 19:58:25 - Train Iteration 1098: loss: 0.6702, d_k_M range: [0.2751, 0.7739], d_k_M_hat range: [0.5197, 0.9552]
2025-03-11 19:58:25 - Train Iteration 1099: loss: 0.6447, d_k_M range: [0.0720, 0.5768], d_k_M_hat range: [0.2940, 0.7885]
2025-03-11 19:58:25 - Train Iteration 1100: loss: 0.8271, d_k_M range: [0.0058, 0.5711], d_k_M_hat range: [0.0964, 0.8119]
2025-03-11 19:58:26 - Train Iteration 1101: loss: 0.8900, d_k_M range: [0.3038, 0.9355], d_k_M_hat range: [0.5514, 0.9923]
2025-03-11 19:58:26 - Train Iteration 1102: loss: 0.6206, d_k_M range: [0.3312, 0.4779], d_k_M_hat range: [0.5898, 0.7360]
2025-03-11 19:58:27 - Train Iteration 1103: loss: 0.6165, d_k_M range: [0.0249, 0.6943], d_k_M_hat range: [0.2455, 0.9091]
2025-03-11 19:58:27 - Train Iteration 1104: loss: 0.6029, d_k_M range: [0.0795, 0.6489], d_k_M_hat range: [0.3274, 0.8935]
2025-03-11 19:58:28 - Train Iteration 1105: loss: 0.8472, d_k_M range: [0.0042, 0.4224], d_k_M_hat range: [0.0838, 0.6945]
2025-03-11 19:58:28 - Train Iteration 1106: loss: 0.6154, d_k_M range: [0.0588, 0.5203], d_k_M_hat range: [0.2981, 0.7733]
2025-03-11 19:58:28 - Train Iteration 1107: loss: 0.7040, d_k_M range: [0.2961, 0.8207], d_k_M_hat range: [0.5440, 0.9817]
2025-03-11 19:58:29 - Train Iteration 1108: loss: 0.6449, d_k_M range: [0.0692, 0.5736], d_k_M_hat range: [0.2662, 0.8050]
2025-03-11 19:58:29 - Train Iteration 1109: loss: 0.6096, d_k_M range: [0.1948, 0.7038], d_k_M_hat range: [0.4349, 0.9230]
2025-03-11 19:58:30 - Train Iteration 1110: loss: 0.9900, d_k_M range: [0.0013, 0.3025], d_k_M_hat range: [0.0063, 0.5236]
2025-03-11 19:58:30 - Train Iteration 1111: loss: 0.6895, d_k_M range: [0.1096, 0.6865], d_k_M_hat range: [0.3756, 0.8798]
2025-03-11 19:58:30 - Train Iteration 1112: loss: 0.6943, d_k_M range: [0.0217, 0.6721], d_k_M_hat range: [0.1885, 0.9077]
2025-03-11 19:58:31 - Train Iteration 1113: loss: 0.9091, d_k_M range: [0.2328, 0.9441], d_k_M_hat range: [0.4728, 0.9907]
2025-03-11 19:58:31 - Train Iteration 1114: loss: 0.6919, d_k_M range: [0.0995, 0.4073], d_k_M_hat range: [0.2676, 0.6426]
2025-03-11 19:58:32 - Train Iteration 1115: loss: 0.7180, d_k_M range: [0.0037, 0.6063], d_k_M_hat range: [0.1563, 0.8261]
2025-03-11 19:58:32 - Train Iteration 1116: loss: 0.6418, d_k_M range: [0.1751, 0.6957], d_k_M_hat range: [0.4581, 0.8945]
2025-03-11 19:58:33 - Train Iteration 1117: loss: 0.7483, d_k_M range: [0.0048, 0.3832], d_k_M_hat range: [0.1421, 0.6436]
2025-03-11 19:58:33 - Train Iteration 1118: loss: 0.6311, d_k_M range: [0.2649, 0.7038], d_k_M_hat range: [0.5340, 0.9094]
2025-03-11 19:58:33 - Train Iteration 1119: loss: 0.6841, d_k_M range: [0.0231, 0.6634], d_k_M_hat range: [0.1960, 0.8661]
2025-03-11 19:58:34 - Train Iteration 1120: loss: 0.8025, d_k_M range: [0.3897, 0.8801], d_k_M_hat range: [0.5882, 0.9843]
2025-03-11 19:58:34 - Train Iteration 1121: loss: 0.6118, d_k_M range: [0.1340, 0.4059], d_k_M_hat range: [0.3534, 0.6542]
2025-03-11 19:58:35 - Train Iteration 1122: loss: 0.7126, d_k_M range: [0.3216, 0.8149], d_k_M_hat range: [0.5856, 0.9707]
2025-03-11 19:58:35 - Train Iteration 1123: loss: 0.6646, d_k_M range: [0.0584, 0.3339], d_k_M_hat range: [0.2778, 0.5524]
2025-03-11 19:58:36 - Train Iteration 1124: loss: 0.6794, d_k_M range: [0.0998, 0.7044], d_k_M_hat range: [0.3150, 0.8802]
2025-03-11 19:58:36 - Train Iteration 1125: loss: 0.6385, d_k_M range: [0.0527, 0.4205], d_k_M_hat range: [0.2536, 0.6728]
2025-03-11 19:58:37 - Train Iteration 1126: loss: 0.6534, d_k_M range: [0.0679, 0.5151], d_k_M_hat range: [0.3168, 0.7811]
2025-03-11 19:58:37 - Train Iteration 1127: loss: 0.6327, d_k_M range: [0.2752, 0.5358], d_k_M_hat range: [0.4797, 0.7477]
2025-03-11 19:58:37 - Train Iteration 1128: loss: 0.6199, d_k_M range: [0.2257, 0.5693], d_k_M_hat range: [0.5177, 0.8191]
2025-03-11 19:58:38 - Train Iteration 1129: loss: 0.6980, d_k_M range: [0.0578, 0.5695], d_k_M_hat range: [0.2273, 0.7997]
2025-03-11 19:58:38 - Train Iteration 1130: loss: 0.9363, d_k_M range: [0.3957, 0.9617], d_k_M_hat range: [0.6301, 0.9941]
2025-03-11 19:58:39 - Train Iteration 1131: loss: 0.8444, d_k_M range: [0.0098, 0.6702], d_k_M_hat range: [0.0909, 0.8763]
2025-03-11 19:58:39 - Train Iteration 1132: loss: 0.6337, d_k_M range: [0.1434, 0.6718], d_k_M_hat range: [0.3716, 0.9111]
2025-03-11 19:58:40 - Train Iteration 1133: loss: 0.7078, d_k_M range: [0.1968, 0.7773], d_k_M_hat range: [0.4489, 0.9359]
2025-03-11 19:58:40 - Train Iteration 1134: loss: 0.7036, d_k_M range: [0.2081, 0.8059], d_k_M_hat range: [0.4490, 0.9671]
2025-03-11 19:58:40 - Train Iteration 1135: loss: 0.8917, d_k_M range: [0.0224, 0.5292], d_k_M_hat range: [0.0781, 0.7752]
2025-03-11 19:58:41 - Train Iteration 1136: loss: 0.6310, d_k_M range: [0.0530, 0.6068], d_k_M_hat range: [0.3298, 0.8535]
2025-03-11 19:58:41 - Train Iteration 1137: loss: 0.6328, d_k_M range: [0.1852, 0.5657], d_k_M_hat range: [0.4091, 0.7702]
2025-03-11 19:58:42 - Train Iteration 1138: loss: 0.6616, d_k_M range: [0.0449, 0.7711], d_k_M_hat range: [0.2991, 0.9577]
2025-03-11 19:58:42 - Train Iteration 1139: loss: 0.5928, d_k_M range: [0.0632, 0.5789], d_k_M_hat range: [0.3074, 0.8200]
2025-03-11 19:58:42 - Train Iteration 1140: loss: 0.6000, d_k_M range: [0.0482, 0.6085], d_k_M_hat range: [0.2863, 0.8339]
2025-03-11 19:58:43 - Train Iteration 1141: loss: 0.8645, d_k_M range: [0.0031, 0.2056], d_k_M_hat range: [0.0733, 0.4927]
2025-03-11 19:58:43 - Train Iteration 1142: loss: 0.6433, d_k_M range: [0.1744, 0.7093], d_k_M_hat range: [0.4348, 0.9297]
2025-03-11 19:58:44 - Train Iteration 1143: loss: 0.6131, d_k_M range: [0.1304, 0.6907], d_k_M_hat range: [0.3592, 0.9077]
2025-03-11 19:58:44 - Train Iteration 1144: loss: 0.6297, d_k_M range: [0.0308, 0.6014], d_k_M_hat range: [0.2522, 0.8079]
2025-03-11 19:58:45 - Train Iteration 1145: loss: 0.8162, d_k_M range: [0.1433, 0.8885], d_k_M_hat range: [0.3801, 0.9850]
2025-03-11 19:58:45 - Train Iteration 1146: loss: 0.8591, d_k_M range: [0.1239, 0.9142], d_k_M_hat range: [0.3602, 0.9873]
2025-03-11 19:58:45 - Train Iteration 1147: loss: 0.8776, d_k_M range: [0.0076, 0.4227], d_k_M_hat range: [0.0707, 0.6531]
2025-03-11 19:58:46 - Train Iteration 1148: loss: 0.6343, d_k_M range: [0.1301, 0.6262], d_k_M_hat range: [0.3545, 0.8298]
2025-03-11 19:58:46 - Train Iteration 1149: loss: 0.6025, d_k_M range: [0.0852, 0.7252], d_k_M_hat range: [0.3555, 0.9490]
2025-03-11 19:58:47 - Train Iteration 1150: loss: 0.5918, d_k_M range: [0.1606, 0.5763], d_k_M_hat range: [0.4546, 0.8402]
2025-03-11 19:58:47 - Train Iteration 1151: loss: 0.5848, d_k_M range: [0.2269, 0.6691], d_k_M_hat range: [0.4795, 0.9044]
2025-03-11 19:58:47 - Train Iteration 1152: loss: 0.6664, d_k_M range: [0.0203, 0.3460], d_k_M_hat range: [0.2039, 0.5961]
2025-03-11 19:58:48 - Train Iteration 1153: loss: 0.5924, d_k_M range: [0.0799, 0.6380], d_k_M_hat range: [0.3482, 0.8731]
2025-03-11 19:58:48 - Train Iteration 1154: loss: 0.6326, d_k_M range: [0.0188, 0.4115], d_k_M_hat range: [0.2568, 0.7202]
2025-03-11 19:58:49 - Train Iteration 1155: loss: 0.6474, d_k_M range: [0.0371, 0.4424], d_k_M_hat range: [0.2532, 0.7228]
2025-03-11 19:58:49 - Train Iteration 1156: loss: 0.6332, d_k_M range: [0.2071, 0.4559], d_k_M_hat range: [0.4429, 0.6601]
2025-03-11 19:58:50 - Train Iteration 1157: loss: 0.7699, d_k_M range: [0.1554, 0.8447], d_k_M_hat range: [0.5209, 0.9739]
2025-03-11 19:58:50 - Train Iteration 1158: loss: 0.6112, d_k_M range: [0.0606, 0.2992], d_k_M_hat range: [0.3355, 0.5385]
2025-03-11 19:58:50 - Train Iteration 1159: loss: 0.7248, d_k_M range: [0.0219, 0.8344], d_k_M_hat range: [0.2439, 0.9831]
2025-03-11 19:58:51 - Train Iteration 1160: loss: 0.5827, d_k_M range: [0.1645, 0.5301], d_k_M_hat range: [0.4235, 0.7914]
2025-03-11 19:58:51 - Train Iteration 1161: loss: 0.7180, d_k_M range: [0.0102, 0.3366], d_k_M_hat range: [0.1629, 0.6009]
2025-03-11 19:58:52 - Train Iteration 1162: loss: 0.6278, d_k_M range: [0.0206, 0.4539], d_k_M_hat range: [0.2302, 0.7405]
2025-03-11 19:58:52 - Train Iteration 1163: loss: 0.6127, d_k_M range: [0.2844, 0.7501], d_k_M_hat range: [0.5544, 0.9673]
2025-03-11 19:58:53 - Train Iteration 1164: loss: 0.5854, d_k_M range: [0.1361, 0.6983], d_k_M_hat range: [0.3885, 0.9332]
2025-03-11 19:58:53 - Train Iteration 1165: loss: 0.6245, d_k_M range: [0.0739, 0.7620], d_k_M_hat range: [0.3149, 0.9718]
2025-03-11 19:58:53 - Train Iteration 1166: loss: 0.6982, d_k_M range: [0.0145, 0.7927], d_k_M_hat range: [0.1919, 0.9571]
2025-03-11 19:58:54 - Train Iteration 1167: loss: 0.6353, d_k_M range: [0.0248, 0.4055], d_k_M_hat range: [0.2345, 0.6787]
2025-03-11 19:58:54 - Train Iteration 1168: loss: 0.6375, d_k_M range: [0.1904, 0.7193], d_k_M_hat range: [0.4141, 0.9208]
2025-03-11 19:58:55 - Train Iteration 1169: loss: 0.6079, d_k_M range: [0.1462, 0.7515], d_k_M_hat range: [0.4027, 0.9718]
2025-03-11 19:58:55 - Train Iteration 1170: loss: 0.7002, d_k_M range: [0.0063, 0.4453], d_k_M_hat range: [0.1695, 0.6961]
2025-03-11 19:58:55 - Train Iteration 1171: loss: 0.6286, d_k_M range: [0.2209, 0.6750], d_k_M_hat range: [0.4281, 0.9193]
2025-03-11 19:58:56 - Train Iteration 1172: loss: 0.7092, d_k_M range: [0.3084, 0.8269], d_k_M_hat range: [0.5679, 0.9848]
2025-03-11 19:58:56 - Train Iteration 1173: loss: 0.6393, d_k_M range: [0.0908, 0.6622], d_k_M_hat range: [0.3050, 0.8909]
2025-03-11 19:58:57 - Train Iteration 1174: loss: 0.6313, d_k_M range: [0.0810, 0.5738], d_k_M_hat range: [0.3220, 0.8070]
2025-03-11 19:58:57 - Train Iteration 1175: loss: 0.6447, d_k_M range: [0.1922, 0.5336], d_k_M_hat range: [0.4296, 0.7881]
2025-03-11 19:58:58 - Train Iteration 1176: loss: 0.9492, d_k_M range: [0.0975, 0.9719], d_k_M_hat range: [0.3479, 0.9976]
2025-03-11 19:58:58 - Train Iteration 1177: loss: 0.7551, d_k_M range: [0.0110, 0.8524], d_k_M_hat range: [0.1870, 0.9835]
2025-03-11 19:58:58 - Train Iteration 1178: loss: 0.6636, d_k_M range: [0.0231, 0.6460], d_k_M_hat range: [0.2397, 0.8754]
2025-03-11 19:58:59 - Train Iteration 1179: loss: 0.6308, d_k_M range: [0.1174, 0.7064], d_k_M_hat range: [0.3429, 0.9319]
2025-03-11 19:58:59 - Train Iteration 1180: loss: 0.6505, d_k_M range: [0.0475, 0.6830], d_k_M_hat range: [0.3174, 0.8844]
2025-03-11 19:59:00 - Train Iteration 1181: loss: 0.5787, d_k_M range: [0.0995, 0.4191], d_k_M_hat range: [0.3387, 0.6619]
2025-03-11 19:59:00 - Train Iteration 1182: loss: 0.6392, d_k_M range: [0.2661, 0.7352], d_k_M_hat range: [0.4666, 0.9401]
2025-03-11 19:59:01 - Train Iteration 1183: loss: 0.7531, d_k_M range: [0.2083, 0.8541], d_k_M_hat range: [0.4861, 0.9864]
2025-03-11 19:59:01 - Train Iteration 1184: loss: 0.6121, d_k_M range: [0.1601, 0.6925], d_k_M_hat range: [0.4508, 0.9323]
2025-03-11 19:59:01 - Train Iteration 1185: loss: 0.7724, d_k_M range: [0.0125, 0.3666], d_k_M_hat range: [0.1389, 0.6439]
2025-03-11 19:59:02 - Train Iteration 1186: loss: 0.5980, d_k_M range: [0.2045, 0.6275], d_k_M_hat range: [0.4439, 0.8932]
2025-03-11 19:59:02 - Train Iteration 1187: loss: 0.5965, d_k_M range: [0.2203, 0.5905], d_k_M_hat range: [0.4528, 0.8311]
2025-03-11 19:59:03 - Train Iteration 1188: loss: 0.9948, d_k_M range: [0.0002, 0.7196], d_k_M_hat range: [0.0028, 0.9329]
2025-03-11 19:59:03 - Train Iteration 1189: loss: 0.7989, d_k_M range: [0.3554, 0.8832], d_k_M_hat range: [0.5962, 0.9894]
2025-03-11 19:59:04 - Train Iteration 1190: loss: 0.6122, d_k_M range: [0.0504, 0.4231], d_k_M_hat range: [0.2679, 0.6887]
2025-03-11 19:59:04 - Train Iteration 1191: loss: 0.6226, d_k_M range: [0.0375, 0.6072], d_k_M_hat range: [0.2655, 0.8274]
2025-03-11 19:59:05 - Train Iteration 1192: loss: 0.5935, d_k_M range: [0.0572, 0.5400], d_k_M_hat range: [0.3453, 0.8094]
2025-03-11 19:59:05 - Train Iteration 1193: loss: 0.5838, d_k_M range: [0.2939, 0.5402], d_k_M_hat range: [0.5549, 0.8413]
2025-03-11 19:59:06 - Train Iteration 1194: loss: 0.9031, d_k_M range: [0.0031, 0.5272], d_k_M_hat range: [0.0528, 0.7617]
2025-03-11 19:59:06 - Train Iteration 1195: loss: 0.6047, d_k_M range: [0.0481, 0.6456], d_k_M_hat range: [0.2866, 0.8680]
2025-03-11 19:59:06 - Train Iteration 1196: loss: 0.7855, d_k_M range: [0.0203, 0.6919], d_k_M_hat range: [0.1340, 0.9249]
2025-03-11 19:59:07 - Train Iteration 1197: loss: 0.6182, d_k_M range: [0.2188, 0.6788], d_k_M_hat range: [0.4484, 0.9066]
2025-03-11 19:59:07 - Train Iteration 1198: loss: 0.6124, d_k_M range: [0.0438, 0.3020], d_k_M_hat range: [0.2908, 0.5377]
2025-03-11 19:59:08 - Train Iteration 1199: loss: 0.6547, d_k_M range: [0.1954, 0.3974], d_k_M_hat range: [0.4134, 0.6616]
2025-03-11 19:59:08 - Train Iteration 1200: loss: 0.6702, d_k_M range: [0.0209, 0.6113], d_k_M_hat range: [0.2556, 0.7926]
2025-03-11 19:59:09 - Train Iteration 1201: loss: 0.6741, d_k_M range: [0.2141, 0.7828], d_k_M_hat range: [0.4183, 0.9618]
2025-03-11 19:59:09 - Train Iteration 1202: loss: 0.6306, d_k_M range: [0.1561, 0.5314], d_k_M_hat range: [0.3975, 0.8134]
2025-03-11 19:59:09 - Train Iteration 1203: loss: 0.5644, d_k_M range: [0.2123, 0.6003], d_k_M_hat range: [0.4948, 0.8490]
2025-03-11 19:59:10 - Train Iteration 1204: loss: 0.6134, d_k_M range: [0.1129, 0.7191], d_k_M_hat range: [0.3951, 0.9473]
2025-03-11 19:59:10 - Train Iteration 1205: loss: 0.5832, d_k_M range: [0.0453, 0.3525], d_k_M_hat range: [0.2839, 0.6198]
2025-03-11 19:59:11 - Train Iteration 1206: loss: 0.7371, d_k_M range: [0.0783, 0.8416], d_k_M_hat range: [0.3579, 0.9831]
2025-03-11 19:59:11 - Train Iteration 1207: loss: 0.7190, d_k_M range: [0.0050, 0.7082], d_k_M_hat range: [0.1643, 0.9480]
2025-03-11 19:59:12 - Train Iteration 1208: loss: 0.6271, d_k_M range: [0.0456, 0.7398], d_k_M_hat range: [0.2679, 0.9479]
2025-03-11 19:59:12 - Train Iteration 1209: loss: 0.7899, d_k_M range: [0.0539, 0.7576], d_k_M_hat range: [0.1651, 0.9378]
2025-03-11 19:59:13 - Train Iteration 1210: loss: 0.5603, d_k_M range: [0.1610, 0.6765], d_k_M_hat range: [0.4237, 0.9279]
2025-03-11 19:59:13 - Train Iteration 1211: loss: 0.5890, d_k_M range: [0.2401, 0.6764], d_k_M_hat range: [0.5055, 0.9090]
2025-03-11 19:59:13 - Train Iteration 1212: loss: 0.8371, d_k_M range: [0.1043, 0.9078], d_k_M_hat range: [0.3621, 0.9929]
2025-03-11 19:59:14 - Train Iteration 1213: loss: 0.7305, d_k_M range: [0.0694, 0.8380], d_k_M_hat range: [0.3412, 0.9833]
2025-03-11 19:59:14 - Train Iteration 1214: loss: 0.6568, d_k_M range: [0.0103, 0.6017], d_k_M_hat range: [0.1998, 0.8879]
2025-03-11 19:59:15 - Train Iteration 1215: loss: 0.7861, d_k_M range: [0.2286, 0.8751], d_k_M_hat range: [0.4882, 0.9884]
2025-03-11 19:59:15 - Train Iteration 1216: loss: 0.6287, d_k_M range: [0.0930, 0.6658], d_k_M_hat range: [0.3589, 0.8916]
2025-03-11 19:59:16 - Train Iteration 1217: loss: 0.5973, d_k_M range: [0.0588, 0.3018], d_k_M_hat range: [0.3467, 0.5294]
2025-03-11 19:59:16 - Train Iteration 1218: loss: 0.9221, d_k_M range: [0.0019, 0.5874], d_k_M_hat range: [0.0417, 0.8283]
2025-03-11 19:59:17 - Train Iteration 1219: loss: 0.7838, d_k_M range: [0.3815, 0.8705], d_k_M_hat range: [0.6184, 0.9852]
2025-03-11 19:59:17 - Train Iteration 1220: loss: 0.6333, d_k_M range: [0.1229, 0.4578], d_k_M_hat range: [0.3605, 0.6725]
2025-03-11 19:59:17 - Train Iteration 1221: loss: 0.5914, d_k_M range: [0.0592, 0.5215], d_k_M_hat range: [0.3250, 0.7754]
2025-03-11 19:59:18 - Train Iteration 1222: loss: 0.6244, d_k_M range: [0.0628, 0.4751], d_k_M_hat range: [0.3287, 0.7389]
2025-03-11 19:59:18 - Train Iteration 1223: loss: 0.6133, d_k_M range: [0.1374, 0.6916], d_k_M_hat range: [0.4186, 0.9084]
2025-03-11 19:59:19 - Train Iteration 1224: loss: 0.6776, d_k_M range: [0.0809, 0.6175], d_k_M_hat range: [0.3693, 0.8559]
2025-03-11 19:59:19 - Train Iteration 1225: loss: 0.6175, d_k_M range: [0.2231, 0.6803], d_k_M_hat range: [0.4962, 0.8945]
2025-03-11 19:59:20 - Train Iteration 1226: loss: 0.7137, d_k_M range: [0.0115, 0.5158], d_k_M_hat range: [0.1667, 0.8021]
2025-03-11 19:59:20 - Train Iteration 1227: loss: 0.7044, d_k_M range: [0.0363, 0.7975], d_k_M_hat range: [0.2652, 0.9582]
2025-03-11 19:59:20 - Train Iteration 1228: loss: 0.6961, d_k_M range: [0.0873, 0.7895], d_k_M_hat range: [0.3099, 0.9552]
2025-03-11 19:59:21 - Train Iteration 1229: loss: 0.7306, d_k_M range: [0.1687, 0.7941], d_k_M_hat range: [0.4669, 0.9394]
2025-03-11 19:59:21 - Train Iteration 1230: loss: 0.6215, d_k_M range: [0.0204, 0.5965], d_k_M_hat range: [0.2341, 0.8597]
2025-03-11 19:59:22 - Train Iteration 1231: loss: 0.6344, d_k_M range: [0.0317, 0.3726], d_k_M_hat range: [0.2655, 0.5809]
2025-03-11 19:59:22 - Train Iteration 1232: loss: 0.6732, d_k_M range: [0.1990, 0.7968], d_k_M_hat range: [0.4972, 0.9763]
2025-03-11 19:59:23 - Train Iteration 1233: loss: 0.6092, d_k_M range: [0.1359, 0.7099], d_k_M_hat range: [0.4147, 0.9294]
2025-03-11 19:59:23 - Train Iteration 1234: loss: 0.6301, d_k_M range: [0.2920, 0.7445], d_k_M_hat range: [0.5407, 0.9507]
2025-03-11 19:59:24 - Train Iteration 1235: loss: 0.6299, d_k_M range: [0.1485, 0.6429], d_k_M_hat range: [0.4326, 0.9195]
2025-03-11 19:59:24 - Train Iteration 1236: loss: 0.5837, d_k_M range: [0.0425, 0.7216], d_k_M_hat range: [0.3195, 0.9576]
2025-03-11 19:59:25 - Train Iteration 1237: loss: 0.5935, d_k_M range: [0.1351, 0.6021], d_k_M_hat range: [0.3833, 0.8864]
2025-03-11 19:59:25 - Train Iteration 1238: loss: 0.5532, d_k_M range: [0.0725, 0.3872], d_k_M_hat range: [0.3287, 0.6555]
2025-03-11 19:59:26 - Train Iteration 1239: loss: 0.6312, d_k_M range: [0.1413, 0.7005], d_k_M_hat range: [0.4293, 0.9386]
2025-03-11 19:59:26 - Train Iteration 1240: loss: 0.7921, d_k_M range: [0.3672, 0.8704], d_k_M_hat range: [0.6791, 0.9804]
2025-03-11 19:59:26 - Train Iteration 1241: loss: 0.6070, d_k_M range: [0.1568, 0.5787], d_k_M_hat range: [0.3837, 0.8617]
2025-03-11 19:59:27 - Train Iteration 1242: loss: 0.8135, d_k_M range: [0.0018, 0.4434], d_k_M_hat range: [0.0998, 0.7475]
2025-03-11 19:59:27 - Train Iteration 1243: loss: 0.6180, d_k_M range: [0.1243, 0.4891], d_k_M_hat range: [0.3666, 0.7344]
2025-03-11 19:59:28 - Train Iteration 1244: loss: 0.5574, d_k_M range: [0.1512, 0.6718], d_k_M_hat range: [0.4518, 0.9432]
2025-03-11 19:59:28 - Train Iteration 1245: loss: 0.8426, d_k_M range: [0.0028, 0.5307], d_k_M_hat range: [0.0849, 0.8126]
2025-03-11 19:59:29 - Train Iteration 1246: loss: 0.7879, d_k_M range: [0.3000, 0.8771], d_k_M_hat range: [0.6448, 0.9895]
2025-03-11 19:59:29 - Train Iteration 1247: loss: 0.6019, d_k_M range: [0.0838, 0.4203], d_k_M_hat range: [0.3237, 0.6790]
2025-03-11 19:59:30 - Train Iteration 1248: loss: 0.6869, d_k_M range: [0.1300, 0.8007], d_k_M_hat range: [0.4146, 0.9719]
2025-03-11 19:59:30 - Train Iteration 1249: loss: 0.6209, d_k_M range: [0.0284, 0.5185], d_k_M_hat range: [0.2404, 0.7339]
2025-03-11 19:59:30 - Train Iteration 1250: loss: 0.7020, d_k_M range: [0.3071, 0.7124], d_k_M_hat range: [0.5005, 0.9058]
2025-03-11 19:59:31 - Train Iteration 1251: loss: 0.8033, d_k_M range: [0.2966, 0.8805], d_k_M_hat range: [0.5456, 0.9843]
2025-03-11 19:59:31 - Train Iteration 1252: loss: 0.6299, d_k_M range: [0.0354, 0.5726], d_k_M_hat range: [0.2417, 0.8257]
2025-03-11 19:59:32 - Train Iteration 1253: loss: 0.6052, d_k_M range: [0.0776, 0.5633], d_k_M_hat range: [0.2996, 0.7862]
2025-03-11 19:59:32 - Train Iteration 1254: loss: 0.6310, d_k_M range: [0.1444, 0.5377], d_k_M_hat range: [0.3526, 0.7853]
2025-03-11 19:59:32 - Train Iteration 1255: loss: 0.6395, d_k_M range: [0.0113, 0.6529], d_k_M_hat range: [0.2116, 0.8966]
2025-03-11 19:59:33 - Train Iteration 1256: loss: 0.8884, d_k_M range: [0.1639, 0.9344], d_k_M_hat range: [0.4257, 0.9918]
2025-03-11 19:59:33 - Train Iteration 1257: loss: 0.6663, d_k_M range: [0.3369, 0.6779], d_k_M_hat range: [0.5439, 0.9050]
2025-03-11 19:59:34 - Train Iteration 1258: loss: 0.6011, d_k_M range: [0.1429, 0.4452], d_k_M_hat range: [0.4122, 0.7266]
2025-03-11 19:59:34 - Train Iteration 1259: loss: 0.5605, d_k_M range: [0.1297, 0.5978], d_k_M_hat range: [0.3811, 0.8619]
2025-03-11 19:59:35 - Train Iteration 1260: loss: 0.7018, d_k_M range: [0.0090, 0.8125], d_k_M_hat range: [0.1867, 0.9748]
2025-03-11 19:59:35 - Train Iteration 1261: loss: 0.5770, d_k_M range: [0.0289, 0.5309], d_k_M_hat range: [0.2779, 0.7970]
2025-03-11 19:59:36 - Train Iteration 1262: loss: 0.8355, d_k_M range: [0.0071, 0.7761], d_k_M_hat range: [0.0930, 0.9499]
2025-03-11 19:59:36 - Train Iteration 1263: loss: 0.5792, d_k_M range: [0.0342, 0.6426], d_k_M_hat range: [0.2749, 0.8816]
2025-03-11 19:59:36 - Train Iteration 1264: loss: 0.6634, d_k_M range: [0.0347, 0.5322], d_k_M_hat range: [0.2206, 0.7800]
2025-03-11 19:59:37 - Train Iteration 1265: loss: 0.5778, d_k_M range: [0.1358, 0.5931], d_k_M_hat range: [0.3918, 0.8369]
2025-03-11 19:59:37 - Train Iteration 1266: loss: 0.6349, d_k_M range: [0.0653, 0.7301], d_k_M_hat range: [0.3351, 0.9333]
2025-03-11 19:59:38 - Train Iteration 1267: loss: 0.6062, d_k_M range: [0.0550, 0.6320], d_k_M_hat range: [0.3145, 0.9012]
2025-03-11 19:59:38 - Train Iteration 1268: loss: 0.6541, d_k_M range: [0.0959, 0.7707], d_k_M_hat range: [0.4551, 0.9620]
2025-03-11 19:59:39 - Train Iteration 1269: loss: 0.5787, d_k_M range: [0.1147, 0.4819], d_k_M_hat range: [0.3587, 0.7565]
2025-03-11 19:59:39 - Train Iteration 1270: loss: 0.6061, d_k_M range: [0.0399, 0.5997], d_k_M_hat range: [0.3026, 0.8825]
2025-03-11 19:59:40 - Train Iteration 1271: loss: 0.5573, d_k_M range: [0.0667, 0.5911], d_k_M_hat range: [0.3723, 0.8446]
2025-03-11 19:59:40 - Train Iteration 1272: loss: 0.8003, d_k_M range: [0.0436, 0.8830], d_k_M_hat range: [0.2848, 0.9884]
2025-03-11 19:59:40 - Train Iteration 1273: loss: 0.7727, d_k_M range: [0.0017, 0.4561], d_k_M_hat range: [0.1227, 0.7418]
2025-03-11 19:59:41 - Train Iteration 1274: loss: 0.5850, d_k_M range: [0.0516, 0.5034], d_k_M_hat range: [0.3031, 0.7385]
2025-03-11 19:59:41 - Train Iteration 1275: loss: 0.5877, d_k_M range: [0.0214, 0.4602], d_k_M_hat range: [0.2548, 0.7166]
2025-03-11 19:59:42 - Train Iteration 1276: loss: 0.7293, d_k_M range: [0.0162, 0.6131], d_k_M_hat range: [0.1622, 0.8841]
2025-03-11 19:59:42 - Train Iteration 1277: loss: 0.5938, d_k_M range: [0.4242, 0.7125], d_k_M_hat range: [0.6856, 0.9419]
2025-03-11 19:59:42 - Train Iteration 1278: loss: 0.5988, d_k_M range: [0.0319, 0.2892], d_k_M_hat range: [0.2581, 0.5833]
2025-03-11 19:59:43 - Train Iteration 1279: loss: 0.6213, d_k_M range: [0.3655, 0.7313], d_k_M_hat range: [0.6060, 0.9650]
2025-03-11 19:59:43 - Train Iteration 1280: loss: 0.5484, d_k_M range: [0.0385, 0.5612], d_k_M_hat range: [0.3420, 0.8623]
2025-03-11 19:59:44 - Train Iteration 1281: loss: 0.6556, d_k_M range: [0.0057, 0.6902], d_k_M_hat range: [0.1960, 0.9477]
2025-03-11 19:59:44 - Train Iteration 1282: loss: 0.7611, d_k_M range: [0.0677, 0.8480], d_k_M_hat range: [0.3774, 0.9756]
2025-03-11 19:59:45 - Train Iteration 1283: loss: 0.6060, d_k_M range: [0.0976, 0.7322], d_k_M_hat range: [0.3663, 0.9538]
2025-03-11 19:59:45 - Train Iteration 1284: loss: 0.5736, d_k_M range: [0.1051, 0.4137], d_k_M_hat range: [0.3898, 0.6996]
2025-03-11 19:59:46 - Train Iteration 1285: loss: 0.7444, d_k_M range: [0.0178, 0.6732], d_k_M_hat range: [0.1550, 0.9057]
2025-03-11 19:59:46 - Train Iteration 1286: loss: 0.5684, d_k_M range: [0.2532, 0.6788], d_k_M_hat range: [0.5474, 0.9388]
2025-03-11 19:59:46 - Train Iteration 1287: loss: 0.5415, d_k_M range: [0.0901, 0.5299], d_k_M_hat range: [0.3761, 0.8040]
2025-03-11 19:59:47 - Train Iteration 1288: loss: 0.6431, d_k_M range: [0.2213, 0.7677], d_k_M_hat range: [0.5165, 0.9658]
2025-03-11 19:59:47 - Train Iteration 1289: loss: 0.7672, d_k_M range: [0.0037, 0.7199], d_k_M_hat range: [0.1278, 0.9473]
2025-03-11 19:59:48 - Train Iteration 1290: loss: 0.8648, d_k_M range: [0.0331, 0.9229], d_k_M_hat range: [0.2636, 0.9930]
2025-03-11 19:59:48 - Train Iteration 1291: loss: 0.9801, d_k_M range: [0.0010, 0.4093], d_k_M_hat range: [0.0110, 0.6838]
2025-03-11 19:59:48 - Train Iteration 1292: loss: 0.5972, d_k_M range: [0.0843, 0.5838], d_k_M_hat range: [0.3115, 0.8555]
2025-03-11 19:59:49 - Train Iteration 1293: loss: 0.5959, d_k_M range: [0.0293, 0.3304], d_k_M_hat range: [0.2573, 0.6122]
2025-03-11 19:59:49 - Train Iteration 1294: loss: 0.6720, d_k_M range: [0.2184, 0.7835], d_k_M_hat range: [0.4358, 0.9638]
2025-03-11 19:59:50 - Train Iteration 1295: loss: 0.5624, d_k_M range: [0.2348, 0.5494], d_k_M_hat range: [0.5086, 0.8172]
2025-03-11 19:59:50 - Train Iteration 1296: loss: 0.8354, d_k_M range: [0.0313, 0.9052], d_k_M_hat range: [0.2905, 0.9912]
2025-03-11 19:59:51 - Train Iteration 1297: loss: 0.6005, d_k_M range: [0.1024, 0.7388], d_k_M_hat range: [0.3710, 0.9639]
2025-03-11 19:59:51 - Train Iteration 1298: loss: 0.5918, d_k_M range: [0.0489, 0.3811], d_k_M_hat range: [0.2862, 0.6771]
2025-03-11 19:59:51 - Train Iteration 1299: loss: 0.6176, d_k_M range: [0.0875, 0.5277], d_k_M_hat range: [0.3617, 0.8347]
2025-03-11 19:59:52 - Train Iteration 1300: loss: 0.5860, d_k_M range: [0.0951, 0.6869], d_k_M_hat range: [0.3866, 0.9214]
2025-03-11 19:59:52 - Train Iteration 1301: loss: 0.6898, d_k_M range: [0.1281, 0.8029], d_k_M_hat range: [0.4915, 0.9723]
2025-03-11 19:59:53 - Train Iteration 1302: loss: 0.7714, d_k_M range: [0.0027, 0.4806], d_k_M_hat range: [0.1244, 0.7163]
2025-03-11 19:59:53 - Train Iteration 1303: loss: 0.6203, d_k_M range: [0.2866, 0.6307], d_k_M_hat range: [0.5576, 0.8431]
2025-03-11 19:59:54 - Train Iteration 1304: loss: 0.7231, d_k_M range: [0.1885, 0.8295], d_k_M_hat range: [0.4088, 0.9791]
2025-03-11 19:59:54 - Train Iteration 1305: loss: 0.7452, d_k_M range: [0.0086, 0.4196], d_k_M_hat range: [0.1454, 0.6847]
2025-03-11 19:59:55 - Train Iteration 1306: loss: 0.6097, d_k_M range: [0.1265, 0.5548], d_k_M_hat range: [0.3855, 0.8225]
2025-03-11 19:59:55 - Train Iteration 1307: loss: 0.6291, d_k_M range: [0.2204, 0.6859], d_k_M_hat range: [0.4781, 0.9090]
2025-03-11 19:59:55 - Train Iteration 1308: loss: 0.5784, d_k_M range: [0.1380, 0.6515], d_k_M_hat range: [0.3973, 0.8952]
2025-03-11 19:59:56 - Train Iteration 1309: loss: 0.5875, d_k_M range: [0.0171, 0.5213], d_k_M_hat range: [0.2635, 0.7753]
2025-03-11 19:59:56 - Train Iteration 1310: loss: 0.7024, d_k_M range: [0.0743, 0.8211], d_k_M_hat range: [0.3919, 0.9830]
2025-03-11 19:59:57 - Train Iteration 1311: loss: 0.6593, d_k_M range: [0.0134, 0.3795], d_k_M_hat range: [0.2022, 0.6168]
2025-03-11 19:59:57 - Train Iteration 1312: loss: 0.6042, d_k_M range: [0.0298, 0.6382], d_k_M_hat range: [0.2877, 0.9025]
2025-03-11 19:59:58 - Train Iteration 1313: loss: 0.6148, d_k_M range: [0.2694, 0.6157], d_k_M_hat range: [0.5431, 0.8696]
2025-03-11 19:59:58 - Train Iteration 1314: loss: 0.6089, d_k_M range: [0.0133, 0.4519], d_k_M_hat range: [0.2330, 0.7198]
2025-03-11 19:59:58 - Train Iteration 1315: loss: 0.5684, d_k_M range: [0.0795, 0.6037], d_k_M_hat range: [0.3542, 0.8819]
2025-03-11 19:59:59 - Train Iteration 1316: loss: 0.6098, d_k_M range: [0.0284, 0.5950], d_k_M_hat range: [0.2683, 0.8507]
2025-03-11 19:59:59 - Train Iteration 1317: loss: 0.6290, d_k_M range: [0.0127, 0.7068], d_k_M_hat range: [0.2196, 0.9263]
2025-03-11 20:00:00 - Train Iteration 1318: loss: 0.5962, d_k_M range: [0.0642, 0.5785], d_k_M_hat range: [0.3412, 0.8130]
2025-03-11 20:00:00 - Train Iteration 1319: loss: 0.5925, d_k_M range: [0.0325, 0.5961], d_k_M_hat range: [0.3025, 0.8263]
2025-03-11 20:00:01 - Train Iteration 1320: loss: 0.5652, d_k_M range: [0.2125, 0.6664], d_k_M_hat range: [0.4984, 0.9433]
2025-03-11 20:00:01 - Train Iteration 1321: loss: 0.6145, d_k_M range: [0.2012, 0.5627], d_k_M_hat range: [0.4871, 0.8330]
2025-03-11 20:00:02 - Train Iteration 1322: loss: 0.5703, d_k_M range: [0.1657, 0.6021], d_k_M_hat range: [0.4597, 0.8645]
2025-03-11 20:00:02 - Train Iteration 1323: loss: 0.9674, d_k_M range: [0.2086, 0.9818], d_k_M_hat range: [0.4987, 0.9982]
2025-03-11 20:00:02 - Train Iteration 1324: loss: 0.8785, d_k_M range: [0.2370, 0.9317], d_k_M_hat range: [0.5049, 0.9944]
2025-03-11 20:00:03 - Train Iteration 1325: loss: 0.9511, d_k_M range: [0.0819, 0.9725], d_k_M_hat range: [0.3759, 0.9973]
2025-03-11 20:00:03 - Train Iteration 1326: loss: 0.9204, d_k_M range: [0.1391, 0.9551], d_k_M_hat range: [0.3799, 0.9957]
2025-03-11 20:00:04 - Train Iteration 1327: loss: 0.6643, d_k_M range: [0.0546, 0.7752], d_k_M_hat range: [0.3274, 0.9602]
2025-03-11 20:00:04 - Train Iteration 1328: loss: 0.9217, d_k_M range: [0.0021, 0.3414], d_k_M_hat range: [0.0420, 0.5797]
2025-03-11 20:00:05 - Train Iteration 1329: loss: 0.6070, d_k_M range: [0.0327, 0.5236], d_k_M_hat range: [0.2535, 0.7846]
2025-03-11 20:00:05 - Train Iteration 1330: loss: 0.9038, d_k_M range: [0.2608, 0.9462], d_k_M_hat range: [0.5262, 0.9955]
2025-03-11 20:00:06 - Train Iteration 1331: loss: 0.6577, d_k_M range: [0.0414, 0.5880], d_k_M_hat range: [0.3152, 0.8823]
2025-03-11 20:00:06 - Train Iteration 1332: loss: 0.5664, d_k_M range: [0.0846, 0.5884], d_k_M_hat range: [0.3398, 0.8442]
2025-03-11 20:00:06 - Train Iteration 1333: loss: 0.5753, d_k_M range: [0.0531, 0.5286], d_k_M_hat range: [0.3257, 0.8461]
2025-03-11 20:00:07 - Train Iteration 1334: loss: 0.6030, d_k_M range: [0.1424, 0.5112], d_k_M_hat range: [0.4302, 0.8094]
2025-03-11 20:00:07 - Train Iteration 1335: loss: 0.9723, d_k_M range: [0.0011, 0.7388], d_k_M_hat range: [0.0151, 0.9564]
2025-03-11 20:00:08 - Train Iteration 1336: loss: 0.5962, d_k_M range: [0.1013, 0.5952], d_k_M_hat range: [0.4230, 0.8724]
2025-03-11 20:00:08 - Train Iteration 1337: loss: 0.5962, d_k_M range: [0.1429, 0.7027], d_k_M_hat range: [0.4138, 0.9306]
2025-03-11 20:00:08 - Train Iteration 1338: loss: 0.6576, d_k_M range: [0.0163, 0.4116], d_k_M_hat range: [0.2053, 0.6851]
2025-03-11 20:00:09 - Train Iteration 1339: loss: 0.5922, d_k_M range: [0.0859, 0.6675], d_k_M_hat range: [0.3975, 0.9059]
2025-03-11 20:00:09 - Train Iteration 1340: loss: 0.7805, d_k_M range: [0.3031, 0.8637], d_k_M_hat range: [0.5855, 0.9803]
2025-03-11 20:00:10 - Train Iteration 1341: loss: 0.6173, d_k_M range: [0.0209, 0.4777], d_k_M_hat range: [0.2352, 0.7177]
2025-03-11 20:00:10 - Train Iteration 1342: loss: 0.8063, d_k_M range: [0.3397, 0.8862], d_k_M_hat range: [0.6054, 0.9883]
2025-03-11 20:00:11 - Train Iteration 1343: loss: 0.7058, d_k_M range: [0.0085, 0.1949], d_k_M_hat range: [0.1684, 0.4224]
2025-03-11 20:00:11 - Train Iteration 1344: loss: 0.6391, d_k_M range: [0.2609, 0.5726], d_k_M_hat range: [0.4925, 0.8369]
2025-03-11 20:00:11 - Train Iteration 1345: loss: 0.8358, d_k_M range: [0.2952, 0.9041], d_k_M_hat range: [0.5310, 0.9899]
2025-03-11 20:00:12 - Train Iteration 1346: loss: 0.8097, d_k_M range: [0.0018, 0.6158], d_k_M_hat range: [0.1020, 0.8575]
2025-03-11 20:00:12 - Train Iteration 1347: loss: 0.6225, d_k_M range: [0.0306, 0.5167], d_k_M_hat range: [0.2416, 0.7681]
2025-03-11 20:00:13 - Train Iteration 1348: loss: 0.7273, d_k_M range: [0.3356, 0.8246], d_k_M_hat range: [0.5928, 0.9717]
2025-03-11 20:00:13 - Train Iteration 1349: loss: 0.6855, d_k_M range: [0.0314, 0.7901], d_k_M_hat range: [0.2265, 0.9622]
2025-03-11 20:00:13 - Train Iteration 1350: loss: 0.6360, d_k_M range: [0.1591, 0.5033], d_k_M_hat range: [0.3616, 0.7152]
2025-03-11 20:00:14 - Train Iteration 1351: loss: 0.8113, d_k_M range: [0.1929, 0.8886], d_k_M_hat range: [0.4406, 0.9879]
2025-03-11 20:00:14 - Train Iteration 1352: loss: 0.7611, d_k_M range: [0.0093, 0.5005], d_k_M_hat range: [0.1369, 0.7116]
2025-03-11 20:00:15 - Train Iteration 1353: loss: 0.6425, d_k_M range: [0.2564, 0.4913], d_k_M_hat range: [0.4917, 0.7031]
2025-03-11 20:00:15 - Train Iteration 1354: loss: 0.6094, d_k_M range: [0.1090, 0.4630], d_k_M_hat range: [0.3867, 0.7533]
2025-03-11 20:00:15 - Train Iteration 1355: loss: 0.6310, d_k_M range: [0.0314, 0.5341], d_k_M_hat range: [0.2888, 0.8060]
2025-03-11 20:00:16 - Train Iteration 1356: loss: 0.5782, d_k_M range: [0.1078, 0.6555], d_k_M_hat range: [0.3872, 0.8951]
2025-03-11 20:00:16 - Train Iteration 1357: loss: 0.9042, d_k_M range: [0.1341, 0.9472], d_k_M_hat range: [0.3802, 0.9964]
2025-03-11 20:00:16 - Train Iteration 1358: loss: 0.5451, d_k_M range: [0.0774, 0.6103], d_k_M_hat range: [0.3543, 0.8720]
2025-03-11 20:00:17 - Train Iteration 1359: loss: 0.5867, d_k_M range: [0.0290, 0.5720], d_k_M_hat range: [0.2796, 0.8687]
2025-03-11 20:00:17 - Train Iteration 1360: loss: 0.5952, d_k_M range: [0.0651, 0.5074], d_k_M_hat range: [0.3070, 0.7740]
2025-03-11 20:00:18 - Train Iteration 1361: loss: 0.6011, d_k_M range: [0.0781, 0.7343], d_k_M_hat range: [0.3505, 0.9642]
2025-03-11 20:00:18 - Train Iteration 1362: loss: 0.7764, d_k_M range: [0.0145, 0.5390], d_k_M_hat range: [0.1334, 0.8391]
2025-03-11 20:00:18 - Train Iteration 1363: loss: 0.6447, d_k_M range: [0.2951, 0.7506], d_k_M_hat range: [0.6151, 0.9477]
2025-03-11 20:00:19 - Train Iteration 1364: loss: 0.6110, d_k_M range: [0.2248, 0.6907], d_k_M_hat range: [0.4610, 0.9454]
2025-03-11 20:00:19 - Train Iteration 1365: loss: 0.5751, d_k_M range: [0.2311, 0.6283], d_k_M_hat range: [0.4799, 0.8951]
2025-03-11 20:00:20 - Train Iteration 1366: loss: 0.6067, d_k_M range: [0.0348, 0.7328], d_k_M_hat range: [0.3391, 0.9539]
2025-03-11 20:00:20 - Train Iteration 1367: loss: 0.5604, d_k_M range: [0.1273, 0.6554], d_k_M_hat range: [0.4101, 0.9385]
2025-03-11 20:00:20 - Train Iteration 1368: loss: 0.5789, d_k_M range: [0.2926, 0.6816], d_k_M_hat range: [0.5942, 0.9473]
2025-03-11 20:00:21 - Train Iteration 1369: loss: 0.9807, d_k_M range: [0.1042, 0.9892], d_k_M_hat range: [0.4073, 0.9989]
2025-03-11 20:00:21 - Train Iteration 1370: loss: 0.5528, d_k_M range: [0.2052, 0.4528], d_k_M_hat range: [0.4617, 0.7505]
2025-03-11 20:00:22 - Train Iteration 1371: loss: 0.8403, d_k_M range: [0.0080, 0.5032], d_k_M_hat range: [0.0913, 0.7875]
2025-03-11 20:00:22 - Train Iteration 1372: loss: 0.5740, d_k_M range: [0.1850, 0.6956], d_k_M_hat range: [0.4572, 0.9380]
2025-03-11 20:00:23 - Train Iteration 1373: loss: 0.5556, d_k_M range: [0.1326, 0.5944], d_k_M_hat range: [0.3872, 0.8673]
2025-03-11 20:00:23 - Train Iteration 1374: loss: 0.5754, d_k_M range: [0.0191, 0.5566], d_k_M_hat range: [0.2629, 0.8410]
2025-03-11 20:00:23 - Train Iteration 1375: loss: 0.7461, d_k_M range: [0.0150, 0.6516], d_k_M_hat range: [0.1512, 0.9136]
2025-03-11 20:00:24 - Train Iteration 1376: loss: 0.9195, d_k_M range: [0.2693, 0.9556], d_k_M_hat range: [0.5013, 0.9966]
2025-03-11 20:00:24 - Train Iteration 1377: loss: 0.6389, d_k_M range: [0.3126, 0.7541], d_k_M_hat range: [0.5272, 0.9547]
2025-03-11 20:00:25 - Train Iteration 1378: loss: 0.7859, d_k_M range: [0.0211, 0.6112], d_k_M_hat range: [0.1345, 0.8750]
2025-03-11 20:00:25 - Train Iteration 1379: loss: 0.7490, d_k_M range: [0.1517, 0.8453], d_k_M_hat range: [0.4287, 0.9799]
2025-03-11 20:00:25 - Train Iteration 1380: loss: 0.5708, d_k_M range: [0.0442, 0.6802], d_k_M_hat range: [0.3359, 0.9354]
2025-03-11 20:00:26 - Train Iteration 1381: loss: 0.6757, d_k_M range: [0.1576, 0.7879], d_k_M_hat range: [0.4299, 0.9658]
2025-03-11 20:00:26 - Train Iteration 1382: loss: 0.6929, d_k_M range: [0.0056, 0.3834], d_k_M_hat range: [0.1732, 0.6548]
2025-03-11 20:00:27 - Train Iteration 1383: loss: 0.6253, d_k_M range: [0.1598, 0.5740], d_k_M_hat range: [0.4039, 0.8334]
2025-03-11 20:00:27 - Train Iteration 1384: loss: 0.5660, d_k_M range: [0.0690, 0.4525], d_k_M_hat range: [0.3456, 0.7491]
2025-03-11 20:00:27 - Train Iteration 1385: loss: 0.9398, d_k_M range: [0.0013, 0.4227], d_k_M_hat range: [0.0319, 0.7005]
2025-03-11 20:00:28 - Train Iteration 1386: loss: 0.5975, d_k_M range: [0.1488, 0.4275], d_k_M_hat range: [0.4245, 0.6604]
2025-03-11 20:00:28 - Train Iteration 1387: loss: 0.5686, d_k_M range: [0.0553, 0.5233], d_k_M_hat range: [0.3033, 0.7755]
2025-03-11 20:00:29 - Train Iteration 1388: loss: 0.8443, d_k_M range: [0.0344, 0.9056], d_k_M_hat range: [0.2080, 0.9867]
2025-03-11 20:00:29 - Train Iteration 1389: loss: 0.5915, d_k_M range: [0.1007, 0.4352], d_k_M_hat range: [0.3525, 0.7080]
2025-03-11 20:00:30 - Train Iteration 1390: loss: 0.8004, d_k_M range: [0.3205, 0.8640], d_k_M_hat range: [0.5853, 0.9831]
2025-03-11 20:00:30 - Train Iteration 1391: loss: 0.6275, d_k_M range: [0.0126, 0.4338], d_k_M_hat range: [0.2675, 0.6817]
2025-03-11 20:00:30 - Train Iteration 1392: loss: 0.6029, d_k_M range: [0.2425, 0.5317], d_k_M_hat range: [0.5661, 0.7746]
2025-03-11 20:00:31 - Train Iteration 1393: loss: 0.7936, d_k_M range: [0.0122, 0.4017], d_k_M_hat range: [0.1213, 0.6112]
2025-03-11 20:00:31 - Train Iteration 1394: loss: 0.5741, d_k_M range: [0.1326, 0.6650], d_k_M_hat range: [0.4345, 0.9073]
2025-03-11 20:00:32 - Train Iteration 1395: loss: 0.6183, d_k_M range: [0.0538, 0.7403], d_k_M_hat range: [0.3083, 0.9539]
2025-03-11 20:00:32 - Train Iteration 1396: loss: 0.6454, d_k_M range: [0.3239, 0.7717], d_k_M_hat range: [0.5575, 0.9683]
2025-03-11 20:00:33 - Train Iteration 1397: loss: 0.9534, d_k_M range: [0.0015, 0.5449], d_k_M_hat range: [0.0251, 0.7993]
2025-03-11 20:00:33 - Train Iteration 1398: loss: 0.6683, d_k_M range: [0.0043, 0.5105], d_k_M_hat range: [0.1868, 0.7501]
2025-03-11 20:00:33 - Train Iteration 1399: loss: 0.6706, d_k_M range: [0.3601, 0.7988], d_k_M_hat range: [0.5931, 0.9799]
2025-03-11 20:00:34 - Train Iteration 1400: loss: 0.6837, d_k_M range: [0.2158, 0.7704], d_k_M_hat range: [0.4443, 0.9436]
2025-03-11 20:00:34 - Train Iteration 1401: loss: 0.6189, d_k_M range: [0.1718, 0.4475], d_k_M_hat range: [0.4046, 0.6818]
2025-03-11 20:00:35 - Train Iteration 1402: loss: 0.6427, d_k_M range: [0.1855, 0.4532], d_k_M_hat range: [0.4306, 0.6978]
2025-03-11 20:00:35 - Train Iteration 1403: loss: 0.7549, d_k_M range: [0.0084, 0.4311], d_k_M_hat range: [0.1396, 0.6601]
2025-03-11 20:00:35 - Train Iteration 1404: loss: 0.6602, d_k_M range: [0.1544, 0.5181], d_k_M_hat range: [0.4182, 0.7454]
2025-03-11 20:00:36 - Train Iteration 1405: loss: 0.6347, d_k_M range: [0.2131, 0.7406], d_k_M_hat range: [0.4872, 0.9439]
2025-03-11 20:00:36 - Train Iteration 1406: loss: 0.5695, d_k_M range: [0.1282, 0.5159], d_k_M_hat range: [0.3739, 0.7613]
2025-03-11 20:00:37 - Train Iteration 1407: loss: 0.5693, d_k_M range: [0.1575, 0.4804], d_k_M_hat range: [0.4030, 0.7516]
2025-03-11 20:00:37 - Train Iteration 1408: loss: 0.5686, d_k_M range: [0.1039, 0.5456], d_k_M_hat range: [0.3800, 0.7915]
2025-03-11 20:00:37 - Train Iteration 1409: loss: 0.5524, d_k_M range: [0.1564, 0.5978], d_k_M_hat range: [0.4442, 0.8722]
2025-03-11 20:00:38 - Train Iteration 1410: loss: 0.8376, d_k_M range: [0.0090, 0.6974], d_k_M_hat range: [0.0938, 0.9375]
2025-03-11 20:00:38 - Train Iteration 1411: loss: 0.6418, d_k_M range: [0.0257, 0.6094], d_k_M_hat range: [0.2438, 0.8463]
2025-03-11 20:00:39 - Train Iteration 1412: loss: 0.5610, d_k_M range: [0.1218, 0.4395], d_k_M_hat range: [0.4072, 0.7463]
2025-03-11 20:00:39 - Train Iteration 1413: loss: 0.5507, d_k_M range: [0.2346, 0.7031], d_k_M_hat range: [0.4925, 0.9702]
2025-03-11 20:00:39 - Train Iteration 1414: loss: 0.6031, d_k_M range: [0.2125, 0.7346], d_k_M_hat range: [0.4881, 0.9635]
2025-03-11 20:00:40 - Train Iteration 1415: loss: 0.5490, d_k_M range: [0.0703, 0.4722], d_k_M_hat range: [0.3294, 0.7772]
2025-03-11 20:00:40 - Train Iteration 1416: loss: 0.9312, d_k_M range: [0.2041, 0.9626], d_k_M_hat range: [0.4972, 0.9977]
2025-03-11 20:00:41 - Train Iteration 1417: loss: 0.5841, d_k_M range: [0.0252, 0.5912], d_k_M_hat range: [0.2609, 0.8546]
2025-03-11 20:00:41 - Train Iteration 1418: loss: 0.6448, d_k_M range: [0.0229, 0.5261], d_k_M_hat range: [0.2199, 0.7840]
2025-03-11 20:00:42 - Train Iteration 1419: loss: 0.7019, d_k_M range: [0.2180, 0.8013], d_k_M_hat range: [0.5071, 0.9635]
2025-03-11 20:00:42 - Train Iteration 1420: loss: 0.7212, d_k_M range: [0.0207, 0.8068], d_k_M_hat range: [0.2897, 0.9575]
2025-03-11 20:00:42 - Train Iteration 1421: loss: 0.5829, d_k_M range: [0.0354, 0.4925], d_k_M_hat range: [0.2964, 0.7707]
2025-03-11 20:00:43 - Train Iteration 1422: loss: 0.6012, d_k_M range: [0.1527, 0.6008], d_k_M_hat range: [0.4468, 0.8472]
2025-03-11 20:00:43 - Train Iteration 1423: loss: 0.5900, d_k_M range: [0.1493, 0.5469], d_k_M_hat range: [0.4085, 0.7951]
2025-03-11 20:00:44 - Train Iteration 1424: loss: 0.6045, d_k_M range: [0.1125, 0.7318], d_k_M_hat range: [0.4024, 0.9543]
2025-03-11 20:00:44 - Train Iteration 1425: loss: 0.5923, d_k_M range: [0.0563, 0.4750], d_k_M_hat range: [0.2868, 0.7586]
2025-03-11 20:00:44 - Train Iteration 1426: loss: 0.5879, d_k_M range: [0.2304, 0.5974], d_k_M_hat range: [0.5110, 0.8770]
2025-03-11 20:00:45 - Train Iteration 1427: loss: 0.5734, d_k_M range: [0.0985, 0.5625], d_k_M_hat range: [0.4201, 0.8487]
2025-03-11 20:00:45 - Train Iteration 1428: loss: 0.5962, d_k_M range: [0.0493, 0.6437], d_k_M_hat range: [0.3375, 0.9343]
2025-03-11 20:00:46 - Train Iteration 1429: loss: 0.7451, d_k_M range: [0.0129, 0.6342], d_k_M_hat range: [0.1760, 0.9157]
2025-03-11 20:00:46 - Train Iteration 1430: loss: 0.6226, d_k_M range: [0.0889, 0.7479], d_k_M_hat range: [0.4255, 0.9668]
2025-03-11 20:00:46 - Train Iteration 1431: loss: 0.8602, d_k_M range: [0.0050, 0.2915], d_k_M_hat range: [0.0775, 0.5973]
2025-03-11 20:00:47 - Train Iteration 1432: loss: 0.5183, d_k_M range: [0.1092, 0.5645], d_k_M_hat range: [0.4302, 0.8715]
2025-03-11 20:00:47 - Train Iteration 1433: loss: 0.5681, d_k_M range: [0.0336, 0.4553], d_k_M_hat range: [0.2799, 0.8281]
2025-03-11 20:00:48 - Train Iteration 1434: loss: 0.6091, d_k_M range: [0.0457, 0.5867], d_k_M_hat range: [0.3027, 0.8830]
2025-03-11 20:00:48 - Train Iteration 1435: loss: 0.6475, d_k_M range: [0.2047, 0.7846], d_k_M_hat range: [0.4609, 0.9800]
2025-03-11 20:00:49 - Train Iteration 1436: loss: 0.5866, d_k_M range: [0.0366, 0.4623], d_k_M_hat range: [0.2769, 0.7335]
2025-03-11 20:00:49 - Train Iteration 1437: loss: 0.6431, d_k_M range: [0.0058, 0.7690], d_k_M_hat range: [0.2079, 0.9670]
2025-03-11 20:00:49 - Train Iteration 1438: loss: 0.6243, d_k_M range: [0.0461, 0.3194], d_k_M_hat range: [0.3090, 0.6033]
2025-03-11 20:00:50 - Train Iteration 1439: loss: 0.9238, d_k_M range: [0.1953, 0.9590], d_k_M_hat range: [0.4980, 0.9978]
2025-03-11 20:00:50 - Train Iteration 1440: loss: 0.5686, d_k_M range: [0.0644, 0.4249], d_k_M_hat range: [0.4162, 0.7008]
2025-03-11 20:00:51 - Train Iteration 1441: loss: 0.8078, d_k_M range: [0.0041, 0.4824], d_k_M_hat range: [0.1053, 0.7543]
2025-03-11 20:00:51 - Train Iteration 1442: loss: 0.5717, d_k_M range: [0.2716, 0.6872], d_k_M_hat range: [0.5780, 0.9312]
2025-03-11 20:00:51 - Train Iteration 1443: loss: 0.5738, d_k_M range: [0.1982, 0.6172], d_k_M_hat range: [0.5259, 0.8859]
2025-03-11 20:00:52 - Train Iteration 1444: loss: 0.8734, d_k_M range: [0.0439, 0.9247], d_k_M_hat range: [0.3313, 0.9902]
2025-03-11 20:00:52 - Train Iteration 1445: loss: 0.6800, d_k_M range: [0.0711, 0.8057], d_k_M_hat range: [0.3554, 0.9811]
2025-03-11 20:00:53 - Train Iteration 1446: loss: 0.6076, d_k_M range: [0.0152, 0.5653], d_k_M_hat range: [0.2554, 0.8925]
2025-03-11 20:00:53 - Train Iteration 1447: loss: 0.5744, d_k_M range: [0.1735, 0.6163], d_k_M_hat range: [0.4648, 0.8889]
2025-03-11 20:00:53 - Train Iteration 1448: loss: 0.6093, d_k_M range: [0.0503, 0.7401], d_k_M_hat range: [0.3834, 0.9595]
2025-03-11 20:00:54 - Train Iteration 1449: loss: 0.7060, d_k_M range: [0.0057, 0.4769], d_k_M_hat range: [0.1654, 0.7912]
2025-03-11 20:00:54 - Train Iteration 1450: loss: 0.6276, d_k_M range: [0.0143, 0.7541], d_k_M_hat range: [0.2222, 0.9623]
2025-03-11 20:00:55 - Train Iteration 1451: loss: 0.7424, d_k_M range: [0.2211, 0.8537], d_k_M_hat range: [0.4474, 0.9921]
2025-03-11 20:00:55 - Train Iteration 1452: loss: 0.7043, d_k_M range: [0.0103, 0.5508], d_k_M_hat range: [0.1711, 0.7876]
2025-03-11 20:00:55 - Train Iteration 1453: loss: 0.6090, d_k_M range: [0.1990, 0.4947], d_k_M_hat range: [0.4718, 0.7622]
2025-03-11 20:00:56 - Train Iteration 1454: loss: 0.5939, d_k_M range: [0.2095, 0.5942], d_k_M_hat range: [0.4652, 0.8235]
2025-03-11 20:00:56 - Train Iteration 1455: loss: 0.8587, d_k_M range: [0.0025, 0.5667], d_k_M_hat range: [0.0758, 0.8361]
2025-03-11 20:00:57 - Train Iteration 1456: loss: 0.6052, d_k_M range: [0.1942, 0.5487], d_k_M_hat range: [0.4162, 0.8266]
2025-03-11 20:00:57 - Train Iteration 1457: loss: 0.6933, d_k_M range: [0.0102, 0.5893], d_k_M_hat range: [0.1776, 0.8557]
2025-03-11 20:00:57 - Train Iteration 1458: loss: 0.7413, d_k_M range: [0.0394, 0.8388], d_k_M_hat range: [0.2947, 0.9778]
2025-03-11 20:00:58 - Train Iteration 1459: loss: 0.5352, d_k_M range: [0.1705, 0.5446], d_k_M_hat range: [0.4951, 0.8327]
2025-03-11 20:00:58 - Train Iteration 1460: loss: 0.6389, d_k_M range: [0.1769, 0.7786], d_k_M_hat range: [0.4759, 0.9793]
2025-03-11 20:00:59 - Train Iteration 1461: loss: 0.6531, d_k_M range: [0.0118, 0.5889], d_k_M_hat range: [0.2037, 0.8351]
2025-03-11 20:00:59 - Train Iteration 1462: loss: 0.9601, d_k_M range: [0.2717, 0.9776], d_k_M_hat range: [0.5485, 0.9978]
2025-03-11 20:00:59 - Train Iteration 1463: loss: 0.8027, d_k_M range: [0.0059, 0.8563], d_k_M_hat range: [0.1100, 0.9763]
2025-03-11 20:01:00 - Train Iteration 1464: loss: 0.5996, d_k_M range: [0.0281, 0.5900], d_k_M_hat range: [0.2538, 0.8400]
2025-03-11 20:01:00 - Train Iteration 1465: loss: 0.6253, d_k_M range: [0.1726, 0.7647], d_k_M_hat range: [0.4675, 0.9740]
2025-03-11 20:01:01 - Train Iteration 1466: loss: 0.5912, d_k_M range: [0.1004, 0.6590], d_k_M_hat range: [0.4257, 0.8911]
2025-03-11 20:01:01 - Train Iteration 1467: loss: 0.5354, d_k_M range: [0.1815, 0.6677], d_k_M_hat range: [0.4852, 0.9524]
2025-03-11 20:01:01 - Train Iteration 1468: loss: 0.5243, d_k_M range: [0.2808, 0.6362], d_k_M_hat range: [0.5959, 0.9122]
2025-03-11 20:01:02 - Train Iteration 1469: loss: 0.9050, d_k_M range: [0.0136, 0.5316], d_k_M_hat range: [0.0623, 0.8226]
2025-03-11 20:01:02 - Train Iteration 1470: loss: 0.7431, d_k_M range: [0.1170, 0.8468], d_k_M_hat range: [0.4505, 0.9847]
2025-03-11 20:01:03 - Train Iteration 1471: loss: 0.6979, d_k_M range: [0.0065, 0.2968], d_k_M_hat range: [0.1711, 0.6515]
2025-03-11 20:01:03 - Train Iteration 1472: loss: 0.8618, d_k_M range: [0.0369, 0.9241], d_k_M_hat range: [0.3049, 0.9958]
2025-03-11 20:01:03 - Train Iteration 1473: loss: 0.6017, d_k_M range: [0.0212, 0.4736], d_k_M_hat range: [0.2455, 0.7604]
2025-03-11 20:01:04 - Train Iteration 1474: loss: 0.5761, d_k_M range: [0.1488, 0.6518], d_k_M_hat range: [0.4428, 0.9121]
2025-03-11 20:01:04 - Train Iteration 1475: loss: 0.6570, d_k_M range: [0.0330, 0.6301], d_k_M_hat range: [0.2224, 0.9191]
2025-03-11 20:01:05 - Train Iteration 1476: loss: 0.7112, d_k_M range: [0.2207, 0.7944], d_k_M_hat range: [0.4554, 0.9511]
2025-03-11 20:01:05 - Train Iteration 1477: loss: 0.6133, d_k_M range: [0.1391, 0.7258], d_k_M_hat range: [0.3586, 0.9426]
2025-03-11 20:01:06 - Train Iteration 1478: loss: 0.5494, d_k_M range: [0.0633, 0.5841], d_k_M_hat range: [0.3620, 0.8952]
2025-03-11 20:01:06 - Train Iteration 1479: loss: 0.6441, d_k_M range: [0.0114, 0.7708], d_k_M_hat range: [0.2471, 0.9682]
2025-03-11 20:01:06 - Train Iteration 1480: loss: 0.5427, d_k_M range: [0.0874, 0.5021], d_k_M_hat range: [0.3617, 0.8326]
2025-03-11 20:01:07 - Train Iteration 1481: loss: 0.6311, d_k_M range: [0.0064, 0.4683], d_k_M_hat range: [0.2119, 0.7494]
2025-03-11 20:01:07 - Train Iteration 1482: loss: 0.8656, d_k_M range: [0.2212, 0.9237], d_k_M_hat range: [0.5130, 0.9933]
2025-03-11 20:01:08 - Train Iteration 1483: loss: 0.5432, d_k_M range: [0.1630, 0.5840], d_k_M_hat range: [0.4512, 0.9014]
2025-03-11 20:01:08 - Train Iteration 1484: loss: 0.4959, d_k_M range: [0.1319, 0.5166], d_k_M_hat range: [0.4433, 0.8344]
2025-03-11 20:01:08 - Train Iteration 1485: loss: 0.6069, d_k_M range: [0.0242, 0.6450], d_k_M_hat range: [0.2451, 0.9437]
2025-03-11 20:01:09 - Train Iteration 1486: loss: 0.5235, d_k_M range: [0.0552, 0.5720], d_k_M_hat range: [0.3317, 0.8781]
2025-03-11 20:01:09 - Train Iteration 1487: loss: 0.5287, d_k_M range: [0.0182, 0.3809], d_k_M_hat range: [0.2981, 0.7150]
2025-03-11 20:01:10 - Train Iteration 1488: loss: 0.5845, d_k_M range: [0.0294, 0.6939], d_k_M_hat range: [0.2813, 0.9293]
2025-03-11 20:01:10 - Train Iteration 1489: loss: 0.5255, d_k_M range: [0.1837, 0.6613], d_k_M_hat range: [0.5012, 0.9364]
2025-03-11 20:01:10 - Train Iteration 1490: loss: 0.5845, d_k_M range: [0.0186, 0.7246], d_k_M_hat range: [0.3089, 0.9600]
2025-03-11 20:01:11 - Train Iteration 1491: loss: 0.7391, d_k_M range: [0.2610, 0.8516], d_k_M_hat range: [0.5612, 0.9919]
2025-03-11 20:01:11 - Train Iteration 1492: loss: 0.7678, d_k_M range: [0.0059, 0.5629], d_k_M_hat range: [0.1296, 0.9018]
2025-03-11 20:01:12 - Train Iteration 1493: loss: 0.8492, d_k_M range: [0.2205, 0.9114], d_k_M_hat range: [0.5104, 0.9899]
2025-03-11 20:01:12 - Train Iteration 1494: loss: 0.7648, d_k_M range: [0.3034, 0.8566], d_k_M_hat range: [0.5849, 0.9820]
2025-03-11 20:01:12 - Train Iteration 1495: loss: 0.5580, d_k_M range: [0.0428, 0.3860], d_k_M_hat range: [0.3169, 0.7688]
2025-03-11 20:01:13 - Train Iteration 1496: loss: 0.5677, d_k_M range: [0.0109, 0.6022], d_k_M_hat range: [0.2574, 0.8929]
2025-03-11 20:01:13 - Train Iteration 1497: loss: 0.9379, d_k_M range: [0.1506, 0.9640], d_k_M_hat range: [0.4837, 0.9956]
2025-03-11 20:01:14 - Train Iteration 1498: loss: 0.7849, d_k_M range: [0.0020, 0.4566], d_k_M_hat range: [0.1161, 0.7262]
2025-03-11 20:01:14 - Train Iteration 1499: loss: 0.5640, d_k_M range: [0.1068, 0.6558], d_k_M_hat range: [0.4204, 0.9087]
2025-03-11 20:01:14 - Train Iteration 1500: loss: 0.5456, d_k_M range: [0.0376, 0.4743], d_k_M_hat range: [0.2989, 0.7545]
2025-03-11 20:01:15 - Train Iteration 1501: loss: 0.5565, d_k_M range: [0.0379, 0.5168], d_k_M_hat range: [0.2919, 0.8024]
2025-03-11 20:01:15 - Train Iteration 1502: loss: 0.7121, d_k_M range: [0.2179, 0.8281], d_k_M_hat range: [0.5098, 0.9843]
2025-03-11 20:01:16 - Train Iteration 1503: loss: 0.5556, d_k_M range: [0.0822, 0.5780], d_k_M_hat range: [0.3607, 0.8591]
2025-03-11 20:01:16 - Train Iteration 1504: loss: 0.6989, d_k_M range: [0.0068, 0.3510], d_k_M_hat range: [0.1717, 0.6731]
2025-03-11 20:01:16 - Train Iteration 1505: loss: 0.5307, d_k_M range: [0.1844, 0.6217], d_k_M_hat range: [0.4766, 0.9155]
2025-03-11 20:01:17 - Train Iteration 1506: loss: 0.5866, d_k_M range: [0.0872, 0.6691], d_k_M_hat range: [0.3329, 0.9182]
2025-03-11 20:01:17 - Train Iteration 1507: loss: 0.8278, d_k_M range: [0.2224, 0.9031], d_k_M_hat range: [0.5453, 0.9933]
2025-03-11 20:01:18 - Train Iteration 1508: loss: 0.5846, d_k_M range: [0.0682, 0.4182], d_k_M_hat range: [0.3563, 0.7216]
2025-03-11 20:01:18 - Train Iteration 1509: loss: 0.5570, d_k_M range: [0.1622, 0.6606], d_k_M_hat range: [0.5292, 0.9320]
2025-03-11 20:01:18 - Train Iteration 1510: loss: 0.5735, d_k_M range: [0.0655, 0.5260], d_k_M_hat range: [0.3690, 0.8348]
2025-03-11 20:01:19 - Train Iteration 1511: loss: 0.5453, d_k_M range: [0.0429, 0.6145], d_k_M_hat range: [0.3045, 0.9459]
2025-03-11 20:01:19 - Train Iteration 1512: loss: 0.5173, d_k_M range: [0.0109, 0.3475], d_k_M_hat range: [0.2917, 0.7261]
2025-03-11 20:01:20 - Train Iteration 1513: loss: 0.7251, d_k_M range: [0.1705, 0.8309], d_k_M_hat range: [0.4794, 0.9793]
2025-03-11 20:01:20 - Train Iteration 1514: loss: 0.5419, d_k_M range: [0.1691, 0.5798], d_k_M_hat range: [0.5067, 0.9127]
2025-03-11 20:01:20 - Train Iteration 1515: loss: 0.7442, d_k_M range: [0.0041, 0.5365], d_k_M_hat range: [0.1415, 0.8015]
2025-03-11 20:01:21 - Train Iteration 1516: loss: 0.5485, d_k_M range: [0.2590, 0.6806], d_k_M_hat range: [0.5736, 0.9436]
2025-03-11 20:01:21 - Train Iteration 1517: loss: 0.6220, d_k_M range: [0.0593, 0.6610], d_k_M_hat range: [0.3453, 0.9394]
2025-03-11 20:01:22 - Train Iteration 1518: loss: 0.8482, d_k_M range: [0.0078, 0.6126], d_k_M_hat range: [0.0869, 0.9030]
2025-03-11 20:01:22 - Train Iteration 1519: loss: 0.5586, d_k_M range: [0.2168, 0.6408], d_k_M_hat range: [0.4695, 0.9038]
2025-03-11 20:01:23 - Train Iteration 1520: loss: 0.5020, d_k_M range: [0.2897, 0.5463], d_k_M_hat range: [0.5911, 0.8391]
2025-03-11 20:01:23 - Train Iteration 1521: loss: 0.7121, d_k_M range: [0.0337, 0.8272], d_k_M_hat range: [0.2264, 0.9833]
2025-03-11 20:01:23 - Train Iteration 1522: loss: 0.5380, d_k_M range: [0.0975, 0.6091], d_k_M_hat range: [0.4049, 0.9422]
2025-03-11 20:01:24 - Train Iteration 1523: loss: 0.9078, d_k_M range: [0.0567, 0.9487], d_k_M_hat range: [0.2662, 0.9959]
2025-03-11 20:01:24 - Train Iteration 1524: loss: 0.5697, d_k_M range: [0.2161, 0.6831], d_k_M_hat range: [0.4914, 0.9372]
2025-03-11 20:01:25 - Train Iteration 1525: loss: 0.5376, d_k_M range: [0.2215, 0.4498], d_k_M_hat range: [0.5238, 0.7571]
2025-03-11 20:01:25 - Train Iteration 1526: loss: 0.5155, d_k_M range: [0.0612, 0.5567], d_k_M_hat range: [0.4258, 0.8388]
2025-03-11 20:01:25 - Train Iteration 1527: loss: 0.5294, d_k_M range: [0.0384, 0.3740], d_k_M_hat range: [0.3758, 0.7221]
2025-03-11 20:01:26 - Train Iteration 1528: loss: 0.4956, d_k_M range: [0.1736, 0.6230], d_k_M_hat range: [0.4766, 0.9307]
2025-03-11 20:01:26 - Train Iteration 1529: loss: 0.4889, d_k_M range: [0.1800, 0.5430], d_k_M_hat range: [0.4840, 0.8642]
2025-03-11 20:01:27 - Train Iteration 1530: loss: 0.5932, d_k_M range: [0.1675, 0.6983], d_k_M_hat range: [0.5201, 0.9281]
2025-03-11 20:01:27 - Train Iteration 1531: loss: 0.5400, d_k_M range: [0.0798, 0.3736], d_k_M_hat range: [0.4082, 0.6791]
2025-03-11 20:01:27 - Train Iteration 1532: loss: 0.5558, d_k_M range: [0.0325, 0.5528], d_k_M_hat range: [0.2870, 0.8443]
2025-03-11 20:01:28 - Train Iteration 1533: loss: 0.9149, d_k_M range: [0.1283, 0.9488], d_k_M_hat range: [0.4963, 0.9923]
2025-03-11 20:01:28 - Train Iteration 1534: loss: 0.5699, d_k_M range: [0.0536, 0.5750], d_k_M_hat range: [0.3721, 0.8807]
2025-03-11 20:01:29 - Train Iteration 1535: loss: 0.5404, d_k_M range: [0.0958, 0.6476], d_k_M_hat range: [0.4363, 0.9182]
2025-03-11 20:01:29 - Train Iteration 1536: loss: 0.5872, d_k_M range: [0.0145, 0.3980], d_k_M_hat range: [0.2485, 0.7033]
2025-03-11 20:01:29 - Train Iteration 1537: loss: 0.5819, d_k_M range: [0.3403, 0.7191], d_k_M_hat range: [0.6807, 0.9602]
2025-03-11 20:01:30 - Train Iteration 1538: loss: 0.6067, d_k_M range: [0.2729, 0.7516], d_k_M_hat range: [0.5284, 0.9726]
2025-03-11 20:01:30 - Train Iteration 1539: loss: 0.8879, d_k_M range: [0.0011, 0.4434], d_k_M_hat range: [0.0588, 0.7575]
2025-03-11 20:01:31 - Train Iteration 1540: loss: 0.5914, d_k_M range: [0.2932, 0.7026], d_k_M_hat range: [0.5539, 0.9667]
2025-03-11 20:01:31 - Train Iteration 1541: loss: 0.6021, d_k_M range: [0.0178, 0.4088], d_k_M_hat range: [0.2419, 0.7367]
2025-03-11 20:01:31 - Train Iteration 1542: loss: 0.6408, d_k_M range: [0.1509, 0.7441], d_k_M_hat range: [0.4592, 0.9436]
2025-03-11 20:01:32 - Train Iteration 1543: loss: 0.6026, d_k_M range: [0.0131, 0.5727], d_k_M_hat range: [0.2368, 0.8587]
2025-03-11 20:01:32 - Train Iteration 1544: loss: 0.6693, d_k_M range: [0.3848, 0.7911], d_k_M_hat range: [0.6920, 0.9730]
2025-03-11 20:01:32 - Train Iteration 1545: loss: 0.5623, d_k_M range: [0.0856, 0.5124], d_k_M_hat range: [0.3513, 0.7774]
2025-03-11 20:01:33 - Train Iteration 1546: loss: 0.9393, d_k_M range: [0.2135, 0.9673], d_k_M_hat range: [0.5599, 0.9981]
2025-03-11 20:01:33 - Train Iteration 1547: loss: 0.5640, d_k_M range: [0.2658, 0.6840], d_k_M_hat range: [0.5436, 0.9677]
2025-03-11 20:01:34 - Train Iteration 1548: loss: 0.6147, d_k_M range: [0.0893, 0.7299], d_k_M_hat range: [0.4426, 0.9460]
2025-03-11 20:01:34 - Train Iteration 1549: loss: 0.6066, d_k_M range: [0.0173, 0.4684], d_k_M_hat range: [0.2384, 0.7142]
2025-03-11 20:01:34 - Train Iteration 1550: loss: 0.9333, d_k_M range: [0.0863, 0.9634], d_k_M_hat range: [0.4013, 0.9973]
2025-03-11 20:01:35 - Train Iteration 1551: loss: 0.8070, d_k_M range: [0.1652, 0.8881], d_k_M_hat range: [0.4676, 0.9898]
2025-03-11 20:01:35 - Train Iteration 1552: loss: 0.5513, d_k_M range: [0.2896, 0.6591], d_k_M_hat range: [0.5786, 0.9339]
2025-03-11 20:01:35 - Train Iteration 1553: loss: 0.5464, d_k_M range: [0.0386, 0.5836], d_k_M_hat range: [0.2995, 0.8637]
2025-03-11 20:01:36 - Train Iteration 1554: loss: 0.5853, d_k_M range: [0.0274, 0.6087], d_k_M_hat range: [0.3341, 0.8883]
2025-03-11 20:01:36 - Train Iteration 1555: loss: 0.5554, d_k_M range: [0.0428, 0.6530], d_k_M_hat range: [0.3075, 0.9077]
2025-03-11 20:01:37 - Train Iteration 1556: loss: 0.6791, d_k_M range: [0.0309, 0.4716], d_k_M_hat range: [0.2096, 0.7265]
2025-03-11 20:01:37 - Train Iteration 1557: loss: 0.9877, d_k_M range: [0.0292, 0.9933], d_k_M_hat range: [0.3464, 0.9995]
2025-03-11 20:01:37 - Train Iteration 1558: loss: 0.6331, d_k_M range: [0.1192, 0.7283], d_k_M_hat range: [0.4449, 0.9326]
2025-03-11 20:01:38 - Train Iteration 1559: loss: 0.6780, d_k_M range: [0.0250, 0.5175], d_k_M_hat range: [0.2422, 0.7467]
2025-03-11 20:01:38 - Train Iteration 1560: loss: 0.9084, d_k_M range: [0.2273, 0.9483], d_k_M_hat range: [0.5197, 0.9952]
2025-03-11 20:01:39 - Train Iteration 1561: loss: 0.9755, d_k_M range: [0.0011, 0.3893], d_k_M_hat range: [0.0134, 0.6880]
2025-03-11 20:01:39 - Train Iteration 1562: loss: 0.5947, d_k_M range: [0.1861, 0.5829], d_k_M_hat range: [0.4567, 0.8632]
2025-03-11 20:01:39 - Train Iteration 1563: loss: 0.5902, d_k_M range: [0.0381, 0.7337], d_k_M_hat range: [0.3234, 0.9656]
2025-03-11 20:01:40 - Train Iteration 1564: loss: 0.5101, d_k_M range: [0.2226, 0.5233], d_k_M_hat range: [0.5371, 0.8314]
2025-03-11 20:01:40 - Train Iteration 1565: loss: 0.5700, d_k_M range: [0.1715, 0.6091], d_k_M_hat range: [0.5132, 0.9030]
2025-03-11 20:01:41 - Train Iteration 1566: loss: 0.5338, d_k_M range: [0.0287, 0.6202], d_k_M_hat range: [0.3193, 0.9164]
2025-03-11 20:01:41 - Train Iteration 1567: loss: 0.5658, d_k_M range: [0.0160, 0.6360], d_k_M_hat range: [0.2638, 0.9205]
2025-03-11 20:01:41 - Train Iteration 1568: loss: 0.6357, d_k_M range: [0.1261, 0.7715], d_k_M_hat range: [0.4403, 0.9742]
2025-03-11 20:01:42 - Train Iteration 1569: loss: 0.5983, d_k_M range: [0.1155, 0.7285], d_k_M_hat range: [0.4063, 0.9588]
2025-03-11 20:01:42 - Train Iteration 1570: loss: 0.6145, d_k_M range: [0.0196, 0.3421], d_k_M_hat range: [0.2357, 0.6113]
2025-03-11 20:01:43 - Train Iteration 1571: loss: 0.6053, d_k_M range: [0.1502, 0.7519], d_k_M_hat range: [0.4714, 0.9739]
2025-03-11 20:01:43 - Train Iteration 1572: loss: 0.5659, d_k_M range: [0.2325, 0.5392], d_k_M_hat range: [0.5453, 0.8368]
2025-03-11 20:01:43 - Train Iteration 1573: loss: 0.7947, d_k_M range: [0.1065, 0.8806], d_k_M_hat range: [0.4572, 0.9891]
2025-03-11 20:01:44 - Train Iteration 1574: loss: 0.9075, d_k_M range: [0.0066, 0.9491], d_k_M_hat range: [0.1352, 0.9965]
2025-03-11 20:01:44 - Train Iteration 1575: loss: 0.5392, d_k_M range: [0.0442, 0.4369], d_k_M_hat range: [0.3117, 0.7178]
2025-03-11 20:01:45 - Train Iteration 1576: loss: 0.4986, d_k_M range: [0.1479, 0.4590], d_k_M_hat range: [0.4677, 0.7643]
2025-03-11 20:01:45 - Train Iteration 1577: loss: 0.7548, d_k_M range: [0.1706, 0.8576], d_k_M_hat range: [0.4935, 0.9888]
2025-03-11 20:01:46 - Train Iteration 1578: loss: 0.5693, d_k_M range: [0.0803, 0.4175], d_k_M_hat range: [0.3535, 0.7625]
2025-03-11 20:01:46 - Train Iteration 1579: loss: 0.6443, d_k_M range: [0.1042, 0.7851], d_k_M_hat range: [0.3532, 0.9824]
2025-03-11 20:01:46 - Train Iteration 1580: loss: 0.6517, d_k_M range: [0.0081, 0.7687], d_k_M_hat range: [0.2627, 0.9615]
2025-03-11 20:01:47 - Train Iteration 1581: loss: 0.5327, d_k_M range: [0.0471, 0.5214], d_k_M_hat range: [0.3404, 0.8237]
2025-03-11 20:01:47 - Train Iteration 1582: loss: 0.5501, d_k_M range: [0.0378, 0.5739], d_k_M_hat range: [0.2961, 0.8635]
2025-03-11 20:01:48 - Train Iteration 1583: loss: 0.5427, d_k_M range: [0.1660, 0.6338], d_k_M_hat range: [0.5105, 0.8971]
2025-03-11 20:01:48 - Train Iteration 1584: loss: 0.6415, d_k_M range: [0.1169, 0.7700], d_k_M_hat range: [0.4208, 0.9690]
2025-03-11 20:01:48 - Train Iteration 1585: loss: 0.6240, d_k_M range: [0.0292, 0.5880], d_k_M_hat range: [0.2392, 0.8457]
2025-03-11 20:01:49 - Train Iteration 1586: loss: 0.8449, d_k_M range: [0.4591, 0.9102], d_k_M_hat range: [0.7395, 0.9910]
2025-03-11 20:01:49 - Train Iteration 1587: loss: 0.5482, d_k_M range: [0.0797, 0.6400], d_k_M_hat range: [0.3639, 0.8996]
2025-03-11 20:01:50 - Train Iteration 1588: loss: 0.5518, d_k_M range: [0.1387, 0.3595], d_k_M_hat range: [0.4203, 0.6327]
2025-03-11 20:01:50 - Train Iteration 1589: loss: 0.5556, d_k_M range: [0.0745, 0.6354], d_k_M_hat range: [0.3833, 0.8900]
2025-03-11 20:01:50 - Train Iteration 1590: loss: 0.8924, d_k_M range: [0.0021, 0.7069], d_k_M_hat range: [0.0575, 0.9504]
2025-03-11 20:01:51 - Train Iteration 1591: loss: 0.6397, d_k_M range: [0.1538, 0.7468], d_k_M_hat range: [0.4568, 0.9470]
2025-03-11 20:01:51 - Train Iteration 1592: loss: 0.5133, d_k_M range: [0.1291, 0.2823], d_k_M_hat range: [0.4854, 0.6290]
2025-03-11 20:01:52 - Train Iteration 1593: loss: 0.5685, d_k_M range: [0.3636, 0.6887], d_k_M_hat range: [0.6875, 0.9635]
2025-03-11 20:01:52 - Train Iteration 1594: loss: 0.5795, d_k_M range: [0.0396, 0.6428], d_k_M_hat range: [0.3524, 0.9477]
2025-03-11 20:01:52 - Train Iteration 1595: loss: 0.8037, d_k_M range: [0.0045, 0.4232], d_k_M_hat range: [0.1080, 0.7101]
2025-03-11 20:01:53 - Train Iteration 1596: loss: 0.5931, d_k_M range: [0.0821, 0.5024], d_k_M_hat range: [0.4131, 0.8290]
2025-03-11 20:01:53 - Train Iteration 1597: loss: 0.6592, d_k_M range: [0.2978, 0.7889], d_k_M_hat range: [0.6152, 0.9770]
2025-03-11 20:01:53 - Train Iteration 1598: loss: 0.5938, d_k_M range: [0.0140, 0.2947], d_k_M_hat range: [0.2434, 0.6271]
2025-03-11 20:01:54 - Train Iteration 1599: loss: 0.5310, d_k_M range: [0.0406, 0.5927], d_k_M_hat range: [0.3680, 0.8642]
2025-03-11 20:01:54 - Train Iteration 1600: loss: 0.6410, d_k_M range: [0.0034, 0.5484], d_k_M_hat range: [0.2028, 0.8273]
2025-03-11 20:01:55 - Train Iteration 1601: loss: 0.9262, d_k_M range: [0.3740, 0.9586], d_k_M_hat range: [0.7004, 0.9962]
2025-03-11 20:01:55 - Train Iteration 1602: loss: 0.8580, d_k_M range: [0.0357, 0.9201], d_k_M_hat range: [0.2902, 0.9938]
2025-03-11 20:01:55 - Train Iteration 1603: loss: 0.5952, d_k_M range: [0.1696, 0.4082], d_k_M_hat range: [0.4426, 0.6726]
2025-03-11 20:01:56 - Train Iteration 1604: loss: 0.6000, d_k_M range: [0.0645, 0.6111], d_k_M_hat range: [0.3972, 0.8810]
2025-03-11 20:01:56 - Train Iteration 1605: loss: 0.5950, d_k_M range: [0.0980, 0.5503], d_k_M_hat range: [0.3984, 0.8282]
2025-03-11 20:01:56 - Train Iteration 1606: loss: 0.5653, d_k_M range: [0.0548, 0.6548], d_k_M_hat range: [0.3426, 0.9319]
2025-03-11 20:01:57 - Train Iteration 1607: loss: 0.5320, d_k_M range: [0.2358, 0.6564], d_k_M_hat range: [0.5241, 0.9270]
2025-03-11 20:01:57 - Train Iteration 1608: loss: 0.6595, d_k_M range: [0.0173, 0.6045], d_k_M_hat range: [0.2053, 0.8973]
2025-03-11 20:01:58 - Train Iteration 1609: loss: 0.7678, d_k_M range: [0.2570, 0.8659], d_k_M_hat range: [0.5756, 0.9897]
2025-03-11 20:01:58 - Train Iteration 1610: loss: 0.7671, d_k_M range: [0.0032, 0.4783], d_k_M_hat range: [0.1273, 0.7150]
2025-03-11 20:01:58 - Train Iteration 1611: loss: 0.6119, d_k_M range: [0.1545, 0.4854], d_k_M_hat range: [0.3723, 0.7245]
2025-03-11 20:01:59 - Train Iteration 1612: loss: 0.5991, d_k_M range: [0.0308, 0.5217], d_k_M_hat range: [0.2958, 0.7477]
2025-03-11 20:01:59 - Train Iteration 1613: loss: 0.6184, d_k_M range: [0.0084, 0.5140], d_k_M_hat range: [0.2221, 0.7984]
2025-03-11 20:02:00 - Train Iteration 1614: loss: 0.8309, d_k_M range: [0.2314, 0.8983], d_k_M_hat range: [0.5249, 0.9868]
2025-03-11 20:02:00 - Train Iteration 1615: loss: 0.5858, d_k_M range: [0.0744, 0.5613], d_k_M_hat range: [0.3806, 0.8191]
2025-03-11 20:02:00 - Train Iteration 1616: loss: 0.5811, d_k_M range: [0.2119, 0.5449], d_k_M_hat range: [0.4556, 0.7926]
2025-03-11 20:02:01 - Train Iteration 1617: loss: 0.5449, d_k_M range: [0.1511, 0.4474], d_k_M_hat range: [0.4130, 0.7243]
2025-03-11 20:02:01 - Train Iteration 1618: loss: 0.5495, d_k_M range: [0.3548, 0.5187], d_k_M_hat range: [0.6540, 0.8001]
2025-03-11 20:02:02 - Train Iteration 1619: loss: 0.6013, d_k_M range: [0.1321, 0.7032], d_k_M_hat range: [0.4365, 0.9278]
2025-03-11 20:02:02 - Train Iteration 1620: loss: 0.5957, d_k_M range: [0.0799, 0.5712], d_k_M_hat range: [0.3658, 0.8905]
2025-03-11 20:02:02 - Train Iteration 1621: loss: 0.5224, d_k_M range: [0.1897, 0.6673], d_k_M_hat range: [0.5101, 0.9534]
2025-03-11 20:02:03 - Train Iteration 1622: loss: 0.5189, d_k_M range: [0.0414, 0.5007], d_k_M_hat range: [0.3382, 0.8499]
2025-03-11 20:02:03 - Train Iteration 1623: loss: 0.6416, d_k_M range: [0.0325, 0.3849], d_k_M_hat range: [0.2314, 0.7386]
2025-03-11 20:02:04 - Train Iteration 1624: loss: 0.5849, d_k_M range: [0.0628, 0.7082], d_k_M_hat range: [0.3848, 0.9665]
2025-03-11 20:02:04 - Train Iteration 1625: loss: 0.5231, d_k_M range: [0.0325, 0.5852], d_k_M_hat range: [0.3093, 0.9094]
2025-03-11 20:02:05 - Train Iteration 1626: loss: 0.5075, d_k_M range: [0.2782, 0.6464], d_k_M_hat range: [0.6202, 0.9340]
2025-03-11 20:02:05 - Train Iteration 1627: loss: 0.6102, d_k_M range: [0.0377, 0.7539], d_k_M_hat range: [0.2571, 0.9728]
2025-03-11 20:02:05 - Train Iteration 1628: loss: 0.5107, d_k_M range: [0.0142, 0.5591], d_k_M_hat range: [0.2996, 0.8853]
2025-03-11 20:02:06 - Train Iteration 1629: loss: 0.8491, d_k_M range: [0.3032, 0.9184], d_k_M_hat range: [0.5686, 0.9970]
2025-03-11 20:02:06 - Train Iteration 1630: loss: 0.7065, d_k_M range: [0.0063, 0.5983], d_k_M_hat range: [0.1658, 0.9083]
2025-03-11 20:02:07 - Train Iteration 1631: loss: 0.5581, d_k_M range: [0.0802, 0.6631], d_k_M_hat range: [0.3916, 0.9516]
2025-03-11 20:02:07 - Train Iteration 1632: loss: 0.5419, d_k_M range: [0.0515, 0.6541], d_k_M_hat range: [0.3565, 0.9197]
2025-03-11 20:02:07 - Train Iteration 1633: loss: 0.5319, d_k_M range: [0.0123, 0.3525], d_k_M_hat range: [0.2962, 0.6554]
2025-03-11 20:02:08 - Train Iteration 1634: loss: 0.7282, d_k_M range: [0.0308, 0.3111], d_k_M_hat range: [0.1774, 0.6510]
2025-03-11 20:02:08 - Train Iteration 1635: loss: 0.5721, d_k_M range: [0.0123, 0.4416], d_k_M_hat range: [0.2559, 0.7626]
2025-03-11 20:02:09 - Train Iteration 1636: loss: 0.9150, d_k_M range: [0.1614, 0.9513], d_k_M_hat range: [0.4536, 0.9948]
2025-03-11 20:02:09 - Train Iteration 1637: loss: 0.6080, d_k_M range: [0.0174, 0.3793], d_k_M_hat range: [0.2929, 0.7281]
2025-03-11 20:02:09 - Train Iteration 1638: loss: 0.5586, d_k_M range: [0.1144, 0.4928], d_k_M_hat range: [0.4294, 0.8203]
2025-03-11 20:02:10 - Train Iteration 1639: loss: 0.5938, d_k_M range: [0.0374, 0.6663], d_k_M_hat range: [0.2668, 0.9244]
2025-03-11 20:02:10 - Train Iteration 1640: loss: 0.5604, d_k_M range: [0.1121, 0.4829], d_k_M_hat range: [0.4004, 0.7896]
2025-03-11 20:02:11 - Train Iteration 1641: loss: 0.5214, d_k_M range: [0.0220, 0.3724], d_k_M_hat range: [0.2999, 0.7327]
2025-03-11 20:02:11 - Train Iteration 1642: loss: 0.5043, d_k_M range: [0.0134, 0.6336], d_k_M_hat range: [0.3080, 0.9347]
2025-03-11 20:02:11 - Train Iteration 1643: loss: 0.8861, d_k_M range: [0.2628, 0.9393], d_k_M_hat range: [0.5858, 0.9980]
2025-03-11 20:02:12 - Train Iteration 1644: loss: 0.5635, d_k_M range: [0.0232, 0.4182], d_k_M_hat range: [0.2842, 0.6797]
2025-03-11 20:02:12 - Train Iteration 1645: loss: 0.5788, d_k_M range: [0.0655, 0.6283], d_k_M_hat range: [0.3916, 0.8676]
2025-03-11 20:02:12 - Train Iteration 1646: loss: 0.6198, d_k_M range: [0.0151, 0.5643], d_k_M_hat range: [0.2279, 0.8523]
2025-03-11 20:02:13 - Train Iteration 1647: loss: 0.8974, d_k_M range: [0.1267, 0.9424], d_k_M_hat range: [0.4233, 0.9950]
2025-03-11 20:02:13 - Train Iteration 1648: loss: 0.6437, d_k_M range: [0.2896, 0.7563], d_k_M_hat range: [0.5470, 0.9540]
2025-03-11 20:02:14 - Train Iteration 1649: loss: 0.7676, d_k_M range: [0.0028, 0.5515], d_k_M_hat range: [0.1267, 0.7709]
2025-03-11 20:02:14 - Train Iteration 1650: loss: 0.5729, d_k_M range: [0.1077, 0.6229], d_k_M_hat range: [0.3837, 0.8981]
2025-03-11 20:02:14 - Train Iteration 1651: loss: 0.5716, d_k_M range: [0.0486, 0.4803], d_k_M_hat range: [0.2926, 0.7675]
2025-03-11 20:02:15 - Train Iteration 1652: loss: 0.5415, d_k_M range: [0.1320, 0.6466], d_k_M_hat range: [0.4296, 0.9251]
2025-03-11 20:02:15 - Train Iteration 1653: loss: 0.5657, d_k_M range: [0.1034, 0.5428], d_k_M_hat range: [0.4175, 0.8165]
2025-03-11 20:02:16 - Train Iteration 1654: loss: 0.5820, d_k_M range: [0.0130, 0.3148], d_k_M_hat range: [0.2501, 0.6538]
2025-03-11 20:02:16 - Train Iteration 1655: loss: 0.5609, d_k_M range: [0.1124, 0.4629], d_k_M_hat range: [0.4176, 0.7775]
2025-03-11 20:02:16 - Train Iteration 1656: loss: 0.6009, d_k_M range: [0.0137, 0.6633], d_k_M_hat range: [0.2386, 0.9269]
2025-03-11 20:02:17 - Train Iteration 1657: loss: 0.6411, d_k_M range: [0.0917, 0.7793], d_k_M_hat range: [0.4042, 0.9786]
2025-03-11 20:02:17 - Train Iteration 1658: loss: 0.6937, d_k_M range: [0.0061, 0.4968], d_k_M_hat range: [0.1732, 0.7959]
2025-03-11 20:02:17 - Train Iteration 1659: loss: 0.4995, d_k_M range: [0.0274, 0.5477], d_k_M_hat range: [0.3418, 0.8409]
2025-03-11 20:02:18 - Train Iteration 1660: loss: 0.5952, d_k_M range: [0.0189, 0.3984], d_k_M_hat range: [0.2474, 0.6486]
2025-03-11 20:02:18 - Train Iteration 1661: loss: 0.6335, d_k_M range: [0.1791, 0.7680], d_k_M_hat range: [0.4987, 0.9720]
2025-03-11 20:02:18 - Train Iteration 1662: loss: 0.5870, d_k_M range: [0.2800, 0.7209], d_k_M_hat range: [0.5722, 0.9623]
2025-03-11 20:02:19 - Train Iteration 1663: loss: 0.5832, d_k_M range: [0.1263, 0.5709], d_k_M_hat range: [0.3626, 0.8751]
2025-03-11 20:02:19 - Train Iteration 1664: loss: 0.6522, d_k_M range: [0.2788, 0.7839], d_k_M_hat range: [0.5387, 0.9763]
2025-03-11 20:02:20 - Train Iteration 1665: loss: 0.9356, d_k_M range: [0.0029, 0.4257], d_k_M_hat range: [0.0356, 0.6794]
2025-03-11 20:02:20 - Train Iteration 1666: loss: 0.6494, d_k_M range: [0.1908, 0.7150], d_k_M_hat range: [0.4205, 0.9443]
2025-03-11 20:02:20 - Train Iteration 1667: loss: 0.5867, d_k_M range: [0.1567, 0.3751], d_k_M_hat range: [0.4132, 0.6427]
2025-03-11 20:02:21 - Train Iteration 1668: loss: 0.5868, d_k_M range: [0.0182, 0.6586], d_k_M_hat range: [0.2521, 0.9288]
2025-03-11 20:02:21 - Train Iteration 1669: loss: 0.6807, d_k_M range: [0.1987, 0.7987], d_k_M_hat range: [0.4954, 0.9736]
2025-03-11 20:02:22 - Train Iteration 1670: loss: 0.6277, d_k_M range: [0.0730, 0.3225], d_k_M_hat range: [0.3147, 0.6379]
2025-03-11 20:02:22 - Train Iteration 1671: loss: 0.6078, d_k_M range: [0.2562, 0.6017], d_k_M_hat range: [0.4766, 0.8640]
2025-03-11 20:02:23 - Train Iteration 1672: loss: 0.7050, d_k_M range: [0.1733, 0.4935], d_k_M_hat range: [0.3337, 0.7688]
2025-03-11 20:02:23 - Train Iteration 1673: loss: 0.6273, d_k_M range: [0.0024, 0.4872], d_k_M_hat range: [0.2103, 0.7647]
2025-03-11 20:02:23 - Train Iteration 1674: loss: 0.5744, d_k_M range: [0.1624, 0.6199], d_k_M_hat range: [0.4763, 0.8969]
2025-03-11 20:02:24 - Train Iteration 1675: loss: 0.5962, d_k_M range: [0.0273, 0.4761], d_k_M_hat range: [0.2551, 0.7308]
2025-03-11 20:02:24 - Train Iteration 1676: loss: 0.9644, d_k_M range: [0.0007, 0.4310], d_k_M_hat range: [0.0187, 0.6821]
2025-03-11 20:02:25 - Train Iteration 1677: loss: 0.7207, d_k_M range: [0.2736, 0.8312], d_k_M_hat range: [0.5972, 0.9823]
2025-03-11 20:02:25 - Train Iteration 1678: loss: 0.7613, d_k_M range: [0.2565, 0.8581], d_k_M_hat range: [0.5484, 0.9856]
2025-03-11 20:02:26 - Train Iteration 1679: loss: 0.5682, d_k_M range: [0.2226, 0.6687], d_k_M_hat range: [0.5445, 0.9149]
2025-03-11 20:02:26 - Train Iteration 1680: loss: 0.5732, d_k_M range: [0.0291, 0.4059], d_k_M_hat range: [0.3397, 0.6807]
2025-03-11 20:02:26 - Train Iteration 1681: loss: 0.5648, d_k_M range: [0.2305, 0.6604], d_k_M_hat range: [0.5078, 0.9089]
2025-03-11 20:02:27 - Train Iteration 1682: loss: 0.5462, d_k_M range: [0.0267, 0.5477], d_k_M_hat range: [0.2980, 0.8087]
2025-03-11 20:02:27 - Train Iteration 1683: loss: 0.5692, d_k_M range: [0.1932, 0.6039], d_k_M_hat range: [0.4932, 0.9207]
2025-03-11 20:02:28 - Train Iteration 1684: loss: 0.9365, d_k_M range: [0.0482, 0.9648], d_k_M_hat range: [0.3568, 0.9970]
2025-03-11 20:02:28 - Train Iteration 1685: loss: 0.5652, d_k_M range: [0.0678, 0.5050], d_k_M_hat range: [0.3257, 0.8412]
2025-03-11 20:02:29 - Train Iteration 1686: loss: 0.5589, d_k_M range: [0.0218, 0.4525], d_k_M_hat range: [0.2742, 0.7275]
2025-03-11 20:02:29 - Train Iteration 1687: loss: 0.6626, d_k_M range: [0.3904, 0.7682], d_k_M_hat range: [0.6559, 0.9584]
2025-03-11 20:02:29 - Train Iteration 1688: loss: 0.6315, d_k_M range: [0.0092, 0.5303], d_k_M_hat range: [0.2171, 0.8228]
2025-03-11 20:02:30 - Train Iteration 1689: loss: 0.9816, d_k_M range: [0.0005, 0.6918], d_k_M_hat range: [0.0098, 0.9403]
2025-03-11 20:02:30 - Train Iteration 1690: loss: 0.6076, d_k_M range: [0.1561, 0.6235], d_k_M_hat range: [0.4475, 0.8690]
2025-03-11 20:02:31 - Train Iteration 1691: loss: 0.6099, d_k_M range: [0.1400, 0.4307], d_k_M_hat range: [0.4239, 0.6839]
2025-03-11 20:02:31 - Train Iteration 1692: loss: 0.6066, d_k_M range: [0.0116, 0.4415], d_k_M_hat range: [0.2328, 0.7294]
2025-03-11 20:02:31 - Train Iteration 1693: loss: 0.8199, d_k_M range: [0.1439, 0.8990], d_k_M_hat range: [0.5039, 0.9935]
2025-03-11 20:02:32 - Train Iteration 1694: loss: 0.6059, d_k_M range: [0.1355, 0.7099], d_k_M_hat range: [0.4223, 0.9315]
2025-03-11 20:02:32 - Train Iteration 1695: loss: 0.5856, d_k_M range: [0.3012, 0.5670], d_k_M_hat range: [0.5488, 0.8505]
2025-03-11 20:02:33 - Train Iteration 1696: loss: 0.5495, d_k_M range: [0.0432, 0.4990], d_k_M_hat range: [0.3620, 0.8083]
2025-03-11 20:02:33 - Train Iteration 1697: loss: 0.9838, d_k_M range: [0.0002, 0.3779], d_k_M_hat range: [0.0083, 0.6496]
2025-03-11 20:02:33 - Train Iteration 1698: loss: 0.5454, d_k_M range: [0.2913, 0.5636], d_k_M_hat range: [0.5648, 0.8251]
2025-03-11 20:02:34 - Train Iteration 1699: loss: 0.5356, d_k_M range: [0.1262, 0.6919], d_k_M_hat range: [0.4603, 0.9601]
2025-03-11 20:02:34 - Train Iteration 1700: loss: 0.5972, d_k_M range: [0.0028, 0.4450], d_k_M_hat range: [0.2301, 0.7694]
2025-03-11 20:02:35 - Train Iteration 1701: loss: 0.8203, d_k_M range: [0.0028, 0.6933], d_k_M_hat range: [0.0971, 0.9582]
2025-03-11 20:02:35 - Train Iteration 1702: loss: 0.9463, d_k_M range: [0.0026, 0.8017], d_k_M_hat range: [0.0299, 0.9862]
2025-03-11 20:02:35 - Train Iteration 1703: loss: 0.9056, d_k_M range: [0.2196, 0.9458], d_k_M_hat range: [0.5223, 0.9942]
2025-03-11 20:02:36 - Train Iteration 1704: loss: 0.5428, d_k_M range: [0.0301, 0.3864], d_k_M_hat range: [0.3251, 0.7459]
2025-03-11 20:02:36 - Train Iteration 1705: loss: 0.4999, d_k_M range: [0.2131, 0.5469], d_k_M_hat range: [0.5226, 0.8614]
2025-03-11 20:02:36 - Train Iteration 1706: loss: 0.7798, d_k_M range: [0.3503, 0.8749], d_k_M_hat range: [0.6219, 0.9926]
2025-03-11 20:02:37 - Train Iteration 1707: loss: 0.5704, d_k_M range: [0.1437, 0.5581], d_k_M_hat range: [0.4216, 0.8052]
2025-03-11 20:02:37 - Train Iteration 1708: loss: 0.5443, d_k_M range: [0.0825, 0.4220], d_k_M_hat range: [0.3870, 0.7024]
2025-03-11 20:02:38 - Train Iteration 1709: loss: 0.5343, d_k_M range: [0.0436, 0.6674], d_k_M_hat range: [0.3127, 0.9520]
2025-03-11 20:02:38 - Train Iteration 1710: loss: 0.5469, d_k_M range: [0.0987, 0.4430], d_k_M_hat range: [0.3658, 0.7863]
2025-03-11 20:02:38 - Train Iteration 1711: loss: 0.7467, d_k_M range: [0.2211, 0.8474], d_k_M_hat range: [0.4822, 0.9864]
2025-03-11 20:02:39 - Train Iteration 1712: loss: 0.5353, d_k_M range: [0.1714, 0.6790], d_k_M_hat range: [0.4502, 0.9473]
2025-03-11 20:02:39 - Train Iteration 1713: loss: 0.5354, d_k_M range: [0.0407, 0.4736], d_k_M_hat range: [0.3206, 0.7957]
2025-03-11 20:02:40 - Train Iteration 1714: loss: 0.6133, d_k_M range: [0.0138, 0.4795], d_k_M_hat range: [0.2307, 0.8279]
2025-03-11 20:02:40 - Train Iteration 1715: loss: 0.6041, d_k_M range: [0.0682, 0.4829], d_k_M_hat range: [0.4166, 0.8047]
2025-03-11 20:02:40 - Train Iteration 1716: loss: 0.6596, d_k_M range: [0.0099, 0.4673], d_k_M_hat range: [0.1977, 0.7421]
2025-03-11 20:02:41 - Train Iteration 1717: loss: 0.5505, d_k_M range: [0.1831, 0.4351], d_k_M_hat range: [0.4527, 0.7524]
2025-03-11 20:02:41 - Train Iteration 1718: loss: 0.6326, d_k_M range: [0.0352, 0.7776], d_k_M_hat range: [0.3004, 0.9822]
2025-03-11 20:02:41 - Train Iteration 1719: loss: 0.6150, d_k_M range: [0.0140, 0.4721], d_k_M_hat range: [0.2298, 0.7860]
2025-03-11 20:02:42 - Train Iteration 1720: loss: 0.5643, d_k_M range: [0.3228, 0.5525], d_k_M_hat range: [0.6094, 0.8450]
2025-03-11 20:02:42 - Train Iteration 1721: loss: 0.6185, d_k_M range: [0.1289, 0.5872], d_k_M_hat range: [0.4278, 0.8676]
2025-03-11 20:02:43 - Train Iteration 1722: loss: 0.6211, d_k_M range: [0.0479, 0.3798], d_k_M_hat range: [0.2597, 0.7189]
2025-03-11 20:02:43 - Train Iteration 1723: loss: 0.7276, d_k_M range: [0.1491, 0.8412], d_k_M_hat range: [0.4509, 0.9882]
2025-03-11 20:02:43 - Train Iteration 1724: loss: 0.6424, d_k_M range: [0.0044, 0.5770], d_k_M_hat range: [0.2029, 0.8282]
2025-03-11 20:02:44 - Train Iteration 1725: loss: 0.5957, d_k_M range: [0.1975, 0.6760], d_k_M_hat range: [0.4677, 0.9270]
2025-03-11 20:02:44 - Train Iteration 1726: loss: 0.6008, d_k_M range: [0.0594, 0.5339], d_k_M_hat range: [0.3170, 0.7950]
2025-03-11 20:02:45 - Train Iteration 1727: loss: 0.5531, d_k_M range: [0.1990, 0.5336], d_k_M_hat range: [0.4553, 0.8488]
2025-03-11 20:02:45 - Train Iteration 1728: loss: 0.5761, d_k_M range: [0.1737, 0.5613], d_k_M_hat range: [0.4153, 0.8580]
2025-03-11 20:02:45 - Train Iteration 1729: loss: 0.6240, d_k_M range: [0.0370, 0.7414], d_k_M_hat range: [0.3061, 0.9515]
2025-03-11 20:02:46 - Train Iteration 1730: loss: 0.6336, d_k_M range: [0.0167, 0.6785], d_k_M_hat range: [0.2208, 0.9134]
2025-03-11 20:02:46 - Train Iteration 1731: loss: 0.5697, d_k_M range: [0.0737, 0.4911], d_k_M_hat range: [0.3800, 0.7929]
2025-03-11 20:02:47 - Train Iteration 1732: loss: 0.6031, d_k_M range: [0.0407, 0.5715], d_k_M_hat range: [0.2831, 0.8659]
2025-03-11 20:02:47 - Train Iteration 1733: loss: 0.8038, d_k_M range: [0.0096, 0.8783], d_k_M_hat range: [0.1218, 0.9818]
2025-03-11 20:02:47 - Train Iteration 1734: loss: 0.5679, d_k_M range: [0.0379, 0.5636], d_k_M_hat range: [0.3942, 0.8577]
2025-03-11 20:02:48 - Train Iteration 1735: loss: 0.7065, d_k_M range: [0.0790, 0.5461], d_k_M_hat range: [0.2385, 0.8460]
2025-03-11 20:02:48 - Train Iteration 1736: loss: 0.8594, d_k_M range: [0.2481, 0.9175], d_k_M_hat range: [0.5482, 0.9905]
2025-03-11 20:02:49 - Train Iteration 1737: loss: 0.7672, d_k_M range: [0.0316, 0.5750], d_k_M_hat range: [0.1557, 0.8652]
2025-03-11 20:02:49 - Train Iteration 1738: loss: 0.5537, d_k_M range: [0.3231, 0.6175], d_k_M_hat range: [0.5949, 0.9158]
2025-03-11 20:02:50 - Train Iteration 1739: loss: 0.9369, d_k_M range: [0.2399, 0.9667], d_k_M_hat range: [0.5465, 0.9988]
2025-03-11 20:02:50 - Train Iteration 1740: loss: 0.5272, d_k_M range: [0.0360, 0.5759], d_k_M_hat range: [0.3099, 0.8813]
2025-03-11 20:02:50 - Train Iteration 1741: loss: 0.5031, d_k_M range: [0.1341, 0.6622], d_k_M_hat range: [0.4571, 0.9529]
2025-03-11 20:02:51 - Train Iteration 1742: loss: 0.6619, d_k_M range: [0.0108, 0.2172], d_k_M_hat range: [0.1973, 0.4894]
2025-03-11 20:02:51 - Train Iteration 1743: loss: 0.5872, d_k_M range: [0.2859, 0.7273], d_k_M_hat range: [0.5728, 0.9610]
2025-03-11 20:02:51 - Train Iteration 1744: loss: 0.5142, d_k_M range: [0.2408, 0.6795], d_k_M_hat range: [0.5372, 0.9624]
2025-03-11 20:02:52 - Train Iteration 1745: loss: 0.5648, d_k_M range: [0.1001, 0.6038], d_k_M_hat range: [0.3485, 0.9078]
2025-03-11 20:02:52 - Train Iteration 1746: loss: 0.6215, d_k_M range: [0.0349, 0.3469], d_k_M_hat range: [0.2465, 0.6826]
2025-03-11 20:02:53 - Train Iteration 1747: loss: 0.6396, d_k_M range: [0.1313, 0.7700], d_k_M_hat range: [0.4524, 0.9833]
2025-03-11 20:02:53 - Train Iteration 1748: loss: 0.5786, d_k_M range: [0.1099, 0.5277], d_k_M_hat range: [0.4197, 0.7671]
2025-03-11 20:02:54 - Train Iteration 1749: loss: 0.6529, d_k_M range: [0.2343, 0.7423], d_k_M_hat range: [0.5372, 0.9384]
2025-03-11 20:02:54 - Train Iteration 1750: loss: 0.8637, d_k_M range: [0.2178, 0.9264], d_k_M_hat range: [0.4578, 0.9971]
2025-03-11 20:02:54 - Train Iteration 1751: loss: 0.5308, d_k_M range: [0.0393, 0.6692], d_k_M_hat range: [0.3108, 0.9432]
2025-03-11 20:02:55 - Train Iteration 1752: loss: 0.5279, d_k_M range: [0.1413, 0.5673], d_k_M_hat range: [0.4817, 0.8408]
2025-03-11 20:02:55 - Train Iteration 1753: loss: 0.5121, d_k_M range: [0.1372, 0.4559], d_k_M_hat range: [0.4408, 0.8118]
2025-03-11 20:02:55 - Train Iteration 1754: loss: 0.8567, d_k_M range: [0.0808, 0.9170], d_k_M_hat range: [0.4373, 0.9935]
2025-03-11 20:02:56 - Train Iteration 1755: loss: 0.5811, d_k_M range: [0.0223, 0.4984], d_k_M_hat range: [0.2754, 0.7546]
2025-03-11 20:02:56 - Train Iteration 1756: loss: 0.4790, d_k_M range: [0.1357, 0.4194], d_k_M_hat range: [0.4726, 0.7519]
2025-03-11 20:02:57 - Train Iteration 1757: loss: 0.8724, d_k_M range: [0.0320, 0.9282], d_k_M_hat range: [0.3217, 0.9942]
2025-03-11 20:02:57 - Train Iteration 1758: loss: 0.8008, d_k_M range: [0.0467, 0.8771], d_k_M_hat range: [0.3507, 0.9822]
2025-03-11 20:02:57 - Train Iteration 1759: loss: 0.5141, d_k_M range: [0.1977, 0.6398], d_k_M_hat range: [0.5057, 0.9228]
2025-03-11 20:02:58 - Train Iteration 1760: loss: 0.7568, d_k_M range: [0.0438, 0.8622], d_k_M_hat range: [0.3009, 0.9923]
2025-03-11 20:02:58 - Train Iteration 1761: loss: 0.5794, d_k_M range: [0.0086, 0.3411], d_k_M_hat range: [0.2496, 0.6693]
2025-03-11 20:02:59 - Train Iteration 1762: loss: 0.5357, d_k_M range: [0.3450, 0.7005], d_k_M_hat range: [0.6418, 0.9697]
2025-03-11 20:02:59 - Train Iteration 1763: loss: 0.6530, d_k_M range: [0.0025, 0.6813], d_k_M_hat range: [0.1944, 0.9585]
2025-03-11 20:02:59 - Train Iteration 1764: loss: 0.5935, d_k_M range: [0.2110, 0.7218], d_k_M_hat range: [0.4994, 0.9515]
2025-03-11 20:03:00 - Train Iteration 1765: loss: 0.5255, d_k_M range: [0.0516, 0.3996], d_k_M_hat range: [0.3267, 0.7475]
2025-03-11 20:03:00 - Train Iteration 1766: loss: 0.5902, d_k_M range: [0.0116, 0.7505], d_k_M_hat range: [0.2632, 0.9822]
2025-03-11 20:03:01 - Train Iteration 1767: loss: 0.5201, d_k_M range: [0.0977, 0.6663], d_k_M_hat range: [0.4171, 0.9481]
2025-03-11 20:03:01 - Train Iteration 1768: loss: 0.5211, d_k_M range: [0.1375, 0.5853], d_k_M_hat range: [0.4629, 0.9040]
2025-03-11 20:03:01 - Train Iteration 1769: loss: 0.4965, d_k_M range: [0.1276, 0.4767], d_k_M_hat range: [0.5038, 0.8717]
2025-03-11 20:03:02 - Train Iteration 1770: loss: 0.5651, d_k_M range: [0.0045, 0.5357], d_k_M_hat range: [0.2527, 0.8968]
2025-03-11 20:03:02 - Train Iteration 1771: loss: 0.4968, d_k_M range: [0.0131, 0.4259], d_k_M_hat range: [0.3087, 0.7713]
2025-03-11 20:03:02 - Train Iteration 1772: loss: 0.7718, d_k_M range: [0.0208, 0.8705], d_k_M_hat range: [0.3176, 0.9919]
2025-03-11 20:03:03 - Train Iteration 1773: loss: 0.6299, d_k_M range: [0.0569, 0.7800], d_k_M_hat range: [0.3951, 0.9863]
2025-03-11 20:03:03 - Train Iteration 1774: loss: 0.9637, d_k_M range: [0.2750, 0.9804], d_k_M_hat range: [0.6191, 0.9987]
2025-03-11 20:03:04 - Train Iteration 1775: loss: 0.4863, d_k_M range: [0.0197, 0.5941], d_k_M_hat range: [0.3223, 0.9251]
2025-03-11 20:03:04 - Train Iteration 1776: loss: 0.5208, d_k_M range: [0.0216, 0.6781], d_k_M_hat range: [0.3150, 0.9564]
2025-03-11 20:03:04 - Train Iteration 1777: loss: 0.5253, d_k_M range: [0.0264, 0.4912], d_k_M_hat range: [0.3354, 0.8157]
2025-03-11 20:03:05 - Train Iteration 1778: loss: 0.6915, d_k_M range: [0.0111, 0.8012], d_k_M_hat range: [0.3243, 0.9696]
2025-03-11 20:03:05 - Train Iteration 1779: loss: 0.9998, d_k_M range: [0.0000, 0.4984], d_k_M_hat range: [0.0001, 0.8615]
2025-03-11 20:03:06 - Train Iteration 1780: loss: 0.4990, d_k_M range: [0.1198, 0.5528], d_k_M_hat range: [0.5153, 0.8979]
2025-03-11 20:03:06 - Train Iteration 1781: loss: 0.8014, d_k_M range: [0.0014, 0.3149], d_k_M_hat range: [0.1062, 0.6927]
2025-03-11 20:03:06 - Train Iteration 1782: loss: 0.7423, d_k_M range: [0.2060, 0.8467], d_k_M_hat range: [0.6001, 0.9852]
2025-03-11 20:03:07 - Train Iteration 1783: loss: 0.5427, d_k_M range: [0.0187, 0.5661], d_k_M_hat range: [0.2820, 0.9135]
2025-03-11 20:03:07 - Train Iteration 1784: loss: 0.5718, d_k_M range: [0.2361, 0.7409], d_k_M_hat range: [0.5417, 0.9847]
2025-03-11 20:03:08 - Train Iteration 1785: loss: 0.7708, d_k_M range: [0.0053, 0.4017], d_k_M_hat range: [0.1273, 0.7393]
2025-03-11 20:03:08 - Train Iteration 1786: loss: 0.8816, d_k_M range: [0.2155, 0.9318], d_k_M_hat range: [0.5171, 0.9929]
2025-03-11 20:03:08 - Train Iteration 1787: loss: 0.6251, d_k_M range: [0.0361, 0.4975], d_k_M_hat range: [0.2454, 0.8075]
2025-03-11 20:03:09 - Train Iteration 1788: loss: 0.5165, d_k_M range: [0.0682, 0.5308], d_k_M_hat range: [0.4347, 0.8320]
2025-03-11 20:03:09 - Train Iteration 1789: loss: 0.6391, d_k_M range: [0.3482, 0.7788], d_k_M_hat range: [0.6383, 0.9793]
2025-03-11 20:03:10 - Train Iteration 1790: loss: 0.7609, d_k_M range: [0.2225, 0.8656], d_k_M_hat range: [0.5269, 0.9933]
2025-03-11 20:03:10 - Train Iteration 1791: loss: 0.6760, d_k_M range: [0.0028, 0.3985], d_k_M_hat range: [0.1807, 0.7411]
2025-03-11 20:03:10 - Train Iteration 1792: loss: 0.5270, d_k_M range: [0.0849, 0.6136], d_k_M_hat range: [0.4242, 0.9336]
2025-03-11 20:03:11 - Train Iteration 1793: loss: 0.6216, d_k_M range: [0.0065, 0.5611], d_k_M_hat range: [0.2181, 0.8639]
2025-03-11 20:03:11 - Train Iteration 1794: loss: 0.5728, d_k_M range: [0.1355, 0.7059], d_k_M_hat range: [0.4362, 0.9491]
2025-03-11 20:03:12 - Train Iteration 1795: loss: 0.4796, d_k_M range: [0.0468, 0.4543], d_k_M_hat range: [0.4029, 0.7818]
2025-03-11 20:03:12 - Train Iteration 1796: loss: 0.6132, d_k_M range: [0.1148, 0.7630], d_k_M_hat range: [0.4291, 0.9800]
2025-03-11 20:03:12 - Train Iteration 1797: loss: 0.7878, d_k_M range: [0.0010, 0.5163], d_k_M_hat range: [0.1134, 0.8463]
2025-03-11 20:03:13 - Train Iteration 1798: loss: 0.5944, d_k_M range: [0.3985, 0.7493], d_k_M_hat range: [0.7425, 0.9801]
2025-03-11 20:03:13 - Train Iteration 1799: loss: 0.5103, d_k_M range: [0.1496, 0.6252], d_k_M_hat range: [0.4632, 0.9256]
2025-03-11 20:03:14 - Train Iteration 1800: loss: 0.6639, d_k_M range: [0.0066, 0.3245], d_k_M_hat range: [0.1918, 0.6233]
2025-03-11 20:03:14 - Train Iteration 1801: loss: 0.5861, d_k_M range: [0.0614, 0.7335], d_k_M_hat range: [0.3746, 0.9679]
2025-03-11 20:03:14 - Train Iteration 1802: loss: 0.5490, d_k_M range: [0.0113, 0.5069], d_k_M_hat range: [0.3172, 0.8309]
2025-03-11 20:03:15 - Train Iteration 1803: loss: 0.5799, d_k_M range: [0.0192, 0.5034], d_k_M_hat range: [0.2577, 0.8061]
2025-03-11 20:03:15 - Train Iteration 1804: loss: 0.9477, d_k_M range: [0.0910, 0.9713], d_k_M_hat range: [0.4577, 0.9978]
2025-03-11 20:03:15 - Train Iteration 1805: loss: 0.8600, d_k_M range: [0.0037, 0.3528], d_k_M_hat range: [0.0767, 0.6640]
2025-03-11 20:03:16 - Train Iteration 1806: loss: 0.8706, d_k_M range: [0.4679, 0.9268], d_k_M_hat range: [0.7742, 0.9937]
2025-03-11 20:03:16 - Train Iteration 1807: loss: 0.6027, d_k_M range: [0.0127, 0.3614], d_k_M_hat range: [0.2364, 0.6681]
2025-03-11 20:03:17 - Train Iteration 1808: loss: 0.5313, d_k_M range: [0.1372, 0.4847], d_k_M_hat range: [0.4083, 0.8134]
2025-03-11 20:03:17 - Train Iteration 1809: loss: 0.5646, d_k_M range: [0.0976, 0.7144], d_k_M_hat range: [0.3717, 0.9630]
2025-03-11 20:03:17 - Train Iteration 1810: loss: 0.5654, d_k_M range: [0.0355, 0.6692], d_k_M_hat range: [0.3533, 0.9546]
2025-03-11 20:03:18 - Train Iteration 1811: loss: 0.5007, d_k_M range: [0.1539, 0.5273], d_k_M_hat range: [0.5082, 0.8520]
2025-03-11 20:03:18 - Train Iteration 1812: loss: 0.5418, d_k_M range: [0.2483, 0.7104], d_k_M_hat range: [0.5407, 0.9743]
2025-03-11 20:03:19 - Train Iteration 1813: loss: 0.5767, d_k_M range: [0.0611, 0.3116], d_k_M_hat range: [0.3733, 0.6424]
2025-03-11 20:03:19 - Train Iteration 1814: loss: 0.5142, d_k_M range: [0.0798, 0.5202], d_k_M_hat range: [0.4603, 0.8641]
2025-03-11 20:03:20 - Train Iteration 1815: loss: 0.6327, d_k_M range: [0.0217, 0.7742], d_k_M_hat range: [0.2995, 0.9788]
2025-03-11 20:03:20 - Train Iteration 1816: loss: 0.5280, d_k_M range: [0.0194, 0.5819], d_k_M_hat range: [0.3031, 0.8952]
2025-03-11 20:03:20 - Train Iteration 1817: loss: 0.6201, d_k_M range: [0.0092, 0.4417], d_k_M_hat range: [0.2217, 0.7826]
2025-03-11 20:03:21 - Train Iteration 1818: loss: 0.6707, d_k_M range: [0.2768, 0.7981], d_k_M_hat range: [0.6511, 0.9791]
2025-03-11 20:03:21 - Train Iteration 1819: loss: 0.7040, d_k_M range: [0.0054, 0.4615], d_k_M_hat range: [0.1664, 0.7673]
2025-03-11 20:03:22 - Train Iteration 1820: loss: 0.5390, d_k_M range: [0.2039, 0.4823], d_k_M_hat range: [0.5598, 0.7827]
2025-03-11 20:03:22 - Train Iteration 1821: loss: 0.6246, d_k_M range: [0.0122, 0.6026], d_k_M_hat range: [0.2219, 0.9018]
2025-03-11 20:03:22 - Train Iteration 1822: loss: 0.5160, d_k_M range: [0.1356, 0.5642], d_k_M_hat range: [0.4899, 0.8685]
2025-03-11 20:03:23 - Train Iteration 1823: loss: 0.4903, d_k_M range: [0.1782, 0.5701], d_k_M_hat range: [0.5088, 0.8863]
2025-03-11 20:03:23 - Train Iteration 1824: loss: 0.7337, d_k_M range: [0.0213, 0.8469], d_k_M_hat range: [0.3043, 0.9903]
2025-03-11 20:03:24 - Train Iteration 1825: loss: 0.4966, d_k_M range: [0.0391, 0.3366], d_k_M_hat range: [0.3423, 0.7289]
2025-03-11 20:03:24 - Train Iteration 1826: loss: 0.5182, d_k_M range: [0.2290, 0.6089], d_k_M_hat range: [0.5737, 0.9318]
2025-03-11 20:03:24 - Train Iteration 1827: loss: 0.5559, d_k_M range: [0.2128, 0.7270], d_k_M_hat range: [0.5100, 0.9814]
2025-03-11 20:03:25 - Train Iteration 1828: loss: 0.6434, d_k_M range: [0.0269, 0.5371], d_k_M_hat range: [0.2248, 0.8563]
2025-03-11 20:03:25 - Train Iteration 1829: loss: 0.8331, d_k_M range: [0.0612, 0.8990], d_k_M_hat range: [0.4173, 0.9863]
2025-03-11 20:03:26 - Train Iteration 1830: loss: 0.6485, d_k_M range: [0.0147, 0.7875], d_k_M_hat range: [0.3037, 0.9822]
2025-03-11 20:03:26 - Train Iteration 1831: loss: 0.5489, d_k_M range: [0.0180, 0.3934], d_k_M_hat range: [0.2771, 0.7489]
2025-03-11 20:03:26 - Train Iteration 1832: loss: 0.5033, d_k_M range: [0.0520, 0.6060], d_k_M_hat range: [0.3694, 0.8966]
2025-03-11 20:03:27 - Train Iteration 1833: loss: 0.8786, d_k_M range: [0.0025, 0.5917], d_k_M_hat range: [0.0652, 0.8926]
2025-03-11 20:03:27 - Train Iteration 1834: loss: 0.5552, d_k_M range: [0.0283, 0.6630], d_k_M_hat range: [0.2846, 0.9529]
2025-03-11 20:03:28 - Train Iteration 1835: loss: 0.6046, d_k_M range: [0.0254, 0.5504], d_k_M_hat range: [0.2478, 0.8555]
2025-03-11 20:03:28 - Train Iteration 1836: loss: 0.4464, d_k_M range: [0.1150, 0.6056], d_k_M_hat range: [0.5146, 0.9405]
2025-03-11 20:03:28 - Train Iteration 1837: loss: 0.5056, d_k_M range: [0.0640, 0.6365], d_k_M_hat range: [0.4074, 0.9254]
2025-03-11 20:03:29 - Train Iteration 1838: loss: 0.5220, d_k_M range: [0.0371, 0.4448], d_k_M_hat range: [0.4048, 0.7790]
2025-03-11 20:03:29 - Train Iteration 1839: loss: 0.6950, d_k_M range: [0.0042, 0.7350], d_k_M_hat range: [0.1705, 0.9795]
2025-03-11 20:03:30 - Train Iteration 1840: loss: 0.6047, d_k_M range: [0.0085, 0.2310], d_k_M_hat range: [0.2308, 0.5999]
2025-03-11 20:03:30 - Train Iteration 1841: loss: 0.5815, d_k_M range: [0.2939, 0.7401], d_k_M_hat range: [0.5606, 0.9776]
2025-03-11 20:03:30 - Train Iteration 1842: loss: 0.4886, d_k_M range: [0.0198, 0.6269], d_k_M_hat range: [0.3250, 0.9294]
2025-03-11 20:03:31 - Train Iteration 1843: loss: 0.6035, d_k_M range: [0.0055, 0.4577], d_k_M_hat range: [0.2348, 0.8208]
2025-03-11 20:03:31 - Train Iteration 1844: loss: 0.4619, d_k_M range: [0.0577, 0.6478], d_k_M_hat range: [0.3925, 0.9681]
2025-03-11 20:03:32 - Train Iteration 1845: loss: 0.5441, d_k_M range: [0.0379, 0.6808], d_k_M_hat range: [0.3024, 0.9431]
2025-03-11 20:03:32 - Train Iteration 1846: loss: 0.5469, d_k_M range: [0.0309, 0.4208], d_k_M_hat range: [0.3225, 0.7333]
2025-03-11 20:03:32 - Train Iteration 1847: loss: 0.5383, d_k_M range: [0.0069, 0.3681], d_k_M_hat range: [0.2733, 0.7061]
2025-03-11 20:03:33 - Train Iteration 1848: loss: 0.4981, d_k_M range: [0.0703, 0.6600], d_k_M_hat range: [0.3719, 0.9543]
2025-03-11 20:03:33 - Train Iteration 1849: loss: 0.6225, d_k_M range: [0.0173, 0.5037], d_k_M_hat range: [0.2593, 0.8524]
2025-03-11 20:03:34 - Train Iteration 1850: loss: 0.4902, d_k_M range: [0.2141, 0.6014], d_k_M_hat range: [0.5139, 0.9162]
2025-03-11 20:03:34 - Train Iteration 1851: loss: 0.5784, d_k_M range: [0.1427, 0.6037], d_k_M_hat range: [0.4297, 0.9330]
2025-03-11 20:03:34 - Train Iteration 1852: loss: 0.5169, d_k_M range: [0.0984, 0.4945], d_k_M_hat range: [0.4299, 0.7756]
2025-03-11 20:03:35 - Train Iteration 1853: loss: 0.5437, d_k_M range: [0.0174, 0.5208], d_k_M_hat range: [0.3396, 0.8191]
2025-03-11 20:03:35 - Train Iteration 1854: loss: 0.5169, d_k_M range: [0.0424, 0.4875], d_k_M_hat range: [0.3626, 0.8128]
2025-03-11 20:03:36 - Train Iteration 1855: loss: 0.7510, d_k_M range: [0.0366, 0.8501], d_k_M_hat range: [0.3581, 0.9835]
2025-03-11 20:03:36 - Train Iteration 1856: loss: 0.6882, d_k_M range: [0.0056, 0.2535], d_k_M_hat range: [0.1760, 0.5725]
2025-03-11 20:03:36 - Train Iteration 1857: loss: 0.5161, d_k_M range: [0.3837, 0.5968], d_k_M_hat range: [0.6757, 0.9323]
2025-03-11 20:03:37 - Train Iteration 1858: loss: 0.6528, d_k_M range: [0.0050, 0.5405], d_k_M_hat range: [0.1970, 0.8886]
2025-03-11 20:03:37 - Train Iteration 1859: loss: 0.4710, d_k_M range: [0.1896, 0.5730], d_k_M_hat range: [0.5511, 0.9191]
2025-03-11 20:03:38 - Train Iteration 1860: loss: 0.4697, d_k_M range: [0.0641, 0.5285], d_k_M_hat range: [0.4368, 0.8881]
2025-03-11 20:03:38 - Train Iteration 1861: loss: 0.7261, d_k_M range: [0.0048, 0.6693], d_k_M_hat range: [0.1527, 0.9504]
2025-03-11 20:03:38 - Train Iteration 1862: loss: 0.5729, d_k_M range: [0.2278, 0.6281], d_k_M_hat range: [0.4709, 0.9155]
2025-03-11 20:03:39 - Train Iteration 1863: loss: 0.5215, d_k_M range: [0.3375, 0.6895], d_k_M_hat range: [0.6412, 0.9674]
2025-03-11 20:03:39 - Train Iteration 1864: loss: 0.5905, d_k_M range: [0.0985, 0.6689], d_k_M_hat range: [0.4330, 0.9643]
2025-03-11 20:03:40 - Train Iteration 1865: loss: 0.7109, d_k_M range: [0.2856, 0.8177], d_k_M_hat range: [0.6187, 0.9813]
2025-03-11 20:03:40 - Train Iteration 1866: loss: 0.7278, d_k_M range: [0.0211, 0.8377], d_k_M_hat range: [0.2874, 0.9846]
2025-03-11 20:03:40 - Train Iteration 1867: loss: 0.6156, d_k_M range: [0.0090, 0.4670], d_k_M_hat range: [0.2244, 0.7931]
2025-03-11 20:03:41 - Train Iteration 1868: loss: 0.5827, d_k_M range: [0.2523, 0.7442], d_k_M_hat range: [0.5946, 0.9808]
2025-03-11 20:03:41 - Train Iteration 1869: loss: 0.7982, d_k_M range: [0.0072, 0.3691], d_k_M_hat range: [0.1138, 0.6492]
2025-03-11 20:03:42 - Train Iteration 1870: loss: 0.5522, d_k_M range: [0.0374, 0.6645], d_k_M_hat range: [0.3557, 0.9645]
2025-03-11 20:03:42 - Train Iteration 1871: loss: 0.4765, d_k_M range: [0.0618, 0.5011], d_k_M_hat range: [0.4493, 0.8280]
2025-03-11 20:03:43 - Train Iteration 1872: loss: 0.4957, d_k_M range: [0.0328, 0.6428], d_k_M_hat range: [0.3629, 0.9387]
2025-03-11 20:03:43 - Train Iteration 1873: loss: 0.5048, d_k_M range: [0.2479, 0.6318], d_k_M_hat range: [0.5652, 0.9416]
2025-03-11 20:03:43 - Train Iteration 1874: loss: 0.5207, d_k_M range: [0.2605, 0.5267], d_k_M_hat range: [0.5706, 0.8953]
2025-03-11 20:03:44 - Train Iteration 1875: loss: 0.7451, d_k_M range: [0.2819, 0.8567], d_k_M_hat range: [0.6167, 0.9935]
2025-03-11 20:03:44 - Train Iteration 1876: loss: 0.5322, d_k_M range: [0.1300, 0.6830], d_k_M_hat range: [0.4772, 0.9536]
2025-03-11 20:03:45 - Train Iteration 1877: loss: 0.5026, d_k_M range: [0.0725, 0.4163], d_k_M_hat range: [0.3799, 0.7319]
2025-03-11 20:03:45 - Train Iteration 1878: loss: 0.5651, d_k_M range: [0.0486, 0.6999], d_k_M_hat range: [0.3216, 0.9482]
2025-03-11 20:03:45 - Train Iteration 1879: loss: 0.5588, d_k_M range: [0.0341, 0.3704], d_k_M_hat range: [0.2938, 0.7559]
2025-03-11 20:03:46 - Train Iteration 1880: loss: 0.8207, d_k_M range: [0.0009, 0.4534], d_k_M_hat range: [0.0950, 0.8018]
2025-03-11 20:03:46 - Train Iteration 1881: loss: 0.5723, d_k_M range: [0.1839, 0.7346], d_k_M_hat range: [0.5166, 0.9781]
2025-03-11 20:03:46 - Train Iteration 1882: loss: 0.5263, d_k_M range: [0.1314, 0.5331], d_k_M_hat range: [0.4609, 0.8783]
2025-03-11 20:03:47 - Train Iteration 1883: loss: 0.5663, d_k_M range: [0.0222, 0.7139], d_k_M_hat range: [0.3716, 0.9614]
2025-03-11 20:03:47 - Train Iteration 1884: loss: 0.5890, d_k_M range: [0.0152, 0.2732], d_k_M_hat range: [0.2478, 0.5755]
2025-03-11 20:03:48 - Train Iteration 1885: loss: 0.4962, d_k_M range: [0.3255, 0.6328], d_k_M_hat range: [0.6211, 0.9636]
2025-03-11 20:03:48 - Train Iteration 1886: loss: 0.5821, d_k_M range: [0.0528, 0.6841], d_k_M_hat range: [0.3368, 0.9712]
2025-03-11 20:03:48 - Train Iteration 1887: loss: 0.4982, d_k_M range: [0.1061, 0.5730], d_k_M_hat range: [0.4355, 0.9093]
2025-03-11 20:03:49 - Train Iteration 1888: loss: 0.5074, d_k_M range: [0.0667, 0.5702], d_k_M_hat range: [0.3966, 0.8804]
2025-03-11 20:03:49 - Train Iteration 1889: loss: 0.5355, d_k_M range: [0.0921, 0.5967], d_k_M_hat range: [0.4030, 0.9321]
2025-03-11 20:03:50 - Train Iteration 1890: loss: 0.4653, d_k_M range: [0.1882, 0.4274], d_k_M_hat range: [0.5496, 0.7830]
2025-03-11 20:03:50 - Train Iteration 1891: loss: 0.5596, d_k_M range: [0.0643, 0.4294], d_k_M_hat range: [0.3602, 0.8539]
2025-03-11 20:03:50 - Train Iteration 1892: loss: 0.6144, d_k_M range: [0.0027, 0.3404], d_k_M_hat range: [0.2188, 0.7406]
2025-03-11 20:03:51 - Train Iteration 1893: loss: 0.7538, d_k_M range: [0.2708, 0.8592], d_k_M_hat range: [0.6154, 0.9909]
2025-03-11 20:03:51 - Train Iteration 1894: loss: 0.9256, d_k_M range: [0.0033, 0.7952], d_k_M_hat range: [0.0413, 0.9798]
2025-03-11 20:03:52 - Train Iteration 1895: loss: 0.4940, d_k_M range: [0.2109, 0.6709], d_k_M_hat range: [0.5813, 0.9680]
2025-03-11 20:03:52 - Train Iteration 1896: loss: 0.5323, d_k_M range: [0.0141, 0.3583], d_k_M_hat range: [0.2846, 0.7206]
2025-03-11 20:03:52 - Train Iteration 1897: loss: 0.5773, d_k_M range: [0.2232, 0.6465], d_k_M_hat range: [0.4634, 0.9530]
2025-03-11 20:03:53 - Train Iteration 1898: loss: 0.6122, d_k_M range: [0.0758, 0.4452], d_k_M_hat range: [0.2934, 0.7692]
2025-03-11 20:03:53 - Train Iteration 1899: loss: 0.5368, d_k_M range: [0.0332, 0.6171], d_k_M_hat range: [0.3708, 0.9269]
2025-03-11 20:03:54 - Train Iteration 1900: loss: 0.5723, d_k_M range: [0.2894, 0.5006], d_k_M_hat range: [0.5904, 0.8345]
2025-03-11 20:03:54 - Train Iteration 1901: loss: 0.4697, d_k_M range: [0.0829, 0.5860], d_k_M_hat range: [0.4201, 0.9362]
2025-03-11 20:03:54 - Train Iteration 1902: loss: 0.7782, d_k_M range: [0.0182, 0.8691], d_k_M_hat range: [0.3515, 0.9869]
2025-03-11 20:03:55 - Train Iteration 1903: loss: 0.5731, d_k_M range: [0.0648, 0.7219], d_k_M_hat range: [0.5051, 0.9649]
2025-03-11 20:03:55 - Train Iteration 1904: loss: 0.6002, d_k_M range: [0.0060, 0.2343], d_k_M_hat range: [0.2342, 0.5733]
2025-03-11 20:03:56 - Train Iteration 1905: loss: 0.4846, d_k_M range: [0.3082, 0.5628], d_k_M_hat range: [0.6411, 0.8667]
2025-03-11 20:03:56 - Train Iteration 1906: loss: 0.6630, d_k_M range: [0.0032, 0.5991], d_k_M_hat range: [0.1890, 0.9198]
2025-03-11 20:03:56 - Train Iteration 1907: loss: 0.5625, d_k_M range: [0.0538, 0.3914], d_k_M_hat range: [0.3988, 0.7202]
2025-03-11 20:03:57 - Train Iteration 1908: loss: 0.5280, d_k_M range: [0.0685, 0.5003], d_k_M_hat range: [0.3419, 0.8059]
2025-03-11 20:03:57 - Train Iteration 1909: loss: 0.5183, d_k_M range: [0.0909, 0.4744], d_k_M_hat range: [0.4501, 0.7563]
2025-03-11 20:03:58 - Train Iteration 1910: loss: 0.6352, d_k_M range: [0.2182, 0.7692], d_k_M_hat range: [0.5672, 0.9722]
2025-03-11 20:03:58 - Train Iteration 1911: loss: 0.4903, d_k_M range: [0.0776, 0.3140], d_k_M_hat range: [0.4178, 0.6563]
2025-03-11 20:03:58 - Train Iteration 1912: loss: 0.5561, d_k_M range: [0.2993, 0.6950], d_k_M_hat range: [0.6081, 0.9760]
2025-03-11 20:03:59 - Train Iteration 1913: loss: 0.6258, d_k_M range: [0.0107, 0.5737], d_k_M_hat range: [0.2196, 0.9255]
2025-03-11 20:03:59 - Train Iteration 1914: loss: 0.5067, d_k_M range: [0.1019, 0.6289], d_k_M_hat range: [0.4492, 0.9383]
2025-03-11 20:03:59 - Train Iteration 1915: loss: 0.5219, d_k_M range: [0.0402, 0.5209], d_k_M_hat range: [0.3178, 0.7990]
2025-03-11 20:04:00 - Train Iteration 1916: loss: 0.5056, d_k_M range: [0.0109, 0.5091], d_k_M_hat range: [0.3190, 0.8040]
2025-03-11 20:04:00 - Train Iteration 1917: loss: 0.4743, d_k_M range: [0.2551, 0.5664], d_k_M_hat range: [0.6471, 0.8960]
2025-03-11 20:04:01 - Train Iteration 1918: loss: 0.7135, d_k_M range: [0.2251, 0.8280], d_k_M_hat range: [0.5868, 0.9833]
2025-03-11 20:04:01 - Train Iteration 1919: loss: 0.9722, d_k_M range: [0.0004, 0.3511], d_k_M_hat range: [0.0144, 0.6328]
2025-03-11 20:04:02 - Train Iteration 1920: loss: 0.5431, d_k_M range: [0.0952, 0.5976], d_k_M_hat range: [0.4003, 0.8738]
2025-03-11 20:04:02 - Train Iteration 1921: loss: 0.5789, d_k_M range: [0.2446, 0.6576], d_k_M_hat range: [0.5409, 0.9273]
2025-03-11 20:04:02 - Train Iteration 1922: loss: 0.5280, d_k_M range: [0.0568, 0.5607], d_k_M_hat range: [0.3805, 0.8729]
2025-03-11 20:04:03 - Train Iteration 1923: loss: 0.5133, d_k_M range: [0.0264, 0.4834], d_k_M_hat range: [0.3333, 0.7915]
2025-03-11 20:04:03 - Train Iteration 1924: loss: 0.5119, d_k_M range: [0.1474, 0.6470], d_k_M_hat range: [0.4856, 0.9364]
2025-03-11 20:04:04 - Train Iteration 1925: loss: 0.4798, d_k_M range: [0.2027, 0.5118], d_k_M_hat range: [0.5528, 0.8527]
2025-03-11 20:04:04 - Train Iteration 1926: loss: 0.5756, d_k_M range: [0.3428, 0.7213], d_k_M_hat range: [0.6961, 0.9813]
2025-03-11 20:04:04 - Train Iteration 1927: loss: 0.4600, d_k_M range: [0.0529, 0.4428], d_k_M_hat range: [0.4446, 0.7914]
2025-03-11 20:04:05 - Train Iteration 1928: loss: 0.5326, d_k_M range: [0.0044, 0.5776], d_k_M_hat range: [0.2746, 0.9290]
2025-03-11 20:04:05 - Train Iteration 1929: loss: 0.4854, d_k_M range: [0.0944, 0.5314], d_k_M_hat range: [0.4696, 0.8765]
2025-03-11 20:04:06 - Train Iteration 1930: loss: 0.5213, d_k_M range: [0.0679, 0.6864], d_k_M_hat range: [0.4683, 0.9644]
2025-03-11 20:04:06 - Train Iteration 1931: loss: 0.5122, d_k_M range: [0.0166, 0.5039], d_k_M_hat range: [0.3447, 0.8609]
2025-03-11 20:04:07 - Train Iteration 1932: loss: 0.4421, d_k_M range: [0.1313, 0.5554], d_k_M_hat range: [0.4916, 0.9245]
2025-03-11 20:04:07 - Train Iteration 1933: loss: 0.6792, d_k_M range: [0.0080, 0.3379], d_k_M_hat range: [0.1839, 0.6716]
2025-03-11 20:04:08 - Train Iteration 1934: loss: 0.5170, d_k_M range: [0.0448, 0.6834], d_k_M_hat range: [0.4470, 0.9644]
2025-03-11 20:04:08 - Train Iteration 1935: loss: 0.4962, d_k_M range: [0.1084, 0.4212], d_k_M_hat range: [0.4259, 0.7687]
2025-03-11 20:04:08 - Train Iteration 1936: loss: 0.8706, d_k_M range: [0.0037, 0.3581], d_k_M_hat range: [0.0707, 0.7199]
2025-03-11 20:04:09 - Train Iteration 1937: loss: 0.9979, d_k_M range: [0.1808, 0.9989], d_k_M_hat range: [0.4855, 1.0000]
2025-03-11 20:04:09 - Train Iteration 1938: loss: 0.4647, d_k_M range: [0.1603, 0.6374], d_k_M_hat range: [0.4861, 0.9621]
2025-03-11 20:04:10 - Train Iteration 1939: loss: 0.5458, d_k_M range: [0.0626, 0.5449], d_k_M_hat range: [0.3888, 0.8410]
2025-03-11 20:04:10 - Train Iteration 1940: loss: 0.7674, d_k_M range: [0.0012, 0.2444], d_k_M_hat range: [0.1252, 0.5887]
2025-03-11 20:04:10 - Train Iteration 1941: loss: 0.8139, d_k_M range: [0.0743, 0.8984], d_k_M_hat range: [0.3549, 0.9962]
2025-03-11 20:04:11 - Train Iteration 1942: loss: 0.5190, d_k_M range: [0.1842, 0.4899], d_k_M_hat range: [0.5264, 0.8225]
2025-03-11 20:04:11 - Train Iteration 1943: loss: 0.5229, d_k_M range: [0.0668, 0.5862], d_k_M_hat range: [0.3854, 0.9416]
2025-03-11 20:04:12 - Train Iteration 1944: loss: 0.5383, d_k_M range: [0.1549, 0.5369], d_k_M_hat range: [0.4945, 0.8669]
2025-03-11 20:04:12 - Train Iteration 1945: loss: 0.5501, d_k_M range: [0.1003, 0.7194], d_k_M_hat range: [0.4458, 0.9777]
2025-03-11 20:04:12 - Train Iteration 1946: loss: 0.5457, d_k_M range: [0.0229, 0.6603], d_k_M_hat range: [0.2842, 0.9397]
2025-03-11 20:04:13 - Train Iteration 1947: loss: 0.6477, d_k_M range: [0.2739, 0.7812], d_k_M_hat range: [0.6023, 0.9765]
2025-03-11 20:04:13 - Train Iteration 1948: loss: 0.4929, d_k_M range: [0.0229, 0.3980], d_k_M_hat range: [0.3317, 0.7938]
2025-03-11 20:04:14 - Train Iteration 1949: loss: 0.6608, d_k_M range: [0.1672, 0.6006], d_k_M_hat range: [0.4857, 0.8455]
2025-03-11 20:04:14 - Train Iteration 1950: loss: 0.4977, d_k_M range: [0.1651, 0.4968], d_k_M_hat range: [0.5227, 0.8114]
2025-03-11 20:04:14 - Train Iteration 1951: loss: 0.5543, d_k_M range: [0.0445, 0.3897], d_k_M_hat range: [0.3473, 0.7258]
2025-03-11 20:04:15 - Train Iteration 1952: loss: 0.6114, d_k_M range: [0.0137, 0.3550], d_k_M_hat range: [0.2318, 0.6820]
2025-03-11 20:04:15 - Train Iteration 1953: loss: 0.8347, d_k_M range: [0.0030, 0.3827], d_k_M_hat range: [0.0894, 0.7255]
2025-03-11 20:04:16 - Train Iteration 1954: loss: 0.5016, d_k_M range: [0.1406, 0.5904], d_k_M_hat range: [0.4324, 0.9327]
2025-03-11 20:04:16 - Train Iteration 1955: loss: 0.4906, d_k_M range: [0.1496, 0.6065], d_k_M_hat range: [0.5020, 0.9334]
2025-03-11 20:04:16 - Train Iteration 1956: loss: 0.4884, d_k_M range: [0.0517, 0.4204], d_k_M_hat range: [0.3638, 0.8366]
2025-03-11 20:04:17 - Train Iteration 1957: loss: 0.5782, d_k_M range: [0.0215, 0.7210], d_k_M_hat range: [0.2924, 0.9606]
2025-03-11 20:04:17 - Train Iteration 1958: loss: 0.4921, d_k_M range: [0.2187, 0.5284], d_k_M_hat range: [0.5349, 0.8464]
2025-03-11 20:04:18 - Train Iteration 1959: loss: 0.5119, d_k_M range: [0.1752, 0.4570], d_k_M_hat range: [0.5108, 0.7496]
2025-03-11 20:04:18 - Train Iteration 1960: loss: 0.4899, d_k_M range: [0.1032, 0.6416], d_k_M_hat range: [0.4490, 0.9596]
2025-03-11 20:04:18 - Train Iteration 1961: loss: 0.5311, d_k_M range: [0.0077, 0.4359], d_k_M_hat range: [0.2790, 0.7634]
2025-03-11 20:04:19 - Train Iteration 1962: loss: 0.4834, d_k_M range: [0.3783, 0.6299], d_k_M_hat range: [0.7609, 0.9411]
2025-03-11 20:04:19 - Train Iteration 1963: loss: 0.7864, d_k_M range: [0.0024, 0.6417], d_k_M_hat range: [0.1156, 0.9454]
2025-03-11 20:04:20 - Train Iteration 1964: loss: 0.5088, d_k_M range: [0.1620, 0.4553], d_k_M_hat range: [0.4487, 0.8028]
2025-03-11 20:04:20 - Train Iteration 1965: loss: 0.5608, d_k_M range: [0.0455, 0.6547], d_k_M_hat range: [0.2966, 0.9471]
2025-03-11 20:04:20 - Train Iteration 1966: loss: 0.5972, d_k_M range: [0.0058, 0.4770], d_k_M_hat range: [0.2330, 0.8624]
2025-03-11 20:04:21 - Train Iteration 1967: loss: 0.4706, d_k_M range: [0.1791, 0.5554], d_k_M_hat range: [0.5220, 0.9041]
2025-03-11 20:04:21 - Train Iteration 1968: loss: 0.5913, d_k_M range: [0.0104, 0.6950], d_k_M_hat range: [0.2414, 0.9642]
2025-03-11 20:04:22 - Train Iteration 1969: loss: 0.7339, d_k_M range: [0.2507, 0.8433], d_k_M_hat range: [0.5625, 0.9866]
2025-03-11 20:04:22 - Train Iteration 1970: loss: 0.5770, d_k_M range: [0.0179, 0.3270], d_k_M_hat range: [0.2583, 0.6605]
2025-03-11 20:04:22 - Train Iteration 1971: loss: 0.5726, d_k_M range: [0.2343, 0.7047], d_k_M_hat range: [0.5452, 0.9480]
2025-03-11 20:04:23 - Train Iteration 1972: loss: 0.5508, d_k_M range: [0.2336, 0.6120], d_k_M_hat range: [0.4914, 0.9394]
2025-03-11 20:04:23 - Train Iteration 1973: loss: 0.6610, d_k_M range: [0.0581, 0.7999], d_k_M_hat range: [0.4549, 0.9869]
2025-03-11 20:04:24 - Train Iteration 1974: loss: 0.5096, d_k_M range: [0.0213, 0.3625], d_k_M_hat range: [0.3216, 0.7189]
2025-03-11 20:04:24 - Train Iteration 1975: loss: 0.5240, d_k_M range: [0.2994, 0.6563], d_k_M_hat range: [0.5755, 0.9612]
2025-03-11 20:04:24 - Train Iteration 1976: loss: 0.4537, d_k_M range: [0.2190, 0.5285], d_k_M_hat range: [0.5507, 0.9113]
2025-03-11 20:04:25 - Train Iteration 1977: loss: 0.7183, d_k_M range: [0.0014, 0.2318], d_k_M_hat range: [0.1539, 0.6519]
2025-03-11 20:04:25 - Train Iteration 1978: loss: 0.5525, d_k_M range: [0.1406, 0.7246], d_k_M_hat range: [0.5139, 0.9813]
2025-03-11 20:04:26 - Train Iteration 1979: loss: 0.5418, d_k_M range: [0.0141, 0.6492], d_k_M_hat range: [0.2780, 0.9373]
2025-03-11 20:04:26 - Train Iteration 1980: loss: 0.4070, d_k_M range: [0.1268, 0.3866], d_k_M_hat range: [0.5283, 0.7557]
2025-03-11 20:04:26 - Train Iteration 1981: loss: 0.6020, d_k_M range: [0.0085, 0.7494], d_k_M_hat range: [0.2326, 0.9803]
2025-03-11 20:04:27 - Train Iteration 1982: loss: 0.5519, d_k_M range: [0.2274, 0.7197], d_k_M_hat range: [0.6028, 0.9768]
2025-03-11 20:04:27 - Train Iteration 1983: loss: 0.4852, d_k_M range: [0.0474, 0.4418], d_k_M_hat range: [0.4167, 0.7690]
2025-03-11 20:04:28 - Train Iteration 1984: loss: 0.4706, d_k_M range: [0.0245, 0.5919], d_k_M_hat range: [0.3385, 0.9215]
2025-03-11 20:04:28 - Train Iteration 1985: loss: 0.7148, d_k_M range: [0.0711, 0.8357], d_k_M_hat range: [0.3869, 0.9902]
2025-03-11 20:04:29 - Train Iteration 1986: loss: 0.7034, d_k_M range: [0.0732, 0.8254], d_k_M_hat range: [0.4034, 0.9867]
2025-03-11 20:04:29 - Train Iteration 1987: loss: 0.8798, d_k_M range: [0.0005, 0.4040], d_k_M_hat range: [0.0625, 0.7931]
2025-03-11 20:04:29 - Train Iteration 1988: loss: 0.5347, d_k_M range: [0.0669, 0.6900], d_k_M_hat range: [0.4045, 0.9701]
2025-03-11 20:04:30 - Train Iteration 1989: loss: 0.5492, d_k_M range: [0.0435, 0.6985], d_k_M_hat range: [0.4182, 0.9574]
2025-03-11 20:04:30 - Train Iteration 1990: loss: 0.9616, d_k_M range: [0.0004, 0.8419], d_k_M_hat range: [0.0198, 0.9912]
2025-03-11 20:04:30 - Train Iteration 1991: loss: 0.5421, d_k_M range: [0.0921, 0.6370], d_k_M_hat range: [0.4479, 0.9441]
2025-03-11 20:04:31 - Train Iteration 1992: loss: 0.4533, d_k_M range: [0.0076, 0.5094], d_k_M_hat range: [0.3344, 0.9122]
2025-03-11 20:04:31 - Train Iteration 1993: loss: 0.5531, d_k_M range: [0.1382, 0.7352], d_k_M_hat range: [0.4841, 0.9915]
2025-03-11 20:04:32 - Train Iteration 1994: loss: 0.9710, d_k_M range: [0.0042, 0.2172], d_k_M_hat range: [0.0188, 0.5538]
2025-03-11 20:04:32 - Train Iteration 1995: loss: 0.4854, d_k_M range: [0.0425, 0.5829], d_k_M_hat range: [0.3544, 0.8861]
2025-03-11 20:04:32 - Train Iteration 1996: loss: 0.4515, d_k_M range: [0.0329, 0.6052], d_k_M_hat range: [0.4100, 0.9474]
2025-03-11 20:04:33 - Train Iteration 1997: loss: 0.6347, d_k_M range: [0.0862, 0.7872], d_k_M_hat range: [0.4659, 0.9905]
2025-03-11 20:04:33 - Train Iteration 1998: loss: 0.9852, d_k_M range: [0.0004, 0.2451], d_k_M_hat range: [0.0079, 0.6690]
2025-03-11 20:04:34 - Train Iteration 1999: loss: 0.6303, d_k_M range: [0.0817, 0.7834], d_k_M_hat range: [0.4385, 0.9895]
2025-03-11 20:04:34 - Train Iteration 2000: loss: 0.5016, d_k_M range: [0.3335, 0.5115], d_k_M_hat range: [0.6543, 0.9099]
2025-03-11 20:04:34 - Train Iteration 2001: loss: 0.5091, d_k_M range: [0.0081, 0.6315], d_k_M_hat range: [0.3346, 0.9503]
2025-03-11 20:04:35 - Train Iteration 2002: loss: 0.4883, d_k_M range: [0.1529, 0.6667], d_k_M_hat range: [0.5103, 0.9736]
2025-03-11 20:04:35 - Train Iteration 2003: loss: 0.8373, d_k_M range: [0.0666, 0.9120], d_k_M_hat range: [0.3839, 0.9970]
2025-03-11 20:04:36 - Train Iteration 2004: loss: 0.5064, d_k_M range: [0.0347, 0.4884], d_k_M_hat range: [0.3418, 0.8844]
2025-03-11 20:04:36 - Train Iteration 2005: loss: 0.5563, d_k_M range: [0.0221, 0.4876], d_k_M_hat range: [0.2762, 0.8613]
2025-03-11 20:04:36 - Train Iteration 2006: loss: 0.4532, d_k_M range: [0.0256, 0.4006], d_k_M_hat range: [0.3935, 0.7542]
2025-03-11 20:04:37 - Train Iteration 2007: loss: 0.4346, d_k_M range: [0.0748, 0.5872], d_k_M_hat range: [0.4672, 0.9280]
2025-03-11 20:04:37 - Train Iteration 2008: loss: 0.5012, d_k_M range: [0.0352, 0.5552], d_k_M_hat range: [0.4083, 0.9014]
2025-03-11 20:04:38 - Train Iteration 2009: loss: 0.5517, d_k_M range: [0.0096, 0.5876], d_k_M_hat range: [0.2669, 0.9557]
2025-03-11 20:04:38 - Train Iteration 2010: loss: 0.4979, d_k_M range: [0.0418, 0.6639], d_k_M_hat range: [0.3798, 0.9583]
2025-03-11 20:04:38 - Train Iteration 2011: loss: 0.5284, d_k_M range: [0.0289, 0.4998], d_k_M_hat range: [0.3130, 0.9122]
2025-03-11 20:04:39 - Train Iteration 2012: loss: 0.4707, d_k_M range: [0.1470, 0.4029], d_k_M_hat range: [0.4924, 0.7738]
2025-03-11 20:04:39 - Train Iteration 2013: loss: 0.5207, d_k_M range: [0.0025, 0.6028], d_k_M_hat range: [0.2809, 0.8916]
2025-03-11 20:04:40 - Train Iteration 2014: loss: 0.4710, d_k_M range: [0.2045, 0.6348], d_k_M_hat range: [0.6171, 0.9484]
2025-03-11 20:04:40 - Train Iteration 2015: loss: 0.4577, d_k_M range: [0.0394, 0.4753], d_k_M_hat range: [0.4460, 0.8631]
2025-03-11 20:04:40 - Train Iteration 2016: loss: 0.5480, d_k_M range: [0.2914, 0.7181], d_k_M_hat range: [0.6487, 0.9778]
2025-03-11 20:04:41 - Train Iteration 2017: loss: 0.6806, d_k_M range: [0.0016, 0.3470], d_k_M_hat range: [0.1766, 0.7221]
2025-03-11 20:04:41 - Train Iteration 2018: loss: 0.5339, d_k_M range: [0.0399, 0.6238], d_k_M_hat range: [0.3092, 0.9065]
2025-03-11 20:04:42 - Train Iteration 2019: loss: 0.4932, d_k_M range: [0.2382, 0.6855], d_k_M_hat range: [0.6042, 0.9832]
2025-03-11 20:04:42 - Train Iteration 2020: loss: 0.5289, d_k_M range: [0.1328, 0.4998], d_k_M_hat range: [0.4852, 0.8480]
2025-03-11 20:04:42 - Train Iteration 2021: loss: 0.4954, d_k_M range: [0.0246, 0.5093], d_k_M_hat range: [0.3289, 0.8836]
2025-03-11 20:04:43 - Train Iteration 2022: loss: 0.5793, d_k_M range: [0.1227, 0.7486], d_k_M_hat range: [0.4764, 0.9875]
2025-03-11 20:04:43 - Train Iteration 2023: loss: 0.6592, d_k_M range: [0.0170, 0.4440], d_k_M_hat range: [0.2051, 0.7399]
2025-03-11 20:04:43 - Train Iteration 2024: loss: 0.6129, d_k_M range: [0.1423, 0.6860], d_k_M_hat range: [0.4743, 0.9121]
2025-03-11 20:04:44 - Train Iteration 2025: loss: 0.4800, d_k_M range: [0.0862, 0.5119], d_k_M_hat range: [0.4030, 0.8598]
2025-03-11 20:04:44 - Train Iteration 2026: loss: 0.4712, d_k_M range: [0.0526, 0.5995], d_k_M_hat range: [0.4596, 0.9130]
2025-03-11 20:04:45 - Train Iteration 2027: loss: 0.7290, d_k_M range: [0.0384, 0.8347], d_k_M_hat range: [0.4087, 0.9809]
2025-03-11 20:04:45 - Train Iteration 2028: loss: 0.5483, d_k_M range: [0.0267, 0.6859], d_k_M_hat range: [0.3028, 0.9829]
2025-03-11 20:04:45 - Train Iteration 2029: loss: 0.7113, d_k_M range: [0.0019, 0.8301], d_k_M_hat range: [0.1808, 0.9867]
2025-03-11 20:04:46 - Train Iteration 2030: loss: 0.4809, d_k_M range: [0.0214, 0.4486], d_k_M_hat range: [0.3280, 0.7974]
2025-03-11 20:04:46 - Train Iteration 2031: loss: 0.9553, d_k_M range: [0.1310, 0.9762], d_k_M_hat range: [0.5447, 0.9988]
2025-03-11 20:04:47 - Train Iteration 2032: loss: 0.5426, d_k_M range: [0.0136, 0.6784], d_k_M_hat range: [0.2770, 0.9575]
2025-03-11 20:04:47 - Train Iteration 2033: loss: 0.4812, d_k_M range: [0.0092, 0.6289], d_k_M_hat range: [0.3252, 0.9498]
2025-03-11 20:04:47 - Train Iteration 2034: loss: 0.7992, d_k_M range: [0.1531, 0.8849], d_k_M_hat range: [0.5369, 0.9909]
2025-03-11 20:04:48 - Train Iteration 2035: loss: 0.5399, d_k_M range: [0.0272, 0.6645], d_k_M_hat range: [0.3682, 0.9297]
2025-03-11 20:04:48 - Train Iteration 2036: loss: 0.4697, d_k_M range: [0.0451, 0.2943], d_k_M_hat range: [0.4244, 0.6337]
2025-03-11 20:04:49 - Train Iteration 2037: loss: 0.4865, d_k_M range: [0.0096, 0.5448], d_k_M_hat range: [0.3627, 0.8532]
2025-03-11 20:04:49 - Train Iteration 2038: loss: 0.7885, d_k_M range: [0.0014, 0.4700], d_k_M_hat range: [0.1134, 0.8464]
2025-03-11 20:04:49 - Train Iteration 2039: loss: 0.8279, d_k_M range: [0.1946, 0.9044], d_k_M_hat range: [0.4999, 0.9945]
2025-03-11 20:04:50 - Train Iteration 2040: loss: 0.9741, d_k_M range: [0.0005, 0.4392], d_k_M_hat range: [0.0135, 0.7783]
2025-03-11 20:04:50 - Train Iteration 2041: loss: 0.5120, d_k_M range: [0.1137, 0.5106], d_k_M_hat range: [0.3982, 0.8717]
2025-03-11 20:04:51 - Train Iteration 2042: loss: 0.5934, d_k_M range: [0.0805, 0.7545], d_k_M_hat range: [0.4811, 0.9842]
2025-03-11 20:04:51 - Train Iteration 2043: loss: 0.5702, d_k_M range: [0.0087, 0.6051], d_k_M_hat range: [0.2536, 0.9066]
2025-03-11 20:04:52 - Train Iteration 2044: loss: 0.6489, d_k_M range: [0.2456, 0.7947], d_k_M_hat range: [0.5703, 0.9892]
2025-03-11 20:04:52 - Train Iteration 2045: loss: 0.7231, d_k_M range: [0.0029, 0.4662], d_k_M_hat range: [0.1526, 0.7784]
2025-03-11 20:04:53 - Train Iteration 2046: loss: 0.6021, d_k_M range: [0.2206, 0.7376], d_k_M_hat range: [0.5468, 0.9799]
2025-03-11 20:04:53 - Train Iteration 2047: loss: 0.5592, d_k_M range: [0.2366, 0.5062], d_k_M_hat range: [0.5364, 0.8271]
2025-03-11 20:04:53 - Train Iteration 2048: loss: 0.5004, d_k_M range: [0.0674, 0.4203], d_k_M_hat range: [0.3614, 0.7401]
2025-03-11 20:04:54 - Train Iteration 2049: loss: 0.5174, d_k_M range: [0.0381, 0.5908], d_k_M_hat range: [0.3874, 0.9314]
2025-03-11 20:04:54 - Train Iteration 2050: loss: 0.4950, d_k_M range: [0.2240, 0.5308], d_k_M_hat range: [0.5551, 0.9109]
2025-03-11 20:04:55 - Train Iteration 2051: loss: 0.5237, d_k_M range: [0.0692, 0.5134], d_k_M_hat range: [0.4216, 0.8755]
2025-03-11 20:04:55 - Train Iteration 2052: loss: 0.5592, d_k_M range: [0.1121, 0.7003], d_k_M_hat range: [0.4884, 0.9525]
2025-03-11 20:04:55 - Train Iteration 2053: loss: 0.7413, d_k_M range: [0.0028, 0.4075], d_k_M_hat range: [0.1418, 0.7515]
2025-03-11 20:04:56 - Train Iteration 2054: loss: 0.9437, d_k_M range: [0.2777, 0.9705], d_k_M_hat range: [0.5766, 0.9990]
2025-03-11 20:04:56 - Train Iteration 2055: loss: 0.5456, d_k_M range: [0.1219, 0.6952], d_k_M_hat range: [0.4776, 0.9566]
2025-03-11 20:04:57 - Train Iteration 2056: loss: 0.5523, d_k_M range: [0.0075, 0.5375], d_k_M_hat range: [0.2643, 0.8747]
2025-03-11 20:04:57 - Train Iteration 2057: loss: 0.5651, d_k_M range: [0.3347, 0.7146], d_k_M_hat range: [0.6861, 0.9629]
2025-03-11 20:04:57 - Train Iteration 2058: loss: 0.5755, d_k_M range: [0.0119, 0.4696], d_k_M_hat range: [0.2676, 0.7676]
2025-03-11 20:04:58 - Train Iteration 2059: loss: 0.5282, d_k_M range: [0.0982, 0.6325], d_k_M_hat range: [0.4003, 0.9382]
2025-03-11 20:04:58 - Train Iteration 2060: loss: 0.8779, d_k_M range: [0.0024, 0.6335], d_k_M_hat range: [0.0654, 0.9329]
2025-03-11 20:04:59 - Train Iteration 2061: loss: 0.5489, d_k_M range: [0.0738, 0.7277], d_k_M_hat range: [0.3622, 0.9869]
2025-03-11 20:04:59 - Train Iteration 2062: loss: 0.5292, d_k_M range: [0.2274, 0.5834], d_k_M_hat range: [0.5551, 0.8783]
2025-03-11 20:04:59 - Train Iteration 2063: loss: 0.8694, d_k_M range: [0.2085, 0.9302], d_k_M_hat range: [0.4876, 0.9978]
2025-03-11 20:05:00 - Train Iteration 2064: loss: 0.5728, d_k_M range: [0.0521, 0.5453], d_k_M_hat range: [0.4143, 0.8598]
2025-03-11 20:05:00 - Train Iteration 2065: loss: 0.4842, d_k_M range: [0.0128, 0.4161], d_k_M_hat range: [0.3225, 0.7462]
2025-03-11 20:05:01 - Train Iteration 2066: loss: 0.5930, d_k_M range: [0.1186, 0.4402], d_k_M_hat range: [0.3950, 0.7976]
2025-03-11 20:05:01 - Train Iteration 2067: loss: 0.5115, d_k_M range: [0.0378, 0.6219], d_k_M_hat range: [0.3300, 0.9519]
2025-03-11 20:05:01 - Train Iteration 2068: loss: 0.5467, d_k_M range: [0.0876, 0.4962], d_k_M_hat range: [0.4184, 0.8292]
2025-03-11 20:05:02 - Train Iteration 2069: loss: 0.7942, d_k_M range: [0.2239, 0.8841], d_k_M_hat range: [0.6340, 0.9929]
2025-03-11 20:05:02 - Train Iteration 2070: loss: 0.4879, d_k_M range: [0.0231, 0.2827], d_k_M_hat range: [0.3758, 0.6387]
2025-03-11 20:05:03 - Train Iteration 2071: loss: 0.4815, d_k_M range: [0.3190, 0.6439], d_k_M_hat range: [0.6895, 0.9677]
2025-03-11 20:05:03 - Train Iteration 2072: loss: 0.5482, d_k_M range: [0.1504, 0.6943], d_k_M_hat range: [0.5810, 0.9539]
2025-03-11 20:05:03 - Train Iteration 2073: loss: 0.4634, d_k_M range: [0.0231, 0.4399], d_k_M_hat range: [0.3424, 0.8069]
2025-03-11 20:05:04 - Train Iteration 2074: loss: 0.5439, d_k_M range: [0.0098, 0.6327], d_k_M_hat range: [0.3112, 0.8952]
2025-03-11 20:05:04 - Train Iteration 2075: loss: 0.4939, d_k_M range: [0.0553, 0.5882], d_k_M_hat range: [0.4122, 0.9596]
2025-03-11 20:05:05 - Train Iteration 2076: loss: 0.6535, d_k_M range: [0.0015, 0.6373], d_k_M_hat range: [0.1931, 0.9585]
2025-03-11 20:05:05 - Train Iteration 2077: loss: 0.6992, d_k_M range: [0.1290, 0.8312], d_k_M_hat range: [0.5274, 0.9950]
2025-03-11 20:05:05 - Train Iteration 2078: loss: 0.4717, d_k_M range: [0.0563, 0.3967], d_k_M_hat range: [0.3751, 0.7220]
2025-03-11 20:05:06 - Train Iteration 2079: loss: 0.5244, d_k_M range: [0.0133, 0.4717], d_k_M_hat range: [0.2959, 0.8134]
2025-03-11 20:05:06 - Train Iteration 2080: loss: 0.5745, d_k_M range: [0.1523, 0.6614], d_k_M_hat range: [0.4982, 0.9726]
2025-03-11 20:05:06 - Train Iteration 2081: loss: 0.9026, d_k_M range: [0.2067, 0.9486], d_k_M_hat range: [0.6078, 0.9986]
2025-03-11 20:05:07 - Train Iteration 2082: loss: 0.4500, d_k_M range: [0.1152, 0.4389], d_k_M_hat range: [0.5107, 0.7680]
2025-03-11 20:05:07 - Train Iteration 2083: loss: 0.5110, d_k_M range: [0.0637, 0.6717], d_k_M_hat range: [0.4254, 0.9569]
2025-03-11 20:05:08 - Train Iteration 2084: loss: 0.5940, d_k_M range: [0.0079, 0.3000], d_k_M_hat range: [0.2372, 0.6418]
2025-03-11 20:05:08 - Train Iteration 2085: loss: 0.4390, d_k_M range: [0.0898, 0.6183], d_k_M_hat range: [0.4787, 0.9557]
2025-03-11 20:05:08 - Train Iteration 2086: loss: 0.4440, d_k_M range: [0.0641, 0.4134], d_k_M_hat range: [0.4183, 0.7859]
2025-03-11 20:05:09 - Train Iteration 2087: loss: 0.5324, d_k_M range: [0.0052, 0.6714], d_k_M_hat range: [0.2756, 0.9592]
2025-03-11 20:05:09 - Train Iteration 2088: loss: 0.9606, d_k_M range: [0.0460, 0.9784], d_k_M_hat range: [0.3886, 0.9983]
2025-03-11 20:05:10 - Train Iteration 2089: loss: 0.4391, d_k_M range: [0.0365, 0.5598], d_k_M_hat range: [0.4438, 0.9279]
2025-03-11 20:05:10 - Train Iteration 2090: loss: 0.4794, d_k_M range: [0.0335, 0.4627], d_k_M_hat range: [0.3412, 0.8512]
2025-03-11 20:05:10 - Train Iteration 2091: loss: 0.6846, d_k_M range: [0.1151, 0.8059], d_k_M_hat range: [0.5151, 0.9785]
2025-03-11 20:05:11 - Train Iteration 2092: loss: 0.5576, d_k_M range: [0.0036, 0.5340], d_k_M_hat range: [0.2569, 0.8824]
2025-03-11 20:05:11 - Train Iteration 2093: loss: 0.4418, d_k_M range: [0.0217, 0.4832], d_k_M_hat range: [0.3715, 0.8432]
2025-03-11 20:05:12 - Train Iteration 2094: loss: 0.5033, d_k_M range: [0.0040, 0.4958], d_k_M_hat range: [0.2945, 0.9240]
2025-03-11 20:05:12 - Train Iteration 2095: loss: 0.4208, d_k_M range: [0.1405, 0.5514], d_k_M_hat range: [0.5005, 0.9027]
2025-03-11 20:05:12 - Train Iteration 2096: loss: 0.4664, d_k_M range: [0.0265, 0.3212], d_k_M_hat range: [0.3474, 0.7068]
2025-03-11 20:05:13 - Train Iteration 2097: loss: 0.4476, d_k_M range: [0.1063, 0.3821], d_k_M_hat range: [0.5400, 0.7849]
2025-03-11 20:05:13 - Train Iteration 2098: loss: 0.5141, d_k_M range: [0.0254, 0.5286], d_k_M_hat range: [0.4174, 0.9358]
2025-03-11 20:05:14 - Train Iteration 2099: loss: 0.6394, d_k_M range: [0.0014, 0.6745], d_k_M_hat range: [0.2017, 0.9448]
2025-03-11 20:05:14 - Train Iteration 2100: loss: 0.4651, d_k_M range: [0.0825, 0.5672], d_k_M_hat range: [0.4409, 0.9253]
2025-03-11 20:05:14 - Train Iteration 2101: loss: 0.6765, d_k_M range: [0.3281, 0.8152], d_k_M_hat range: [0.7256, 0.9926]
2025-03-11 20:05:15 - Train Iteration 2102: loss: 0.5798, d_k_M range: [0.0027, 0.5196], d_k_M_hat range: [0.2426, 0.8331]
2025-03-11 20:05:15 - Train Iteration 2103: loss: 0.5511, d_k_M range: [0.0431, 0.6759], d_k_M_hat range: [0.4586, 0.9335]
2025-03-11 20:05:16 - Train Iteration 2104: loss: 0.4375, d_k_M range: [0.1576, 0.4284], d_k_M_hat range: [0.5651, 0.8194]
2025-03-11 20:05:16 - Train Iteration 2105: loss: 0.4558, d_k_M range: [0.1451, 0.4892], d_k_M_hat range: [0.5772, 0.8802]
2025-03-11 20:05:17 - Train Iteration 2106: loss: 0.5234, d_k_M range: [0.0225, 0.5857], d_k_M_hat range: [0.2991, 0.9374]
2025-03-11 20:05:17 - Train Iteration 2107: loss: 0.5628, d_k_M range: [0.1647, 0.7430], d_k_M_hat range: [0.5162, 0.9928]
2025-03-11 20:05:17 - Train Iteration 2108: loss: 0.4928, d_k_M range: [0.0392, 0.6399], d_k_M_hat range: [0.4127, 0.9379]
2025-03-11 20:05:18 - Train Iteration 2109: loss: 0.8755, d_k_M range: [0.0010, 0.8355], d_k_M_hat range: [0.0653, 0.9924]
2025-03-11 20:05:18 - Train Iteration 2110: loss: 0.5725, d_k_M range: [0.0018, 0.5641], d_k_M_hat range: [0.2451, 0.9502]
2025-03-11 20:05:18 - Train Iteration 2111: loss: 0.4777, d_k_M range: [0.0159, 0.6688], d_k_M_hat range: [0.3341, 0.9776]
2025-03-11 20:05:19 - Train Iteration 2112: loss: 0.5738, d_k_M range: [0.0565, 0.7383], d_k_M_hat range: [0.4641, 0.9889]
2025-03-11 20:05:19 - Train Iteration 2113: loss: 0.4185, d_k_M range: [0.0608, 0.4958], d_k_M_hat range: [0.4675, 0.9117]
2025-03-11 20:05:20 - Train Iteration 2114: loss: 0.4593, d_k_M range: [0.0262, 0.5177], d_k_M_hat range: [0.3507, 0.9284]
2025-03-11 20:05:20 - Train Iteration 2115: loss: 0.3701, d_k_M range: [0.0117, 0.3382], d_k_M_hat range: [0.4040, 0.7995]
2025-03-11 20:05:20 - Train Iteration 2116: loss: 0.8268, d_k_M range: [0.2713, 0.9071], d_k_M_hat range: [0.7511, 0.9978]
2025-03-11 20:05:21 - Train Iteration 2117: loss: 0.4303, d_k_M range: [0.0140, 0.6255], d_k_M_hat range: [0.4054, 0.9696]
2025-03-11 20:05:21 - Train Iteration 2118: loss: 0.4090, d_k_M range: [0.0340, 0.5285], d_k_M_hat range: [0.4444, 0.9484]
2025-03-11 20:05:22 - Train Iteration 2119: loss: 0.3310, d_k_M range: [0.0146, 0.2651], d_k_M_hat range: [0.4943, 0.7110]
2025-03-11 20:05:22 - Train Iteration 2120: loss: 0.5393, d_k_M range: [0.0036, 0.3973], d_k_M_hat range: [0.2693, 0.8975]
2025-03-11 20:05:23 - Train Iteration 2121: loss: 0.8606, d_k_M range: [0.1887, 0.9264], d_k_M_hat range: [0.7031, 0.9987]
2025-03-11 20:05:23 - Train Iteration 2122: loss: 0.4486, d_k_M range: [0.0426, 0.6330], d_k_M_hat range: [0.4758, 0.9632]
2025-03-11 20:05:23 - Train Iteration 2123: loss: 0.4131, d_k_M range: [0.0288, 0.4652], d_k_M_hat range: [0.4003, 0.8294]
2025-03-11 20:05:24 - Train Iteration 2124: loss: 0.7543, d_k_M range: [0.0847, 0.8629], d_k_M_hat range: [0.5619, 0.9944]
2025-03-11 20:05:24 - Train Iteration 2125: loss: 0.4568, d_k_M range: [0.1368, 0.5380], d_k_M_hat range: [0.5261, 0.8753]
2025-03-11 20:05:25 - Train Iteration 2126: loss: 0.4253, d_k_M range: [0.1799, 0.4964], d_k_M_hat range: [0.5959, 0.8767]
2025-03-11 20:05:25 - Train Iteration 2127: loss: 0.4913, d_k_M range: [0.0126, 0.5530], d_k_M_hat range: [0.3117, 0.9220]
2025-03-11 20:05:25 - Train Iteration 2128: loss: 0.6565, d_k_M range: [0.4612, 0.8047], d_k_M_hat range: [0.8025, 0.9944]
2025-03-11 20:05:26 - Train Iteration 2129: loss: 0.4892, d_k_M range: [0.0712, 0.4158], d_k_M_hat range: [0.3755, 0.7729]
2025-03-11 20:05:26 - Train Iteration 2130: loss: 0.4211, d_k_M range: [0.1218, 0.4328], d_k_M_hat range: [0.4957, 0.8302]
2025-03-11 20:05:27 - Train Iteration 2131: loss: 0.5105, d_k_M range: [0.0162, 0.4744], d_k_M_hat range: [0.3657, 0.8240]
2025-03-11 20:05:27 - Train Iteration 2132: loss: 0.4168, d_k_M range: [0.0132, 0.3260], d_k_M_hat range: [0.3794, 0.6965]
2025-03-11 20:05:27 - Train Iteration 2133: loss: 0.5882, d_k_M range: [0.1190, 0.7497], d_k_M_hat range: [0.5149, 0.9827]
2025-03-11 20:05:28 - Train Iteration 2134: loss: 0.5171, d_k_M range: [0.0051, 0.4094], d_k_M_hat range: [0.2860, 0.8137]
2025-03-11 20:05:28 - Train Iteration 2135: loss: 0.5949, d_k_M range: [0.3844, 0.7527], d_k_M_hat range: [0.7730, 0.9814]
2025-03-11 20:05:29 - Train Iteration 2136: loss: 0.4671, d_k_M range: [0.0224, 0.5297], d_k_M_hat range: [0.3634, 0.8765]
2025-03-11 20:05:29 - Train Iteration 2137: loss: 0.5652, d_k_M range: [0.0036, 0.5549], d_k_M_hat range: [0.2519, 0.9079]
2025-03-11 20:05:30 - Train Iteration 2138: loss: 0.5302, d_k_M range: [0.1768, 0.5518], d_k_M_hat range: [0.4486, 0.9066]
2025-03-11 20:05:30 - Train Iteration 2139: loss: 0.4552, d_k_M range: [0.0368, 0.5390], d_k_M_hat range: [0.3833, 0.8922]
2025-03-11 20:05:30 - Train Iteration 2140: loss: 0.4807, d_k_M range: [0.2482, 0.5628], d_k_M_hat range: [0.5556, 0.9070]
2025-03-11 20:05:31 - Train Iteration 2141: loss: 0.7936, d_k_M range: [0.0749, 0.8849], d_k_M_hat range: [0.4129, 0.9940]
2025-03-11 20:05:31 - Train Iteration 2142: loss: 0.5040, d_k_M range: [0.1583, 0.5530], d_k_M_hat range: [0.4745, 0.8797]
2025-03-11 20:05:32 - Train Iteration 2143: loss: 0.5103, d_k_M range: [0.2015, 0.5502], d_k_M_hat range: [0.5564, 0.8359]
2025-03-11 20:05:32 - Train Iteration 2144: loss: 0.8756, d_k_M range: [0.2729, 0.9309], d_k_M_hat range: [0.6023, 0.9951]
2025-03-11 20:05:33 - Train Iteration 2145: loss: 0.5114, d_k_M range: [0.0494, 0.6860], d_k_M_hat range: [0.4086, 0.9709]
2025-03-11 20:05:33 - Train Iteration 2146: loss: 0.5048, d_k_M range: [0.0306, 0.5814], d_k_M_hat range: [0.3420, 0.9021]
2025-03-11 20:05:33 - Train Iteration 2147: loss: 0.7029, d_k_M range: [0.0102, 0.5337], d_k_M_hat range: [0.1718, 0.8497]
2025-03-11 20:05:34 - Train Iteration 2148: loss: 0.5091, d_k_M range: [0.1828, 0.4716], d_k_M_hat range: [0.4948, 0.8739]
2025-03-11 20:05:34 - Train Iteration 2149: loss: 0.4395, d_k_M range: [0.1896, 0.6242], d_k_M_hat range: [0.6108, 0.9613]
2025-03-11 20:05:35 - Train Iteration 2150: loss: 0.7325, d_k_M range: [0.0293, 0.8451], d_k_M_hat range: [0.3975, 0.9892]
2025-03-11 20:05:35 - Train Iteration 2151: loss: 0.7059, d_k_M range: [0.0556, 0.8299], d_k_M_hat range: [0.4428, 0.9897]
2025-03-11 20:05:36 - Train Iteration 2152: loss: 0.4837, d_k_M range: [0.0375, 0.4081], d_k_M_hat range: [0.4235, 0.8433]
2025-03-11 20:05:36 - Train Iteration 2153: loss: 0.4841, d_k_M range: [0.0276, 0.4180], d_k_M_hat range: [0.3758, 0.7708]
2025-03-11 20:05:37 - Train Iteration 2154: loss: 0.4896, d_k_M range: [0.0393, 0.6516], d_k_M_hat range: [0.4078, 0.9519]
2025-03-11 20:05:37 - Train Iteration 2155: loss: 0.3951, d_k_M range: [0.0100, 0.5225], d_k_M_hat range: [0.3816, 0.9037]
2025-03-11 20:05:38 - Train Iteration 2156: loss: 0.8505, d_k_M range: [0.0938, 0.9182], d_k_M_hat range: [0.5472, 0.9959]
2025-03-11 20:05:38 - Train Iteration 2157: loss: 0.6284, d_k_M range: [0.0039, 0.5009], d_k_M_hat range: [0.2112, 0.8884]
2025-03-11 20:05:38 - Train Iteration 2158: loss: 0.6834, d_k_M range: [0.2778, 0.8218], d_k_M_hat range: [0.7180, 0.9952]
2025-03-11 20:05:39 - Train Iteration 2159: loss: 0.6307, d_k_M range: [0.0020, 0.3026], d_k_M_hat range: [0.2078, 0.7168]
2025-03-11 20:05:39 - Train Iteration 2160: loss: 0.5542, d_k_M range: [0.2245, 0.7205], d_k_M_hat range: [0.6723, 0.9902]
2025-03-11 20:05:40 - Train Iteration 2161: loss: 0.6591, d_k_M range: [0.0019, 0.4480], d_k_M_hat range: [0.1901, 0.8283]
2025-03-11 20:05:40 - Train Iteration 2162: loss: 0.7027, d_k_M range: [0.0739, 0.8211], d_k_M_hat range: [0.4375, 0.9828]
2025-03-11 20:05:41 - Train Iteration 2163: loss: 0.7727, d_k_M range: [0.0015, 0.3290], d_k_M_hat range: [0.1225, 0.6996]
2025-03-11 20:05:41 - Train Iteration 2164: loss: 0.5195, d_k_M range: [0.2001, 0.7101], d_k_M_hat range: [0.5810, 0.9894]
2025-03-11 20:05:42 - Train Iteration 2165: loss: 0.4634, d_k_M range: [0.0376, 0.4079], d_k_M_hat range: [0.4041, 0.8041]
2025-03-11 20:05:42 - Train Iteration 2166: loss: 0.5859, d_k_M range: [0.0642, 0.7546], d_k_M_hat range: [0.4797, 0.9892]
2025-03-11 20:05:42 - Train Iteration 2167: loss: 0.6072, d_k_M range: [0.0061, 0.4675], d_k_M_hat range: [0.2664, 0.8330]
2025-03-11 20:05:43 - Train Iteration 2168: loss: 0.7570, d_k_M range: [0.1864, 0.8581], d_k_M_hat range: [0.5388, 0.9880]
2025-03-11 20:05:43 - Train Iteration 2169: loss: 0.6487, d_k_M range: [0.0053, 0.5057], d_k_M_hat range: [0.1998, 0.8889]
2025-03-11 20:05:44 - Train Iteration 2170: loss: 0.8646, d_k_M range: [0.0795, 0.9252], d_k_M_hat range: [0.4955, 0.9953]
2025-03-11 20:05:44 - Train Iteration 2171: loss: 0.4712, d_k_M range: [0.0102, 0.3022], d_k_M_hat range: [0.3286, 0.6596]
2025-03-11 20:05:44 - Train Iteration 2172: loss: 0.4211, d_k_M range: [0.0475, 0.4232], d_k_M_hat range: [0.4269, 0.8156]
2025-03-11 20:05:45 - Train Iteration 2173: loss: 0.4443, d_k_M range: [0.0411, 0.5010], d_k_M_hat range: [0.3745, 0.8346]
2025-03-11 20:05:45 - Train Iteration 2174: loss: 0.4373, d_k_M range: [0.1542, 0.6235], d_k_M_hat range: [0.5656, 0.9622]
2025-03-11 20:05:46 - Train Iteration 2175: loss: 0.7459, d_k_M range: [0.0264, 0.3508], d_k_M_hat range: [0.1627, 0.6743]
2025-03-11 20:05:46 - Train Iteration 2176: loss: 0.5249, d_k_M range: [0.2430, 0.6076], d_k_M_hat range: [0.5267, 0.9512]
2025-03-11 20:05:46 - Train Iteration 2177: loss: 0.5187, d_k_M range: [0.0104, 0.3897], d_k_M_hat range: [0.2902, 0.7853]
2025-03-11 20:05:47 - Train Iteration 2178: loss: 0.4678, d_k_M range: [0.1257, 0.6316], d_k_M_hat range: [0.5157, 0.9476]
2025-03-11 20:05:47 - Train Iteration 2179: loss: 0.5284, d_k_M range: [0.0921, 0.7012], d_k_M_hat range: [0.4928, 0.9742]
2025-03-11 20:05:48 - Train Iteration 2180: loss: 0.6177, d_k_M range: [0.0230, 0.7581], d_k_M_hat range: [0.3847, 0.9722]
2025-03-11 20:05:48 - Train Iteration 2181: loss: 0.5043, d_k_M range: [0.0059, 0.4719], d_k_M_hat range: [0.2958, 0.8392]
2025-03-11 20:05:49 - Train Iteration 2182: loss: 0.4447, d_k_M range: [0.1189, 0.5536], d_k_M_hat range: [0.4680, 0.9185]
2025-03-11 20:05:49 - Train Iteration 2183: loss: 0.5991, d_k_M range: [0.0014, 0.5058], d_k_M_hat range: [0.2274, 0.8475]
2025-03-11 20:05:50 - Train Iteration 2184: loss: 0.4958, d_k_M range: [0.0695, 0.5010], d_k_M_hat range: [0.4455, 0.8702]
2025-03-11 20:05:50 - Train Iteration 2185: loss: 0.5280, d_k_M range: [0.0091, 0.6299], d_k_M_hat range: [0.2825, 0.9473]
2025-03-11 20:05:50 - Train Iteration 2186: loss: 0.4356, d_k_M range: [0.0243, 0.6206], d_k_M_hat range: [0.4204, 0.9606]
2025-03-11 20:05:51 - Train Iteration 2187: loss: 0.4880, d_k_M range: [0.0096, 0.4628], d_k_M_hat range: [0.3111, 0.8653]
2025-03-11 20:05:51 - Train Iteration 2188: loss: 0.4399, d_k_M range: [0.0679, 0.3518], d_k_M_hat range: [0.4046, 0.7568]
2025-03-11 20:05:52 - Train Iteration 2189: loss: 0.4424, d_k_M range: [0.0716, 0.5907], d_k_M_hat range: [0.4065, 0.9314]
2025-03-11 20:05:52 - Train Iteration 2190: loss: 0.4358, d_k_M range: [0.0071, 0.5410], d_k_M_hat range: [0.3470, 0.9513]
2025-03-11 20:05:52 - Train Iteration 2191: loss: 0.9920, d_k_M range: [0.0001, 0.5192], d_k_M_hat range: [0.0041, 0.9336]
2025-03-11 20:05:53 - Train Iteration 2192: loss: 0.4517, d_k_M range: [0.0126, 0.4868], d_k_M_hat range: [0.3587, 0.9011]
2025-03-11 20:05:53 - Train Iteration 2193: loss: 0.4742, d_k_M range: [0.2445, 0.5337], d_k_M_hat range: [0.6651, 0.9356]
2025-03-11 20:05:54 - Train Iteration 2194: loss: 0.4534, d_k_M range: [0.0032, 0.3279], d_k_M_hat range: [0.3298, 0.7280]
2025-03-11 20:05:54 - Train Iteration 2195: loss: 0.6882, d_k_M range: [0.1080, 0.8255], d_k_M_hat range: [0.5161, 0.9960]
2025-03-11 20:05:55 - Train Iteration 2196: loss: 0.6053, d_k_M range: [0.0070, 0.6387], d_k_M_hat range: [0.2290, 0.9432]
2025-03-11 20:05:55 - Train Iteration 2197: loss: 0.5125, d_k_M range: [0.1422, 0.6946], d_k_M_hat range: [0.5806, 0.9787]
2025-03-11 20:05:56 - Train Iteration 2198: loss: 0.6117, d_k_M range: [0.0022, 0.5224], d_k_M_hat range: [0.2201, 0.9359]
2025-03-11 20:05:56 - Train Iteration 2199: loss: 0.6920, d_k_M range: [0.3203, 0.8186], d_k_M_hat range: [0.6871, 0.9867]
2025-03-11 20:05:56 - Train Iteration 2200: loss: 0.6472, d_k_M range: [0.0010, 0.2259], d_k_M_hat range: [0.2045, 0.5980]
2025-03-11 20:05:57 - Train Iteration 2201: loss: 0.4934, d_k_M range: [0.1955, 0.6226], d_k_M_hat range: [0.5784, 0.9597]
2025-03-11 20:05:57 - Train Iteration 2202: loss: 0.4958, d_k_M range: [0.1632, 0.5806], d_k_M_hat range: [0.5314, 0.9369]
2025-03-11 20:05:58 - Train Iteration 2203: loss: 0.5172, d_k_M range: [0.0209, 0.5328], d_k_M_hat range: [0.3978, 0.9248]
2025-03-11 20:05:58 - Train Iteration 2204: loss: 0.5331, d_k_M range: [0.0722, 0.6871], d_k_M_hat range: [0.4013, 0.9718]
2025-03-11 20:05:59 - Train Iteration 2205: loss: 0.5289, d_k_M range: [0.0066, 0.3845], d_k_M_hat range: [0.2794, 0.8442]
2025-03-11 20:05:59 - Train Iteration 2206: loss: 0.5292, d_k_M range: [0.1769, 0.4929], d_k_M_hat range: [0.5266, 0.9132]
2025-03-11 20:05:59 - Train Iteration 2207: loss: 0.5315, d_k_M range: [0.2689, 0.7184], d_k_M_hat range: [0.6300, 0.9893]
2025-03-11 20:06:00 - Train Iteration 2208: loss: 0.6321, d_k_M range: [0.0169, 0.4966], d_k_M_hat range: [0.2218, 0.8894]
2025-03-11 20:06:00 - Train Iteration 2209: loss: 0.4414, d_k_M range: [0.1429, 0.3782], d_k_M_hat range: [0.5419, 0.7803]
2025-03-11 20:06:01 - Train Iteration 2210: loss: 0.4343, d_k_M range: [0.2053, 0.5289], d_k_M_hat range: [0.6169, 0.9429]
2025-03-11 20:06:01 - Train Iteration 2211: loss: 0.4313, d_k_M range: [0.0200, 0.6208], d_k_M_hat range: [0.3632, 0.9694]
2025-03-11 20:06:02 - Train Iteration 2212: loss: 0.4315, d_k_M range: [0.0125, 0.5618], d_k_M_hat range: [0.3556, 0.9322]
2025-03-11 20:06:02 - Train Iteration 2213: loss: 0.4398, d_k_M range: [0.0258, 0.5765], d_k_M_hat range: [0.4104, 0.9394]
2025-03-11 20:06:03 - Train Iteration 2214: loss: 0.4903, d_k_M range: [0.0269, 0.6873], d_k_M_hat range: [0.3589, 0.9871]
2025-03-11 20:06:03 - Train Iteration 2215: loss: 0.5730, d_k_M range: [0.0145, 0.1651], d_k_M_hat range: [0.2575, 0.7062]
2025-03-11 20:06:03 - Train Iteration 2216: loss: 0.4760, d_k_M range: [0.1382, 0.6617], d_k_M_hat range: [0.5512, 0.9718]
2025-03-11 20:06:04 - Train Iteration 2217: loss: 0.5068, d_k_M range: [0.0070, 0.5729], d_k_M_hat range: [0.2951, 0.9231]
2025-03-11 20:06:05 - Train Iteration 2218: loss: 0.5922, d_k_M range: [0.0069, 0.4472], d_k_M_hat range: [0.2373, 0.8341]
2025-03-11 20:06:05 - Train Iteration 2219: loss: 0.4517, d_k_M range: [0.0110, 0.4062], d_k_M_hat range: [0.3395, 0.8064]
2025-03-11 20:06:06 - Train Iteration 2220: loss: 0.8994, d_k_M range: [0.0432, 0.9460], d_k_M_hat range: [0.4776, 0.9976]
2025-03-11 20:06:06 - Train Iteration 2221: loss: 0.5592, d_k_M range: [0.0063, 0.7063], d_k_M_hat range: [0.3248, 0.9585]
2025-03-11 20:06:07 - Train Iteration 2222: loss: 0.4934, d_k_M range: [0.0126, 0.4429], d_k_M_hat range: [0.3101, 0.8442]
2025-03-11 20:06:07 - Train Iteration 2223: loss: 0.8554, d_k_M range: [0.2739, 0.9205], d_k_M_hat range: [0.5910, 0.9956]
2025-03-11 20:06:08 - Train Iteration 2224: loss: 0.7854, d_k_M range: [0.0020, 0.4194], d_k_M_hat range: [0.1158, 0.8415]
2025-03-11 20:06:08 - Train Iteration 2225: loss: 0.4622, d_k_M range: [0.0079, 0.5747], d_k_M_hat range: [0.3355, 0.8949]
2025-03-11 20:06:09 - Train Iteration 2226: loss: 0.6725, d_k_M range: [0.0017, 0.4649], d_k_M_hat range: [0.1816, 0.7990]
2025-03-11 20:06:09 - Train Iteration 2227: loss: 0.7482, d_k_M range: [0.0036, 0.6003], d_k_M_hat range: [0.1386, 0.9756]
2025-03-11 20:06:09 - Train Iteration 2228: loss: 0.5297, d_k_M range: [0.1802, 0.4894], d_k_M_hat range: [0.5766, 0.9107]
2025-03-11 20:06:10 - Train Iteration 2229: loss: 0.4911, d_k_M range: [0.0749, 0.6558], d_k_M_hat range: [0.4776, 0.9550]
2025-03-11 20:06:10 - Train Iteration 2230: loss: 0.7079, d_k_M range: [0.0006, 0.5294], d_k_M_hat range: [0.1593, 0.8933]
2025-03-11 20:06:10 - Train Iteration 2231: loss: 0.6882, d_k_M range: [0.2751, 0.8193], d_k_M_hat range: [0.6974, 0.9897]
2025-03-11 20:06:11 - Train Iteration 2232: loss: 0.5596, d_k_M range: [0.0039, 0.4625], d_k_M_hat range: [0.2558, 0.8199]
2025-03-11 20:06:11 - Train Iteration 2233: loss: 0.8046, d_k_M range: [0.1485, 0.8918], d_k_M_hat range: [0.4650, 0.9948]
2025-03-11 20:06:12 - Train Iteration 2234: loss: 0.4860, d_k_M range: [0.0173, 0.5950], d_k_M_hat range: [0.3411, 0.9474]
2025-03-11 20:06:12 - Train Iteration 2235: loss: 0.4691, d_k_M range: [0.0465, 0.4862], d_k_M_hat range: [0.3824, 0.8852]
2025-03-11 20:06:13 - Train Iteration 2236: loss: 0.4893, d_k_M range: [0.0075, 0.5466], d_k_M_hat range: [0.3079, 0.9037]
2025-03-11 20:06:13 - Train Iteration 2237: loss: 0.5656, d_k_M range: [0.2578, 0.7370], d_k_M_hat range: [0.6258, 0.9850]
2025-03-11 20:06:13 - Train Iteration 2238: loss: 0.4785, d_k_M range: [0.0034, 0.2689], d_k_M_hat range: [0.3117, 0.6157]
2025-03-11 20:06:14 - Train Iteration 2239: loss: 0.4919, d_k_M range: [0.0054, 0.6245], d_k_M_hat range: [0.3328, 0.9231]
2025-03-11 20:06:14 - Train Iteration 2240: loss: 0.5285, d_k_M range: [0.0091, 0.4262], d_k_M_hat range: [0.2822, 0.8254]
2025-03-11 20:06:14 - Train Iteration 2241: loss: 0.4864, d_k_M range: [0.3975, 0.6586], d_k_M_hat range: [0.8011, 0.9612]
2025-03-11 20:06:15 - Train Iteration 2242: loss: 0.4734, d_k_M range: [0.0058, 0.5281], d_k_M_hat range: [0.3178, 0.9034]
2025-03-11 20:06:15 - Train Iteration 2243: loss: 0.4679, d_k_M range: [0.0271, 0.6276], d_k_M_hat range: [0.4489, 0.9436]
2025-03-11 20:06:16 - Train Iteration 2244: loss: 0.6464, d_k_M range: [0.0019, 0.2760], d_k_M_hat range: [0.1979, 0.7045]
2025-03-11 20:06:16 - Train Iteration 2245: loss: 0.5250, d_k_M range: [0.2202, 0.6415], d_k_M_hat range: [0.5468, 0.9618]
2025-03-11 20:06:17 - Train Iteration 2246: loss: 0.5790, d_k_M range: [0.0848, 0.7197], d_k_M_hat range: [0.4528, 0.9588]
2025-03-11 20:06:17 - Train Iteration 2247: loss: 0.5346, d_k_M range: [0.0037, 0.5090], d_k_M_hat range: [0.2745, 0.8823]
2025-03-11 20:06:17 - Train Iteration 2248: loss: 0.5998, d_k_M range: [0.0167, 0.7337], d_k_M_hat range: [0.2869, 0.9592]
2025-03-11 20:06:18 - Train Iteration 2249: loss: 0.5319, d_k_M range: [0.2838, 0.6088], d_k_M_hat range: [0.5614, 0.9262]
2025-03-11 20:06:18 - Train Iteration 2250: loss: 0.4729, d_k_M range: [0.1142, 0.5241], d_k_M_hat range: [0.5119, 0.8784]
2025-03-11 20:06:19 - Train Iteration 2251: loss: 0.4587, d_k_M range: [0.0322, 0.4761], d_k_M_hat range: [0.3682, 0.8216]
2025-03-11 20:06:19 - Train Iteration 2252: loss: 0.4569, d_k_M range: [0.0407, 0.3413], d_k_M_hat range: [0.4322, 0.7739]
2025-03-11 20:06:19 - Train Iteration 2253: loss: 0.5151, d_k_M range: [0.2739, 0.4884], d_k_M_hat range: [0.6157, 0.9192]
2025-03-11 20:06:20 - Train Iteration 2254: loss: 0.4285, d_k_M range: [0.1801, 0.4104], d_k_M_hat range: [0.5498, 0.7753]
2025-03-11 20:06:20 - Train Iteration 2255: loss: 0.7848, d_k_M range: [0.0544, 0.8765], d_k_M_hat range: [0.4383, 0.9955]
2025-03-11 20:06:21 - Train Iteration 2256: loss: 0.4386, d_k_M range: [0.0229, 0.2992], d_k_M_hat range: [0.3751, 0.6712]
2025-03-11 20:06:21 - Train Iteration 2257: loss: 0.9349, d_k_M range: [0.0002, 0.4086], d_k_M_hat range: [0.0334, 0.8674]
2025-03-11 20:06:21 - Train Iteration 2258: loss: 0.4494, d_k_M range: [0.1507, 0.4321], d_k_M_hat range: [0.5670, 0.8802]
2025-03-11 20:06:22 - Train Iteration 2259: loss: 0.4524, d_k_M range: [0.2734, 0.6248], d_k_M_hat range: [0.6028, 0.9756]
2025-03-11 20:06:22 - Train Iteration 2260: loss: 0.9028, d_k_M range: [0.0105, 0.9458], d_k_M_hat range: [0.3300, 0.9957]
2025-03-11 20:06:23 - Train Iteration 2261: loss: 0.5694, d_k_M range: [0.3267, 0.7277], d_k_M_hat range: [0.6780, 0.9731]
2025-03-11 20:06:23 - Train Iteration 2262: loss: 0.4872, d_k_M range: [0.1064, 0.5894], d_k_M_hat range: [0.5313, 0.9639]
2025-03-11 20:06:23 - Train Iteration 2263: loss: 0.4491, d_k_M range: [0.0525, 0.5363], d_k_M_hat range: [0.4864, 0.9073]
2025-03-11 20:06:24 - Train Iteration 2264: loss: 0.4572, d_k_M range: [0.0507, 0.5285], d_k_M_hat range: [0.4119, 0.9167]
2025-03-11 20:06:24 - Train Iteration 2265: loss: 0.5338, d_k_M range: [0.0088, 0.5352], d_k_M_hat range: [0.2782, 0.9329]
2025-03-11 20:06:25 - Train Iteration 2266: loss: 0.5739, d_k_M range: [0.0155, 0.5851], d_k_M_hat range: [0.2580, 0.9545]
2025-03-11 20:06:25 - Train Iteration 2267: loss: 0.4729, d_k_M range: [0.1228, 0.6365], d_k_M_hat range: [0.4804, 0.9488]
2025-03-11 20:06:25 - Train Iteration 2268: loss: 0.5848, d_k_M range: [0.0363, 0.7591], d_k_M_hat range: [0.2930, 0.9944]
2025-03-11 20:06:26 - Train Iteration 2269: loss: 0.9033, d_k_M range: [0.0013, 0.3538], d_k_M_hat range: [0.0509, 0.7486]
2025-03-11 20:06:26 - Train Iteration 2270: loss: 0.8370, d_k_M range: [0.0663, 0.9083], d_k_M_hat range: [0.4113, 0.9935]
2025-03-11 20:06:27 - Train Iteration 2271: loss: 0.6515, d_k_M range: [0.0037, 0.7992], d_k_M_hat range: [0.2345, 0.9920]
2025-03-11 20:06:27 - Train Iteration 2272: loss: 0.5400, d_k_M range: [0.0036, 0.6147], d_k_M_hat range: [0.2688, 0.9425]
2025-03-11 20:06:27 - Train Iteration 2273: loss: 0.4853, d_k_M range: [0.2190, 0.6637], d_k_M_hat range: [0.5508, 0.9671]
2025-03-11 20:06:28 - Train Iteration 2274: loss: 0.4817, d_k_M range: [0.2217, 0.6509], d_k_M_hat range: [0.5728, 0.9679]
2025-03-11 20:06:28 - Train Iteration 2275: loss: 0.4305, d_k_M range: [0.0621, 0.4682], d_k_M_hat range: [0.4770, 0.8250]
2025-03-11 20:06:29 - Train Iteration 2276: loss: 0.5477, d_k_M range: [0.0107, 0.3810], d_k_M_hat range: [0.2706, 0.7041]
2025-03-11 20:06:29 - Train Iteration 2277: loss: 0.8036, d_k_M range: [0.2347, 0.8916], d_k_M_hat range: [0.6174, 0.9952]
2025-03-11 20:06:29 - Train Iteration 2278: loss: 0.5775, d_k_M range: [0.0061, 0.4519], d_k_M_hat range: [0.2626, 0.8336]
2025-03-11 20:06:30 - Train Iteration 2279: loss: 0.4024, d_k_M range: [0.0902, 0.2420], d_k_M_hat range: [0.4592, 0.6442]
2025-03-11 20:06:30 - Train Iteration 2280: loss: 0.6406, d_k_M range: [0.0076, 0.7626], d_k_M_hat range: [0.2087, 0.9622]
2025-03-11 20:06:31 - Train Iteration 2281: loss: 0.7895, d_k_M range: [0.0005, 0.4015], d_k_M_hat range: [0.1119, 0.7971]
2025-03-11 20:06:31 - Train Iteration 2282: loss: 0.8361, d_k_M range: [0.0148, 0.9114], d_k_M_hat range: [0.2847, 0.9970]
2025-03-11 20:06:31 - Train Iteration 2283: loss: 0.4713, d_k_M range: [0.0231, 0.3099], d_k_M_hat range: [0.3752, 0.6593]
2025-03-11 20:06:32 - Train Iteration 2284: loss: 0.4915, d_k_M range: [0.0514, 0.4874], d_k_M_hat range: [0.4757, 0.7863]
2025-03-11 20:06:32 - Train Iteration 2285: loss: 0.4715, d_k_M range: [0.0324, 0.5562], d_k_M_hat range: [0.3665, 0.8889]
2025-03-11 20:06:33 - Train Iteration 2286: loss: 0.4566, d_k_M range: [0.0313, 0.5794], d_k_M_hat range: [0.4576, 0.9414]
2025-03-11 20:06:33 - Train Iteration 2287: loss: 0.4678, d_k_M range: [0.0069, 0.5747], d_k_M_hat range: [0.3364, 0.9474]
2025-03-11 20:06:33 - Train Iteration 2288: loss: 0.6388, d_k_M range: [0.1512, 0.7886], d_k_M_hat range: [0.5258, 0.9893]
2025-03-11 20:06:34 - Train Iteration 2289: loss: 0.5183, d_k_M range: [0.0217, 0.5223], d_k_M_hat range: [0.3417, 0.8023]
2025-03-11 20:06:34 - Train Iteration 2290: loss: 0.5183, d_k_M range: [0.0050, 0.4423], d_k_M_hat range: [0.2851, 0.7953]
2025-03-11 20:06:35 - Train Iteration 2291: loss: 0.7249, d_k_M range: [0.2204, 0.8451], d_k_M_hat range: [0.5729, 0.9937]
2025-03-11 20:06:35 - Train Iteration 2292: loss: 0.5385, d_k_M range: [0.0171, 0.4143], d_k_M_hat range: [0.2833, 0.7960]
2025-03-11 20:06:36 - Train Iteration 2293: loss: 0.5302, d_k_M range: [0.2585, 0.6730], d_k_M_hat range: [0.5358, 0.9577]
2025-03-11 20:06:36 - Train Iteration 2294: loss: 0.4586, d_k_M range: [0.0358, 0.5592], d_k_M_hat range: [0.3648, 0.9336]
2025-03-11 20:06:36 - Train Iteration 2295: loss: 0.4932, d_k_M range: [0.0421, 0.4540], d_k_M_hat range: [0.3399, 0.7850]
2025-03-11 20:06:37 - Train Iteration 2296: loss: 0.5130, d_k_M range: [0.0110, 0.3582], d_k_M_hat range: [0.3004, 0.7176]
2025-03-11 20:06:37 - Train Iteration 2297: loss: 0.4636, d_k_M range: [0.0864, 0.5744], d_k_M_hat range: [0.4178, 0.9448]
2025-03-11 20:06:38 - Train Iteration 2298: loss: 0.4584, d_k_M range: [0.0679, 0.4619], d_k_M_hat range: [0.3961, 0.8512]
2025-03-11 20:06:38 - Train Iteration 2299: loss: 0.6193, d_k_M range: [0.0831, 0.7561], d_k_M_hat range: [0.4784, 0.9692]
2025-03-11 20:06:38 - Train Iteration 2300: loss: 0.5586, d_k_M range: [0.0019, 0.3025], d_k_M_hat range: [0.2603, 0.6691]
2025-03-11 20:06:39 - Train Iteration 2301: loss: 0.7744, d_k_M range: [0.2565, 0.8703], d_k_M_hat range: [0.6211, 0.9903]
2025-03-11 20:06:39 - Train Iteration 2302: loss: 0.6385, d_k_M range: [0.1557, 0.7891], d_k_M_hat range: [0.5345, 0.9901]
2025-03-11 20:06:40 - Train Iteration 2303: loss: 0.6105, d_k_M range: [0.0059, 0.3540], d_k_M_hat range: [0.2245, 0.7363]
2025-03-11 20:06:40 - Train Iteration 2304: loss: 0.9879, d_k_M range: [0.2486, 0.9934], d_k_M_hat range: [0.6947, 0.9994]
2025-03-11 20:06:40 - Train Iteration 2305: loss: 0.4476, d_k_M range: [0.0125, 0.3879], d_k_M_hat range: [0.3876, 0.7967]
2025-03-11 20:06:41 - Train Iteration 2306: loss: 0.6694, d_k_M range: [0.0238, 0.8094], d_k_M_hat range: [0.4082, 0.9913]
2025-03-11 20:06:41 - Train Iteration 2307: loss: 0.4352, d_k_M range: [0.0540, 0.5375], d_k_M_hat range: [0.4207, 0.9019]
2025-03-11 20:06:42 - Train Iteration 2308: loss: 0.4362, d_k_M range: [0.0217, 0.1878], d_k_M_hat range: [0.3946, 0.5708]
2025-03-11 20:06:42 - Train Iteration 2309: loss: 0.5480, d_k_M range: [0.2009, 0.6912], d_k_M_hat range: [0.5111, 0.9744]
2025-03-11 20:06:42 - Train Iteration 2310: loss: 0.5059, d_k_M range: [0.2363, 0.6890], d_k_M_hat range: [0.6107, 0.9778]
2025-03-11 20:06:43 - Train Iteration 2311: loss: 0.4344, d_k_M range: [0.0469, 0.3857], d_k_M_hat range: [0.4828, 0.7435]
2025-03-11 20:06:43 - Train Iteration 2312: loss: 0.4913, d_k_M range: [0.0029, 0.5136], d_k_M_hat range: [0.3019, 0.9159]
2025-03-11 20:06:44 - Train Iteration 2313: loss: 0.8644, d_k_M range: [0.0559, 0.9267], d_k_M_hat range: [0.4563, 0.9969]
2025-03-11 20:06:44 - Train Iteration 2314: loss: 0.7343, d_k_M range: [0.0613, 0.8499], d_k_M_hat range: [0.4181, 0.9929]
2025-03-11 20:06:44 - Train Iteration 2315: loss: 0.4566, d_k_M range: [0.0946, 0.5624], d_k_M_hat range: [0.5239, 0.9415]
2025-03-11 20:06:45 - Train Iteration 2316: loss: 0.5290, d_k_M range: [0.0162, 0.6749], d_k_M_hat range: [0.3215, 0.9476]
2025-03-11 20:06:45 - Train Iteration 2317: loss: 0.5531, d_k_M range: [0.0480, 0.7305], d_k_M_hat range: [0.4330, 0.9868]
2025-03-11 20:06:45 - Train Iteration 2318: loss: 0.5073, d_k_M range: [0.0756, 0.6962], d_k_M_hat range: [0.5185, 0.9840]
2025-03-11 20:06:46 - Train Iteration 2319: loss: 0.6708, d_k_M range: [0.0011, 0.4863], d_k_M_hat range: [0.1823, 0.8758]
2025-03-11 20:06:46 - Train Iteration 2320: loss: 0.9343, d_k_M range: [0.0453, 0.9634], d_k_M_hat range: [0.5126, 0.9968]
2025-03-11 20:06:47 - Train Iteration 2321: loss: 0.4418, d_k_M range: [0.0200, 0.3645], d_k_M_hat range: [0.3554, 0.7599]
2025-03-11 20:06:47 - Train Iteration 2322: loss: 0.4646, d_k_M range: [0.1441, 0.6469], d_k_M_hat range: [0.5495, 0.9653]
2025-03-11 20:06:47 - Train Iteration 2323: loss: 0.7726, d_k_M range: [0.0015, 0.2553], d_k_M_hat range: [0.1225, 0.6664]
2025-03-11 20:06:48 - Train Iteration 2324: loss: 0.4409, d_k_M range: [0.0777, 0.5973], d_k_M_hat range: [0.4790, 0.9333]
2025-03-11 20:06:48 - Train Iteration 2325: loss: 0.4290, d_k_M range: [0.0578, 0.5570], d_k_M_hat range: [0.4317, 0.9340]
2025-03-11 20:06:49 - Train Iteration 2326: loss: 0.4409, d_k_M range: [0.1586, 0.6309], d_k_M_hat range: [0.5660, 0.9712]
2025-03-11 20:06:49 - Train Iteration 2327: loss: 0.9361, d_k_M range: [0.3696, 0.9661], d_k_M_hat range: [0.7332, 0.9986]
2025-03-11 20:06:50 - Train Iteration 2328: loss: 0.7117, d_k_M range: [0.0091, 0.3360], d_k_M_hat range: [0.1681, 0.7872]
2025-03-11 20:06:50 - Train Iteration 2329: loss: 0.3945, d_k_M range: [0.1645, 0.5375], d_k_M_hat range: [0.6108, 0.9423]
2025-03-11 20:06:50 - Train Iteration 2330: loss: 0.5394, d_k_M range: [0.0027, 0.5568], d_k_M_hat range: [0.2682, 0.9591]
2025-03-11 20:06:51 - Train Iteration 2331: loss: 0.8530, d_k_M range: [0.0012, 0.9197], d_k_M_hat range: [0.1458, 0.9961]
2025-03-11 20:06:51 - Train Iteration 2332: loss: 0.4275, d_k_M range: [0.1217, 0.6006], d_k_M_hat range: [0.5607, 0.9467]
2025-03-11 20:06:52 - Train Iteration 2333: loss: 0.6820, d_k_M range: [0.0100, 0.6424], d_k_M_hat range: [0.1842, 0.9666]
2025-03-11 20:06:52 - Train Iteration 2334: loss: 0.5194, d_k_M range: [0.2590, 0.6334], d_k_M_hat range: [0.6837, 0.9747]
2025-03-11 20:06:53 - Train Iteration 2335: loss: 0.4774, d_k_M range: [0.0386, 0.4772], d_k_M_hat range: [0.3861, 0.7863]
2025-03-11 20:06:53 - Train Iteration 2336: loss: 0.5217, d_k_M range: [0.0049, 0.4383], d_k_M_hat range: [0.4100, 0.8650]
2025-03-11 20:06:53 - Train Iteration 2337: loss: 0.5065, d_k_M range: [0.0108, 0.6504], d_k_M_hat range: [0.2991, 0.9742]
2025-03-11 20:06:54 - Train Iteration 2338: loss: 0.6730, d_k_M range: [0.0422, 0.8115], d_k_M_hat range: [0.4917, 0.9911]
2025-03-11 20:06:54 - Train Iteration 2339: loss: 0.3882, d_k_M range: [0.0287, 0.4306], d_k_M_hat range: [0.4775, 0.8704]
2025-03-11 20:06:55 - Train Iteration 2340: loss: 0.4065, d_k_M range: [0.0497, 0.4769], d_k_M_hat range: [0.4683, 0.9033]
2025-03-11 20:06:55 - Train Iteration 2341: loss: 0.6909, d_k_M range: [0.0328, 0.8247], d_k_M_hat range: [0.4154, 0.9935]
2025-03-11 20:06:55 - Train Iteration 2342: loss: 0.7070, d_k_M range: [0.0078, 0.8224], d_k_M_hat range: [0.1866, 0.9891]
2025-03-11 20:06:56 - Train Iteration 2343: loss: 0.5806, d_k_M range: [0.0560, 0.7500], d_k_M_hat range: [0.3779, 0.9880]
2025-03-11 20:06:56 - Train Iteration 2344: loss: 0.8500, d_k_M range: [0.0006, 0.2928], d_k_M_hat range: [0.0805, 0.6403]
2025-03-11 20:06:57 - Train Iteration 2345: loss: 0.4656, d_k_M range: [0.1220, 0.4980], d_k_M_hat range: [0.5021, 0.9030]
2025-03-11 20:06:57 - Train Iteration 2346: loss: 0.5041, d_k_M range: [0.0120, 0.6959], d_k_M_hat range: [0.3389, 0.9859]
2025-03-11 20:06:57 - Train Iteration 2347: loss: 0.4414, d_k_M range: [0.0224, 0.4591], d_k_M_hat range: [0.3580, 0.8016]
2025-03-11 20:06:58 - Train Iteration 2348: loss: 0.8468, d_k_M range: [0.0219, 0.9190], d_k_M_hat range: [0.3352, 0.9988]
2025-03-11 20:06:58 - Train Iteration 2349: loss: 0.8597, d_k_M range: [0.0020, 0.9223], d_k_M_hat range: [0.2892, 0.9951]
2025-03-11 20:06:58 - Train Iteration 2350: loss: 0.4657, d_k_M range: [0.0498, 0.5316], d_k_M_hat range: [0.4309, 0.9127]
2025-03-11 20:06:59 - Train Iteration 2351: loss: 0.4330, d_k_M range: [0.0458, 0.4473], d_k_M_hat range: [0.4403, 0.8316]
2025-03-11 20:06:59 - Train Iteration 2352: loss: 0.4279, d_k_M range: [0.0940, 0.5449], d_k_M_hat range: [0.4399, 0.9423]
2025-03-11 20:07:00 - Train Iteration 2353: loss: 0.4830, d_k_M range: [0.0534, 0.6545], d_k_M_hat range: [0.4023, 0.9595]
2025-03-11 20:07:00 - Train Iteration 2354: loss: 0.4952, d_k_M range: [0.0035, 0.2910], d_k_M_hat range: [0.2998, 0.6631]
2025-03-11 20:07:01 - Train Iteration 2355: loss: 0.5148, d_k_M range: [0.2589, 0.6913], d_k_M_hat range: [0.6273, 0.9738]
2025-03-11 20:07:01 - Train Iteration 2356: loss: 0.6884, d_k_M range: [0.0048, 0.4386], d_k_M_hat range: [0.1751, 0.7992]
2025-03-11 20:07:01 - Train Iteration 2357: loss: 0.4352, d_k_M range: [0.0613, 0.5670], d_k_M_hat range: [0.4319, 0.9472]
2025-03-11 20:07:02 - Train Iteration 2358: loss: 0.4898, d_k_M range: [0.0285, 0.3634], d_k_M_hat range: [0.3286, 0.7601]
2025-03-11 20:07:02 - Train Iteration 2359: loss: 0.5782, d_k_M range: [0.0037, 0.2559], d_k_M_hat range: [0.2433, 0.5938]
2025-03-11 20:07:03 - Train Iteration 2360: loss: 0.5392, d_k_M range: [0.0727, 0.5795], d_k_M_hat range: [0.3847, 0.9104]
2025-03-11 20:07:03 - Train Iteration 2361: loss: 0.5472, d_k_M range: [0.0851, 0.7209], d_k_M_hat range: [0.4584, 0.9812]
2025-03-11 20:07:03 - Train Iteration 2362: loss: 0.5430, d_k_M range: [0.0103, 0.5909], d_k_M_hat range: [0.2734, 0.9616]
2025-03-11 20:07:04 - Train Iteration 2363: loss: 0.5476, d_k_M range: [0.1617, 0.6511], d_k_M_hat range: [0.4562, 0.9111]
2025-03-11 20:07:04 - Train Iteration 2364: loss: 0.5082, d_k_M range: [0.0208, 0.4409], d_k_M_hat range: [0.3875, 0.7280]
2025-03-11 20:07:05 - Train Iteration 2365: loss: 0.4653, d_k_M range: [0.2878, 0.6634], d_k_M_hat range: [0.6277, 0.9812]
2025-03-11 20:07:05 - Train Iteration 2366: loss: 0.4970, d_k_M range: [0.0654, 0.6630], d_k_M_hat range: [0.4330, 0.9667]
2025-03-11 20:07:05 - Train Iteration 2367: loss: 0.9677, d_k_M range: [0.0002, 0.3487], d_k_M_hat range: [0.0165, 0.7968]
2025-03-11 20:07:06 - Train Iteration 2368: loss: 0.4288, d_k_M range: [0.1130, 0.4407], d_k_M_hat range: [0.5043, 0.8404]
2025-03-11 20:07:06 - Train Iteration 2369: loss: 0.5171, d_k_M range: [0.1381, 0.3960], d_k_M_hat range: [0.4190, 0.8303]
2025-03-11 20:07:07 - Train Iteration 2370: loss: 0.5237, d_k_M range: [0.0105, 0.3888], d_k_M_hat range: [0.2869, 0.7432]
2025-03-11 20:07:07 - Train Iteration 2371: loss: 0.5814, d_k_M range: [0.1726, 0.6462], d_k_M_hat range: [0.6148, 0.9617]
2025-03-11 20:07:07 - Train Iteration 2372: loss: 0.4254, d_k_M range: [0.0045, 0.5811], d_k_M_hat range: [0.3523, 0.9648]
2025-03-11 20:07:08 - Train Iteration 2373: loss: 0.6064, d_k_M range: [0.0753, 0.7695], d_k_M_hat range: [0.4990, 0.9907]
2025-03-11 20:07:08 - Train Iteration 2374: loss: 0.5681, d_k_M range: [0.0082, 0.5628], d_k_M_hat range: [0.2544, 0.9462]
2025-03-11 20:07:09 - Train Iteration 2375: loss: 0.4694, d_k_M range: [0.0176, 0.4077], d_k_M_hat range: [0.3324, 0.7996]
2025-03-11 20:07:09 - Train Iteration 2376: loss: 0.4641, d_k_M range: [0.0516, 0.5718], d_k_M_hat range: [0.4492, 0.9353]
2025-03-11 20:07:09 - Train Iteration 2377: loss: 0.4680, d_k_M range: [0.0268, 0.4999], d_k_M_hat range: [0.4719, 0.9268]
2025-03-11 20:07:10 - Train Iteration 2378: loss: 0.9058, d_k_M range: [0.0006, 0.3574], d_k_M_hat range: [0.0492, 0.7612]
2025-03-11 20:07:10 - Train Iteration 2379: loss: 0.5296, d_k_M range: [0.0678, 0.7152], d_k_M_hat range: [0.5415, 0.9874]
2025-03-11 20:07:11 - Train Iteration 2380: loss: 0.3969, d_k_M range: [0.0236, 0.3667], d_k_M_hat range: [0.4131, 0.8229]
2025-03-11 20:07:11 - Train Iteration 2381: loss: 0.4923, d_k_M range: [0.0494, 0.5678], d_k_M_hat range: [0.4696, 0.9519]
2025-03-11 20:07:11 - Train Iteration 2382: loss: 0.4499, d_k_M range: [0.1681, 0.6498], d_k_M_hat range: [0.5759, 0.9790]
2025-03-11 20:07:12 - Train Iteration 2383: loss: 0.4556, d_k_M range: [0.0425, 0.5906], d_k_M_hat range: [0.5047, 0.9594]
2025-03-11 20:07:12 - Train Iteration 2384: loss: 0.8946, d_k_M range: [0.0012, 0.4618], d_k_M_hat range: [0.0554, 0.8643]
2025-03-11 20:07:13 - Train Iteration 2385: loss: 0.9711, d_k_M range: [0.0077, 0.9845], d_k_M_hat range: [0.4040, 0.9990]
2025-03-11 20:07:13 - Train Iteration 2386: loss: 0.6928, d_k_M range: [0.1388, 0.8257], d_k_M_hat range: [0.5818, 0.9934]
2025-03-11 20:07:13 - Train Iteration 2387: loss: 0.6279, d_k_M range: [0.0003, 0.3687], d_k_M_hat range: [0.2079, 0.7784]
2025-03-11 20:07:14 - Train Iteration 2388: loss: 0.5039, d_k_M range: [0.0384, 0.6827], d_k_M_hat range: [0.3755, 0.9729]
2025-03-11 20:07:14 - Train Iteration 2389: loss: 0.5718, d_k_M range: [0.0025, 0.3669], d_k_M_hat range: [0.2571, 0.7483]
2025-03-11 20:07:15 - Train Iteration 2390: loss: 0.4598, d_k_M range: [0.1353, 0.6130], d_k_M_hat range: [0.5968, 0.9519]
2025-03-11 20:07:15 - Train Iteration 2391: loss: 0.4328, d_k_M range: [0.1822, 0.4738], d_k_M_hat range: [0.5594, 0.8902]
2025-03-11 20:07:15 - Train Iteration 2392: loss: 0.4915, d_k_M range: [0.1804, 0.5073], d_k_M_hat range: [0.5873, 0.8830]
2025-03-11 20:07:16 - Train Iteration 2393: loss: 0.3691, d_k_M range: [0.0265, 0.5341], d_k_M_hat range: [0.4231, 0.9514]
2025-03-11 20:07:16 - Train Iteration 2394: loss: 0.4135, d_k_M range: [0.0269, 0.5285], d_k_M_hat range: [0.4194, 0.8855]
2025-03-11 20:07:17 - Train Iteration 2395: loss: 0.4238, d_k_M range: [0.0495, 0.5512], d_k_M_hat range: [0.4757, 0.9534]
2025-03-11 20:07:17 - Train Iteration 2396: loss: 0.5711, d_k_M range: [0.0014, 0.6330], d_k_M_hat range: [0.2457, 0.9814]
2025-03-11 20:07:18 - Train Iteration 2397: loss: 0.9211, d_k_M range: [0.1490, 0.9589], d_k_M_hat range: [0.6275, 0.9992]
2025-03-11 20:07:18 - Train Iteration 2398: loss: 0.4819, d_k_M range: [0.0710, 0.6331], d_k_M_hat range: [0.5194, 0.9390]
2025-03-11 20:07:18 - Train Iteration 2399: loss: 0.4069, d_k_M range: [0.0073, 0.5564], d_k_M_hat range: [0.3695, 0.9587]
2025-03-11 20:07:19 - Train Iteration 2400: loss: 0.5850, d_k_M range: [0.0056, 0.7527], d_k_M_hat range: [0.2765, 0.9912]
2025-03-11 20:07:19 - Train Iteration 2401: loss: 0.8618, d_k_M range: [0.0008, 0.4810], d_k_M_hat range: [0.0725, 0.9134]
2025-03-11 20:07:20 - Train Iteration 2402: loss: 0.4547, d_k_M range: [0.0113, 0.6442], d_k_M_hat range: [0.4132, 0.9809]
2025-03-11 20:07:20 - Train Iteration 2403: loss: 0.8409, d_k_M range: [0.0860, 0.9108], d_k_M_hat range: [0.5543, 0.9938]
2025-03-11 20:07:20 - Train Iteration 2404: loss: 0.4252, d_k_M range: [0.1137, 0.6372], d_k_M_hat range: [0.5332, 0.9851]
2025-03-11 20:07:21 - Train Iteration 2405: loss: 0.3934, d_k_M range: [0.0226, 0.5028], d_k_M_hat range: [0.4248, 0.9080]
2025-03-11 20:07:21 - Train Iteration 2406: loss: 0.5129, d_k_M range: [0.0900, 0.3025], d_k_M_hat range: [0.5011, 0.8286]
2025-03-11 20:07:22 - Train Iteration 2407: loss: 0.4598, d_k_M range: [0.1665, 0.6561], d_k_M_hat range: [0.5163, 0.9781]
2025-03-11 20:07:22 - Train Iteration 2408: loss: 0.7454, d_k_M range: [0.0036, 0.3185], d_k_M_hat range: [0.1410, 0.7607]
2025-03-11 20:07:22 - Train Iteration 2409: loss: 0.5328, d_k_M range: [0.3232, 0.7100], d_k_M_hat range: [0.7543, 0.9800]
2025-03-11 20:07:23 - Train Iteration 2410: loss: 0.4201, d_k_M range: [0.0668, 0.3361], d_k_M_hat range: [0.4205, 0.8398]
2025-03-11 20:07:23 - Train Iteration 2411: loss: 0.4235, d_k_M range: [0.1148, 0.4877], d_k_M_hat range: [0.5677, 0.8992]
2025-03-11 20:07:24 - Train Iteration 2412: loss: 0.4786, d_k_M range: [0.0893, 0.6117], d_k_M_hat range: [0.5478, 0.9198]
2025-03-11 20:07:24 - Train Iteration 2413: loss: 0.4299, d_k_M range: [0.0337, 0.5331], d_k_M_hat range: [0.3781, 0.9303]
2025-03-11 20:07:24 - Train Iteration 2414: loss: 0.4642, d_k_M range: [0.0111, 0.2549], d_k_M_hat range: [0.3297, 0.6636]
2025-03-11 20:07:25 - Train Iteration 2415: loss: 0.9404, d_k_M range: [0.3497, 0.9667], d_k_M_hat range: [0.7434, 0.9970]
2025-03-11 20:07:25 - Train Iteration 2416: loss: 0.5709, d_k_M range: [0.0129, 0.7396], d_k_M_hat range: [0.3432, 0.9841]
2025-03-11 20:07:26 - Train Iteration 2417: loss: 0.4884, d_k_M range: [0.0040, 0.4493], d_k_M_hat range: [0.3051, 0.8677]
2025-03-11 20:07:26 - Train Iteration 2418: loss: 0.7121, d_k_M range: [0.1466, 0.8394], d_k_M_hat range: [0.5467, 0.9956]
2025-03-11 20:07:27 - Train Iteration 2419: loss: 0.4311, d_k_M range: [0.0192, 0.3517], d_k_M_hat range: [0.3836, 0.6969]
2025-03-11 20:07:27 - Train Iteration 2420: loss: 0.5080, d_k_M range: [0.2007, 0.5705], d_k_M_hat range: [0.6765, 0.9591]
2025-03-11 20:07:27 - Train Iteration 2421: loss: 0.6674, d_k_M range: [0.0443, 0.8118], d_k_M_hat range: [0.4484, 0.9949]
2025-03-11 20:07:28 - Train Iteration 2422: loss: 0.4235, d_k_M range: [0.0117, 0.3424], d_k_M_hat range: [0.3610, 0.7301]
2025-03-11 20:07:28 - Train Iteration 2423: loss: 0.7764, d_k_M range: [0.0040, 0.7078], d_k_M_hat range: [0.1229, 0.9822]
2025-03-11 20:07:29 - Train Iteration 2424: loss: 0.5189, d_k_M range: [0.1826, 0.7101], d_k_M_hat range: [0.4988, 0.9898]
2025-03-11 20:07:29 - Train Iteration 2425: loss: 0.4368, d_k_M range: [0.1285, 0.5802], d_k_M_hat range: [0.5328, 0.9709]
2025-03-11 20:07:29 - Train Iteration 2426: loss: 0.9239, d_k_M range: [0.0010, 0.9598], d_k_M_hat range: [0.2596, 0.9986]
2025-03-11 20:07:30 - Train Iteration 2427: loss: 0.8761, d_k_M range: [0.0003, 0.6177], d_k_M_hat range: [0.0643, 0.9570]
2025-03-11 20:07:30 - Train Iteration 2428: loss: 0.4365, d_k_M range: [0.0888, 0.4672], d_k_M_hat range: [0.4586, 0.8876]
2025-03-11 20:07:31 - Train Iteration 2429: loss: 0.4423, d_k_M range: [0.0665, 0.6136], d_k_M_hat range: [0.4479, 0.9583]
2025-03-11 20:07:31 - Train Iteration 2430: loss: 0.7175, d_k_M range: [0.0025, 0.2268], d_k_M_hat range: [0.1554, 0.5959]
2025-03-11 20:07:32 - Train Iteration 2431: loss: 0.5380, d_k_M range: [0.0054, 0.3282], d_k_M_hat range: [0.2719, 0.7279]
2025-03-11 20:07:32 - Train Iteration 2432: loss: 0.3788, d_k_M range: [0.2324, 0.5477], d_k_M_hat range: [0.6553, 0.9574]
2025-03-11 20:07:32 - Train Iteration 2433: loss: 0.5298, d_k_M range: [0.0227, 0.3333], d_k_M_hat range: [0.2949, 0.6959]
2025-03-11 20:07:33 - Train Iteration 2434: loss: 0.6401, d_k_M range: [0.0250, 0.7832], d_k_M_hat range: [0.3953, 0.9831]
2025-03-11 20:07:33 - Train Iteration 2435: loss: 0.4103, d_k_M range: [0.0384, 0.3967], d_k_M_hat range: [0.4240, 0.7562]
2025-03-11 20:07:34 - Train Iteration 2436: loss: 0.3872, d_k_M range: [0.0303, 0.3363], d_k_M_hat range: [0.4341, 0.7964]
2025-03-11 20:07:34 - Train Iteration 2437: loss: 0.5412, d_k_M range: [0.0639, 0.7152], d_k_M_hat range: [0.5047, 0.9795]
2025-03-11 20:07:34 - Train Iteration 2438: loss: 0.4912, d_k_M range: [0.0119, 0.4187], d_k_M_hat range: [0.3980, 0.7178]
2025-03-11 20:07:35 - Train Iteration 2439: loss: 0.4271, d_k_M range: [0.0573, 0.5523], d_k_M_hat range: [0.4960, 0.9164]
2025-03-11 20:07:35 - Train Iteration 2440: loss: 0.6415, d_k_M range: [0.1261, 0.7854], d_k_M_hat range: [0.5276, 0.9845]
2025-03-11 20:07:36 - Train Iteration 2441: loss: 0.4286, d_k_M range: [0.0104, 0.4419], d_k_M_hat range: [0.3631, 0.8813]
2025-03-11 20:07:36 - Train Iteration 2442: loss: 0.5619, d_k_M range: [0.0095, 0.6634], d_k_M_hat range: [0.2599, 0.9882]
2025-03-11 20:07:37 - Train Iteration 2443: loss: 0.4222, d_k_M range: [0.2626, 0.6279], d_k_M_hat range: [0.6587, 0.9782]
2025-03-11 20:07:37 - Train Iteration 2444: loss: 0.7876, d_k_M range: [0.0004, 0.3387], d_k_M_hat range: [0.1129, 0.6901]
2025-03-11 20:07:37 - Train Iteration 2445: loss: 0.4940, d_k_M range: [0.1353, 0.6570], d_k_M_hat range: [0.4674, 0.9541]
2025-03-11 20:07:38 - Train Iteration 2446: loss: 0.5715, d_k_M range: [0.0600, 0.3036], d_k_M_hat range: [0.3143, 0.6771]
2025-03-11 20:07:38 - Train Iteration 2447: loss: 0.4976, d_k_M range: [0.0228, 0.4902], d_k_M_hat range: [0.3174, 0.8576]
2025-03-11 20:07:39 - Train Iteration 2448: loss: 0.4955, d_k_M range: [0.0429, 0.6743], d_k_M_hat range: [0.3939, 0.9704]
2025-03-11 20:07:39 - Train Iteration 2449: loss: 0.4807, d_k_M range: [0.0194, 0.4431], d_k_M_hat range: [0.3334, 0.8153]
2025-03-11 20:07:40 - Train Iteration 2450: loss: 0.4637, d_k_M range: [0.1527, 0.3768], d_k_M_hat range: [0.5699, 0.7323]
2025-03-11 20:07:40 - Train Iteration 2451: loss: 0.4354, d_k_M range: [0.1800, 0.6025], d_k_M_hat range: [0.5785, 0.9519]
2025-03-11 20:07:40 - Train Iteration 2452: loss: 0.4194, d_k_M range: [0.0961, 0.3798], d_k_M_hat range: [0.5369, 0.7818]
2025-03-11 20:07:41 - Train Iteration 2453: loss: 0.4972, d_k_M range: [0.0054, 0.3744], d_k_M_hat range: [0.3004, 0.7855]
2025-03-11 20:07:41 - Train Iteration 2454: loss: 0.4946, d_k_M range: [0.0837, 0.6044], d_k_M_hat range: [0.4627, 0.9511]
2025-03-11 20:07:42 - Train Iteration 2455: loss: 0.6172, d_k_M range: [0.3333, 0.7727], d_k_M_hat range: [0.7369, 0.9875]
2025-03-11 20:07:42 - Train Iteration 2456: loss: 0.4484, d_k_M range: [0.0102, 0.4082], d_k_M_hat range: [0.3958, 0.7715]
2025-03-11 20:07:42 - Train Iteration 2457: loss: 0.4711, d_k_M range: [0.1775, 0.4855], d_k_M_hat range: [0.4944, 0.8871]
2025-03-11 20:07:43 - Train Iteration 2458: loss: 0.8095, d_k_M range: [0.1529, 0.8944], d_k_M_hat range: [0.5873, 0.9947]
2025-03-11 20:07:43 - Train Iteration 2459: loss: 0.4011, d_k_M range: [0.0675, 0.4787], d_k_M_hat range: [0.5466, 0.8607]
2025-03-11 20:07:44 - Train Iteration 2460: loss: 0.8021, d_k_M range: [0.2869, 0.8917], d_k_M_hat range: [0.7201, 0.9961]
2025-03-11 20:07:44 - Train Iteration 2461: loss: 0.4556, d_k_M range: [0.0930, 0.4079], d_k_M_hat range: [0.4593, 0.7855]
2025-03-11 20:07:45 - Train Iteration 2462: loss: 0.4447, d_k_M range: [0.1067, 0.5818], d_k_M_hat range: [0.4911, 0.9586]
2025-03-11 20:07:45 - Train Iteration 2463: loss: 0.4802, d_k_M range: [0.1331, 0.6274], d_k_M_hat range: [0.5360, 0.9877]
2025-03-11 20:07:46 - Train Iteration 2464: loss: 0.5384, d_k_M range: [0.0844, 0.7076], d_k_M_hat range: [0.5653, 0.9750]
2025-03-11 20:07:46 - Train Iteration 2465: loss: 0.4664, d_k_M range: [0.1462, 0.6719], d_k_M_hat range: [0.5656, 0.9890]
2025-03-11 20:07:46 - Train Iteration 2466: loss: 0.9409, d_k_M range: [0.0004, 0.5141], d_k_M_hat range: [0.0304, 0.9541]
2025-03-11 20:07:47 - Train Iteration 2467: loss: 0.4330, d_k_M range: [0.0850, 0.4289], d_k_M_hat range: [0.5390, 0.9274]
2025-03-11 20:07:47 - Train Iteration 2468: loss: 0.5647, d_k_M range: [0.0038, 0.2730], d_k_M_hat range: [0.2595, 0.6917]
2025-03-11 20:07:48 - Train Iteration 2469: loss: 0.4110, d_k_M range: [0.2234, 0.4801], d_k_M_hat range: [0.6380, 0.9511]
2025-03-11 20:07:48 - Train Iteration 2470: loss: 0.3966, d_k_M range: [0.0092, 0.4147], d_k_M_hat range: [0.3849, 0.8172]
2025-03-11 20:07:48 - Train Iteration 2471: loss: 0.4455, d_k_M range: [0.1912, 0.5660], d_k_M_hat range: [0.5455, 0.9608]
2025-03-11 20:07:49 - Train Iteration 2472: loss: 0.5372, d_k_M range: [0.0090, 0.7222], d_k_M_hat range: [0.3722, 0.9893]
2025-03-11 20:07:49 - Train Iteration 2473: loss: 0.7423, d_k_M range: [0.0003, 0.7441], d_k_M_hat range: [0.1387, 0.9902]
2025-03-11 20:07:50 - Train Iteration 2474: loss: 0.4686, d_k_M range: [0.0052, 0.4406], d_k_M_hat range: [0.3217, 0.8994]
2025-03-11 20:07:50 - Train Iteration 2475: loss: 0.4701, d_k_M range: [0.0989, 0.5646], d_k_M_hat range: [0.4132, 0.9731]
2025-03-11 20:07:50 - Train Iteration 2476: loss: 0.3734, d_k_M range: [0.0224, 0.3493], d_k_M_hat range: [0.4260, 0.8264]
2025-03-11 20:07:51 - Train Iteration 2477: loss: 0.5031, d_k_M range: [0.1400, 0.6862], d_k_M_hat range: [0.6132, 0.9769]
2025-03-11 20:07:51 - Train Iteration 2478: loss: 0.4223, d_k_M range: [0.0328, 0.5842], d_k_M_hat range: [0.3887, 0.9600]
2025-03-11 20:07:52 - Train Iteration 2479: loss: 0.4943, d_k_M range: [0.1810, 0.6384], d_k_M_hat range: [0.6563, 0.9855]
2025-03-11 20:07:52 - Train Iteration 2480: loss: 0.4734, d_k_M range: [0.0093, 0.5230], d_k_M_hat range: [0.3213, 0.9829]
2025-03-11 20:07:53 - Train Iteration 2481: loss: 0.4762, d_k_M range: [0.0076, 0.5177], d_k_M_hat range: [0.3175, 0.9046]
2025-03-11 20:07:53 - Train Iteration 2482: loss: 0.5620, d_k_M range: [0.0098, 0.2498], d_k_M_hat range: [0.2624, 0.6505]
2025-03-11 20:07:53 - Train Iteration 2483: loss: 0.5099, d_k_M range: [0.3571, 0.7050], d_k_M_hat range: [0.8093, 0.9944]
2025-03-11 20:07:54 - Train Iteration 2484: loss: 0.4776, d_k_M range: [0.0091, 0.4102], d_k_M_hat range: [0.3180, 0.7970]
2025-03-11 20:07:54 - Train Iteration 2485: loss: 0.4211, d_k_M range: [0.1333, 0.3163], d_k_M_hat range: [0.4844, 0.7304]
2025-03-11 20:07:55 - Train Iteration 2486: loss: 0.3444, d_k_M range: [0.0386, 0.4602], d_k_M_hat range: [0.4908, 0.8789]
2025-03-11 20:07:55 - Train Iteration 2487: loss: 0.4895, d_k_M range: [0.0186, 0.3484], d_k_M_hat range: [0.3492, 0.7798]
2025-03-11 20:07:56 - Train Iteration 2488: loss: 0.4602, d_k_M range: [0.1380, 0.6669], d_k_M_hat range: [0.5311, 0.9885]
2025-03-11 20:07:56 - Train Iteration 2489: loss: 0.5110, d_k_M range: [0.0105, 0.3421], d_k_M_hat range: [0.3464, 0.7300]
2025-03-11 20:07:56 - Train Iteration 2490: loss: 0.5021, d_k_M range: [0.0091, 0.7000], d_k_M_hat range: [0.3428, 0.9913]
2025-03-11 20:07:57 - Train Iteration 2491: loss: 0.4558, d_k_M range: [0.2295, 0.5837], d_k_M_hat range: [0.5544, 0.9397]
2025-03-11 20:07:57 - Train Iteration 2492: loss: 0.5460, d_k_M range: [0.0014, 0.4397], d_k_M_hat range: [0.2625, 0.8870]
2025-03-11 20:07:58 - Train Iteration 2493: loss: 0.5048, d_k_M range: [0.0628, 0.5678], d_k_M_hat range: [0.5248, 0.9501]
2025-03-11 20:07:58 - Train Iteration 2494: loss: 0.4987, d_k_M range: [0.1171, 0.6822], d_k_M_hat range: [0.5252, 0.9760]
2025-03-11 20:07:58 - Train Iteration 2495: loss: 0.4294, d_k_M range: [0.0807, 0.5150], d_k_M_hat range: [0.4254, 0.9299]
2025-03-11 20:07:59 - Train Iteration 2496: loss: 0.4970, d_k_M range: [0.0011, 0.3164], d_k_M_hat range: [0.2962, 0.7741]
2025-03-11 20:07:59 - Train Iteration 2497: loss: 0.4672, d_k_M range: [0.1250, 0.6685], d_k_M_hat range: [0.6112, 0.9849]
2025-03-11 20:08:00 - Train Iteration 2498: loss: 0.5011, d_k_M range: [0.0021, 0.2961], d_k_M_hat range: [0.2942, 0.7056]
2025-03-11 20:08:00 - Train Iteration 2499: loss: 0.4243, d_k_M range: [0.0551, 0.5954], d_k_M_hat range: [0.4977, 0.9717]
2025-03-11 20:08:01 - Train Iteration 2500: loss: 0.6430, d_k_M range: [0.0048, 0.3185], d_k_M_hat range: [0.2247, 0.6708]
2025-03-11 20:08:01 - Train Iteration 2501: loss: 0.4467, d_k_M range: [0.0376, 0.6354], d_k_M_hat range: [0.4233, 0.9670]
2025-03-11 20:08:01 - Train Iteration 2502: loss: 0.5102, d_k_M range: [0.0341, 0.4438], d_k_M_hat range: [0.5299, 0.8385]
2025-03-11 20:08:02 - Train Iteration 2503: loss: 0.4342, d_k_M range: [0.0304, 0.5123], d_k_M_hat range: [0.4727, 0.8725]
2025-03-11 20:08:02 - Train Iteration 2504: loss: 0.4026, d_k_M range: [0.0191, 0.5770], d_k_M_hat range: [0.4842, 0.9425]
2025-03-11 20:08:03 - Train Iteration 2505: loss: 0.3970, d_k_M range: [0.0212, 0.5832], d_k_M_hat range: [0.3938, 0.9531]
2025-03-11 20:08:03 - Train Iteration 2506: loss: 0.4564, d_k_M range: [0.0056, 0.5797], d_k_M_hat range: [0.3976, 0.9041]
2025-03-11 20:08:04 - Train Iteration 2507: loss: 0.5055, d_k_M range: [0.0056, 0.3657], d_k_M_hat range: [0.2946, 0.8283]
2025-03-11 20:08:04 - Train Iteration 2508: loss: 0.4687, d_k_M range: [0.0209, 0.6636], d_k_M_hat range: [0.3787, 0.9790]
2025-03-11 20:08:04 - Train Iteration 2509: loss: 0.5775, d_k_M range: [0.0211, 0.7450], d_k_M_hat range: [0.3942, 0.9850]
2025-03-11 20:08:05 - Train Iteration 2510: loss: 0.4836, d_k_M range: [0.0090, 0.5942], d_k_M_hat range: [0.3136, 0.9372]
2025-03-11 20:08:05 - Train Iteration 2511: loss: 0.3877, d_k_M range: [0.1596, 0.5639], d_k_M_hat range: [0.5980, 0.9702]
2025-03-11 20:08:06 - Train Iteration 2512: loss: 0.8960, d_k_M range: [0.0002, 0.3457], d_k_M_hat range: [0.0537, 0.7049]
2025-03-11 20:08:06 - Train Iteration 2513: loss: 0.4025, d_k_M range: [0.0601, 0.5598], d_k_M_hat range: [0.5301, 0.9254]
2025-03-11 20:08:07 - Train Iteration 2514: loss: 0.4626, d_k_M range: [0.0250, 0.4497], d_k_M_hat range: [0.4236, 0.9009]
2025-03-11 20:08:07 - Train Iteration 2515: loss: 0.4247, d_k_M range: [0.0127, 0.4792], d_k_M_hat range: [0.3738, 0.8659]
2025-03-11 20:08:08 - Train Iteration 2516: loss: 0.4059, d_k_M range: [0.1521, 0.4004], d_k_M_hat range: [0.5908, 0.8695]
2025-03-11 20:08:08 - Train Iteration 2517: loss: 0.5327, d_k_M range: [0.0035, 0.5728], d_k_M_hat range: [0.2736, 0.9761]
2025-03-11 20:08:08 - Train Iteration 2518: loss: 0.4108, d_k_M range: [0.0844, 0.4973], d_k_M_hat range: [0.5106, 0.9030]
2025-03-11 20:08:09 - Train Iteration 2519: loss: 0.6529, d_k_M range: [0.0058, 0.8004], d_k_M_hat range: [0.4007, 0.9924]
2025-03-11 20:08:09 - Train Iteration 2520: loss: 0.3897, d_k_M range: [0.0216, 0.3059], d_k_M_hat range: [0.4311, 0.6961]
2025-03-11 20:08:10 - Train Iteration 2521: loss: 0.4529, d_k_M range: [0.2133, 0.6454], d_k_M_hat range: [0.6464, 0.9724]
2025-03-11 20:08:10 - Train Iteration 2522: loss: 0.4900, d_k_M range: [0.0540, 0.6756], d_k_M_hat range: [0.4868, 0.9756]
2025-03-11 20:08:10 - Train Iteration 2523: loss: 0.4444, d_k_M range: [0.1189, 0.5129], d_k_M_hat range: [0.5457, 0.9241]
2025-03-11 20:08:11 - Train Iteration 2524: loss: 0.8044, d_k_M range: [0.2254, 0.8854], d_k_M_hat range: [0.6354, 0.9886]
2025-03-11 20:08:11 - Train Iteration 2525: loss: 0.4519, d_k_M range: [0.0105, 0.2693], d_k_M_hat range: [0.3437, 0.6753]
2025-03-11 20:08:12 - Train Iteration 2526: loss: 0.4005, d_k_M range: [0.0068, 0.5552], d_k_M_hat range: [0.4355, 0.9500]
2025-03-11 20:08:12 - Train Iteration 2527: loss: 0.3955, d_k_M range: [0.0108, 0.3608], d_k_M_hat range: [0.3818, 0.8026]
2025-03-11 20:08:13 - Train Iteration 2528: loss: 0.4851, d_k_M range: [0.0532, 0.6701], d_k_M_hat range: [0.4611, 0.9736]
2025-03-11 20:08:13 - Train Iteration 2529: loss: 0.5611, d_k_M range: [0.0023, 0.7173], d_k_M_hat range: [0.3001, 0.9682]
2025-03-11 20:08:13 - Train Iteration 2530: loss: 0.4464, d_k_M range: [0.0077, 0.4831], d_k_M_hat range: [0.3762, 0.8493]
2025-03-11 20:08:14 - Train Iteration 2531: loss: 0.4981, d_k_M range: [0.0334, 0.4498], d_k_M_hat range: [0.4519, 0.8568]
2025-03-11 20:08:14 - Train Iteration 2532: loss: 0.4509, d_k_M range: [0.0369, 0.5778], d_k_M_hat range: [0.4251, 0.9416]
2025-03-11 20:08:15 - Train Iteration 2533: loss: 0.4806, d_k_M range: [0.0020, 0.5828], d_k_M_hat range: [0.3087, 0.9470]
2025-03-11 20:08:15 - Train Iteration 2534: loss: 0.4004, d_k_M range: [0.0128, 0.5140], d_k_M_hat range: [0.4845, 0.9124]
2025-03-11 20:08:15 - Train Iteration 2535: loss: 0.5080, d_k_M range: [0.0051, 0.4966], d_k_M_hat range: [0.2924, 0.7951]
2025-03-11 20:08:16 - Train Iteration 2536: loss: 0.4636, d_k_M range: [0.1531, 0.6660], d_k_M_hat range: [0.5582, 0.9851]
2025-03-11 20:08:16 - Train Iteration 2537: loss: 0.4457, d_k_M range: [0.0187, 0.3502], d_k_M_hat range: [0.3511, 0.7636]
2025-03-11 20:08:17 - Train Iteration 2538: loss: 0.3910, d_k_M range: [0.0581, 0.4600], d_k_M_hat range: [0.5490, 0.9143]
2025-03-11 20:08:17 - Train Iteration 2539: loss: 0.4398, d_k_M range: [0.0051, 0.3420], d_k_M_hat range: [0.3418, 0.7183]
2025-03-11 20:08:17 - Train Iteration 2540: loss: 0.4352, d_k_M range: [0.0275, 0.3914], d_k_M_hat range: [0.4529, 0.7874]
2025-03-11 20:08:18 - Train Iteration 2541: loss: 0.6192, d_k_M range: [0.0040, 0.4087], d_k_M_hat range: [0.2171, 0.7392]
2025-03-11 20:08:18 - Train Iteration 2542: loss: 0.6657, d_k_M range: [0.3174, 0.8046], d_k_M_hat range: [0.7606, 0.9887]
2025-03-11 20:08:19 - Train Iteration 2543: loss: 0.4189, d_k_M range: [0.0336, 0.4643], d_k_M_hat range: [0.4290, 0.8171]
2025-03-11 20:08:19 - Train Iteration 2544: loss: 0.6840, d_k_M range: [0.0067, 0.8192], d_k_M_hat range: [0.2426, 0.9921]
2025-03-11 20:08:19 - Train Iteration 2545: loss: 0.9411, d_k_M range: [0.0003, 0.3137], d_k_M_hat range: [0.0302, 0.6851]
2025-03-11 20:08:20 - Train Iteration 2546: loss: 0.8935, d_k_M range: [0.0001, 0.3313], d_k_M_hat range: [0.0548, 0.7520]
2025-03-11 20:08:20 - Train Iteration 2547: loss: 0.4391, d_k_M range: [0.0352, 0.5422], d_k_M_hat range: [0.4171, 0.9023]
2025-03-11 20:08:21 - Train Iteration 2548: loss: 0.5766, d_k_M range: [0.0539, 0.7522], d_k_M_hat range: [0.4733, 0.9929]
2025-03-11 20:08:21 - Train Iteration 2549: loss: 0.6103, d_k_M range: [0.0018, 0.1641], d_k_M_hat range: [0.2206, 0.6478]
2025-03-11 20:08:22 - Train Iteration 2550: loss: 0.7483, d_k_M range: [0.0144, 0.4938], d_k_M_hat range: [0.1494, 0.8460]
2025-03-11 20:08:22 - Train Iteration 2551: loss: 0.4677, d_k_M range: [0.0174, 0.6158], d_k_M_hat range: [0.3443, 0.9327]
2025-03-11 20:08:22 - Train Iteration 2552: loss: 0.6784, d_k_M range: [0.0080, 0.8118], d_k_M_hat range: [0.3471, 0.9881]
2025-03-11 20:08:23 - Train Iteration 2553: loss: 0.4628, d_k_M range: [0.0325, 0.3421], d_k_M_hat range: [0.3522, 0.6735]
2025-03-11 20:08:23 - Train Iteration 2554: loss: 0.5682, d_k_M range: [0.0246, 0.4925], d_k_M_hat range: [0.2801, 0.8556]
2025-03-11 20:08:24 - Train Iteration 2555: loss: 0.4691, d_k_M range: [0.0536, 0.6228], d_k_M_hat range: [0.3838, 0.9379]
2025-03-11 20:08:24 - Train Iteration 2556: loss: 0.4271, d_k_M range: [0.0078, 0.3751], d_k_M_hat range: [0.4082, 0.7880]
2025-03-11 20:08:24 - Train Iteration 2557: loss: 0.5814, d_k_M range: [0.0033, 0.2775], d_k_M_hat range: [0.2412, 0.6799]
2025-03-11 20:08:25 - Train Iteration 2558: loss: 0.4147, d_k_M range: [0.0803, 0.5440], d_k_M_hat range: [0.4688, 0.9000]
2025-03-11 20:08:25 - Train Iteration 2559: loss: 0.4002, d_k_M range: [0.0550, 0.5519], d_k_M_hat range: [0.4659, 0.9405]
2025-03-11 20:08:26 - Train Iteration 2560: loss: 0.4335, d_k_M range: [0.0117, 0.6383], d_k_M_hat range: [0.4195, 0.9849]
2025-03-11 20:08:26 - Train Iteration 2561: loss: 0.7674, d_k_M range: [0.0078, 0.6965], d_k_M_hat range: [0.1318, 0.9876]
2025-03-11 20:08:27 - Train Iteration 2562: loss: 0.4593, d_k_M range: [0.0057, 0.5274], d_k_M_hat range: [0.3279, 0.8745]
2025-03-11 20:08:27 - Train Iteration 2563: loss: 0.5316, d_k_M range: [0.0367, 0.5676], d_k_M_hat range: [0.4497, 0.9331]
2025-03-11 20:08:27 - Train Iteration 2564: loss: 0.5082, d_k_M range: [0.0125, 0.6051], d_k_M_hat range: [0.2997, 0.9576]
2025-03-11 20:08:28 - Train Iteration 2565: loss: 0.4433, d_k_M range: [0.0134, 0.4192], d_k_M_hat range: [0.3476, 0.7836]
2025-03-11 20:08:28 - Train Iteration 2566: loss: 0.5222, d_k_M range: [0.2448, 0.6539], d_k_M_hat range: [0.6994, 0.9722]
2025-03-11 20:08:29 - Train Iteration 2567: loss: 0.7364, d_k_M range: [0.0984, 0.8498], d_k_M_hat range: [0.5503, 0.9916]
2025-03-11 20:08:29 - Train Iteration 2568: loss: 0.6884, d_k_M range: [0.0032, 0.4564], d_k_M_hat range: [0.1736, 0.8556]
2025-03-11 20:08:30 - Train Iteration 2569: loss: 0.4818, d_k_M range: [0.0710, 0.4779], d_k_M_hat range: [0.4348, 0.8678]
2025-03-11 20:08:30 - Train Iteration 2570: loss: 0.5253, d_k_M range: [0.0105, 0.5951], d_k_M_hat range: [0.2857, 0.9343]
2025-03-11 20:08:30 - Train Iteration 2571: loss: 0.4273, d_k_M range: [0.0247, 0.4726], d_k_M_hat range: [0.4920, 0.8741]
2025-03-11 20:08:31 - Train Iteration 2572: loss: 0.5593, d_k_M range: [0.0345, 0.3676], d_k_M_hat range: [0.2867, 0.7069]
2025-03-11 20:08:31 - Train Iteration 2573: loss: 0.4257, d_k_M range: [0.0109, 0.5835], d_k_M_hat range: [0.3783, 0.9453]
2025-03-11 20:08:32 - Train Iteration 2574: loss: 0.4512, d_k_M range: [0.0147, 0.6427], d_k_M_hat range: [0.3763, 0.9710]
2025-03-11 20:08:32 - Train Iteration 2575: loss: 0.4703, d_k_M range: [0.0315, 0.6553], d_k_M_hat range: [0.4115, 0.9695]
2025-03-11 20:08:32 - Train Iteration 2576: loss: 0.4229, d_k_M range: [0.0184, 0.4192], d_k_M_hat range: [0.3835, 0.8405]
2025-03-11 20:08:33 - Train Iteration 2577: loss: 0.4997, d_k_M range: [0.0081, 0.3448], d_k_M_hat range: [0.3012, 0.7978]
2025-03-11 20:08:33 - Train Iteration 2578: loss: 0.4321, d_k_M range: [0.0136, 0.5808], d_k_M_hat range: [0.3563, 0.9615]
2025-03-11 20:08:34 - Train Iteration 2579: loss: 0.4801, d_k_M range: [0.0121, 0.6217], d_k_M_hat range: [0.4394, 0.9289]
2025-03-11 20:08:34 - Train Iteration 2580: loss: 0.4613, d_k_M range: [0.0790, 0.6317], d_k_M_hat range: [0.5305, 0.9525]
2025-03-11 20:08:35 - Train Iteration 2581: loss: 0.5663, d_k_M range: [0.0584, 0.7353], d_k_M_hat range: [0.4975, 0.9828]
2025-03-11 20:08:35 - Train Iteration 2582: loss: 0.4204, d_k_M range: [0.0648, 0.4409], d_k_M_hat range: [0.5351, 0.8394]
2025-03-11 20:08:36 - Train Iteration 2583: loss: 0.3797, d_k_M range: [0.0093, 0.5830], d_k_M_hat range: [0.3931, 0.9706]
2025-03-11 20:08:36 - Train Iteration 2584: loss: 0.5157, d_k_M range: [0.0014, 0.1748], d_k_M_hat range: [0.2833, 0.6273]
2025-03-11 20:08:36 - Train Iteration 2585: loss: 0.6841, d_k_M range: [0.2274, 0.8182], d_k_M_hat range: [0.6479, 0.9910]
2025-03-11 20:08:37 - Train Iteration 2586: loss: 0.4547, d_k_M range: [0.1102, 0.4741], d_k_M_hat range: [0.5571, 0.8825]
2025-03-11 20:08:37 - Train Iteration 2587: loss: 0.7286, d_k_M range: [0.0015, 0.5276], d_k_M_hat range: [0.1479, 0.8940]
2025-03-11 20:08:38 - Train Iteration 2588: loss: 0.4600, d_k_M range: [0.0060, 0.6628], d_k_M_hat range: [0.4349, 0.9846]
2025-03-11 20:08:38 - Train Iteration 2589: loss: 0.4557, d_k_M range: [0.0166, 0.6298], d_k_M_hat range: [0.3415, 0.9787]
2025-03-11 20:08:39 - Train Iteration 2590: loss: 0.5384, d_k_M range: [0.2917, 0.7248], d_k_M_hat range: [0.6535, 0.9911]
2025-03-11 20:08:39 - Train Iteration 2591: loss: 0.3995, d_k_M range: [0.0533, 0.5028], d_k_M_hat range: [0.4821, 0.8832]
2025-03-11 20:08:39 - Train Iteration 2592: loss: 0.9251, d_k_M range: [0.0005, 0.6139], d_k_M_hat range: [0.0386, 0.9593]
2025-03-11 20:08:40 - Train Iteration 2593: loss: 0.4994, d_k_M range: [0.0112, 0.6371], d_k_M_hat range: [0.3355, 0.9304]
2025-03-11 20:08:40 - Train Iteration 2594: loss: 0.4709, d_k_M range: [0.0054, 0.4531], d_k_M_hat range: [0.3191, 0.8803]
2025-03-11 20:08:41 - Train Iteration 2595: loss: 0.7111, d_k_M range: [0.0020, 0.7783], d_k_M_hat range: [0.1587, 0.9930]
2025-03-11 20:08:41 - Train Iteration 2596: loss: 0.3812, d_k_M range: [0.0436, 0.5759], d_k_M_hat range: [0.4917, 0.9585]
2025-03-11 20:08:41 - Train Iteration 2597: loss: 0.5172, d_k_M range: [0.1100, 0.4420], d_k_M_hat range: [0.3908, 0.8982]
2025-03-11 20:08:42 - Train Iteration 2598: loss: 0.7209, d_k_M range: [0.3149, 0.8435], d_k_M_hat range: [0.7539, 0.9944]
2025-03-11 20:08:42 - Train Iteration 2599: loss: 0.6760, d_k_M range: [0.0012, 0.1909], d_k_M_hat range: [0.1790, 0.6675]
2025-03-11 20:08:43 - Train Iteration 2600: loss: 0.5356, d_k_M range: [0.0548, 0.6918], d_k_M_hat range: [0.5092, 0.9600]
2025-03-11 20:08:43 - Train Iteration 2601: loss: 0.5358, d_k_M range: [0.0034, 0.4685], d_k_M_hat range: [0.2714, 0.8381]
2025-03-11 20:08:43 - Train Iteration 2602: loss: 0.4085, d_k_M range: [0.1556, 0.4832], d_k_M_hat range: [0.5759, 0.8457]
2025-03-11 20:08:44 - Train Iteration 2603: loss: 0.4320, d_k_M range: [0.0097, 0.4122], d_k_M_hat range: [0.3932, 0.8539]
2025-03-11 20:08:44 - Train Iteration 2604: loss: 0.4724, d_k_M range: [0.1479, 0.6772], d_k_M_hat range: [0.5957, 0.9899]
2025-03-11 20:08:45 - Train Iteration 2605: loss: 0.7097, d_k_M range: [0.0017, 0.8389], d_k_M_hat range: [0.2260, 0.9965]
2025-03-11 20:08:45 - Train Iteration 2606: loss: 0.6190, d_k_M range: [0.0045, 0.4296], d_k_M_hat range: [0.2178, 0.8313]
2025-03-11 20:08:46 - Train Iteration 2607: loss: 0.5422, d_k_M range: [0.0823, 0.7242], d_k_M_hat range: [0.4782, 0.9878]
2025-03-11 20:08:46 - Train Iteration 2608: loss: 0.5600, d_k_M range: [0.1299, 0.5931], d_k_M_hat range: [0.3816, 0.9115]
2025-03-11 20:08:46 - Train Iteration 2609: loss: 0.4435, d_k_M range: [0.0348, 0.5482], d_k_M_hat range: [0.5116, 0.9385]
2025-03-11 20:08:47 - Train Iteration 2610: loss: 0.3943, d_k_M range: [0.0258, 0.5393], d_k_M_hat range: [0.4445, 0.9113]
2025-03-11 20:08:47 - Train Iteration 2611: loss: 0.4329, d_k_M range: [0.0530, 0.6032], d_k_M_hat range: [0.4127, 0.9641]
2025-03-11 20:08:48 - Train Iteration 2612: loss: 0.4648, d_k_M range: [0.0140, 0.3919], d_k_M_hat range: [0.3323, 0.9249]
2025-03-11 20:08:48 - Train Iteration 2613: loss: 0.8643, d_k_M range: [0.0204, 0.9276], d_k_M_hat range: [0.4223, 0.9980]
2025-03-11 20:08:48 - Train Iteration 2614: loss: 0.3662, d_k_M range: [0.0155, 0.3501], d_k_M_hat range: [0.4582, 0.8486]
2025-03-11 20:08:49 - Train Iteration 2615: loss: 0.3530, d_k_M range: [0.2885, 0.4770], d_k_M_hat range: [0.7050, 0.8998]
2025-03-11 20:08:49 - Train Iteration 2616: loss: 0.4431, d_k_M range: [0.0760, 0.6559], d_k_M_hat range: [0.5175, 0.9903]
2025-03-11 20:08:50 - Train Iteration 2617: loss: 0.4219, d_k_M range: [0.0114, 0.5969], d_k_M_hat range: [0.3734, 0.9474]
2025-03-11 20:08:50 - Train Iteration 2618: loss: 0.7026, d_k_M range: [0.0018, 0.5011], d_k_M_hat range: [0.1635, 0.9215]
2025-03-11 20:08:51 - Train Iteration 2619: loss: 0.4606, d_k_M range: [0.0913, 0.6692], d_k_M_hat range: [0.4574, 0.9906]
2025-03-11 20:08:51 - Train Iteration 2620: loss: 0.4450, d_k_M range: [0.2751, 0.4956], d_k_M_hat range: [0.6081, 0.9406]
2025-03-11 20:08:51 - Train Iteration 2621: loss: 0.5112, d_k_M range: [0.0129, 0.7070], d_k_M_hat range: [0.4356, 0.9921]
2025-03-11 20:08:52 - Train Iteration 2622: loss: 0.8663, d_k_M range: [0.0007, 0.1435], d_k_M_hat range: [0.0699, 0.5240]
2025-03-11 20:08:52 - Train Iteration 2623: loss: 0.3857, d_k_M range: [0.2949, 0.5998], d_k_M_hat range: [0.6826, 0.9816]
2025-03-11 20:08:53 - Train Iteration 2624: loss: 0.5136, d_k_M range: [0.0960, 0.6901], d_k_M_hat range: [0.5179, 0.9740]
2025-03-11 20:08:53 - Train Iteration 2625: loss: 0.4162, d_k_M range: [0.0224, 0.5640], d_k_M_hat range: [0.3772, 0.9479]
2025-03-11 20:08:53 - Train Iteration 2626: loss: 0.5151, d_k_M range: [0.0905, 0.6545], d_k_M_hat range: [0.5035, 0.9368]
2025-03-11 20:08:54 - Train Iteration 2627: loss: 0.3904, d_k_M range: [0.0497, 0.5485], d_k_M_hat range: [0.4692, 0.9655]
2025-03-11 20:08:54 - Train Iteration 2628: loss: 0.5477, d_k_M range: [0.0196, 0.6925], d_k_M_hat range: [0.4370, 0.9524]
2025-03-11 20:08:55 - Train Iteration 2629: loss: 0.3914, d_k_M range: [0.0127, 0.3074], d_k_M_hat range: [0.3996, 0.7910]
2025-03-11 20:08:55 - Train Iteration 2630: loss: 0.5150, d_k_M range: [0.1274, 0.7135], d_k_M_hat range: [0.5977, 0.9959]
2025-03-11 20:08:56 - Train Iteration 2631: loss: 0.3739, d_k_M range: [0.0721, 0.4929], d_k_M_hat range: [0.5307, 0.9160]
2025-03-11 20:08:56 - Train Iteration 2632: loss: 0.4832, d_k_M range: [0.0259, 0.6767], d_k_M_hat range: [0.4494, 0.9816]
2025-03-11 20:08:56 - Train Iteration 2633: loss: 0.6634, d_k_M range: [0.1391, 0.7966], d_k_M_hat range: [0.5063, 0.9820]
2025-03-11 20:08:57 - Train Iteration 2634: loss: 0.5442, d_k_M range: [0.1613, 0.7313], d_k_M_hat range: [0.5730, 0.9935]
2025-03-11 20:08:57 - Train Iteration 2635: loss: 0.5155, d_k_M range: [0.0006, 0.5645], d_k_M_hat range: [0.2901, 0.9604]
2025-03-11 20:08:58 - Train Iteration 2636: loss: 0.6200, d_k_M range: [0.0174, 0.6168], d_k_M_hat range: [0.2299, 0.9792]
2025-03-11 20:08:58 - Train Iteration 2637: loss: 0.4909, d_k_M range: [0.0179, 0.6902], d_k_M_hat range: [0.3649, 0.9896]
2025-03-11 20:08:59 - Train Iteration 2638: loss: 0.3790, d_k_M range: [0.0048, 0.3795], d_k_M_hat range: [0.4431, 0.8534]
2025-03-11 20:08:59 - Train Iteration 2639: loss: 0.4361, d_k_M range: [0.0501, 0.5648], d_k_M_hat range: [0.4090, 0.9562]
2025-03-11 20:09:00 - Train Iteration 2640: loss: 0.3900, d_k_M range: [0.0575, 0.5567], d_k_M_hat range: [0.5514, 0.9322]
2025-03-11 20:09:00 - Train Iteration 2641: loss: 0.5917, d_k_M range: [0.0321, 0.7623], d_k_M_hat range: [0.4533, 0.9931]
2025-03-11 20:09:00 - Train Iteration 2642: loss: 0.3635, d_k_M range: [0.0202, 0.4162], d_k_M_hat range: [0.4243, 0.8991]
2025-03-11 20:09:01 - Train Iteration 2643: loss: 0.5284, d_k_M range: [0.0068, 0.7107], d_k_M_hat range: [0.3522, 0.9882]
2025-03-11 20:09:01 - Train Iteration 2644: loss: 0.3517, d_k_M range: [0.1153, 0.5304], d_k_M_hat range: [0.5222, 0.9496]
2025-03-11 20:09:02 - Train Iteration 2645: loss: 0.9306, d_k_M range: [0.0005, 0.4171], d_k_M_hat range: [0.0358, 0.8500]
2025-03-11 20:09:02 - Train Iteration 2646: loss: 0.4387, d_k_M range: [0.0905, 0.4786], d_k_M_hat range: [0.5846, 0.9255]
2025-03-11 20:09:02 - Train Iteration 2647: loss: 0.4213, d_k_M range: [0.0060, 0.5336], d_k_M_hat range: [0.3647, 0.9242]
2025-03-11 20:09:03 - Train Iteration 2648: loss: 0.5139, d_k_M range: [0.0162, 0.7072], d_k_M_hat range: [0.4525, 0.9904]
2025-03-11 20:09:03 - Train Iteration 2649: loss: 0.4978, d_k_M range: [0.0235, 0.4877], d_k_M_hat range: [0.3488, 0.9612]
2025-03-11 20:09:04 - Train Iteration 2650: loss: 0.3790, d_k_M range: [0.0261, 0.5210], d_k_M_hat range: [0.4105, 0.9466]
2025-03-11 20:09:04 - Train Iteration 2651: loss: 0.3375, d_k_M range: [0.0463, 0.5184], d_k_M_hat range: [0.5034, 0.9375]
2025-03-11 20:09:05 - Train Iteration 2652: loss: 0.5502, d_k_M range: [0.0258, 0.7371], d_k_M_hat range: [0.4128, 0.9954]
2025-03-11 20:09:05 - Train Iteration 2653: loss: 0.4811, d_k_M range: [0.0017, 0.3994], d_k_M_hat range: [0.3081, 0.8205]
2025-03-11 20:09:05 - Train Iteration 2654: loss: 0.8555, d_k_M range: [0.0159, 0.9225], d_k_M_hat range: [0.3786, 0.9976]
2025-03-11 20:09:06 - Train Iteration 2655: loss: 0.8605, d_k_M range: [0.0005, 0.3574], d_k_M_hat range: [0.0728, 0.8282]
2025-03-11 20:09:06 - Train Iteration 2656: loss: 0.5785, d_k_M range: [0.0215, 0.7492], d_k_M_hat range: [0.4556, 0.9886]
2025-03-11 20:09:07 - Train Iteration 2657: loss: 0.4508, d_k_M range: [0.0026, 0.2706], d_k_M_hat range: [0.3313, 0.6867]
2025-03-11 20:09:07 - Train Iteration 2658: loss: 0.3550, d_k_M range: [0.1032, 0.4981], d_k_M_hat range: [0.5074, 0.9216]
2025-03-11 20:09:07 - Train Iteration 2659: loss: 0.3703, d_k_M range: [0.0081, 0.4200], d_k_M_hat range: [0.3996, 0.9160]
2025-03-11 20:09:08 - Train Iteration 2660: loss: 0.3842, d_k_M range: [0.0437, 0.4800], d_k_M_hat range: [0.4538, 0.8601]
2025-03-11 20:09:08 - Train Iteration 2661: loss: 0.3708, d_k_M range: [0.0093, 0.5421], d_k_M_hat range: [0.4004, 0.9527]
2025-03-11 20:09:09 - Train Iteration 2662: loss: 0.4053, d_k_M range: [0.2531, 0.4702], d_k_M_hat range: [0.6610, 0.8336]
2025-03-11 20:09:09 - Train Iteration 2663: loss: 0.4512, d_k_M range: [0.2278, 0.5888], d_k_M_hat range: [0.7286, 0.9838]
2025-03-11 20:09:10 - Train Iteration 2664: loss: 0.5069, d_k_M range: [0.1097, 0.6953], d_k_M_hat range: [0.5151, 0.9833]
2025-03-11 20:09:10 - Train Iteration 2665: loss: 0.4122, d_k_M range: [0.0029, 0.3569], d_k_M_hat range: [0.3718, 0.8349]
2025-03-11 20:09:10 - Train Iteration 2666: loss: 0.4387, d_k_M range: [0.0844, 0.5756], d_k_M_hat range: [0.5367, 0.9831]
2025-03-11 20:09:11 - Train Iteration 2667: loss: 0.8969, d_k_M range: [0.0146, 0.9456], d_k_M_hat range: [0.4830, 0.9986]
2025-03-11 20:09:11 - Train Iteration 2668: loss: 0.4344, d_k_M range: [0.0374, 0.6415], d_k_M_hat range: [0.3782, 0.9922]
2025-03-11 20:09:12 - Train Iteration 2669: loss: 0.3757, d_k_M range: [0.1708, 0.5912], d_k_M_hat range: [0.6601, 0.9782]
2025-03-11 20:09:12 - Train Iteration 2670: loss: 0.3957, d_k_M range: [0.0254, 0.3948], d_k_M_hat range: [0.4486, 0.8141]
2025-03-11 20:09:13 - Train Iteration 2671: loss: 0.4040, d_k_M range: [0.0990, 0.6134], d_k_M_hat range: [0.5477, 0.9778]
2025-03-11 20:09:13 - Train Iteration 2672: loss: 0.6191, d_k_M range: [0.3598, 0.7760], d_k_M_hat range: [0.8039, 0.9892]
2025-03-11 20:09:13 - Train Iteration 2673: loss: 0.3816, d_k_M range: [0.0324, 0.2735], d_k_M_hat range: [0.5131, 0.7398]
2025-03-11 20:09:14 - Train Iteration 2674: loss: 0.9032, d_k_M range: [0.0654, 0.9475], d_k_M_hat range: [0.5476, 0.9971]
2025-03-11 20:09:14 - Train Iteration 2675: loss: 0.3450, d_k_M range: [0.0385, 0.5543], d_k_M_hat range: [0.4661, 0.9669]
2025-03-11 20:09:15 - Train Iteration 2676: loss: 0.5635, d_k_M range: [0.0109, 0.2155], d_k_M_hat range: [0.2602, 0.6713]
2025-03-11 20:09:15 - Train Iteration 2677: loss: 0.4495, d_k_M range: [0.3058, 0.6386], d_k_M_hat range: [0.7950, 0.9763]
2025-03-11 20:09:15 - Train Iteration 2678: loss: 0.4147, d_k_M range: [0.1102, 0.4793], d_k_M_hat range: [0.5507, 0.9502]
2025-03-11 20:09:16 - Train Iteration 2679: loss: 0.5034, d_k_M range: [0.0279, 0.7059], d_k_M_hat range: [0.5144, 0.9964]
2025-03-11 20:09:16 - Train Iteration 2680: loss: 0.3391, d_k_M range: [0.0535, 0.4454], d_k_M_hat range: [0.4780, 0.8652]
2025-03-11 20:09:17 - Train Iteration 2681: loss: 0.4400, d_k_M range: [0.0172, 0.5131], d_k_M_hat range: [0.3539, 0.9725]
2025-03-11 20:09:17 - Train Iteration 2682: loss: 0.5982, d_k_M range: [0.0145, 0.7680], d_k_M_hat range: [0.4492, 0.9946]
2025-03-11 20:09:17 - Train Iteration 2683: loss: 0.7736, d_k_M range: [0.0007, 0.2386], d_k_M_hat range: [0.1212, 0.6255]
2025-03-11 20:09:18 - Train Iteration 2684: loss: 0.7946, d_k_M range: [0.0294, 0.8838], d_k_M_hat range: [0.5479, 0.9924]
2025-03-11 20:09:18 - Train Iteration 2685: loss: 0.4874, d_k_M range: [0.0119, 0.4813], d_k_M_hat range: [0.3741, 0.9101]
2025-03-11 20:09:19 - Train Iteration 2686: loss: 0.4449, d_k_M range: [0.0101, 0.3434], d_k_M_hat range: [0.3431, 0.8161]
2025-03-11 20:09:19 - Train Iteration 2687: loss: 0.6853, d_k_M range: [0.0014, 0.5914], d_k_M_hat range: [0.1736, 0.9487]
2025-03-11 20:09:20 - Train Iteration 2688: loss: 0.4047, d_k_M range: [0.0092, 0.4417], d_k_M_hat range: [0.3730, 0.9488]
2025-03-11 20:09:20 - Train Iteration 2689: loss: 0.4843, d_k_M range: [0.0568, 0.6809], d_k_M_hat range: [0.4454, 0.9850]
2025-03-11 20:09:21 - Train Iteration 2690: loss: 0.5929, d_k_M range: [0.0031, 0.2358], d_k_M_hat range: [0.2331, 0.6587]
2025-03-11 20:09:21 - Train Iteration 2691: loss: 0.4444, d_k_M range: [0.1001, 0.6513], d_k_M_hat range: [0.4908, 0.9847]
2025-03-11 20:09:21 - Train Iteration 2692: loss: 0.3819, d_k_M range: [0.0406, 0.2851], d_k_M_hat range: [0.4644, 0.7750]
2025-03-11 20:09:22 - Train Iteration 2693: loss: 0.4899, d_k_M range: [0.0052, 0.5176], d_k_M_hat range: [0.3052, 0.9488]
2025-03-11 20:09:22 - Train Iteration 2694: loss: 0.5177, d_k_M range: [0.0022, 0.5719], d_k_M_hat range: [0.2827, 0.9420]
2025-03-11 20:09:23 - Train Iteration 2695: loss: 0.5600, d_k_M range: [0.2898, 0.6723], d_k_M_hat range: [0.6839, 0.9871]
2025-03-11 20:09:23 - Train Iteration 2696: loss: 0.7029, d_k_M range: [0.1710, 0.8358], d_k_M_hat range: [0.5118, 0.9974]
2025-03-11 20:09:24 - Train Iteration 2697: loss: 0.4560, d_k_M range: [0.0094, 0.4655], d_k_M_hat range: [0.3973, 0.8594]
2025-03-11 20:09:24 - Train Iteration 2698: loss: 0.3851, d_k_M range: [0.0461, 0.5302], d_k_M_hat range: [0.4256, 0.9470]
2025-03-11 20:09:24 - Train Iteration 2699: loss: 0.4988, d_k_M range: [0.1198, 0.6767], d_k_M_hat range: [0.5716, 0.9704]
2025-03-11 20:09:25 - Train Iteration 2700: loss: 0.7714, d_k_M range: [0.0004, 0.4200], d_k_M_hat range: [0.1221, 0.8317]
2025-03-11 20:09:25 - Train Iteration 2701: loss: 0.7881, d_k_M range: [0.1274, 0.8859], d_k_M_hat range: [0.6590, 0.9981]
2025-03-11 20:09:26 - Train Iteration 2702: loss: 0.4073, d_k_M range: [0.0266, 0.3562], d_k_M_hat range: [0.3989, 0.8448]
2025-03-11 20:09:26 - Train Iteration 2703: loss: 0.3764, d_k_M range: [0.2236, 0.4871], d_k_M_hat range: [0.6851, 0.9149]
2025-03-11 20:09:27 - Train Iteration 2704: loss: 0.7402, d_k_M range: [0.0051, 0.3320], d_k_M_hat range: [0.1447, 0.7364]
2025-03-11 20:09:27 - Train Iteration 2705: loss: 0.6947, d_k_M range: [0.1213, 0.8294], d_k_M_hat range: [0.5066, 0.9960]
2025-03-11 20:09:27 - Train Iteration 2706: loss: 0.4745, d_k_M range: [0.0237, 0.4228], d_k_M_hat range: [0.4544, 0.7340]
2025-03-11 20:09:28 - Train Iteration 2707: loss: 0.7698, d_k_M range: [0.2396, 0.8758], d_k_M_hat range: [0.6480, 0.9984]
2025-03-11 20:09:28 - Train Iteration 2708: loss: 0.4552, d_k_M range: [0.0292, 0.4563], d_k_M_hat range: [0.4024, 0.8670]
2025-03-11 20:09:29 - Train Iteration 2709: loss: 0.4810, d_k_M range: [0.0483, 0.5822], d_k_M_hat range: [0.4768, 0.8886]
2025-03-11 20:09:29 - Train Iteration 2710: loss: 0.5828, d_k_M range: [0.0016, 0.6043], d_k_M_hat range: [0.2382, 0.9618]
2025-03-11 20:09:29 - Train Iteration 2711: loss: 0.4601, d_k_M range: [0.0040, 0.4696], d_k_M_hat range: [0.3257, 0.9090]
2025-03-11 20:09:30 - Train Iteration 2712: loss: 0.5035, d_k_M range: [0.2615, 0.5542], d_k_M_hat range: [0.6047, 0.9403]
2025-03-11 20:09:30 - Train Iteration 2713: loss: 0.4300, d_k_M range: [0.1775, 0.6365], d_k_M_hat range: [0.6645, 0.9807]
2025-03-11 20:09:31 - Train Iteration 2714: loss: 0.4465, d_k_M range: [0.1478, 0.5753], d_k_M_hat range: [0.5464, 0.9758]
2025-03-11 20:09:31 - Train Iteration 2715: loss: 0.3966, d_k_M range: [0.1404, 0.4862], d_k_M_hat range: [0.5753, 0.8564]
2025-03-11 20:09:32 - Train Iteration 2716: loss: 0.3389, d_k_M range: [0.0340, 0.4717], d_k_M_hat range: [0.4754, 0.9638]
2025-03-11 20:09:32 - Train Iteration 2717: loss: 0.3919, d_k_M range: [0.0177, 0.3132], d_k_M_hat range: [0.4345, 0.8309]
2025-03-11 20:09:32 - Train Iteration 2718: loss: 0.4034, d_k_M range: [0.0173, 0.4901], d_k_M_hat range: [0.5208, 0.8549]
2025-03-11 20:09:33 - Train Iteration 2719: loss: 0.4055, d_k_M range: [0.0680, 0.4892], d_k_M_hat range: [0.4660, 0.9443]
2025-03-11 20:09:33 - Train Iteration 2720: loss: 0.6462, d_k_M range: [0.0128, 0.7900], d_k_M_hat range: [0.4404, 0.9963]
2025-03-11 20:09:34 - Train Iteration 2721: loss: 0.4328, d_k_M range: [0.0028, 0.3752], d_k_M_hat range: [0.3450, 0.8154]
2025-03-11 20:09:34 - Train Iteration 2722: loss: 0.5514, d_k_M range: [0.0767, 0.7281], d_k_M_hat range: [0.4574, 0.9856]
2025-03-11 20:09:35 - Train Iteration 2723: loss: 0.3829, d_k_M range: [0.0282, 0.5148], d_k_M_hat range: [0.4506, 0.9386]
2025-03-11 20:09:35 - Train Iteration 2724: loss: 0.5110, d_k_M range: [0.0062, 0.6250], d_k_M_hat range: [0.2914, 0.9758]
2025-03-11 20:09:36 - Train Iteration 2725: loss: 0.4283, d_k_M range: [0.0422, 0.5793], d_k_M_hat range: [0.5051, 0.9506]
2025-03-11 20:09:36 - Train Iteration 2726: loss: 0.6211, d_k_M range: [0.0007, 0.7480], d_k_M_hat range: [0.2126, 0.9951]
2025-03-11 20:09:37 - Train Iteration 2727: loss: 0.7069, d_k_M range: [0.1284, 0.8386], d_k_M_hat range: [0.5994, 0.9978]
2025-03-11 20:09:37 - Train Iteration 2728: loss: 0.4182, d_k_M range: [0.0143, 0.3746], d_k_M_hat range: [0.3676, 0.7608]
2025-03-11 20:09:37 - Train Iteration 2729: loss: 0.3700, d_k_M range: [0.0054, 0.5070], d_k_M_hat range: [0.4106, 0.8988]
2025-03-11 20:09:38 - Train Iteration 2730: loss: 0.5016, d_k_M range: [0.0015, 0.4002], d_k_M_hat range: [0.2933, 0.8887]
2025-03-11 20:09:38 - Train Iteration 2731: loss: 0.4790, d_k_M range: [0.0177, 0.3538], d_k_M_hat range: [0.3255, 0.7708]
2025-03-11 20:09:39 - Train Iteration 2732: loss: 0.4505, d_k_M range: [0.0179, 0.4702], d_k_M_hat range: [0.4402, 0.8790]
2025-03-11 20:09:39 - Train Iteration 2733: loss: 0.7319, d_k_M range: [0.0015, 0.8045], d_k_M_hat range: [0.1459, 0.9961]
2025-03-11 20:09:39 - Train Iteration 2734: loss: 0.5074, d_k_M range: [0.1216, 0.6953], d_k_M_hat range: [0.4623, 0.9829]
2025-03-11 20:09:40 - Train Iteration 2735: loss: 0.3787, d_k_M range: [0.0486, 0.5784], d_k_M_hat range: [0.4876, 0.9742]
2025-03-11 20:09:40 - Train Iteration 2736: loss: 0.7015, d_k_M range: [0.0051, 0.3179], d_k_M_hat range: [0.1676, 0.7008]
2025-03-11 20:09:41 - Train Iteration 2737: loss: 0.3659, d_k_M range: [0.0380, 0.4835], d_k_M_hat range: [0.4840, 0.9508]
2025-03-11 20:09:41 - Train Iteration 2738: loss: 0.9098, d_k_M range: [0.1656, 0.9528], d_k_M_hat range: [0.5752, 0.9990]
2025-03-11 20:09:42 - Train Iteration 2739: loss: 0.8743, d_k_M range: [0.0001, 0.3396], d_k_M_hat range: [0.0659, 0.6875]
2025-03-11 20:09:42 - Train Iteration 2740: loss: 0.4262, d_k_M range: [0.1829, 0.6302], d_k_M_hat range: [0.5543, 0.9774]
2025-03-11 20:09:42 - Train Iteration 2741: loss: 0.4214, d_k_M range: [0.1219, 0.5974], d_k_M_hat range: [0.5451, 0.9760]
2025-03-11 20:09:43 - Train Iteration 2742: loss: 0.4181, d_k_M range: [0.0893, 0.6289], d_k_M_hat range: [0.5390, 0.9823]
2025-03-11 20:09:43 - Train Iteration 2743: loss: 0.5812, d_k_M range: [0.0030, 0.3762], d_k_M_hat range: [0.2441, 0.7350]
2025-03-11 20:09:44 - Train Iteration 2744: loss: 0.6108, d_k_M range: [0.0025, 0.5175], d_k_M_hat range: [0.2296, 0.8485]
2025-03-11 20:09:44 - Train Iteration 2745: loss: 0.4521, d_k_M range: [0.0767, 0.6541], d_k_M_hat range: [0.5100, 0.9817]
2025-03-11 20:09:44 - Train Iteration 2746: loss: 0.6872, d_k_M range: [0.1972, 0.8234], d_k_M_hat range: [0.6081, 0.9944]
2025-03-11 20:09:45 - Train Iteration 2747: loss: 0.5907, d_k_M range: [0.0036, 0.5082], d_k_M_hat range: [0.3639, 0.9126]
2025-03-11 20:09:45 - Train Iteration 2748: loss: 0.4455, d_k_M range: [0.0142, 0.4946], d_k_M_hat range: [0.3631, 0.9034]
2025-03-11 20:09:46 - Train Iteration 2749: loss: 0.4716, d_k_M range: [0.0297, 0.6749], d_k_M_hat range: [0.4510, 0.9882]
2025-03-11 20:09:46 - Train Iteration 2750: loss: 0.5476, d_k_M range: [0.0518, 0.7306], d_k_M_hat range: [0.5232, 0.9906]
2025-03-11 20:09:47 - Train Iteration 2751: loss: 0.4214, d_k_M range: [0.0081, 0.4380], d_k_M_hat range: [0.3930, 0.8423]
2025-03-11 20:09:47 - Train Iteration 2752: loss: 0.4501, d_k_M range: [0.0127, 0.5471], d_k_M_hat range: [0.3666, 0.9646]
2025-03-11 20:09:47 - Train Iteration 2753: loss: 0.6078, d_k_M range: [0.0155, 0.7691], d_k_M_hat range: [0.4313, 0.9894]
2025-03-11 20:09:48 - Train Iteration 2754: loss: 0.6610, d_k_M range: [0.0035, 0.7959], d_k_M_hat range: [0.3380, 0.9829]
2025-03-11 20:09:48 - Train Iteration 2755: loss: 0.7187, d_k_M range: [0.0020, 0.1503], d_k_M_hat range: [0.1542, 0.5626]
2025-03-11 20:09:49 - Train Iteration 2756: loss: 0.4734, d_k_M range: [0.0105, 0.6014], d_k_M_hat range: [0.3225, 0.9562]
2025-03-11 20:09:49 - Train Iteration 2757: loss: 0.4649, d_k_M range: [0.0509, 0.3893], d_k_M_hat range: [0.5281, 0.7992]
2025-03-11 20:09:49 - Train Iteration 2758: loss: 0.4344, d_k_M range: [0.0773, 0.5137], d_k_M_hat range: [0.4704, 0.8622]
2025-03-11 20:09:50 - Train Iteration 2759: loss: 0.4572, d_k_M range: [0.1853, 0.5808], d_k_M_hat range: [0.6422, 0.9598]
2025-03-11 20:09:50 - Train Iteration 2760: loss: 0.3497, d_k_M range: [0.1113, 0.5090], d_k_M_hat range: [0.5200, 0.9291]
2025-03-11 20:09:51 - Train Iteration 2761: loss: 0.4574, d_k_M range: [0.0037, 0.3637], d_k_M_hat range: [0.3274, 0.7464]
2025-03-11 20:09:51 - Train Iteration 2762: loss: 0.4806, d_k_M range: [0.0646, 0.6661], d_k_M_hat range: [0.5340, 0.9729]
2025-03-11 20:09:52 - Train Iteration 2763: loss: 0.4081, d_k_M range: [0.1370, 0.6146], d_k_M_hat range: [0.4981, 0.9889]
2025-03-11 20:09:52 - Train Iteration 2764: loss: 0.4539, d_k_M range: [0.1309, 0.6407], d_k_M_hat range: [0.5581, 0.9669]
2025-03-11 20:09:52 - Train Iteration 2765: loss: 0.3701, d_k_M range: [0.0626, 0.5619], d_k_M_hat range: [0.5402, 0.9733]
2025-03-11 20:09:53 - Train Iteration 2766: loss: 0.3658, d_k_M range: [0.2534, 0.5821], d_k_M_hat range: [0.6746, 0.9772]
2025-03-11 20:09:53 - Train Iteration 2767: loss: 0.6040, d_k_M range: [0.0021, 0.5555], d_k_M_hat range: [0.2313, 0.9742]
2025-03-11 20:09:54 - Train Iteration 2768: loss: 0.4430, d_k_M range: [0.0367, 0.6480], d_k_M_hat range: [0.5074, 0.9937]
2025-03-11 20:09:54 - Train Iteration 2769: loss: 0.7330, d_k_M range: [0.0007, 0.4545], d_k_M_hat range: [0.1452, 0.9127]
2025-03-11 20:09:55 - Train Iteration 2770: loss: 0.3445, d_k_M range: [0.0460, 0.2491], d_k_M_hat range: [0.5224, 0.6836]
2025-03-11 20:09:55 - Train Iteration 2771: loss: 0.5372, d_k_M range: [0.0012, 0.3491], d_k_M_hat range: [0.2683, 0.8090]
2025-03-11 20:09:56 - Train Iteration 2772: loss: 0.4492, d_k_M range: [0.0373, 0.6609], d_k_M_hat range: [0.5766, 0.9907]
2025-03-11 20:09:56 - Train Iteration 2773: loss: 0.8835, d_k_M range: [0.0003, 0.5371], d_k_M_hat range: [0.0604, 0.9183]
2025-03-11 20:09:56 - Train Iteration 2774: loss: 0.4299, d_k_M range: [0.0502, 0.6334], d_k_M_hat range: [0.5288, 0.9777]
2025-03-11 20:09:57 - Train Iteration 2775: loss: 0.6944, d_k_M range: [0.0017, 0.5460], d_k_M_hat range: [0.1684, 0.9625]
2025-03-11 20:09:57 - Train Iteration 2776: loss: 0.4016, d_k_M range: [0.2309, 0.6069], d_k_M_hat range: [0.6730, 0.9732]
2025-03-11 20:09:58 - Train Iteration 2777: loss: 0.5878, d_k_M range: [0.0002, 0.4311], d_k_M_hat range: [0.2335, 0.8471]
2025-03-11 20:09:58 - Train Iteration 2778: loss: 0.3924, d_k_M range: [0.2259, 0.4457], d_k_M_hat range: [0.5995, 0.8968]
2025-03-11 20:09:58 - Train Iteration 2779: loss: 0.4532, d_k_M range: [0.1580, 0.6605], d_k_M_hat range: [0.6414, 0.9873]
2025-03-11 20:09:59 - Train Iteration 2780: loss: 0.3536, d_k_M range: [0.0057, 0.3749], d_k_M_hat range: [0.4292, 0.8855]
2025-03-11 20:09:59 - Train Iteration 2781: loss: 0.4633, d_k_M range: [0.0014, 0.3940], d_k_M_hat range: [0.3207, 0.8700]
2025-03-11 20:10:00 - Train Iteration 2782: loss: 0.4054, d_k_M range: [0.0182, 0.6074], d_k_M_hat range: [0.4145, 0.9706]
2025-03-11 20:10:00 - Train Iteration 2783: loss: 0.3514, d_k_M range: [0.0124, 0.4060], d_k_M_hat range: [0.4196, 0.9269]
2025-03-11 20:10:01 - Train Iteration 2784: loss: 0.4305, d_k_M range: [0.0368, 0.6309], d_k_M_hat range: [0.5245, 0.9748]
2025-03-11 20:10:01 - Train Iteration 2785: loss: 0.5133, d_k_M range: [0.0011, 0.3297], d_k_M_hat range: [0.2846, 0.8453]
2025-03-11 20:10:01 - Train Iteration 2786: loss: 0.3206, d_k_M range: [0.0919, 0.5386], d_k_M_hat range: [0.5989, 0.9724]
2025-03-11 20:10:02 - Train Iteration 2787: loss: 0.3559, d_k_M range: [0.0078, 0.2760], d_k_M_hat range: [0.4445, 0.6795]
2025-03-11 20:10:02 - Train Iteration 2788: loss: 0.4562, d_k_M range: [0.0127, 0.6275], d_k_M_hat range: [0.3373, 0.9873]
2025-03-11 20:10:03 - Train Iteration 2789: loss: 0.4095, d_k_M range: [0.2186, 0.6191], d_k_M_hat range: [0.6419, 0.9791]
2025-03-11 20:10:03 - Train Iteration 2790: loss: 0.5027, d_k_M range: [0.0034, 0.4236], d_k_M_hat range: [0.2944, 0.8810]
2025-03-11 20:10:03 - Train Iteration 2791: loss: 0.6624, d_k_M range: [0.2991, 0.8074], d_k_M_hat range: [0.7862, 0.9941]
2025-03-11 20:10:04 - Train Iteration 2792: loss: 0.7127, d_k_M range: [0.0019, 0.7690], d_k_M_hat range: [0.1577, 0.9945]
2025-03-11 20:10:04 - Train Iteration 2793: loss: 0.6447, d_k_M range: [0.0130, 0.7935], d_k_M_hat range: [0.4200, 0.9905]
2025-03-11 20:10:05 - Train Iteration 2794: loss: 0.3727, d_k_M range: [0.0080, 0.3110], d_k_M_hat range: [0.3984, 0.7625]
2025-03-11 20:10:05 - Train Iteration 2795: loss: 0.4605, d_k_M range: [0.0032, 0.6253], d_k_M_hat range: [0.3246, 0.9686]
2025-03-11 20:10:06 - Train Iteration 2796: loss: 0.4673, d_k_M range: [0.2077, 0.6516], d_k_M_hat range: [0.6501, 0.9680]
2025-03-11 20:10:06 - Train Iteration 2797: loss: 0.3925, d_k_M range: [0.0089, 0.5819], d_k_M_hat range: [0.3879, 0.9554]
2025-03-11 20:10:06 - Train Iteration 2798: loss: 0.3418, d_k_M range: [0.0063, 0.2443], d_k_M_hat range: [0.4216, 0.6744]
2025-03-11 20:10:07 - Train Iteration 2799: loss: 0.4295, d_k_M range: [0.0862, 0.6261], d_k_M_hat range: [0.5202, 0.9859]
2025-03-11 20:10:07 - Train Iteration 2800: loss: 0.3781, d_k_M range: [0.0165, 0.4198], d_k_M_hat range: [0.4568, 0.8247]
2025-03-11 20:10:08 - Train Iteration 2801: loss: 0.6919, d_k_M range: [0.0370, 0.8301], d_k_M_hat range: [0.4243, 0.9983]
2025-03-11 20:10:08 - Train Iteration 2802: loss: 0.9721, d_k_M range: [0.0108, 0.9856], d_k_M_hat range: [0.4231, 0.9996]
2025-03-11 20:10:08 - Train Iteration 2803: loss: 0.6206, d_k_M range: [0.0109, 0.7759], d_k_M_hat range: [0.4431, 0.9881]
2025-03-11 20:10:09 - Train Iteration 2804: loss: 0.3663, d_k_M range: [0.0248, 0.5494], d_k_M_hat range: [0.5548, 0.9633]
2025-03-11 20:10:09 - Train Iteration 2805: loss: 0.4307, d_k_M range: [0.0039, 0.6139], d_k_M_hat range: [0.3476, 0.9772]
2025-03-11 20:10:10 - Train Iteration 2806: loss: 0.6776, d_k_M range: [0.0087, 0.8191], d_k_M_hat range: [0.3693, 0.9959]
2025-03-11 20:10:10 - Train Iteration 2807: loss: 0.8740, d_k_M range: [0.1279, 0.9333], d_k_M_hat range: [0.6086, 0.9987]
2025-03-11 20:10:10 - Train Iteration 2808: loss: 0.9203, d_k_M range: [0.0003, 0.3805], d_k_M_hat range: [0.0410, 0.8318]
2025-03-11 20:10:11 - Train Iteration 2809: loss: 0.5963, d_k_M range: [0.0023, 0.4969], d_k_M_hat range: [0.2301, 0.9211]
2025-03-11 20:10:11 - Train Iteration 2810: loss: 0.7723, d_k_M range: [0.0017, 0.4465], d_k_M_hat range: [0.1229, 0.8799]
2025-03-11 20:10:12 - Train Iteration 2811: loss: 0.3361, d_k_M range: [0.0862, 0.3096], d_k_M_hat range: [0.5227, 0.8151]
2025-03-11 20:10:12 - Train Iteration 2812: loss: 0.4543, d_k_M range: [0.0027, 0.5398], d_k_M_hat range: [0.3287, 0.9208]
2025-03-11 20:10:13 - Train Iteration 2813: loss: 0.3741, d_k_M range: [0.0839, 0.5039], d_k_M_hat range: [0.4852, 0.9515]
2025-03-11 20:10:13 - Train Iteration 2814: loss: 0.5805, d_k_M range: [0.0065, 0.5032], d_k_M_hat range: [0.2446, 0.9207]
2025-03-11 20:10:13 - Train Iteration 2815: loss: 0.3901, d_k_M range: [0.0615, 0.4475], d_k_M_hat range: [0.5401, 0.8953]
2025-03-11 20:10:14 - Train Iteration 2816: loss: 0.5266, d_k_M range: [0.0017, 0.5468], d_k_M_hat range: [0.2761, 0.9438]
2025-03-11 20:10:14 - Train Iteration 2817: loss: 0.7617, d_k_M range: [0.2339, 0.8720], d_k_M_hat range: [0.7364, 0.9993]
2025-03-11 20:10:15 - Train Iteration 2818: loss: 0.9739, d_k_M range: [0.0001, 0.0957], d_k_M_hat range: [0.0132, 0.5573]
2025-03-11 20:10:15 - Train Iteration 2819: loss: 0.4144, d_k_M range: [0.0422, 0.3390], d_k_M_hat range: [0.4448, 0.7565]
2025-03-11 20:10:15 - Train Iteration 2820: loss: 0.6320, d_k_M range: [0.0006, 0.4919], d_k_M_hat range: [0.2056, 0.9191]
2025-03-11 20:10:16 - Train Iteration 2821: loss: 0.4824, d_k_M range: [0.1458, 0.6707], d_k_M_hat range: [0.5933, 0.9819]
2025-03-11 20:10:16 - Train Iteration 2822: loss: 0.4666, d_k_M range: [0.0259, 0.3078], d_k_M_hat range: [0.3657, 0.6313]
2025-03-11 20:10:17 - Train Iteration 2823: loss: 0.4119, d_k_M range: [0.0527, 0.4996], d_k_M_hat range: [0.4859, 0.8939]
2025-03-11 20:10:17 - Train Iteration 2824: loss: 0.5256, d_k_M range: [0.0075, 0.3912], d_k_M_hat range: [0.2839, 0.8030]
2025-03-11 20:10:18 - Train Iteration 2825: loss: 0.4225, d_k_M range: [0.0773, 0.5263], d_k_M_hat range: [0.4685, 0.9596]
2025-03-11 20:10:18 - Train Iteration 2826: loss: 0.4442, d_k_M range: [0.1743, 0.4493], d_k_M_hat range: [0.5325, 0.8602]
2025-03-11 20:10:19 - Train Iteration 2827: loss: 0.4311, d_k_M range: [0.0420, 0.4940], d_k_M_hat range: [0.4524, 0.8922]
2025-03-11 20:10:19 - Train Iteration 2828: loss: 0.5421, d_k_M range: [0.2656, 0.7142], d_k_M_hat range: [0.7382, 0.9779]
2025-03-11 20:10:19 - Train Iteration 2829: loss: 0.7348, d_k_M range: [0.0005, 0.5264], d_k_M_hat range: [0.1433, 0.9513]
2025-03-11 20:10:20 - Train Iteration 2830: loss: 0.9525, d_k_M range: [0.1040, 0.9754], d_k_M_hat range: [0.5467, 0.9994]
2025-03-11 20:10:20 - Train Iteration 2831: loss: 0.4692, d_k_M range: [0.0324, 0.4822], d_k_M_hat range: [0.4810, 0.8834]
2025-03-11 20:10:21 - Train Iteration 2832: loss: 0.4496, d_k_M range: [0.0116, 0.3350], d_k_M_hat range: [0.3543, 0.8121]
2025-03-11 20:10:21 - Train Iteration 2833: loss: 0.5779, d_k_M range: [0.0072, 0.7357], d_k_M_hat range: [0.3364, 0.9755]
2025-03-11 20:10:21 - Train Iteration 2834: loss: 0.3654, d_k_M range: [0.0484, 0.4494], d_k_M_hat range: [0.4985, 0.8591]
2025-03-11 20:10:22 - Train Iteration 2835: loss: 0.2880, d_k_M range: [0.0156, 0.4002], d_k_M_hat range: [0.5078, 0.8862]
2025-03-11 20:10:22 - Train Iteration 2836: loss: 0.4080, d_k_M range: [0.0160, 0.5682], d_k_M_hat range: [0.3773, 0.9557]
2025-03-11 20:10:23 - Train Iteration 2837: loss: 0.6877, d_k_M range: [0.1337, 0.8238], d_k_M_hat range: [0.6183, 0.9946]
2025-03-11 20:10:23 - Train Iteration 2838: loss: 0.4630, d_k_M range: [0.0029, 0.5283], d_k_M_hat range: [0.3229, 0.9510]
2025-03-11 20:10:24 - Train Iteration 2839: loss: 0.5662, d_k_M range: [0.1631, 0.7475], d_k_M_hat range: [0.6444, 0.9950]
2025-03-11 20:10:24 - Train Iteration 2840: loss: 0.5274, d_k_M range: [0.0011, 0.7108], d_k_M_hat range: [0.3040, 0.9846]
2025-03-11 20:10:24 - Train Iteration 2841: loss: 0.4711, d_k_M range: [0.0711, 0.4792], d_k_M_hat range: [0.5527, 0.9574]
2025-03-11 20:10:25 - Train Iteration 2842: loss: 0.4267, d_k_M range: [0.2923, 0.6467], d_k_M_hat range: [0.6893, 0.9935]
2025-03-11 20:10:25 - Train Iteration 2843: loss: 0.3543, d_k_M range: [0.0104, 0.2674], d_k_M_hat range: [0.4222, 0.7271]
2025-03-11 20:10:26 - Train Iteration 2844: loss: 0.8063, d_k_M range: [0.0239, 0.8929], d_k_M_hat range: [0.4380, 0.9950]
2025-03-11 20:10:26 - Train Iteration 2845: loss: 0.4333, d_k_M range: [0.0106, 0.4240], d_k_M_hat range: [0.3538, 0.8426]
2025-03-11 20:10:27 - Train Iteration 2846: loss: 0.3474, d_k_M range: [0.2498, 0.5060], d_k_M_hat range: [0.6688, 0.9480]
2025-03-11 20:10:27 - Train Iteration 2847: loss: 0.3969, d_k_M range: [0.0920, 0.4082], d_k_M_hat range: [0.4948, 0.7781]
2025-03-11 20:10:27 - Train Iteration 2848: loss: 0.3872, d_k_M range: [0.1001, 0.5577], d_k_M_hat range: [0.5474, 0.9510]
2025-03-11 20:10:28 - Train Iteration 2849: loss: 0.7211, d_k_M range: [0.0612, 0.8362], d_k_M_hat range: [0.5111, 0.9870]
2025-03-11 20:10:28 - Train Iteration 2850: loss: 0.4493, d_k_M range: [0.0072, 0.4708], d_k_M_hat range: [0.3369, 0.9262]
2025-03-11 20:10:29 - Train Iteration 2851: loss: 0.5048, d_k_M range: [0.0093, 0.5096], d_k_M_hat range: [0.2988, 0.9278]
2025-03-11 20:10:29 - Train Iteration 2852: loss: 0.4065, d_k_M range: [0.0220, 0.5164], d_k_M_hat range: [0.4800, 0.9234]
2025-03-11 20:10:30 - Train Iteration 2853: loss: 0.6395, d_k_M range: [0.0050, 0.4055], d_k_M_hat range: [0.2070, 0.8337]
2025-03-11 20:10:30 - Train Iteration 2854: loss: 0.4257, d_k_M range: [0.0027, 0.5461], d_k_M_hat range: [0.3502, 0.9641]
2025-03-11 20:10:30 - Train Iteration 2855: loss: 0.5159, d_k_M range: [0.1731, 0.6959], d_k_M_hat range: [0.5962, 0.9776]
2025-03-11 20:10:31 - Train Iteration 2856: loss: 0.4757, d_k_M range: [0.0068, 0.5766], d_k_M_hat range: [0.3514, 0.9612]
2025-03-11 20:10:31 - Train Iteration 2857: loss: 0.7420, d_k_M range: [0.4049, 0.8571], d_k_M_hat range: [0.7837, 0.9958]
2025-03-11 20:10:32 - Train Iteration 2858: loss: 0.4198, d_k_M range: [0.0249, 0.4907], d_k_M_hat range: [0.4805, 0.9617]
2025-03-11 20:10:32 - Train Iteration 2859: loss: 0.4225, d_k_M range: [0.0134, 0.2935], d_k_M_hat range: [0.4136, 0.6876]
2025-03-11 20:10:33 - Train Iteration 2860: loss: 0.4566, d_k_M range: [0.0300, 0.6383], d_k_M_hat range: [0.4982, 0.9692]
2025-03-11 20:10:33 - Train Iteration 2861: loss: 0.5140, d_k_M range: [0.0018, 0.4492], d_k_M_hat range: [0.2849, 0.9407]
2025-03-11 20:10:34 - Train Iteration 2862: loss: 0.3645, d_k_M range: [0.1544, 0.5397], d_k_M_hat range: [0.6996, 0.9595]
2025-03-11 20:10:34 - Train Iteration 2863: loss: 0.3829, d_k_M range: [0.0116, 0.3641], d_k_M_hat range: [0.4249, 0.8500]
2025-03-11 20:10:35 - Train Iteration 2864: loss: 0.5475, d_k_M range: [0.0007, 0.4621], d_k_M_hat range: [0.2608, 0.8129]
2025-03-11 20:10:35 - Train Iteration 2865: loss: 0.6355, d_k_M range: [0.0380, 0.7930], d_k_M_hat range: [0.5405, 0.9959]
2025-03-11 20:10:35 - Train Iteration 2866: loss: 0.3662, d_k_M range: [0.0127, 0.4074], d_k_M_hat range: [0.4979, 0.9070]
2025-03-11 20:10:36 - Train Iteration 2867: loss: 0.3909, d_k_M range: [0.1185, 0.5674], d_k_M_hat range: [0.5738, 0.9548]
2025-03-11 20:10:36 - Train Iteration 2868: loss: 0.9085, d_k_M range: [0.0001, 0.5693], d_k_M_hat range: [0.0471, 0.9552]
2025-03-11 20:10:37 - Train Iteration 2869: loss: 0.4005, d_k_M range: [0.2213, 0.5895], d_k_M_hat range: [0.5884, 0.9886]
2025-03-11 20:10:37 - Train Iteration 2870: loss: 0.4211, d_k_M range: [0.0867, 0.5223], d_k_M_hat range: [0.5810, 0.9591]
2025-03-11 20:10:38 - Train Iteration 2871: loss: 0.6685, d_k_M range: [0.0476, 0.8122], d_k_M_hat range: [0.5649, 0.9946]
2025-03-11 20:10:38 - Train Iteration 2872: loss: 0.4087, d_k_M range: [0.0035, 0.1806], d_k_M_hat range: [0.3781, 0.6445]
2025-03-11 20:10:39 - Train Iteration 2873: loss: 0.9466, d_k_M range: [0.2954, 0.9722], d_k_M_hat range: [0.6605, 0.9993]
2025-03-11 20:10:39 - Train Iteration 2874: loss: 0.3739, d_k_M range: [0.0364, 0.3032], d_k_M_hat range: [0.4695, 0.7680]
2025-03-11 20:10:39 - Train Iteration 2875: loss: 0.9163, d_k_M range: [0.0773, 0.9523], d_k_M_hat range: [0.5399, 0.9951]
2025-03-11 20:10:40 - Train Iteration 2876: loss: 0.4525, d_k_M range: [0.0447, 0.4988], d_k_M_hat range: [0.4459, 0.9303]
2025-03-11 20:10:40 - Train Iteration 2877: loss: 0.3946, d_k_M range: [0.0159, 0.3913], d_k_M_hat range: [0.4681, 0.8807]
2025-03-11 20:10:41 - Train Iteration 2878: loss: 0.4311, d_k_M range: [0.0865, 0.6472], d_k_M_hat range: [0.5928, 0.9906]
2025-03-11 20:10:41 - Train Iteration 2879: loss: 0.6540, d_k_M range: [0.0003, 0.4525], d_k_M_hat range: [0.1916, 0.8718]
2025-03-11 20:10:42 - Train Iteration 2880: loss: 0.5860, d_k_M range: [0.1414, 0.7589], d_k_M_hat range: [0.6091, 0.9934]
2025-03-11 20:10:42 - Train Iteration 2881: loss: 0.6001, d_k_M range: [0.0038, 0.1259], d_k_M_hat range: [0.2291, 0.5914]
2025-03-11 20:10:42 - Train Iteration 2882: loss: 0.4571, d_k_M range: [0.1627, 0.6106], d_k_M_hat range: [0.5080, 0.9561]
2025-03-11 20:10:43 - Train Iteration 2883: loss: 0.4243, d_k_M range: [0.2001, 0.4717], d_k_M_hat range: [0.5486, 0.8291]
2025-03-11 20:10:43 - Train Iteration 2884: loss: 0.5912, d_k_M range: [0.1117, 0.7288], d_k_M_hat range: [0.5752, 0.9600]
2025-03-11 20:10:44 - Train Iteration 2885: loss: 0.4003, d_k_M range: [0.0090, 0.5231], d_k_M_hat range: [0.3994, 0.9279]
2025-03-11 20:10:44 - Train Iteration 2886: loss: 0.6264, d_k_M range: [0.0132, 0.7309], d_k_M_hat range: [0.4187, 0.9395]
2025-03-11 20:10:45 - Train Iteration 2887: loss: 0.4591, d_k_M range: [0.0492, 0.4964], d_k_M_hat range: [0.4390, 0.9351]
2025-03-11 20:10:45 - Train Iteration 2888: loss: 0.3886, d_k_M range: [0.0070, 0.3413], d_k_M_hat range: [0.4344, 0.8572]
2025-03-11 20:10:45 - Train Iteration 2889: loss: 0.7264, d_k_M range: [0.0476, 0.8416], d_k_M_hat range: [0.5835, 0.9893]
2025-03-11 20:10:46 - Train Iteration 2890: loss: 0.7726, d_k_M range: [0.0012, 0.1866], d_k_M_hat range: [0.1222, 0.6245]
2025-03-11 20:10:46 - Train Iteration 2891: loss: 0.4807, d_k_M range: [0.1664, 0.5348], d_k_M_hat range: [0.5987, 0.9343]
2025-03-11 20:10:47 - Train Iteration 2892: loss: 0.6332, d_k_M range: [0.0538, 0.7896], d_k_M_hat range: [0.4413, 0.9975]
2025-03-11 20:10:47 - Train Iteration 2893: loss: 0.5451, d_k_M range: [0.0043, 0.3788], d_k_M_hat range: [0.2729, 0.8297]
2025-03-11 20:10:48 - Train Iteration 2894: loss: 0.4528, d_k_M range: [0.0078, 0.5673], d_k_M_hat range: [0.3349, 0.9442]
2025-03-11 20:10:48 - Train Iteration 2895: loss: 0.4984, d_k_M range: [0.2665, 0.6800], d_k_M_hat range: [0.7071, 0.9740]
2025-03-11 20:10:48 - Train Iteration 2896: loss: 0.4547, d_k_M range: [0.0036, 0.3482], d_k_M_hat range: [0.3293, 0.8091]
2025-03-11 20:10:49 - Train Iteration 2897: loss: 0.5077, d_k_M range: [0.0274, 0.6427], d_k_M_hat range: [0.3570, 0.9818]
2025-03-11 20:10:49 - Train Iteration 2898: loss: 0.8583, d_k_M range: [0.0558, 0.9242], d_k_M_hat range: [0.4196, 0.9978]
2025-03-11 20:10:50 - Train Iteration 2899: loss: 0.7471, d_k_M range: [0.0023, 0.8595], d_k_M_hat range: [0.1654, 0.9951]
2025-03-11 20:10:50 - Train Iteration 2900: loss: 0.4349, d_k_M range: [0.1803, 0.5005], d_k_M_hat range: [0.5602, 0.8905]
2025-03-11 20:10:51 - Train Iteration 2901: loss: 0.4130, d_k_M range: [0.2754, 0.4620], d_k_M_hat range: [0.6327, 0.9328]
2025-03-11 20:10:51 - Train Iteration 2902: loss: 0.3551, d_k_M range: [0.0352, 0.4273], d_k_M_hat range: [0.5199, 0.9027]
2025-03-11 20:10:52 - Train Iteration 2903: loss: 0.5884, d_k_M range: [0.0039, 0.5265], d_k_M_hat range: [0.2368, 0.9664]
2025-03-11 20:10:52 - Train Iteration 2904: loss: 0.6378, d_k_M range: [0.0150, 0.7963], d_k_M_hat range: [0.2344, 0.9976]
2025-03-11 20:10:53 - Train Iteration 2905: loss: 0.4403, d_k_M range: [0.0124, 0.6476], d_k_M_hat range: [0.3488, 0.9918]
2025-03-11 20:10:53 - Train Iteration 2906: loss: 0.6216, d_k_M range: [0.1963, 0.7787], d_k_M_hat range: [0.6950, 0.9903]
2025-03-11 20:10:53 - Train Iteration 2907: loss: 0.5537, d_k_M range: [0.0066, 0.5938], d_k_M_hat range: [0.3060, 0.9595]
2025-03-11 20:10:54 - Train Iteration 2908: loss: 0.7222, d_k_M range: [0.1131, 0.8411], d_k_M_hat range: [0.5880, 0.9913]
2025-03-11 20:10:54 - Train Iteration 2909: loss: 0.3907, d_k_M range: [0.0185, 0.3612], d_k_M_hat range: [0.3935, 0.7833]
2025-03-11 20:10:55 - Train Iteration 2910: loss: 0.5566, d_k_M range: [0.1423, 0.7278], d_k_M_hat range: [0.5751, 0.9818]
2025-03-11 20:10:55 - Train Iteration 2911: loss: 0.4542, d_k_M range: [0.0015, 0.4824], d_k_M_hat range: [0.3276, 0.8811]
2025-03-11 20:10:55 - Train Iteration 2912: loss: 0.3865, d_k_M range: [0.1065, 0.4032], d_k_M_hat range: [0.6494, 0.9081]
2025-03-11 20:10:56 - Train Iteration 2913: loss: 0.3622, d_k_M range: [0.0574, 0.5510], d_k_M_hat range: [0.5279, 0.9492]
2025-03-11 20:10:56 - Train Iteration 2914: loss: 0.6076, d_k_M range: [0.0071, 0.7644], d_k_M_hat range: [0.3543, 0.9849]
2025-03-11 20:10:57 - Train Iteration 2915: loss: 0.5155, d_k_M range: [0.0017, 0.5232], d_k_M_hat range: [0.2838, 0.9590]
2025-03-11 20:10:57 - Train Iteration 2916: loss: 0.4154, d_k_M range: [0.0194, 0.3340], d_k_M_hat range: [0.4193, 0.7925]
2025-03-11 20:10:57 - Train Iteration 2917: loss: 0.5887, d_k_M range: [0.2038, 0.7542], d_k_M_hat range: [0.7634, 0.9960]
2025-03-11 20:10:58 - Train Iteration 2918: loss: 0.6323, d_k_M range: [0.0024, 0.4349], d_k_M_hat range: [0.2078, 0.8851]
2025-03-11 20:10:58 - Train Iteration 2919: loss: 0.4494, d_k_M range: [0.0526, 0.4528], d_k_M_hat range: [0.4578, 0.9031]
2025-03-11 20:10:59 - Train Iteration 2920: loss: 0.8573, d_k_M range: [0.0005, 0.2792], d_k_M_hat range: [0.0747, 0.7305]
2025-03-11 20:10:59 - Train Iteration 2921: loss: 0.4671, d_k_M range: [0.0436, 0.6015], d_k_M_hat range: [0.5043, 0.9732]
2025-03-11 20:10:59 - Train Iteration 2922: loss: 0.4330, d_k_M range: [0.0755, 0.5744], d_k_M_hat range: [0.4317, 0.9534]
2025-03-11 20:11:00 - Train Iteration 2923: loss: 0.4307, d_k_M range: [0.0145, 0.5619], d_k_M_hat range: [0.4954, 0.9635]
2025-03-11 20:11:00 - Train Iteration 2924: loss: 0.4016, d_k_M range: [0.0629, 0.5260], d_k_M_hat range: [0.5600, 0.9290]
2025-03-11 20:11:01 - Train Iteration 2925: loss: 0.6047, d_k_M range: [0.0005, 0.7247], d_k_M_hat range: [0.2229, 0.9902]
2025-03-11 20:11:01 - Train Iteration 2926: loss: 0.4419, d_k_M range: [0.2387, 0.6564], d_k_M_hat range: [0.6317, 0.9916]
2025-03-11 20:11:02 - Train Iteration 2927: loss: 0.4674, d_k_M range: [0.0027, 0.5577], d_k_M_hat range: [0.3306, 0.9647]
2025-03-11 20:11:02 - Train Iteration 2928: loss: 0.4347, d_k_M range: [0.0595, 0.3999], d_k_M_hat range: [0.4512, 0.8487]
2025-03-11 20:11:02 - Train Iteration 2929: loss: 0.7014, d_k_M range: [0.0042, 0.2856], d_k_M_hat range: [0.1667, 0.7438]
2025-03-11 20:11:03 - Train Iteration 2930: loss: 0.4760, d_k_M range: [0.0788, 0.6666], d_k_M_hat range: [0.6208, 0.9766]
2025-03-11 20:11:03 - Train Iteration 2931: loss: 0.4517, d_k_M range: [0.0135, 0.3423], d_k_M_hat range: [0.4852, 0.7187]
2025-03-11 20:11:04 - Train Iteration 2932: loss: 0.9226, d_k_M range: [0.0104, 0.9598], d_k_M_hat range: [0.4220, 0.9993]
2025-03-11 20:11:04 - Train Iteration 2933: loss: 0.4588, d_k_M range: [0.0040, 0.5147], d_k_M_hat range: [0.3389, 0.9127]
2025-03-11 20:11:05 - Train Iteration 2934: loss: 0.3901, d_k_M range: [0.1877, 0.5920], d_k_M_hat range: [0.6800, 0.9852]
2025-03-11 20:11:05 - Train Iteration 2935: loss: 0.4715, d_k_M range: [0.0044, 0.2307], d_k_M_hat range: [0.3178, 0.5924]
2025-03-11 20:11:05 - Train Iteration 2936: loss: 0.7663, d_k_M range: [0.0184, 0.8718], d_k_M_hat range: [0.3588, 0.9964]
2025-03-11 20:11:06 - Train Iteration 2937: loss: 0.4811, d_k_M range: [0.0479, 0.6865], d_k_M_hat range: [0.5027, 0.9929]
2025-03-11 20:11:06 - Train Iteration 2938: loss: 0.5196, d_k_M range: [0.0040, 0.7000], d_k_M_hat range: [0.3870, 0.9792]
2025-03-11 20:11:07 - Train Iteration 2939: loss: 0.3962, d_k_M range: [0.0056, 0.5263], d_k_M_hat range: [0.4050, 0.9570]
2025-03-11 20:11:07 - Train Iteration 2940: loss: 0.5218, d_k_M range: [0.0020, 0.5226], d_k_M_hat range: [0.2797, 0.9213]
2025-03-11 20:11:07 - Train Iteration 2941: loss: 0.4935, d_k_M range: [0.0038, 0.6905], d_k_M_hat range: [0.3499, 0.9880]
2025-03-11 20:11:08 - Train Iteration 2942: loss: 0.4714, d_k_M range: [0.1457, 0.4380], d_k_M_hat range: [0.5769, 0.8527]
2025-03-11 20:11:08 - Train Iteration 2943: loss: 0.5823, d_k_M range: [0.2957, 0.7605], d_k_M_hat range: [0.6710, 0.9975]
2025-03-11 20:11:09 - Train Iteration 2944: loss: 0.5164, d_k_M range: [0.0009, 0.5261], d_k_M_hat range: [0.2823, 0.9399]
2025-03-11 20:11:09 - Train Iteration 2945: loss: 0.5805, d_k_M range: [0.0295, 0.7472], d_k_M_hat range: [0.4444, 0.9894]
2025-03-11 20:11:10 - Train Iteration 2946: loss: 0.3834, d_k_M range: [0.0116, 0.2858], d_k_M_hat range: [0.4474, 0.6667]
2025-03-11 20:11:10 - Train Iteration 2947: loss: 0.3739, d_k_M range: [0.0190, 0.3921], d_k_M_hat range: [0.4090, 0.8937]
2025-03-11 20:11:10 - Train Iteration 2948: loss: 0.3687, d_k_M range: [0.2268, 0.5534], d_k_M_hat range: [0.6539, 0.9765]
2025-03-11 20:11:11 - Train Iteration 2949: loss: 0.3756, d_k_M range: [0.0441, 0.4762], d_k_M_hat range: [0.5329, 0.9505]
2025-03-11 20:11:11 - Train Iteration 2950: loss: 0.7324, d_k_M range: [0.0575, 0.8541], d_k_M_hat range: [0.4416, 0.9984]
2025-03-11 20:11:12 - Train Iteration 2951: loss: 0.3941, d_k_M range: [0.0101, 0.2388], d_k_M_hat range: [0.4003, 0.6757]
2025-03-11 20:11:12 - Train Iteration 2952: loss: 0.3835, d_k_M range: [0.1314, 0.5365], d_k_M_hat range: [0.6071, 0.9279]
2025-03-11 20:11:13 - Train Iteration 2953: loss: 0.3873, d_k_M range: [0.0121, 0.4208], d_k_M_hat range: [0.4121, 0.8922]
2025-03-11 20:11:13 - Train Iteration 2954: loss: 0.3768, d_k_M range: [0.0415, 0.4073], d_k_M_hat range: [0.5110, 0.8659]
2025-03-11 20:11:14 - Train Iteration 2955: loss: 0.3354, d_k_M range: [0.0110, 0.4916], d_k_M_hat range: [0.4319, 0.9227]
2025-03-11 20:11:14 - Train Iteration 2956: loss: 0.6355, d_k_M range: [0.3816, 0.7897], d_k_M_hat range: [0.7684, 0.9953]
2025-03-11 20:11:15 - Train Iteration 2957: loss: 0.3697, d_k_M range: [0.0178, 0.5018], d_k_M_hat range: [0.4230, 0.9357]
2025-03-11 20:11:15 - Train Iteration 2958: loss: 0.4141, d_k_M range: [0.0191, 0.4808], d_k_M_hat range: [0.4599, 0.8373]
2025-03-11 20:11:16 - Train Iteration 2959: loss: 0.4996, d_k_M range: [0.0231, 0.5066], d_k_M_hat range: [0.3163, 0.9212]
2025-03-11 20:11:16 - Train Iteration 2960: loss: 0.4604, d_k_M range: [0.0091, 0.6541], d_k_M_hat range: [0.4416, 0.9756]
2025-03-11 20:11:16 - Train Iteration 2961: loss: 0.3743, d_k_M range: [0.0079, 0.2941], d_k_M_hat range: [0.4202, 0.7937]
2025-03-11 20:11:17 - Train Iteration 2962: loss: 0.3721, d_k_M range: [0.0124, 0.3348], d_k_M_hat range: [0.4024, 0.9044]
2025-03-11 20:11:17 - Train Iteration 2963: loss: 0.5157, d_k_M range: [0.0209, 0.6371], d_k_M_hat range: [0.4169, 0.9672]
2025-03-11 20:11:18 - Train Iteration 2964: loss: 0.3595, d_k_M range: [0.0061, 0.3751], d_k_M_hat range: [0.4109, 0.9020]
2025-03-11 20:11:18 - Train Iteration 2965: loss: 0.4013, d_k_M range: [0.0027, 0.3795], d_k_M_hat range: [0.3808, 0.9279]
2025-03-11 20:11:19 - Train Iteration 2966: loss: 0.4443, d_k_M range: [0.0033, 0.6122], d_k_M_hat range: [0.3780, 0.9456]
2025-03-11 20:11:19 - Train Iteration 2967: loss: 0.7371, d_k_M range: [0.2322, 0.8564], d_k_M_hat range: [0.7364, 0.9978]
2025-03-11 20:11:19 - Train Iteration 2968: loss: 0.4010, d_k_M range: [0.0608, 0.5687], d_k_M_hat range: [0.5760, 0.9840]
2025-03-11 20:11:20 - Train Iteration 2969: loss: 0.4253, d_k_M range: [0.0131, 0.5194], d_k_M_hat range: [0.3610, 0.9770]
2025-03-11 20:11:20 - Train Iteration 2970: loss: 0.3284, d_k_M range: [0.0060, 0.4637], d_k_M_hat range: [0.4329, 0.9447]
2025-03-11 20:11:21 - Train Iteration 2971: loss: 0.6392, d_k_M range: [0.0863, 0.7971], d_k_M_hat range: [0.6938, 0.9976]
2025-03-11 20:11:21 - Train Iteration 2972: loss: 0.4281, d_k_M range: [0.0034, 0.4018], d_k_M_hat range: [0.3548, 0.8684]
2025-03-11 20:11:22 - Train Iteration 2973: loss: 0.3775, d_k_M range: [0.0238, 0.5245], d_k_M_hat range: [0.4936, 0.9797]
2025-03-11 20:11:22 - Train Iteration 2974: loss: 0.6268, d_k_M range: [0.0295, 0.7737], d_k_M_hat range: [0.4071, 0.9820]
2025-03-11 20:11:23 - Train Iteration 2975: loss: 0.3575, d_k_M range: [0.0100, 0.4059], d_k_M_hat range: [0.4937, 0.9161]
2025-03-11 20:11:23 - Train Iteration 2976: loss: 0.7365, d_k_M range: [0.0023, 0.5007], d_k_M_hat range: [0.1441, 0.9533]
2025-03-11 20:11:24 - Train Iteration 2977: loss: 0.5624, d_k_M range: [0.0230, 0.7340], d_k_M_hat range: [0.4822, 0.9841]
2025-03-11 20:11:24 - Train Iteration 2978: loss: 0.6165, d_k_M range: [0.0014, 0.3500], d_k_M_hat range: [0.2163, 0.7666]
2025-03-11 20:11:25 - Train Iteration 2979: loss: 0.7985, d_k_M range: [0.3470, 0.8870], d_k_M_hat range: [0.6689, 0.9934]
2025-03-11 20:11:25 - Train Iteration 2980: loss: 0.4689, d_k_M range: [0.1476, 0.5989], d_k_M_hat range: [0.5858, 0.9766]
2025-03-11 20:11:26 - Train Iteration 2981: loss: 0.3385, d_k_M range: [0.0138, 0.5020], d_k_M_hat range: [0.4726, 0.9219]
2025-03-11 20:11:26 - Train Iteration 2982: loss: 0.5409, d_k_M range: [0.2073, 0.7331], d_k_M_hat range: [0.6316, 0.9976]
2025-03-11 20:11:26 - Train Iteration 2983: loss: 0.3622, d_k_M range: [0.0145, 0.4934], d_k_M_hat range: [0.4291, 0.9759]
2025-03-11 20:11:27 - Train Iteration 2984: loss: 0.5764, d_k_M range: [0.0008, 0.5792], d_k_M_hat range: [0.2416, 0.9469]
2025-03-11 20:11:27 - Train Iteration 2985: loss: 0.4584, d_k_M range: [0.1897, 0.6081], d_k_M_hat range: [0.5126, 0.9775]
2025-03-11 20:11:28 - Train Iteration 2986: loss: 0.4492, d_k_M range: [0.0046, 0.5974], d_k_M_hat range: [0.3344, 0.9480]
2025-03-11 20:11:28 - Train Iteration 2987: loss: 0.6374, d_k_M range: [0.0688, 0.7939], d_k_M_hat range: [0.5368, 0.9955]
2025-03-11 20:11:29 - Train Iteration 2988: loss: 0.9338, d_k_M range: [0.0002, 0.3029], d_k_M_hat range: [0.0339, 0.7401]
2025-03-11 20:11:29 - Train Iteration 2989: loss: 0.5899, d_k_M range: [0.0182, 0.7567], d_k_M_hat range: [0.5050, 0.9887]
2025-03-11 20:11:30 - Train Iteration 2990: loss: 0.3636, d_k_M range: [0.0208, 0.4862], d_k_M_hat range: [0.4524, 0.8898]
2025-03-11 20:11:30 - Train Iteration 2991: loss: 0.4277, d_k_M range: [0.0056, 0.5799], d_k_M_hat range: [0.3516, 0.9627]
2025-03-11 20:11:30 - Train Iteration 2992: loss: 0.4023, d_k_M range: [0.2808, 0.5787], d_k_M_hat range: [0.6466, 0.9703]
2025-03-11 20:11:31 - Train Iteration 2993: loss: 0.4291, d_k_M range: [0.0103, 0.3695], d_k_M_hat range: [0.4006, 0.9089]
2025-03-11 20:11:31 - Train Iteration 2994: loss: 0.4242, d_k_M range: [0.0447, 0.6196], d_k_M_hat range: [0.5812, 0.9683]
2025-03-11 20:11:32 - Train Iteration 2995: loss: 0.3670, d_k_M range: [0.0164, 0.5901], d_k_M_hat range: [0.4764, 0.9843]
2025-03-11 20:11:32 - Train Iteration 2996: loss: 0.4831, d_k_M range: [0.0033, 0.5722], d_k_M_hat range: [0.3140, 0.9821]
2025-03-11 20:11:33 - Train Iteration 2997: loss: 0.3336, d_k_M range: [0.1500, 0.5234], d_k_M_hat range: [0.6144, 0.9615]
2025-03-11 20:11:33 - Train Iteration 2998: loss: 0.5759, d_k_M range: [0.2652, 0.7435], d_k_M_hat range: [0.7829, 0.9855]
2025-03-11 20:11:33 - Train Iteration 2999: loss: 0.4466, d_k_M range: [0.0449, 0.3546], d_k_M_hat range: [0.5324, 0.7191]
2025-03-11 20:11:34 - Train Iteration 3000: loss: 0.4845, d_k_M range: [0.0064, 0.6606], d_k_M_hat range: [0.4594, 0.9646]
2025-03-11 20:11:35 - Train Iteration 3001: loss: 0.3794, d_k_M range: [0.0016, 0.3784], d_k_M_hat range: [0.3856, 0.8720]
2025-03-11 20:11:35 - Train Iteration 3002: loss: 0.4529, d_k_M range: [0.1698, 0.6493], d_k_M_hat range: [0.5752, 0.9900]
2025-03-11 20:11:36 - Train Iteration 3003: loss: 0.4406, d_k_M range: [0.0268, 0.4437], d_k_M_hat range: [0.5621, 0.8879]
2025-03-11 20:11:36 - Train Iteration 3004: loss: 0.3494, d_k_M range: [0.0292, 0.5191], d_k_M_hat range: [0.4381, 0.9777]
2025-03-11 20:11:37 - Train Iteration 3005: loss: 0.3832, d_k_M range: [0.0071, 0.5569], d_k_M_hat range: [0.4118, 0.9585]
2025-03-11 20:11:37 - Train Iteration 3006: loss: 0.5416, d_k_M range: [0.0548, 0.6000], d_k_M_hat range: [0.4969, 0.9825]
2025-03-11 20:11:37 - Train Iteration 3007: loss: 0.4458, d_k_M range: [0.0092, 0.6583], d_k_M_hat range: [0.4241, 0.9906]
2025-03-11 20:11:38 - Train Iteration 3008: loss: 0.3895, d_k_M range: [0.0013, 0.3396], d_k_M_hat range: [0.3837, 0.7625]
2025-03-11 20:11:38 - Train Iteration 3009: loss: 0.4344, d_k_M range: [0.0099, 0.6221], d_k_M_hat range: [0.3816, 0.9793]
2025-03-11 20:11:39 - Train Iteration 3010: loss: 0.3501, d_k_M range: [0.0044, 0.2348], d_k_M_hat range: [0.4171, 0.7764]
2025-03-11 20:11:39 - Train Iteration 3011: loss: 0.4510, d_k_M range: [0.0154, 0.3811], d_k_M_hat range: [0.3438, 0.8766]
2025-03-11 20:11:39 - Train Iteration 3012: loss: 0.3328, d_k_M range: [0.0094, 0.4245], d_k_M_hat range: [0.4325, 0.9016]
2025-03-11 20:11:40 - Train Iteration 3013: loss: 0.8716, d_k_M range: [0.3402, 0.9319], d_k_M_hat range: [0.7366, 0.9983]
2025-03-11 20:11:40 - Train Iteration 3014: loss: 0.3310, d_k_M range: [0.0066, 0.3602], d_k_M_hat range: [0.4517, 0.8472]
2025-03-11 20:11:41 - Train Iteration 3015: loss: 0.4110, d_k_M range: [0.0824, 0.2945], d_k_M_hat range: [0.5536, 0.7424]
2025-03-11 20:11:41 - Train Iteration 3016: loss: 0.3262, d_k_M range: [0.1453, 0.4803], d_k_M_hat range: [0.6779, 0.9693]
2025-03-11 20:11:41 - Train Iteration 3017: loss: 0.3223, d_k_M range: [0.0144, 0.5543], d_k_M_hat range: [0.4479, 0.9866]
2025-03-11 20:11:42 - Train Iteration 3018: loss: 0.3726, d_k_M range: [0.0362, 0.5218], d_k_M_hat range: [0.4442, 0.9575]
2025-03-11 20:11:42 - Train Iteration 3019: loss: 0.4513, d_k_M range: [0.0037, 0.4637], d_k_M_hat range: [0.3319, 0.9377]
2025-03-11 20:11:43 - Train Iteration 3020: loss: 0.3526, d_k_M range: [0.0384, 0.5832], d_k_M_hat range: [0.5603, 0.9893]
2025-03-11 20:11:43 - Train Iteration 3021: loss: 0.3819, d_k_M range: [0.0049, 0.5166], d_k_M_hat range: [0.4325, 0.9811]
2025-03-11 20:11:44 - Train Iteration 3022: loss: 0.7991, d_k_M range: [0.0359, 0.8921], d_k_M_hat range: [0.5427, 0.9982]
2025-03-11 20:11:44 - Train Iteration 3023: loss: 0.6217, d_k_M range: [0.0067, 0.7782], d_k_M_hat range: [0.4033, 0.9897]
2025-03-11 20:11:44 - Train Iteration 3024: loss: 0.3274, d_k_M range: [0.0225, 0.5085], d_k_M_hat range: [0.4603, 0.9363]
2025-03-11 20:11:45 - Train Iteration 3025: loss: 0.3745, d_k_M range: [0.0109, 0.5361], d_k_M_hat range: [0.3989, 0.9599]
2025-03-11 20:11:45 - Train Iteration 3026: loss: 0.3948, d_k_M range: [0.1885, 0.6019], d_k_M_hat range: [0.6795, 0.9768]
2025-03-11 20:11:46 - Train Iteration 3027: loss: 0.4484, d_k_M range: [0.0009, 0.4090], d_k_M_hat range: [0.3313, 0.8227]
2025-03-11 20:11:46 - Train Iteration 3028: loss: 0.5376, d_k_M range: [0.0403, 0.5093], d_k_M_hat range: [0.4984, 0.9590]
2025-03-11 20:11:46 - Train Iteration 3029: loss: 0.3452, d_k_M range: [0.0093, 0.3368], d_k_M_hat range: [0.4218, 0.8798]
2025-03-11 20:11:47 - Train Iteration 3030: loss: 0.5377, d_k_M range: [0.0338, 0.7228], d_k_M_hat range: [0.5495, 0.9895]
2025-03-11 20:11:47 - Train Iteration 3031: loss: 0.8116, d_k_M range: [0.0012, 0.5074], d_k_M_hat range: [0.1003, 0.9233]
2025-03-11 20:11:48 - Train Iteration 3032: loss: 0.5541, d_k_M range: [0.0023, 0.7332], d_k_M_hat range: [0.3817, 0.9889]
2025-03-11 20:11:48 - Train Iteration 3033: loss: 0.3349, d_k_M range: [0.0148, 0.3816], d_k_M_hat range: [0.5061, 0.8226]
2025-03-11 20:11:49 - Train Iteration 3034: loss: 0.5220, d_k_M range: [0.0282, 0.7045], d_k_M_hat range: [0.4561, 0.9820]
2025-03-11 20:11:49 - Train Iteration 3035: loss: 0.6000, d_k_M range: [0.0004, 0.6135], d_k_M_hat range: [0.2258, 0.9686]
2025-03-11 20:11:49 - Train Iteration 3036: loss: 0.3705, d_k_M range: [0.0180, 0.5398], d_k_M_hat range: [0.4094, 0.9548]
2025-03-11 20:11:50 - Train Iteration 3037: loss: 0.7251, d_k_M range: [0.1433, 0.8497], d_k_M_hat range: [0.6984, 0.9982]
2025-03-11 20:11:50 - Train Iteration 3038: loss: 0.6855, d_k_M range: [0.0014, 0.3802], d_k_M_hat range: [0.1735, 0.8701]
2025-03-11 20:11:51 - Train Iteration 3039: loss: 0.4857, d_k_M range: [0.0434, 0.6877], d_k_M_hat range: [0.5216, 0.9907]
2025-03-11 20:11:51 - Train Iteration 3040: loss: 0.5293, d_k_M range: [0.0120, 0.7203], d_k_M_hat range: [0.3685, 0.9928]
2025-03-11 20:11:51 - Train Iteration 3041: loss: 0.6120, d_k_M range: [0.0058, 0.6172], d_k_M_hat range: [0.2235, 0.9707]
2025-03-11 20:11:52 - Train Iteration 3042: loss: 0.3552, d_k_M range: [0.1168, 0.4557], d_k_M_hat range: [0.5836, 0.9507]
2025-03-11 20:11:52 - Train Iteration 3043: loss: 0.4431, d_k_M range: [0.0160, 0.4184], d_k_M_hat range: [0.4790, 0.8982]
2025-03-11 20:11:53 - Train Iteration 3044: loss: 0.5346, d_k_M range: [0.0471, 0.7200], d_k_M_hat range: [0.5507, 0.9889]
2025-03-11 20:11:53 - Train Iteration 3045: loss: 0.4575, d_k_M range: [0.0877, 0.6232], d_k_M_hat range: [0.5370, 0.9693]
2025-03-11 20:11:54 - Train Iteration 3046: loss: 0.7911, d_k_M range: [0.0025, 0.4214], d_k_M_hat range: [0.1131, 0.9221]
2025-03-11 20:11:54 - Train Iteration 3047: loss: 0.3609, d_k_M range: [0.1463, 0.4333], d_k_M_hat range: [0.6481, 0.9150]
2025-03-11 20:11:54 - Train Iteration 3048: loss: 0.4486, d_k_M range: [0.0104, 0.6480], d_k_M_hat range: [0.4776, 0.9782]
2025-03-11 20:11:55 - Train Iteration 3049: loss: 0.5077, d_k_M range: [0.0040, 0.5645], d_k_M_hat range: [0.2915, 0.9748]
2025-03-11 20:11:55 - Train Iteration 3050: loss: 0.4116, d_k_M range: [0.0554, 0.6266], d_k_M_hat range: [0.5535, 0.9851]
2025-03-11 20:11:56 - Train Iteration 3051: loss: 0.4444, d_k_M range: [0.0033, 0.3699], d_k_M_hat range: [0.3389, 0.8664]
2025-03-11 20:11:56 - Train Iteration 3052: loss: 0.9950, d_k_M range: [0.0896, 0.9973], d_k_M_hat range: [0.5357, 0.9998]
2025-03-11 20:11:57 - Train Iteration 3053: loss: 0.3749, d_k_M range: [0.0353, 0.4780], d_k_M_hat range: [0.5303, 0.9396]
2025-03-11 20:11:57 - Train Iteration 3054: loss: 0.4776, d_k_M range: [0.0011, 0.1397], d_k_M_hat range: [0.3107, 0.5235]
2025-03-11 20:11:58 - Train Iteration 3055: loss: 0.4988, d_k_M range: [0.0039, 0.3966], d_k_M_hat range: [0.2976, 0.8729]
2025-03-11 20:11:58 - Train Iteration 3056: loss: 0.3621, d_k_M range: [0.0049, 0.3821], d_k_M_hat range: [0.4032, 0.8131]
2025-03-11 20:11:58 - Train Iteration 3057: loss: 0.4343, d_k_M range: [0.0241, 0.6532], d_k_M_hat range: [0.5041, 0.9941]
2025-03-11 20:11:59 - Train Iteration 3058: loss: 0.3795, d_k_M range: [0.0361, 0.5434], d_k_M_hat range: [0.4735, 0.9273]
2025-03-11 20:11:59 - Train Iteration 3059: loss: 0.4983, d_k_M range: [0.0009, 0.3423], d_k_M_hat range: [0.2950, 0.7119]
2025-03-11 20:12:00 - Train Iteration 3060: loss: 0.3783, d_k_M range: [0.0526, 0.5828], d_k_M_hat range: [0.4676, 0.9677]
2025-03-11 20:12:00 - Train Iteration 3061: loss: 0.3997, d_k_M range: [0.0035, 0.4521], d_k_M_hat range: [0.3812, 0.9458]
2025-03-11 20:12:01 - Train Iteration 3062: loss: 0.3443, d_k_M range: [0.1124, 0.4929], d_k_M_hat range: [0.5559, 0.9192]
2025-03-11 20:12:01 - Train Iteration 3063: loss: 0.4340, d_k_M range: [0.0028, 0.2808], d_k_M_hat range: [0.3582, 0.7911]
2025-03-11 20:12:01 - Train Iteration 3064: loss: 0.5021, d_k_M range: [0.0186, 0.6725], d_k_M_hat range: [0.4697, 0.9784]
2025-03-11 20:12:02 - Train Iteration 3065: loss: 0.7383, d_k_M range: [0.0010, 0.5463], d_k_M_hat range: [0.1417, 0.9341]
2025-03-11 20:12:02 - Train Iteration 3066: loss: 0.3625, d_k_M range: [0.1496, 0.5489], d_k_M_hat range: [0.6467, 0.9725]
2025-03-11 20:12:03 - Train Iteration 3067: loss: 0.6199, d_k_M range: [0.0917, 0.7828], d_k_M_hat range: [0.6094, 0.9955]
2025-03-11 20:12:03 - Train Iteration 3068: loss: 0.4950, d_k_M range: [0.0037, 0.4270], d_k_M_hat range: [0.3001, 0.8878]
2025-03-11 20:12:03 - Train Iteration 3069: loss: 0.7653, d_k_M range: [0.0421, 0.8659], d_k_M_hat range: [0.4556, 0.9911]
2025-03-11 20:12:04 - Train Iteration 3070: loss: 0.4500, d_k_M range: [0.0055, 0.4504], d_k_M_hat range: [0.3584, 0.8883]
2025-03-11 20:12:04 - Train Iteration 3071: loss: 0.4472, d_k_M range: [0.0019, 0.2778], d_k_M_hat range: [0.3332, 0.7364]
2025-03-11 20:12:05 - Train Iteration 3072: loss: 0.3929, d_k_M range: [0.0783, 0.5771], d_k_M_hat range: [0.5427, 0.9834]
2025-03-11 20:12:05 - Train Iteration 3073: loss: 0.8543, d_k_M range: [0.2306, 0.9221], d_k_M_hat range: [0.6477, 0.9978]
2025-03-11 20:12:06 - Train Iteration 3074: loss: 0.4359, d_k_M range: [0.0448, 0.6103], d_k_M_hat range: [0.5122, 0.9688]
2025-03-11 20:12:06 - Train Iteration 3075: loss: 0.4800, d_k_M range: [0.0304, 0.4487], d_k_M_hat range: [0.4955, 0.9399]
2025-03-11 20:12:06 - Train Iteration 3076: loss: 0.3542, d_k_M range: [0.0151, 0.4014], d_k_M_hat range: [0.4199, 0.9019]
2025-03-11 20:12:07 - Train Iteration 3077: loss: 0.7327, d_k_M range: [0.1934, 0.8482], d_k_M_hat range: [0.6684, 0.9922]
2025-03-11 20:12:07 - Train Iteration 3078: loss: 0.3973, d_k_M range: [0.0590, 0.3469], d_k_M_hat range: [0.5788, 0.8241]
2025-03-11 20:12:08 - Train Iteration 3079: loss: 0.3928, d_k_M range: [0.1649, 0.5997], d_k_M_hat range: [0.6528, 0.9744]
2025-03-11 20:12:08 - Train Iteration 3080: loss: 0.4261, d_k_M range: [0.0159, 0.6412], d_k_M_hat range: [0.4685, 0.9884]
2025-03-11 20:12:09 - Train Iteration 3081: loss: 0.3451, d_k_M range: [0.0164, 0.2832], d_k_M_hat range: [0.4852, 0.7204]
2025-03-11 20:12:09 - Train Iteration 3082: loss: 0.3645, d_k_M range: [0.0237, 0.4067], d_k_M_hat range: [0.5378, 0.8608]
2025-03-11 20:12:09 - Train Iteration 3083: loss: 0.3174, d_k_M range: [0.0050, 0.2593], d_k_M_hat range: [0.4548, 0.7350]
2025-03-11 20:12:10 - Train Iteration 3084: loss: 0.3714, d_k_M range: [0.0527, 0.5651], d_k_M_hat range: [0.5084, 0.9822]
2025-03-11 20:12:10 - Train Iteration 3085: loss: 0.4170, d_k_M range: [0.3068, 0.5611], d_k_M_hat range: [0.6611, 0.9802]
2025-03-11 20:12:11 - Train Iteration 3086: loss: 0.5891, d_k_M range: [0.0025, 0.2593], d_k_M_hat range: [0.2350, 0.6594]
2025-03-11 20:12:11 - Train Iteration 3087: loss: 0.5812, d_k_M range: [0.0198, 0.7521], d_k_M_hat range: [0.4724, 0.9923]
2025-03-11 20:12:12 - Train Iteration 3088: loss: 0.4461, d_k_M range: [0.0053, 0.3956], d_k_M_hat range: [0.3436, 0.8908]
2025-03-11 20:12:12 - Train Iteration 3089: loss: 0.4268, d_k_M range: [0.0721, 0.6120], d_k_M_hat range: [0.5880, 0.9587]
2025-03-11 20:12:12 - Train Iteration 3090: loss: 0.4210, d_k_M range: [0.0013, 0.3627], d_k_M_hat range: [0.3524, 0.7825]
2025-03-11 20:12:13 - Train Iteration 3091: loss: 0.4365, d_k_M range: [0.2479, 0.6004], d_k_M_hat range: [0.6802, 0.9704]
2025-03-11 20:12:13 - Train Iteration 3092: loss: 0.4106, d_k_M range: [0.0308, 0.5752], d_k_M_hat range: [0.4719, 0.9345]
2025-03-11 20:12:14 - Train Iteration 3093: loss: 0.5828, d_k_M range: [0.0007, 0.4452], d_k_M_hat range: [0.2373, 0.9139]
2025-03-11 20:12:14 - Train Iteration 3094: loss: 0.6269, d_k_M range: [0.2687, 0.7857], d_k_M_hat range: [0.7297, 0.9939]
2025-03-11 20:12:15 - Train Iteration 3095: loss: 0.4697, d_k_M range: [0.1033, 0.4913], d_k_M_hat range: [0.5537, 0.9682]
2025-03-11 20:12:15 - Train Iteration 3096: loss: 0.3479, d_k_M range: [0.0292, 0.3867], d_k_M_hat range: [0.5600, 0.8520]
2025-03-11 20:12:15 - Train Iteration 3097: loss: 0.4354, d_k_M range: [0.1059, 0.6476], d_k_M_hat range: [0.5818, 0.9878]
2025-03-11 20:12:16 - Train Iteration 3098: loss: 0.4380, d_k_M range: [0.0044, 0.5018], d_k_M_hat range: [0.3434, 0.9091]
2025-03-11 20:12:16 - Train Iteration 3099: loss: 0.7633, d_k_M range: [0.0301, 0.8716], d_k_M_hat range: [0.5536, 0.9980]
2025-03-11 20:12:17 - Train Iteration 3100: loss: 0.6320, d_k_M range: [0.0031, 0.7839], d_k_M_hat range: [0.2987, 0.9889]
2025-03-11 20:12:17 - Train Iteration 3101: loss: 0.3931, d_k_M range: [0.0106, 0.5068], d_k_M_hat range: [0.4223, 0.9449]
2025-03-11 20:12:18 - Train Iteration 3102: loss: 0.8253, d_k_M range: [0.0001, 0.3386], d_k_M_hat range: [0.0916, 0.8218]
2025-03-11 20:12:18 - Train Iteration 3103: loss: 0.3630, d_k_M range: [0.0119, 0.5341], d_k_M_hat range: [0.4344, 0.9557]
2025-03-11 20:12:19 - Train Iteration 3104: loss: 0.4051, d_k_M range: [0.0175, 0.5688], d_k_M_hat range: [0.4264, 0.9746]
2025-03-11 20:12:19 - Train Iteration 3105: loss: 0.6699, d_k_M range: [0.2841, 0.8108], d_k_M_hat range: [0.6795, 0.9923]
2025-03-11 20:12:19 - Train Iteration 3106: loss: 0.4195, d_k_M range: [0.0029, 0.5444], d_k_M_hat range: [0.3552, 0.9833]
2025-03-11 20:12:20 - Train Iteration 3107: loss: 0.3454, d_k_M range: [0.0361, 0.3748], d_k_M_hat range: [0.5019, 0.8407]
2025-03-11 20:12:20 - Train Iteration 3108: loss: 0.3099, d_k_M range: [0.0264, 0.4107], d_k_M_hat range: [0.5061, 0.8540]
2025-03-11 20:12:21 - Train Iteration 3109: loss: 0.3157, d_k_M range: [0.0685, 0.5261], d_k_M_hat range: [0.6322, 0.9779]
2025-03-11 20:12:21 - Train Iteration 3110: loss: 0.3384, d_k_M range: [0.0427, 0.4515], d_k_M_hat range: [0.5291, 0.9403]
2025-03-11 20:12:21 - Train Iteration 3111: loss: 0.3561, d_k_M range: [0.0269, 0.5498], d_k_M_hat range: [0.4425, 0.9852]
2025-03-11 20:12:22 - Train Iteration 3112: loss: 0.6120, d_k_M range: [0.0005, 0.4983], d_k_M_hat range: [0.2182, 0.9292]
2025-03-11 20:12:22 - Train Iteration 3113: loss: 0.3926, d_k_M range: [0.0401, 0.5070], d_k_M_hat range: [0.5795, 0.9551]
2025-03-11 20:12:23 - Train Iteration 3114: loss: 0.3680, d_k_M range: [0.0712, 0.5577], d_k_M_hat range: [0.5653, 0.9706]
2025-03-11 20:12:23 - Train Iteration 3115: loss: 0.3319, d_k_M range: [0.0655, 0.5164], d_k_M_hat range: [0.5123, 0.9521]
2025-03-11 20:12:24 - Train Iteration 3116: loss: 0.4809, d_k_M range: [0.0589, 0.6750], d_k_M_hat range: [0.5382, 0.9919]
2025-03-11 20:12:24 - Train Iteration 3117: loss: 0.2675, d_k_M range: [0.0241, 0.3183], d_k_M_hat range: [0.5072, 0.8599]
2025-03-11 20:12:24 - Train Iteration 3118: loss: 0.3912, d_k_M range: [0.0158, 0.5058], d_k_M_hat range: [0.5217, 0.9694]
2025-03-11 20:12:25 - Train Iteration 3119: loss: 0.9098, d_k_M range: [0.1783, 0.9529], d_k_M_hat range: [0.6930, 0.9991]
2025-03-11 20:12:25 - Train Iteration 3120: loss: 0.7465, d_k_M range: [0.0006, 0.6449], d_k_M_hat range: [0.1365, 0.9904]
2025-03-11 20:12:26 - Train Iteration 3121: loss: 0.6387, d_k_M range: [0.0613, 0.7966], d_k_M_hat range: [0.5653, 0.9974]
2025-03-11 20:12:26 - Train Iteration 3122: loss: 0.4205, d_k_M range: [0.0012, 0.4039], d_k_M_hat range: [0.3527, 0.9050]
2025-03-11 20:12:27 - Train Iteration 3123: loss: 0.6132, d_k_M range: [0.0805, 0.7728], d_k_M_hat range: [0.5697, 0.9950]
2025-03-11 20:12:27 - Train Iteration 3124: loss: 0.4167, d_k_M range: [0.0029, 0.4693], d_k_M_hat range: [0.3574, 0.9392]
2025-03-11 20:12:28 - Train Iteration 3125: loss: 0.3670, d_k_M range: [0.0735, 0.3403], d_k_M_hat range: [0.5408, 0.7507]
2025-03-11 20:12:28 - Train Iteration 3126: loss: 0.3371, d_k_M range: [0.0050, 0.4197], d_k_M_hat range: [0.4865, 0.8789]
2025-03-11 20:12:29 - Train Iteration 3127: loss: 0.4003, d_k_M range: [0.0853, 0.5780], d_k_M_hat range: [0.6371, 0.9704]
2025-03-11 20:12:29 - Train Iteration 3128: loss: 0.3859, d_k_M range: [0.0341, 0.3534], d_k_M_hat range: [0.5017, 0.8048]
2025-03-11 20:12:29 - Train Iteration 3129: loss: 0.4903, d_k_M range: [0.0015, 0.4658], d_k_M_hat range: [0.3013, 0.8751]
2025-03-11 20:12:30 - Train Iteration 3130: loss: 0.8726, d_k_M range: [0.2167, 0.9325], d_k_M_hat range: [0.6541, 0.9983]
2025-03-11 20:12:30 - Train Iteration 3131: loss: 0.3250, d_k_M range: [0.0687, 0.5037], d_k_M_hat range: [0.5659, 0.9359]
2025-03-11 20:12:31 - Train Iteration 3132: loss: 0.3683, d_k_M range: [0.0407, 0.4656], d_k_M_hat range: [0.5110, 0.8921]
2025-03-11 20:12:31 - Train Iteration 3133: loss: 0.4009, d_k_M range: [0.0771, 0.6038], d_k_M_hat range: [0.6045, 0.9735]
2025-03-11 20:12:32 - Train Iteration 3134: loss: 0.3582, d_k_M range: [0.0295, 0.5028], d_k_M_hat range: [0.5637, 0.9242]
2025-03-11 20:12:32 - Train Iteration 3135: loss: 0.4578, d_k_M range: [0.0688, 0.6680], d_k_M_hat range: [0.5182, 0.9914]
2025-03-11 20:12:33 - Train Iteration 3136: loss: 0.4175, d_k_M range: [0.2119, 0.6323], d_k_M_hat range: [0.6676, 0.9861]
2025-03-11 20:12:33 - Train Iteration 3137: loss: 0.3965, d_k_M range: [0.0026, 0.3943], d_k_M_hat range: [0.3729, 0.8832]
2025-03-11 20:12:33 - Train Iteration 3138: loss: 0.4045, d_k_M range: [0.0942, 0.5249], d_k_M_hat range: [0.6276, 0.9559]
2025-03-11 20:12:34 - Train Iteration 3139: loss: 0.4236, d_k_M range: [0.0025, 0.2840], d_k_M_hat range: [0.3517, 0.8174]
2025-03-11 20:12:34 - Train Iteration 3140: loss: 0.3829, d_k_M range: [0.2860, 0.5921], d_k_M_hat range: [0.8885, 0.9847]
2025-03-11 20:12:35 - Train Iteration 3141: loss: 0.4486, d_k_M range: [0.0055, 0.3759], d_k_M_hat range: [0.3396, 0.9187]
2025-03-11 20:12:35 - Train Iteration 3142: loss: 0.4031, d_k_M range: [0.0644, 0.6102], d_k_M_hat range: [0.5608, 0.9753]
2025-03-11 20:12:35 - Train Iteration 3143: loss: 0.7261, d_k_M range: [0.0134, 0.8403], d_k_M_hat range: [0.3959, 0.9882]
2025-03-11 20:12:36 - Train Iteration 3144: loss: 0.3887, d_k_M range: [0.0762, 0.5617], d_k_M_hat range: [0.5108, 0.9793]
2025-03-11 20:12:36 - Train Iteration 3145: loss: 0.4634, d_k_M range: [0.0025, 0.3272], d_k_M_hat range: [0.3217, 0.8482]
2025-03-11 20:12:37 - Train Iteration 3146: loss: 0.4153, d_k_M range: [0.1634, 0.6330], d_k_M_hat range: [0.6915, 0.9885]
2025-03-11 20:12:37 - Train Iteration 3147: loss: 0.4072, d_k_M range: [0.0026, 0.4355], d_k_M_hat range: [0.3645, 0.8675]
2025-03-11 20:12:38 - Train Iteration 3148: loss: 0.3595, d_k_M range: [0.0910, 0.4896], d_k_M_hat range: [0.5780, 0.9654]
2025-03-11 20:12:38 - Train Iteration 3149: loss: 0.4401, d_k_M range: [0.0172, 0.4129], d_k_M_hat range: [0.3538, 0.8525]
2025-03-11 20:12:39 - Train Iteration 3150: loss: 0.4331, d_k_M range: [0.0058, 0.5276], d_k_M_hat range: [0.3635, 0.9716]
2025-03-11 20:12:39 - Train Iteration 3151: loss: 0.4818, d_k_M range: [0.0002, 0.4196], d_k_M_hat range: [0.3061, 0.9266]
2025-03-11 20:12:39 - Train Iteration 3152: loss: 0.3046, d_k_M range: [0.0190, 0.5156], d_k_M_hat range: [0.4915, 0.9715]
2025-03-11 20:12:40 - Train Iteration 3153: loss: 0.6135, d_k_M range: [0.0012, 0.7808], d_k_M_hat range: [0.3776, 0.9976]
2025-03-11 20:12:40 - Train Iteration 3154: loss: 0.4562, d_k_M range: [0.0040, 0.4326], d_k_M_hat range: [0.3286, 0.8863]
2025-03-11 20:12:41 - Train Iteration 3155: loss: 0.3244, d_k_M range: [0.0367, 0.5425], d_k_M_hat range: [0.5330, 0.9786]
2025-03-11 20:12:41 - Train Iteration 3156: loss: 0.5162, d_k_M range: [0.0015, 0.3086], d_k_M_hat range: [0.2831, 0.7005]
2025-03-11 20:12:41 - Train Iteration 3157: loss: 0.3630, d_k_M range: [0.0021, 0.4444], d_k_M_hat range: [0.3996, 0.8963]
2025-03-11 20:12:42 - Train Iteration 3158: loss: 0.4857, d_k_M range: [0.0123, 0.6859], d_k_M_hat range: [0.4505, 0.9890]
2025-03-11 20:12:42 - Train Iteration 3159: loss: 0.6489, d_k_M range: [0.0007, 0.3341], d_k_M_hat range: [0.1952, 0.7993]
2025-03-11 20:12:43 - Train Iteration 3160: loss: 0.3902, d_k_M range: [0.0951, 0.6101], d_k_M_hat range: [0.6213, 0.9918]
2025-03-11 20:12:43 - Train Iteration 3161: loss: 0.3018, d_k_M range: [0.0697, 0.4978], d_k_M_hat range: [0.5331, 0.9696]
2025-03-11 20:12:44 - Train Iteration 3162: loss: 0.4702, d_k_M range: [0.0206, 0.4557], d_k_M_hat range: [0.4564, 0.9007]
2025-03-11 20:12:44 - Train Iteration 3163: loss: 0.3496, d_k_M range: [0.0504, 0.5490], d_k_M_hat range: [0.4959, 0.9598]
2025-03-11 20:12:44 - Train Iteration 3164: loss: 0.2952, d_k_M range: [0.0101, 0.4590], d_k_M_hat range: [0.4786, 0.9635]
2025-03-11 20:12:45 - Train Iteration 3165: loss: 0.8912, d_k_M range: [0.0003, 0.1892], d_k_M_hat range: [0.0563, 0.7869]
2025-03-11 20:12:45 - Train Iteration 3166: loss: 0.4009, d_k_M range: [0.0876, 0.5064], d_k_M_hat range: [0.6236, 0.9601]
2025-03-11 20:12:46 - Train Iteration 3167: loss: 0.7743, d_k_M range: [0.0910, 0.8769], d_k_M_hat range: [0.7105, 0.9970]
2025-03-11 20:12:46 - Train Iteration 3168: loss: 0.6565, d_k_M range: [0.0676, 0.8011], d_k_M_hat range: [0.5443, 0.9952]
2025-03-11 20:12:47 - Train Iteration 3169: loss: 0.4154, d_k_M range: [0.0004, 0.2987], d_k_M_hat range: [0.3611, 0.7424]
2025-03-11 20:12:47 - Train Iteration 3170: loss: 0.3507, d_k_M range: [0.0014, 0.5473], d_k_M_hat range: [0.4116, 0.9590]
2025-03-11 20:12:48 - Train Iteration 3171: loss: 0.3510, d_k_M range: [0.0519, 0.4757], d_k_M_hat range: [0.5443, 0.9470]
2025-03-11 20:12:48 - Train Iteration 3172: loss: 0.5253, d_k_M range: [0.0387, 0.7203], d_k_M_hat range: [0.3979, 0.9955]
2025-03-11 20:12:48 - Train Iteration 3173: loss: 0.7002, d_k_M range: [0.0006, 0.2961], d_k_M_hat range: [0.1638, 0.8514]
2025-03-11 20:12:49 - Train Iteration 3174: loss: 0.3841, d_k_M range: [0.0195, 0.4933], d_k_M_hat range: [0.5633, 0.9583]
2025-03-11 20:12:49 - Train Iteration 3175: loss: 0.4213, d_k_M range: [0.0223, 0.5802], d_k_M_hat range: [0.5015, 0.9898]
2025-03-11 20:12:50 - Train Iteration 3176: loss: 0.3321, d_k_M range: [0.1001, 0.4073], d_k_M_hat range: [0.5677, 0.9375]
2025-03-11 20:12:50 - Train Iteration 3177: loss: 0.3765, d_k_M range: [0.0642, 0.6085], d_k_M_hat range: [0.5619, 0.9949]
2025-03-11 20:12:51 - Train Iteration 3178: loss: 0.3629, d_k_M range: [0.0510, 0.5372], d_k_M_hat range: [0.4759, 0.9833]
2025-03-11 20:12:51 - Train Iteration 3179: loss: 0.7756, d_k_M range: [0.3056, 0.8802], d_k_M_hat range: [0.7069, 0.9995]
2025-03-11 20:12:52 - Train Iteration 3180: loss: 0.6019, d_k_M range: [0.0005, 0.2624], d_k_M_hat range: [0.2247, 0.8542]
2025-03-11 20:12:52 - Train Iteration 3181: loss: 0.4866, d_k_M range: [0.1410, 0.6865], d_k_M_hat range: [0.6567, 0.9889]
2025-03-11 20:12:53 - Train Iteration 3182: loss: 0.6546, d_k_M range: [0.0007, 0.3985], d_k_M_hat range: [0.1916, 0.8653]
2025-03-11 20:12:53 - Train Iteration 3183: loss: 0.4907, d_k_M range: [0.0875, 0.6869], d_k_M_hat range: [0.6290, 0.9864]
2025-03-11 20:12:54 - Train Iteration 3184: loss: 0.4635, d_k_M range: [0.1650, 0.6756], d_k_M_hat range: [0.6378, 0.9948]
2025-03-11 20:12:54 - Train Iteration 3185: loss: 0.5690, d_k_M range: [0.0320, 0.7503], d_k_M_hat range: [0.4952, 0.9960]
2025-03-11 20:12:54 - Train Iteration 3186: loss: 0.7504, d_k_M range: [0.0004, 0.4394], d_k_M_hat range: [0.1341, 0.8809]
2025-03-11 20:12:55 - Train Iteration 3187: loss: 0.5432, d_k_M range: [0.0100, 0.7313], d_k_M_hat range: [0.4735, 0.9942]
2025-03-11 20:12:55 - Train Iteration 3188: loss: 0.4569, d_k_M range: [0.0050, 0.4154], d_k_M_hat range: [0.3290, 0.9215]
2025-03-11 20:12:56 - Train Iteration 3189: loss: 0.3929, d_k_M range: [0.0611, 0.6036], d_k_M_hat range: [0.5152, 0.9768]
2025-03-11 20:12:56 - Train Iteration 3190: loss: 0.3821, d_k_M range: [0.0175, 0.4107], d_k_M_hat range: [0.4239, 0.8478]
2025-03-11 20:12:57 - Train Iteration 3191: loss: 0.3434, d_k_M range: [0.0096, 0.4398], d_k_M_hat range: [0.4380, 0.9319]
2025-03-11 20:12:57 - Train Iteration 3192: loss: 0.5257, d_k_M range: [0.1259, 0.7122], d_k_M_hat range: [0.5491, 0.9872]
2025-03-11 20:12:58 - Train Iteration 3193: loss: 0.5147, d_k_M range: [0.0009, 0.2587], d_k_M_hat range: [0.2854, 0.7346]
2025-03-11 20:12:58 - Train Iteration 3194: loss: 0.4841, d_k_M range: [0.1030, 0.6755], d_k_M_hat range: [0.5360, 0.9798]
2025-03-11 20:12:59 - Train Iteration 3195: loss: 0.4700, d_k_M range: [0.0060, 0.5335], d_k_M_hat range: [0.3394, 0.9440]
2025-03-11 20:12:59 - Train Iteration 3196: loss: 0.5101, d_k_M range: [0.0093, 0.4425], d_k_M_hat range: [0.2951, 0.9016]
2025-03-11 20:12:59 - Train Iteration 3197: loss: 0.4221, d_k_M range: [0.0132, 0.2787], d_k_M_hat range: [0.3635, 0.7145]
2025-03-11 20:13:00 - Train Iteration 3198: loss: 0.7747, d_k_M range: [0.0004, 0.5333], d_k_M_hat range: [0.1202, 0.9560]
2025-03-11 20:13:00 - Train Iteration 3199: loss: 0.4097, d_k_M range: [0.0829, 0.6287], d_k_M_hat range: [0.5771, 0.9886]
2025-03-11 20:13:01 - Train Iteration 3200: loss: 0.4888, d_k_M range: [0.0053, 0.4979], d_k_M_hat range: [0.3188, 0.9452]
2025-03-11 20:13:01 - Train Iteration 3201: loss: 0.3729, d_k_M range: [0.2764, 0.4928], d_k_M_hat range: [0.6658, 0.9396]
2025-03-11 20:13:02 - Train Iteration 3202: loss: 0.4217, d_k_M range: [0.0214, 0.6317], d_k_M_hat range: [0.4253, 0.9867]
2025-03-11 20:13:02 - Train Iteration 3203: loss: 0.3643, d_k_M range: [0.0117, 0.5686], d_k_M_hat range: [0.5340, 0.9693]
2025-03-11 20:13:02 - Train Iteration 3204: loss: 0.3264, d_k_M range: [0.0387, 0.3760], d_k_M_hat range: [0.5023, 0.8231]
2025-03-11 20:13:03 - Train Iteration 3205: loss: 0.3481, d_k_M range: [0.0303, 0.4055], d_k_M_hat range: [0.5079, 0.8227]
2025-03-11 20:13:03 - Train Iteration 3206: loss: 0.3825, d_k_M range: [0.0153, 0.4642], d_k_M_hat range: [0.4557, 0.8572]
2025-03-11 20:13:04 - Train Iteration 3207: loss: 0.4359, d_k_M range: [0.0405, 0.6041], d_k_M_hat range: [0.5852, 0.9463]
2025-03-11 20:13:04 - Train Iteration 3208: loss: 0.4106, d_k_M range: [0.0911, 0.4854], d_k_M_hat range: [0.5855, 0.9822]
2025-03-11 20:13:05 - Train Iteration 3209: loss: 0.9475, d_k_M range: [0.0130, 0.9728], d_k_M_hat range: [0.4001, 0.9994]
2025-03-11 20:13:05 - Train Iteration 3210: loss: 0.3321, d_k_M range: [0.0034, 0.3593], d_k_M_hat range: [0.4416, 0.8318]
2025-03-11 20:13:05 - Train Iteration 3211: loss: 0.5341, d_k_M range: [0.0032, 0.7223], d_k_M_hat range: [0.4091, 0.9914]
2025-03-11 20:13:06 - Train Iteration 3212: loss: 0.4287, d_k_M range: [0.0065, 0.3479], d_k_M_hat range: [0.3734, 0.7731]
2025-03-11 20:13:06 - Train Iteration 3213: loss: 0.5812, d_k_M range: [0.0789, 0.7402], d_k_M_hat range: [0.6443, 0.9779]
2025-03-11 20:13:07 - Train Iteration 3214: loss: 0.4132, d_k_M range: [0.0536, 0.4349], d_k_M_hat range: [0.5145, 0.9137]
2025-03-11 20:13:07 - Train Iteration 3215: loss: 0.4282, d_k_M range: [0.0410, 0.4542], d_k_M_hat range: [0.5012, 0.9204]
2025-03-11 20:13:08 - Train Iteration 3216: loss: 0.5593, d_k_M range: [0.0044, 0.5899], d_k_M_hat range: [0.2565, 0.9705]
2025-03-11 20:13:08 - Train Iteration 3217: loss: 0.3884, d_k_M range: [0.0803, 0.6077], d_k_M_hat range: [0.5674, 0.9844]
2025-03-11 20:13:09 - Train Iteration 3218: loss: 0.5999, d_k_M range: [0.0020, 0.4004], d_k_M_hat range: [0.2275, 0.8799]
2025-03-11 20:13:09 - Train Iteration 3219: loss: 0.3595, d_k_M range: [0.1026, 0.5381], d_k_M_hat range: [0.6040, 0.9530]
2025-03-11 20:13:10 - Train Iteration 3220: loss: 0.4096, d_k_M range: [0.0136, 0.4265], d_k_M_hat range: [0.3736, 0.9594]
2025-03-11 20:13:10 - Train Iteration 3221: loss: 0.4196, d_k_M range: [0.0034, 0.6125], d_k_M_hat range: [0.4062, 0.9758]
2025-03-11 20:13:10 - Train Iteration 3222: loss: 0.8757, d_k_M range: [0.0001, 0.4486], d_k_M_hat range: [0.0644, 0.9227]
2025-03-11 20:13:11 - Train Iteration 3223: loss: 0.3091, d_k_M range: [0.0370, 0.4959], d_k_M_hat range: [0.5005, 0.9399]
2025-03-11 20:13:11 - Train Iteration 3224: loss: 0.4816, d_k_M range: [0.0059, 0.6494], d_k_M_hat range: [0.3364, 0.9800]
2025-03-11 20:13:12 - Train Iteration 3225: loss: 0.3250, d_k_M range: [0.0221, 0.4820], d_k_M_hat range: [0.4520, 0.9350]
2025-03-11 20:13:12 - Train Iteration 3226: loss: 0.3857, d_k_M range: [0.0069, 0.4266], d_k_M_hat range: [0.4094, 0.9300]
2025-03-11 20:13:12 - Train Iteration 3227: loss: 0.9847, d_k_M range: [0.0000, 0.3071], d_k_M_hat range: [0.0077, 0.7324]
2025-03-11 20:13:13 - Train Iteration 3228: loss: 0.4325, d_k_M range: [0.0059, 0.5785], d_k_M_hat range: [0.3482, 0.9693]
2025-03-11 20:13:13 - Train Iteration 3229: loss: 0.4742, d_k_M range: [0.0375, 0.6606], d_k_M_hat range: [0.5101, 0.9758]
2025-03-11 20:13:14 - Train Iteration 3230: loss: 0.4190, d_k_M range: [0.0590, 0.2829], d_k_M_hat range: [0.4890, 0.8058]
2025-03-11 20:13:14 - Train Iteration 3231: loss: 0.4606, d_k_M range: [0.0076, 0.6615], d_k_M_hat range: [0.4521, 0.9828]
2025-03-11 20:13:15 - Train Iteration 3232: loss: 0.7779, d_k_M range: [0.0003, 0.4187], d_k_M_hat range: [0.1184, 0.9069]
2025-03-11 20:13:15 - Train Iteration 3233: loss: 0.3720, d_k_M range: [0.0163, 0.5637], d_k_M_hat range: [0.5022, 0.9538]
2025-03-11 20:13:16 - Train Iteration 3234: loss: 0.4974, d_k_M range: [0.0145, 0.4142], d_k_M_hat range: [0.4158, 0.8676]
2025-03-11 20:13:16 - Train Iteration 3235: loss: 0.4454, d_k_M range: [0.0260, 0.5878], d_k_M_hat range: [0.4615, 0.9816]
2025-03-11 20:13:16 - Train Iteration 3236: loss: 0.4879, d_k_M range: [0.0047, 0.3443], d_k_M_hat range: [0.3062, 0.8785]
2025-03-11 20:13:17 - Train Iteration 3237: loss: 0.7219, d_k_M range: [0.0357, 0.8456], d_k_M_hat range: [0.5992, 0.9960]
2025-03-11 20:13:17 - Train Iteration 3238: loss: 0.3382, d_k_M range: [0.0431, 0.2558], d_k_M_hat range: [0.4934, 0.7131]
2025-03-11 20:13:18 - Train Iteration 3239: loss: 0.3566, d_k_M range: [0.0024, 0.4560], d_k_M_hat range: [0.4053, 0.9238]
2025-03-11 20:13:18 - Train Iteration 3240: loss: 0.7715, d_k_M range: [0.0966, 0.8771], d_k_M_hat range: [0.5864, 0.9988]
2025-03-11 20:13:19 - Train Iteration 3241: loss: 0.3803, d_k_M range: [0.0827, 0.5803], d_k_M_hat range: [0.5304, 0.9636]
2025-03-11 20:13:19 - Train Iteration 3242: loss: 0.4572, d_k_M range: [0.0021, 0.6627], d_k_M_hat range: [0.3385, 0.9866]
2025-03-11 20:13:19 - Train Iteration 3243: loss: 0.3779, d_k_M range: [0.0049, 0.3164], d_k_M_hat range: [0.3902, 0.8473]
2025-03-11 20:13:20 - Train Iteration 3244: loss: 0.3037, d_k_M range: [0.0629, 0.5066], d_k_M_hat range: [0.5922, 0.9785]
2025-03-11 20:13:20 - Train Iteration 3245: loss: 0.7391, d_k_M range: [0.0634, 0.8485], d_k_M_hat range: [0.5371, 0.9888]
2025-03-11 20:13:21 - Train Iteration 3246: loss: 0.2889, d_k_M range: [0.0207, 0.4898], d_k_M_hat range: [0.5479, 0.9524]
2025-03-11 20:13:21 - Train Iteration 3247: loss: 0.3757, d_k_M range: [0.0160, 0.5641], d_k_M_hat range: [0.5088, 0.9511]
2025-03-11 20:13:21 - Train Iteration 3248: loss: 0.3202, d_k_M range: [0.0423, 0.4780], d_k_M_hat range: [0.5747, 0.9200]
2025-03-11 20:13:22 - Train Iteration 3249: loss: 0.4045, d_k_M range: [0.0062, 0.3355], d_k_M_hat range: [0.3702, 0.7815]
2025-03-11 20:13:22 - Train Iteration 3250: loss: 0.3555, d_k_M range: [0.0152, 0.5820], d_k_M_hat range: [0.5411, 0.9881]
2025-03-11 20:13:23 - Train Iteration 3251: loss: 0.5617, d_k_M range: [0.0027, 0.7439], d_k_M_hat range: [0.3896, 0.9944]
2025-03-11 20:13:23 - Train Iteration 3252: loss: 0.3332, d_k_M range: [0.0273, 0.5673], d_k_M_hat range: [0.4999, 0.9900]
2025-03-11 20:13:24 - Train Iteration 3253: loss: 0.4057, d_k_M range: [0.0203, 0.5493], d_k_M_hat range: [0.4789, 0.9716]
2025-03-11 20:13:24 - Train Iteration 3254: loss: 0.3438, d_k_M range: [0.0223, 0.5713], d_k_M_hat range: [0.4994, 0.9849]
2025-03-11 20:13:24 - Train Iteration 3255: loss: 0.5073, d_k_M range: [0.0032, 0.3763], d_k_M_hat range: [0.2910, 0.9209]
2025-03-11 20:13:25 - Train Iteration 3256: loss: 0.3346, d_k_M range: [0.1595, 0.4870], d_k_M_hat range: [0.6474, 0.9695]
2025-03-11 20:13:25 - Train Iteration 3257: loss: 0.3143, d_k_M range: [0.0229, 0.4110], d_k_M_hat range: [0.5414, 0.9171]
2025-03-11 20:13:26 - Train Iteration 3258: loss: 0.6599, d_k_M range: [0.0084, 0.5651], d_k_M_hat range: [0.1961, 0.9868]
2025-03-11 20:13:26 - Train Iteration 3259: loss: 0.6847, d_k_M range: [0.0318, 0.8260], d_k_M_hat range: [0.5507, 0.9985]
2025-03-11 20:13:26 - Train Iteration 3260: loss: 0.3788, d_k_M range: [0.0056, 0.3643], d_k_M_hat range: [0.4274, 0.8914]
2025-03-11 20:13:27 - Train Iteration 3261: loss: 0.3449, d_k_M range: [0.0263, 0.5802], d_k_M_hat range: [0.6063, 0.9929]
2025-03-11 20:13:27 - Train Iteration 3262: loss: 0.3339, d_k_M range: [0.0184, 0.3966], d_k_M_hat range: [0.4459, 0.9355]
2025-03-11 20:13:28 - Train Iteration 3263: loss: 0.6007, d_k_M range: [0.2007, 0.7672], d_k_M_hat range: [0.6933, 0.9953]
2025-03-11 20:13:28 - Train Iteration 3264: loss: 0.3430, d_k_M range: [0.0632, 0.3632], d_k_M_hat range: [0.5123, 0.8540]
2025-03-11 20:13:29 - Train Iteration 3265: loss: 0.4025, d_k_M range: [0.1596, 0.5715], d_k_M_hat range: [0.5939, 0.9812]
2025-03-11 20:13:29 - Train Iteration 3266: loss: 0.4165, d_k_M range: [0.0017, 0.3594], d_k_M_hat range: [0.3575, 0.8575]
2025-03-11 20:13:30 - Train Iteration 3267: loss: 0.5573, d_k_M range: [0.1180, 0.7454], d_k_M_hat range: [0.6109, 0.9988]
2025-03-11 20:13:30 - Train Iteration 3268: loss: 0.3986, d_k_M range: [0.0033, 0.4406], d_k_M_hat range: [0.3961, 0.8435]
2025-03-11 20:13:31 - Train Iteration 3269: loss: 0.7096, d_k_M range: [0.0300, 0.8399], d_k_M_hat range: [0.5095, 0.9975]
2025-03-11 20:13:31 - Train Iteration 3270: loss: 0.5154, d_k_M range: [0.0100, 0.6826], d_k_M_hat range: [0.3561, 0.9647]
2025-03-11 20:13:31 - Train Iteration 3271: loss: 0.3751, d_k_M range: [0.0020, 0.3973], d_k_M_hat range: [0.4026, 0.9157]
2025-03-11 20:13:32 - Train Iteration 3272: loss: 0.8147, d_k_M range: [0.2298, 0.8984], d_k_M_hat range: [0.7102, 0.9957]
2025-03-11 20:13:32 - Train Iteration 3273: loss: 0.4650, d_k_M range: [0.0003, 0.4139], d_k_M_hat range: [0.3184, 0.9506]
2025-03-11 20:13:33 - Train Iteration 3274: loss: 0.4591, d_k_M range: [0.0730, 0.6732], d_k_M_hat range: [0.5794, 0.9956]
2025-03-11 20:13:33 - Train Iteration 3275: loss: 0.3956, d_k_M range: [0.0066, 0.3302], d_k_M_hat range: [0.3777, 0.7027]
2025-03-11 20:13:33 - Train Iteration 3276: loss: 0.3676, d_k_M range: [0.0421, 0.5739], d_k_M_hat range: [0.5500, 0.9760]
2025-03-11 20:13:34 - Train Iteration 3277: loss: 0.5088, d_k_M range: [0.0041, 0.4102], d_k_M_hat range: [0.2930, 0.7709]
2025-03-11 20:13:34 - Train Iteration 3278: loss: 0.6372, d_k_M range: [0.0875, 0.7966], d_k_M_hat range: [0.5826, 0.9984]
2025-03-11 20:13:35 - Train Iteration 3279: loss: 0.3827, d_k_M range: [0.0010, 0.0855], d_k_M_hat range: [0.3823, 0.5925]
2025-03-11 20:13:35 - Train Iteration 3280: loss: 0.4688, d_k_M range: [0.0027, 0.2857], d_k_M_hat range: [0.3180, 0.7748]
2025-03-11 20:13:35 - Train Iteration 3281: loss: 0.4653, d_k_M range: [0.0771, 0.6679], d_k_M_hat range: [0.5647, 0.9858]
2025-03-11 20:13:36 - Train Iteration 3282: loss: 0.4124, d_k_M range: [0.0020, 0.5280], d_k_M_hat range: [0.4131, 0.9660]
2025-03-11 20:13:36 - Train Iteration 3283: loss: 0.3145, d_k_M range: [0.0190, 0.4681], d_k_M_hat range: [0.4817, 0.9487]
2025-03-11 20:13:37 - Train Iteration 3284: loss: 0.3568, d_k_M range: [0.0102, 0.5714], d_k_M_hat range: [0.5149, 0.9741]
2025-03-11 20:13:37 - Train Iteration 3285: loss: 0.3730, d_k_M range: [0.0159, 0.3108], d_k_M_hat range: [0.4052, 0.8283]
2025-03-11 20:13:38 - Train Iteration 3286: loss: 0.4032, d_k_M range: [0.1188, 0.6023], d_k_M_hat range: [0.6108, 0.9788]
2025-03-11 20:13:38 - Train Iteration 3287: loss: 0.3608, d_k_M range: [0.0081, 0.5291], d_k_M_hat range: [0.4074, 0.9670]
2025-03-11 20:13:39 - Train Iteration 3288: loss: 0.4024, d_k_M range: [0.0956, 0.6227], d_k_M_hat range: [0.6537, 0.9884]
2025-03-11 20:13:39 - Train Iteration 3289: loss: 0.3393, d_k_M range: [0.0084, 0.5316], d_k_M_hat range: [0.4453, 0.9835]
2025-03-11 20:13:39 - Train Iteration 3290: loss: 0.3046, d_k_M range: [0.0843, 0.4515], d_k_M_hat range: [0.5396, 0.9522]
2025-03-11 20:13:40 - Train Iteration 3291: loss: 0.5205, d_k_M range: [0.0206, 0.7158], d_k_M_hat range: [0.5016, 0.9954]
2025-03-11 20:13:40 - Train Iteration 3292: loss: 0.4543, d_k_M range: [0.0207, 0.6685], d_k_M_hat range: [0.5383, 0.9945]
2025-03-11 20:13:41 - Train Iteration 3293: loss: 0.3646, d_k_M range: [0.0789, 0.5904], d_k_M_hat range: [0.5723, 0.9866]
2025-03-11 20:13:41 - Train Iteration 3294: loss: 0.4097, d_k_M range: [0.0245, 0.3359], d_k_M_hat range: [0.3865, 0.9184]
2025-03-11 20:13:41 - Train Iteration 3295: loss: 0.4893, d_k_M range: [0.1969, 0.6923], d_k_M_hat range: [0.6461, 0.9928]
2025-03-11 20:13:42 - Train Iteration 3296: loss: 0.3708, d_k_M range: [0.0131, 0.2918], d_k_M_hat range: [0.4078, 0.8084]
2025-03-11 20:13:42 - Train Iteration 3297: loss: 0.5231, d_k_M range: [0.0004, 0.2746], d_k_M_hat range: [0.2771, 0.8228]
2025-03-11 20:13:43 - Train Iteration 3298: loss: 0.5712, d_k_M range: [0.1229, 0.7383], d_k_M_hat range: [0.6548, 0.9825]
2025-03-11 20:13:43 - Train Iteration 3299: loss: 0.4978, d_k_M range: [0.0016, 0.4421], d_k_M_hat range: [0.2977, 0.9415]
2025-03-11 20:13:44 - Train Iteration 3300: loss: 0.3600, d_k_M range: [0.0277, 0.5836], d_k_M_hat range: [0.5737, 0.9836]
2025-03-11 20:13:44 - Train Iteration 3301: loss: 0.5049, d_k_M range: [0.0050, 0.5483], d_k_M_hat range: [0.2944, 0.9606]
2025-03-11 20:13:45 - Train Iteration 3302: loss: 0.3533, d_k_M range: [0.0430, 0.5249], d_k_M_hat range: [0.5304, 0.9712]
2025-03-11 20:13:45 - Train Iteration 3303: loss: 0.5006, d_k_M range: [0.0013, 0.6899], d_k_M_hat range: [0.3357, 0.9823]
2025-03-11 20:13:45 - Train Iteration 3304: loss: 0.3603, d_k_M range: [0.0031, 0.3939], d_k_M_hat range: [0.4074, 0.8409]
2025-03-11 20:13:46 - Train Iteration 3305: loss: 0.4932, d_k_M range: [0.0076, 0.4344], d_k_M_hat range: [0.3306, 0.9389]
2025-03-11 20:13:46 - Train Iteration 3306: loss: 0.3446, d_k_M range: [0.0038, 0.4714], d_k_M_hat range: [0.4247, 0.9364]
2025-03-11 20:13:47 - Train Iteration 3307: loss: 0.3303, d_k_M range: [0.0079, 0.4815], d_k_M_hat range: [0.4331, 0.9714]
2025-03-11 20:13:47 - Train Iteration 3308: loss: 0.8424, d_k_M range: [0.0004, 0.4455], d_k_M_hat range: [0.0826, 0.8956]
2025-03-11 20:13:48 - Train Iteration 3309: loss: 0.3501, d_k_M range: [0.0210, 0.3775], d_k_M_hat range: [0.4753, 0.8360]
2025-03-11 20:13:48 - Train Iteration 3310: loss: 0.7314, d_k_M range: [0.0002, 0.3884], d_k_M_hat range: [0.1450, 0.8630]
2025-03-11 20:13:49 - Train Iteration 3311: loss: 0.3663, d_k_M range: [0.0037, 0.3730], d_k_M_hat range: [0.3985, 0.7822]
2025-03-11 20:13:49 - Train Iteration 3312: loss: 0.5957, d_k_M range: [0.2335, 0.7619], d_k_M_hat range: [0.6294, 0.9901]
2025-03-11 20:13:50 - Train Iteration 3313: loss: 0.4167, d_k_M range: [0.1108, 0.5224], d_k_M_hat range: [0.6550, 0.9507]
2025-03-11 20:13:50 - Train Iteration 3314: loss: 0.4556, d_k_M range: [0.0039, 0.3893], d_k_M_hat range: [0.3290, 0.7596]
2025-03-11 20:13:50 - Train Iteration 3315: loss: 0.4154, d_k_M range: [0.0060, 0.6172], d_k_M_hat range: [0.4706, 0.9792]
2025-03-11 20:13:51 - Train Iteration 3316: loss: 0.3469, d_k_M range: [0.0224, 0.4612], d_k_M_hat range: [0.4738, 0.8893]
2025-03-11 20:13:51 - Train Iteration 3317: loss: 0.3831, d_k_M range: [0.0017, 0.2686], d_k_M_hat range: [0.3827, 0.8175]
2025-03-11 20:13:52 - Train Iteration 3318: loss: 0.2963, d_k_M range: [0.1122, 0.5001], d_k_M_hat range: [0.6372, 0.9715]
2025-03-11 20:13:52 - Train Iteration 3319: loss: 0.3153, d_k_M range: [0.0452, 0.3903], d_k_M_hat range: [0.5576, 0.9367]
2025-03-11 20:13:53 - Train Iteration 3320: loss: 0.6339, d_k_M range: [0.0001, 0.4917], d_k_M_hat range: [0.2039, 0.9743]
2025-03-11 20:13:53 - Train Iteration 3321: loss: 0.3034, d_k_M range: [0.0049, 0.4649], d_k_M_hat range: [0.4578, 0.9587]
2025-03-11 20:13:54 - Train Iteration 3322: loss: 0.4409, d_k_M range: [0.0005, 0.2037], d_k_M_hat range: [0.3365, 0.7643]
2025-03-11 20:13:54 - Train Iteration 3323: loss: 0.6587, d_k_M range: [0.0091, 0.7978], d_k_M_hat range: [0.5003, 0.9862]
2025-03-11 20:13:55 - Train Iteration 3324: loss: 0.5289, d_k_M range: [0.0026, 0.4007], d_k_M_hat range: [0.2753, 0.9617]
2025-03-11 20:13:55 - Train Iteration 3325: loss: 0.4734, d_k_M range: [0.4120, 0.6790], d_k_M_hat range: [0.8791, 0.9934]
2025-03-11 20:13:56 - Train Iteration 3326: loss: 0.3660, d_k_M range: [0.2694, 0.5721], d_k_M_hat range: [0.7704, 0.9702]
2025-03-11 20:13:56 - Train Iteration 3327: loss: 0.3612, d_k_M range: [0.0011, 0.5240], d_k_M_hat range: [0.4161, 0.9726]
2025-03-11 20:13:56 - Train Iteration 3328: loss: 0.3609, d_k_M range: [0.0080, 0.4575], d_k_M_hat range: [0.4629, 0.9085]
2025-03-11 20:13:57 - Train Iteration 3329: loss: 0.3731, d_k_M range: [0.0106, 0.5229], d_k_M_hat range: [0.4324, 0.9403]
2025-03-11 20:13:57 - Train Iteration 3330: loss: 0.3541, d_k_M range: [0.0241, 0.3461], d_k_M_hat range: [0.5398, 0.9186]
2025-03-11 20:13:58 - Train Iteration 3331: loss: 0.3015, d_k_M range: [0.0294, 0.4596], d_k_M_hat range: [0.4883, 0.9556]
2025-03-11 20:13:58 - Train Iteration 3332: loss: 0.3973, d_k_M range: [0.0147, 0.4733], d_k_M_hat range: [0.4823, 0.8804]
2025-03-11 20:13:59 - Train Iteration 3333: loss: 0.9756, d_k_M range: [0.0015, 0.5574], d_k_M_hat range: [0.0137, 0.9823]
2025-03-11 20:13:59 - Train Iteration 3334: loss: 0.2405, d_k_M range: [0.0126, 0.3650], d_k_M_hat range: [0.5492, 0.8769]
2025-03-11 20:13:59 - Train Iteration 3335: loss: 0.2656, d_k_M range: [0.0057, 0.4813], d_k_M_hat range: [0.5054, 0.9866]
2025-03-11 20:14:00 - Train Iteration 3336: loss: 0.3730, d_k_M range: [0.0506, 0.5177], d_k_M_hat range: [0.6184, 0.9754]
2025-03-11 20:14:00 - Train Iteration 3337: loss: 0.6162, d_k_M range: [0.0075, 0.7841], d_k_M_hat range: [0.5262, 0.9992]
2025-03-11 20:14:01 - Train Iteration 3338: loss: 0.8983, d_k_M range: [0.0002, 0.1652], d_k_M_hat range: [0.0525, 0.6228]
2025-03-11 20:14:01 - Train Iteration 3339: loss: 0.5010, d_k_M range: [0.0315, 0.7010], d_k_M_hat range: [0.5354, 0.9932]
2025-03-11 20:14:01 - Train Iteration 3340: loss: 0.4237, d_k_M range: [0.0099, 0.0355], d_k_M_hat range: [0.3649, 0.5532]
2025-03-11 20:14:02 - Train Iteration 3341: loss: 0.4183, d_k_M range: [0.0848, 0.6304], d_k_M_hat range: [0.6155, 0.9837]
2025-03-11 20:14:02 - Train Iteration 3342: loss: 0.3440, d_k_M range: [0.0175, 0.5441], d_k_M_hat range: [0.5037, 0.9576]
2025-03-11 20:14:03 - Train Iteration 3343: loss: 0.4995, d_k_M range: [0.0032, 0.6938], d_k_M_hat range: [0.3865, 0.9871]
2025-03-11 20:14:03 - Train Iteration 3344: loss: 0.3360, d_k_M range: [0.0085, 0.5278], d_k_M_hat range: [0.4558, 0.9716]
2025-03-11 20:14:04 - Train Iteration 3345: loss: 0.5643, d_k_M range: [0.3663, 0.7418], d_k_M_hat range: [0.8728, 0.9906]
2025-03-11 20:14:04 - Train Iteration 3346: loss: 0.2945, d_k_M range: [0.0037, 0.2620], d_k_M_hat range: [0.4766, 0.8486]
2025-03-11 20:14:04 - Train Iteration 3347: loss: 0.9324, d_k_M range: [0.0006, 0.9637], d_k_M_hat range: [0.3209, 0.9981]
2025-03-11 20:14:05 - Train Iteration 3348: loss: 0.7456, d_k_M range: [0.0019, 0.5319], d_k_M_hat range: [0.1385, 0.9692]
2025-03-11 20:14:05 - Train Iteration 3349: loss: 0.4573, d_k_M range: [0.0399, 0.6571], d_k_M_hat range: [0.4166, 0.9808]
2025-03-11 20:14:06 - Train Iteration 3350: loss: 0.2814, d_k_M range: [0.0540, 0.4630], d_k_M_hat range: [0.5356, 0.9600]
2025-03-11 20:14:06 - Train Iteration 3351: loss: 0.9827, d_k_M range: [0.0682, 0.9911], d_k_M_hat range: [0.5130, 0.9998]
2025-03-11 20:14:07 - Train Iteration 3352: loss: 0.4656, d_k_M range: [0.0039, 0.3964], d_k_M_hat range: [0.3216, 0.9098]
2025-03-11 20:14:07 - Train Iteration 3353: loss: 0.3597, d_k_M range: [0.0469, 0.5788], d_k_M_hat range: [0.6033, 0.9841]
2025-03-11 20:14:08 - Train Iteration 3354: loss: 0.3618, d_k_M range: [0.0022, 0.2294], d_k_M_hat range: [0.4007, 0.7305]
2025-03-11 20:14:08 - Train Iteration 3355: loss: 0.4024, d_k_M range: [0.0391, 0.3521], d_k_M_hat range: [0.4883, 0.8459]
2025-03-11 20:14:08 - Train Iteration 3356: loss: 0.3064, d_k_M range: [0.0058, 0.2318], d_k_M_hat range: [0.4523, 0.7262]
2025-03-11 20:14:09 - Train Iteration 3357: loss: 0.3439, d_k_M range: [0.0803, 0.5687], d_k_M_hat range: [0.5660, 0.9823]
2025-03-11 20:14:09 - Train Iteration 3358: loss: 0.4002, d_k_M range: [0.0236, 0.6143], d_k_M_hat range: [0.4759, 0.9817]
2025-03-11 20:14:10 - Train Iteration 3359: loss: 0.3788, d_k_M range: [0.0103, 0.3542], d_k_M_hat range: [0.3949, 0.8840]
2025-03-11 20:14:10 - Train Iteration 3360: loss: 0.5779, d_k_M range: [0.3502, 0.7567], d_k_M_hat range: [0.8025, 0.9966]
2025-03-11 20:14:10 - Train Iteration 3361: loss: 0.5747, d_k_M range: [0.0154, 0.7315], d_k_M_hat range: [0.4725, 0.9734]
2025-03-11 20:14:11 - Train Iteration 3362: loss: 0.5190, d_k_M range: [0.0017, 0.4883], d_k_M_hat range: [0.2819, 0.9548]
2025-03-11 20:14:11 - Train Iteration 3363: loss: 0.4725, d_k_M range: [0.1287, 0.6705], d_k_M_hat range: [0.6618, 0.9831]
2025-03-11 20:14:12 - Train Iteration 3364: loss: 0.5129, d_k_M range: [0.0012, 0.5186], d_k_M_hat range: [0.2850, 0.9491]
2025-03-11 20:14:12 - Train Iteration 3365: loss: 0.3848, d_k_M range: [0.0115, 0.5901], d_k_M_hat range: [0.3994, 0.9822]
2025-03-11 20:14:13 - Train Iteration 3366: loss: 0.4291, d_k_M range: [0.0045, 0.2937], d_k_M_hat range: [0.3497, 0.7952]
2025-03-11 20:14:13 - Train Iteration 3367: loss: 0.4747, d_k_M range: [0.0405, 0.6436], d_k_M_hat range: [0.5408, 0.9612]
2025-03-11 20:14:13 - Train Iteration 3368: loss: 0.4522, d_k_M range: [0.0023, 0.5002], d_k_M_hat range: [0.3665, 0.9515]
2025-03-11 20:14:14 - Train Iteration 3369: loss: 0.4780, d_k_M range: [0.0037, 0.5445], d_k_M_hat range: [0.3123, 0.9497]
2025-03-11 20:14:14 - Train Iteration 3370: loss: 0.4895, d_k_M range: [0.0071, 0.5535], d_k_M_hat range: [0.3927, 0.9569]
2025-03-11 20:14:15 - Train Iteration 3371: loss: 0.3584, d_k_M range: [0.0122, 0.4296], d_k_M_hat range: [0.4447, 0.8926]
2025-03-11 20:14:15 - Train Iteration 3372: loss: 0.8354, d_k_M range: [0.3276, 0.9108], d_k_M_hat range: [0.8419, 0.9968]
2025-03-11 20:14:16 - Train Iteration 3373: loss: 0.4038, d_k_M range: [0.0830, 0.5942], d_k_M_hat range: [0.5747, 0.9806]
2025-03-11 20:14:16 - Train Iteration 3374: loss: 0.3767, d_k_M range: [0.0053, 0.5641], d_k_M_hat range: [0.4148, 0.9732]
2025-03-11 20:14:17 - Train Iteration 3375: loss: 0.4489, d_k_M range: [0.0020, 0.4282], d_k_M_hat range: [0.3358, 0.9384]
2025-03-11 20:14:17 - Train Iteration 3376: loss: 0.3791, d_k_M range: [0.0912, 0.5382], d_k_M_hat range: [0.6252, 0.9364]
2025-03-11 20:14:18 - Train Iteration 3377: loss: 0.3277, d_k_M range: [0.0233, 0.4016], d_k_M_hat range: [0.4725, 0.9113]
2025-03-11 20:14:18 - Train Iteration 3378: loss: 0.7301, d_k_M range: [0.0013, 0.4487], d_k_M_hat range: [0.1469, 0.9274]
2025-03-11 20:14:19 - Train Iteration 3379: loss: 0.4664, d_k_M range: [0.0010, 0.4762], d_k_M_hat range: [0.3181, 0.9276]
2025-03-11 20:14:19 - Train Iteration 3380: loss: 0.8909, d_k_M range: [0.0786, 0.9423], d_k_M_hat range: [0.6216, 0.9984]
2025-03-11 20:14:19 - Train Iteration 3381: loss: 0.3268, d_k_M range: [0.0133, 0.4028], d_k_M_hat range: [0.4508, 0.9013]
2025-03-11 20:14:20 - Train Iteration 3382: loss: 0.3905, d_k_M range: [0.0095, 0.2319], d_k_M_hat range: [0.3845, 0.6881]
2025-03-11 20:14:20 - Train Iteration 3383: loss: 0.4291, d_k_M range: [0.0625, 0.5538], d_k_M_hat range: [0.5649, 0.9528]
2025-03-11 20:14:21 - Train Iteration 3384: loss: 0.7359, d_k_M range: [0.2136, 0.8521], d_k_M_hat range: [0.6860, 0.9962]
2025-03-11 20:14:21 - Train Iteration 3385: loss: 0.5301, d_k_M range: [0.0083, 0.5649], d_k_M_hat range: [0.3667, 0.9652]
2025-03-11 20:14:22 - Train Iteration 3386: loss: 0.5514, d_k_M range: [0.0222, 0.4720], d_k_M_hat range: [0.4683, 0.9261]
2025-03-11 20:14:22 - Train Iteration 3387: loss: 0.5085, d_k_M range: [0.0020, 0.2993], d_k_M_hat range: [0.2889, 0.7772]
2025-03-11 20:14:22 - Train Iteration 3388: loss: 0.3586, d_k_M range: [0.0165, 0.4977], d_k_M_hat range: [0.5679, 0.9675]
2025-03-11 20:14:23 - Train Iteration 3389: loss: 0.5611, d_k_M range: [0.0007, 0.1837], d_k_M_hat range: [0.2516, 0.7143]
2025-03-11 20:14:23 - Train Iteration 3390: loss: 0.4867, d_k_M range: [0.0100, 0.6937], d_k_M_hat range: [0.5681, 0.9960]
2025-03-11 20:14:24 - Train Iteration 3391: loss: 0.7589, d_k_M range: [0.0023, 0.5093], d_k_M_hat range: [0.1311, 0.9623]
2025-03-11 20:14:24 - Train Iteration 3392: loss: 0.8701, d_k_M range: [0.0013, 0.4553], d_k_M_hat range: [0.0685, 0.9356]
2025-03-11 20:14:25 - Train Iteration 3393: loss: 0.4220, d_k_M range: [0.0614, 0.5502], d_k_M_hat range: [0.6052, 0.9532]
2025-03-11 20:14:25 - Train Iteration 3394: loss: 0.4590, d_k_M range: [0.0021, 0.3657], d_k_M_hat range: [0.4623, 0.8645]
2025-03-11 20:14:25 - Train Iteration 3395: loss: 0.4125, d_k_M range: [0.0034, 0.3974], d_k_M_hat range: [0.3611, 0.8328]
2025-03-11 20:14:26 - Train Iteration 3396: loss: 0.3272, d_k_M range: [0.0214, 0.4191], d_k_M_hat range: [0.4699, 0.9106]
2025-03-11 20:14:26 - Train Iteration 3397: loss: 0.4295, d_k_M range: [0.0027, 0.3949], d_k_M_hat range: [0.3473, 0.8628]
2025-03-11 20:14:27 - Train Iteration 3398: loss: 0.4235, d_k_M range: [0.0046, 0.3107], d_k_M_hat range: [0.3538, 0.8688]
2025-03-11 20:14:27 - Train Iteration 3399: loss: 0.6065, d_k_M range: [0.0587, 0.7751], d_k_M_hat range: [0.6026, 0.9963]
2025-03-11 20:14:28 - Train Iteration 3400: loss: 0.3283, d_k_M range: [0.0145, 0.3948], d_k_M_hat range: [0.4694, 0.8624]
2025-03-11 20:14:28 - Train Iteration 3401: loss: 0.3437, d_k_M range: [0.0036, 0.3551], d_k_M_hat range: [0.4173, 0.8239]
2025-03-11 20:14:29 - Train Iteration 3402: loss: 0.3348, d_k_M range: [0.0620, 0.4999], d_k_M_hat range: [0.5506, 0.9448]
2025-03-11 20:14:29 - Train Iteration 3403: loss: 0.2632, d_k_M range: [0.0199, 0.3127], d_k_M_hat range: [0.5399, 0.8700]
2025-03-11 20:14:30 - Train Iteration 3404: loss: 0.3956, d_k_M range: [0.0528, 0.5251], d_k_M_hat range: [0.5598, 0.9693]
2025-03-11 20:14:30 - Train Iteration 3405: loss: 0.3766, d_k_M range: [0.0012, 0.4055], d_k_M_hat range: [0.3876, 0.7919]
2025-03-11 20:14:30 - Train Iteration 3406: loss: 0.3469, d_k_M range: [0.0281, 0.5739], d_k_M_hat range: [0.4993, 0.9849]
2025-03-11 20:14:31 - Train Iteration 3407: loss: 0.8574, d_k_M range: [0.0062, 0.9236], d_k_M_hat range: [0.4056, 0.9976]
2025-03-11 20:14:31 - Train Iteration 3408: loss: 0.3797, d_k_M range: [0.0030, 0.2437], d_k_M_hat range: [0.4005, 0.6953]
2025-03-11 20:14:32 - Train Iteration 3409: loss: 0.3038, d_k_M range: [0.0276, 0.4869], d_k_M_hat range: [0.5451, 0.9504]
2025-03-11 20:14:32 - Train Iteration 3410: loss: 0.3992, d_k_M range: [0.0020, 0.3810], d_k_M_hat range: [0.3847, 0.8601]
2025-03-11 20:14:33 - Train Iteration 3411: loss: 0.7286, d_k_M range: [0.0208, 0.8525], d_k_M_hat range: [0.5672, 0.9989]
2025-03-11 20:14:33 - Train Iteration 3412: loss: 0.4411, d_k_M range: [0.0027, 0.4263], d_k_M_hat range: [0.3386, 0.9665]
2025-03-11 20:14:33 - Train Iteration 3413: loss: 0.7953, d_k_M range: [0.0002, 0.3296], d_k_M_hat range: [0.1085, 0.8239]
2025-03-11 20:14:34 - Train Iteration 3414: loss: 0.7620, d_k_M range: [0.0190, 0.8686], d_k_M_hat range: [0.5380, 0.9957]
2025-03-11 20:14:34 - Train Iteration 3415: loss: 0.3211, d_k_M range: [0.0171, 0.4759], d_k_M_hat range: [0.4587, 0.9472]
2025-03-11 20:14:35 - Train Iteration 3416: loss: 0.3173, d_k_M range: [0.0700, 0.5252], d_k_M_hat range: [0.6035, 0.9765]
2025-03-11 20:14:35 - Train Iteration 3417: loss: 0.4064, d_k_M range: [0.0015, 0.4087], d_k_M_hat range: [0.3640, 0.9088]
2025-03-11 20:14:35 - Train Iteration 3418: loss: 0.3958, d_k_M range: [0.0609, 0.4529], d_k_M_hat range: [0.5567, 0.9521]
2025-03-11 20:14:36 - Train Iteration 3419: loss: 0.3793, d_k_M range: [0.0009, 0.3254], d_k_M_hat range: [0.3853, 0.8116]
2025-03-11 20:14:36 - Train Iteration 3420: loss: 0.3705, d_k_M range: [0.0114, 0.4254], d_k_M_hat range: [0.4027, 0.8922]
2025-03-11 20:14:37 - Train Iteration 3421: loss: 0.3329, d_k_M range: [0.0021, 0.5132], d_k_M_hat range: [0.4598, 0.9457]
2025-03-11 20:14:37 - Train Iteration 3422: loss: 0.9416, d_k_M range: [0.0002, 0.5195], d_k_M_hat range: [0.0299, 0.9528]
2025-03-11 20:14:38 - Train Iteration 3423: loss: 0.4182, d_k_M range: [0.0282, 0.3744], d_k_M_hat range: [0.5391, 0.8717]
2025-03-11 20:14:38 - Train Iteration 3424: loss: 0.6782, d_k_M range: [0.0043, 0.8208], d_k_M_hat range: [0.3836, 0.9973]
2025-03-11 20:14:38 - Train Iteration 3425: loss: 0.3182, d_k_M range: [0.0273, 0.3799], d_k_M_hat range: [0.5433, 0.8157]
2025-03-11 20:14:39 - Train Iteration 3426: loss: 0.3269, d_k_M range: [0.0121, 0.4903], d_k_M_hat range: [0.4858, 0.9538]
2025-03-11 20:14:39 - Train Iteration 3427: loss: 0.3182, d_k_M range: [0.0718, 0.4350], d_k_M_hat range: [0.5899, 0.9082]
2025-03-11 20:14:40 - Train Iteration 3428: loss: 0.3861, d_k_M range: [0.0576, 0.4273], d_k_M_hat range: [0.4362, 0.9208]
2025-03-11 20:14:40 - Train Iteration 3429: loss: 0.5915, d_k_M range: [0.0460, 0.7660], d_k_M_hat range: [0.5679, 0.9969]
2025-03-11 20:14:41 - Train Iteration 3430: loss: 0.8441, d_k_M range: [0.0547, 0.9180], d_k_M_hat range: [0.5868, 0.9992]
2025-03-11 20:14:41 - Train Iteration 3431: loss: 0.3937, d_k_M range: [0.0036, 0.5453], d_k_M_hat range: [0.4262, 0.9648]
2025-03-11 20:14:42 - Train Iteration 3432: loss: 0.3810, d_k_M range: [0.0074, 0.5768], d_k_M_hat range: [0.5294, 0.9595]
2025-03-11 20:14:42 - Train Iteration 3433: loss: 0.4429, d_k_M range: [0.0007, 0.5847], d_k_M_hat range: [0.3354, 0.9781]
2025-03-11 20:14:42 - Train Iteration 3434: loss: 0.5261, d_k_M range: [0.0002, 0.4047], d_k_M_hat range: [0.2748, 0.9464]
2025-03-11 20:14:43 - Train Iteration 3435: loss: 0.6564, d_k_M range: [0.0640, 0.8066], d_k_M_hat range: [0.6228, 0.9964]
2025-03-11 20:14:43 - Train Iteration 3436: loss: 0.3274, d_k_M range: [0.0020, 0.3233], d_k_M_hat range: [0.4337, 0.7904]
2025-03-11 20:14:44 - Train Iteration 3437: loss: 0.3676, d_k_M range: [0.0390, 0.4591], d_k_M_hat range: [0.4891, 0.9148]
2025-03-11 20:14:44 - Train Iteration 3438: loss: 0.3403, d_k_M range: [0.0030, 0.4318], d_k_M_hat range: [0.4196, 0.9449]
2025-03-11 20:14:45 - Train Iteration 3439: loss: 0.2902, d_k_M range: [0.0338, 0.3935], d_k_M_hat range: [0.5719, 0.9491]
2025-03-11 20:14:45 - Train Iteration 3440: loss: 0.5203, d_k_M range: [0.3428, 0.7164], d_k_M_hat range: [0.8437, 0.9951]
2025-03-11 20:14:45 - Train Iteration 3441: loss: 0.6699, d_k_M range: [0.0076, 0.8154], d_k_M_hat range: [0.4604, 0.9969]
2025-03-11 20:14:46 - Train Iteration 3442: loss: 0.3209, d_k_M range: [0.0039, 0.3681], d_k_M_hat range: [0.4529, 0.9254]
2025-03-11 20:14:46 - Train Iteration 3443: loss: 0.3851, d_k_M range: [0.0099, 0.4929], d_k_M_hat range: [0.4910, 0.9327]
2025-03-11 20:14:47 - Train Iteration 3444: loss: 0.9507, d_k_M range: [0.0949, 0.9743], d_k_M_hat range: [0.6312, 0.9993]
2025-03-11 20:14:47 - Train Iteration 3445: loss: 0.3559, d_k_M range: [0.0040, 0.4600], d_k_M_hat range: [0.4724, 0.9017]
2025-03-11 20:14:48 - Train Iteration 3446: loss: 0.3710, d_k_M range: [0.0449, 0.5714], d_k_M_hat range: [0.4973, 0.9872]
2025-03-11 20:14:48 - Train Iteration 3447: loss: 0.4513, d_k_M range: [0.0039, 0.6040], d_k_M_hat range: [0.3321, 0.9921]
2025-03-11 20:14:48 - Train Iteration 3448: loss: 0.3441, d_k_M range: [0.0407, 0.4176], d_k_M_hat range: [0.5684, 0.9499]
2025-03-11 20:14:49 - Train Iteration 3449: loss: 0.7591, d_k_M range: [0.0149, 0.8694], d_k_M_hat range: [0.5028, 0.9981]
2025-03-11 20:14:49 - Train Iteration 3450: loss: 0.6735, d_k_M range: [0.0012, 0.8156], d_k_M_hat range: [0.4145, 0.9949]
2025-03-11 20:14:50 - Train Iteration 3451: loss: 0.3785, d_k_M range: [0.0023, 0.5229], d_k_M_hat range: [0.3871, 0.9397]
2025-03-11 20:14:50 - Train Iteration 3452: loss: 0.3456, d_k_M range: [0.0021, 0.5212], d_k_M_hat range: [0.4142, 0.9478]
2025-03-11 20:14:51 - Train Iteration 3453: loss: 0.3563, d_k_M range: [0.0963, 0.5753], d_k_M_hat range: [0.6584, 0.9784]
2025-03-11 20:14:51 - Train Iteration 3454: loss: 0.3476, d_k_M range: [0.1354, 0.5571], d_k_M_hat range: [0.6563, 0.9796]
2025-03-11 20:14:52 - Train Iteration 3455: loss: 0.4173, d_k_M range: [0.0022, 0.5832], d_k_M_hat range: [0.3562, 0.9786]
2025-03-11 20:14:52 - Train Iteration 3456: loss: 0.5846, d_k_M range: [0.0168, 0.7583], d_k_M_hat range: [0.5797, 0.9944]
2025-03-11 20:14:53 - Train Iteration 3457: loss: 0.9135, d_k_M range: [0.0000, 0.0435], d_k_M_hat range: [0.0443, 0.5653]
2025-03-11 20:14:53 - Train Iteration 3458: loss: 0.3922, d_k_M range: [0.0085, 0.5520], d_k_M_hat range: [0.3822, 0.9661]
2025-03-11 20:14:54 - Train Iteration 3459: loss: 0.6111, d_k_M range: [0.0311, 0.7779], d_k_M_hat range: [0.5807, 0.9961]
2025-03-11 20:14:54 - Train Iteration 3460: loss: 0.3720, d_k_M range: [0.0026, 0.1276], d_k_M_hat range: [0.4284, 0.7562]
2025-03-11 20:14:55 - Train Iteration 3461: loss: 0.4333, d_k_M range: [0.0029, 0.3705], d_k_M_hat range: [0.3446, 0.8131]
2025-03-11 20:14:55 - Train Iteration 3462: loss: 0.7122, d_k_M range: [0.1580, 0.8381], d_k_M_hat range: [0.6802, 0.9969]
2025-03-11 20:14:55 - Train Iteration 3463: loss: 0.4118, d_k_M range: [0.0013, 0.4106], d_k_M_hat range: [0.3596, 0.8477]
2025-03-11 20:14:56 - Train Iteration 3464: loss: 0.3643, d_k_M range: [0.0340, 0.5799], d_k_M_hat range: [0.5602, 0.9764]
2025-03-11 20:14:56 - Train Iteration 3465: loss: 0.3998, d_k_M range: [0.0014, 0.4701], d_k_M_hat range: [0.3691, 0.9432]
2025-03-11 20:14:57 - Train Iteration 3466: loss: 0.3529, d_k_M range: [0.0117, 0.4631], d_k_M_hat range: [0.5047, 0.9250]
2025-03-11 20:14:57 - Train Iteration 3467: loss: 0.4463, d_k_M range: [0.0994, 0.5464], d_k_M_hat range: [0.6788, 0.9804]
2025-03-11 20:14:57 - Train Iteration 3468: loss: 0.8207, d_k_M range: [0.0091, 0.3955], d_k_M_hat range: [0.1031, 0.9135]
2025-03-11 20:14:58 - Train Iteration 3469: loss: 0.7522, d_k_M range: [0.4543, 0.8653], d_k_M_hat range: [0.8659, 0.9988]
2025-03-11 20:14:58 - Train Iteration 3470: loss: 0.3107, d_k_M range: [0.1000, 0.4816], d_k_M_hat range: [0.6440, 0.9664]
2025-03-11 20:14:59 - Train Iteration 3471: loss: 0.6326, d_k_M range: [0.0060, 0.5886], d_k_M_hat range: [0.2169, 0.9667]
2025-03-11 20:14:59 - Train Iteration 3472: loss: 0.5072, d_k_M range: [0.0009, 0.6973], d_k_M_hat range: [0.4481, 0.9851]
2025-03-11 20:15:00 - Train Iteration 3473: loss: 0.4402, d_k_M range: [0.0025, 0.2391], d_k_M_hat range: [0.3390, 0.7257]
2025-03-11 20:15:00 - Train Iteration 3474: loss: 0.6174, d_k_M range: [0.1446, 0.7688], d_k_M_hat range: [0.6999, 0.9875]
2025-03-11 20:15:00 - Train Iteration 3475: loss: 0.4587, d_k_M range: [0.0006, 0.4700], d_k_M_hat range: [0.3233, 0.9363]
2025-03-11 20:15:01 - Train Iteration 3476: loss: 0.4251, d_k_M range: [0.0110, 0.5382], d_k_M_hat range: [0.4538, 0.9717]
2025-03-11 20:15:01 - Train Iteration 3477: loss: 0.3172, d_k_M range: [0.0144, 0.3270], d_k_M_hat range: [0.5168, 0.8221]
2025-03-11 20:15:02 - Train Iteration 3478: loss: 0.2879, d_k_M range: [0.0166, 0.5221], d_k_M_hat range: [0.5386, 0.9855]
2025-03-11 20:15:02 - Train Iteration 3479: loss: 0.3417, d_k_M range: [0.0063, 0.5225], d_k_M_hat range: [0.5666, 0.9379]
2025-03-11 20:15:02 - Train Iteration 3480: loss: 0.4014, d_k_M range: [0.0007, 0.4838], d_k_M_hat range: [0.3707, 0.8674]
2025-03-11 20:15:03 - Train Iteration 3481: loss: 0.4598, d_k_M range: [0.0010, 0.4229], d_k_M_hat range: [0.3229, 0.9589]
2025-03-11 20:15:03 - Train Iteration 3482: loss: 0.8419, d_k_M range: [0.0020, 0.4548], d_k_M_hat range: [0.0845, 0.9579]
2025-03-11 20:15:04 - Train Iteration 3483: loss: 0.4819, d_k_M range: [0.0135, 0.6722], d_k_M_hat range: [0.4481, 0.9857]
2025-03-11 20:15:04 - Train Iteration 3484: loss: 0.8119, d_k_M range: [0.0004, 0.3671], d_k_M_hat range: [0.0994, 0.9287]
2025-03-11 20:15:05 - Train Iteration 3485: loss: 0.3793, d_k_M range: [0.0391, 0.5753], d_k_M_hat range: [0.5226, 0.9594]
2025-03-11 20:15:05 - Train Iteration 3486: loss: 0.4776, d_k_M range: [0.0041, 0.2997], d_k_M_hat range: [0.3130, 0.7631]
2025-03-11 20:15:06 - Train Iteration 3487: loss: 0.3505, d_k_M range: [0.0071, 0.4087], d_k_M_hat range: [0.4270, 0.9526]
2025-03-11 20:15:06 - Train Iteration 3488: loss: 0.3556, d_k_M range: [0.0019, 0.4778], d_k_M_hat range: [0.4060, 0.9489]
2025-03-11 20:15:06 - Train Iteration 3489: loss: 0.3683, d_k_M range: [0.0810, 0.5901], d_k_M_hat range: [0.6646, 0.9832]
2025-03-11 20:15:07 - Train Iteration 3490: loss: 0.3145, d_k_M range: [0.1677, 0.4236], d_k_M_hat range: [0.7763, 0.9079]
2025-03-11 20:15:07 - Train Iteration 3491: loss: 0.3752, d_k_M range: [0.2215, 0.5811], d_k_M_hat range: [0.6828, 0.9686]
2025-03-11 20:15:08 - Train Iteration 3492: loss: 0.2783, d_k_M range: [0.0382, 0.3196], d_k_M_hat range: [0.5832, 0.8980]
2025-03-11 20:15:08 - Train Iteration 3493: loss: 0.3892, d_k_M range: [0.0033, 0.4521], d_k_M_hat range: [0.3794, 0.9475]
2025-03-11 20:15:09 - Train Iteration 3494: loss: 0.4339, d_k_M range: [0.0553, 0.6577], d_k_M_hat range: [0.6010, 0.9990]
2025-03-11 20:15:09 - Train Iteration 3495: loss: 0.8868, d_k_M range: [0.0006, 0.3682], d_k_M_hat range: [0.0595, 0.9241]
2025-03-11 20:15:09 - Train Iteration 3496: loss: 0.6492, d_k_M range: [0.3137, 0.8020], d_k_M_hat range: [0.8647, 0.9973]
2025-03-11 20:15:10 - Train Iteration 3497: loss: 0.5120, d_k_M range: [0.0024, 0.4096], d_k_M_hat range: [0.3514, 0.8866]
2025-03-11 20:15:10 - Train Iteration 3498: loss: 0.4154, d_k_M range: [0.0035, 0.4013], d_k_M_hat range: [0.3590, 0.8787]
2025-03-11 20:15:11 - Train Iteration 3499: loss: 0.4928, d_k_M range: [0.0467, 0.6906], d_k_M_hat range: [0.5464, 0.9886]
2025-03-11 20:15:11 - Train Iteration 3500: loss: 0.9928, d_k_M range: [0.0000, 0.1347], d_k_M_hat range: [0.0036, 0.7095]
2025-03-11 20:15:11 - Train Iteration 3501: loss: 0.4098, d_k_M range: [0.0179, 0.3424], d_k_M_hat range: [0.4527, 0.8970]
2025-03-11 20:15:12 - Train Iteration 3502: loss: 0.3545, d_k_M range: [0.0349, 0.5310], d_k_M_hat range: [0.6011, 0.9758]
2025-03-11 20:15:12 - Train Iteration 3503: loss: 0.6227, d_k_M range: [0.0039, 0.3442], d_k_M_hat range: [0.2148, 0.8337]
2025-03-11 20:15:13 - Train Iteration 3504: loss: 0.3895, d_k_M range: [0.0271, 0.5195], d_k_M_hat range: [0.4213, 0.9605]
2025-03-11 20:15:13 - Train Iteration 3505: loss: 0.3238, d_k_M range: [0.0152, 0.3476], d_k_M_hat range: [0.4461, 0.8962]
2025-03-11 20:15:14 - Train Iteration 3506: loss: 0.3965, d_k_M range: [0.0277, 0.3196], d_k_M_hat range: [0.4915, 0.7382]
2025-03-11 20:15:15 - Train Iteration 3507: loss: 0.3717, d_k_M range: [0.0131, 0.4035], d_k_M_hat range: [0.5134, 0.9060]
2025-03-11 20:15:15 - Train Iteration 3508: loss: 0.9213, d_k_M range: [0.1871, 0.9591], d_k_M_hat range: [0.7317, 0.9993]
2025-03-11 20:15:15 - Train Iteration 3509: loss: 0.7479, d_k_M range: [0.0026, 0.4269], d_k_M_hat range: [0.1380, 0.8925]
2025-03-11 20:15:16 - Train Iteration 3510: loss: 0.3739, d_k_M range: [0.0923, 0.6031], d_k_M_hat range: [0.6404, 0.9916]
2025-03-11 20:15:16 - Train Iteration 3511: loss: 0.4506, d_k_M range: [0.0067, 0.3283], d_k_M_hat range: [0.3486, 0.8137]
2025-03-11 20:15:17 - Train Iteration 3512: loss: 0.6915, d_k_M range: [0.1619, 0.8305], d_k_M_hat range: [0.7470, 0.9989]
2025-03-11 20:15:17 - Train Iteration 3513: loss: 0.9391, d_k_M range: [0.0001, 0.1833], d_k_M_hat range: [0.0310, 0.6708]
2025-03-11 20:15:18 - Train Iteration 3514: loss: 0.3667, d_k_M range: [0.0050, 0.5625], d_k_M_hat range: [0.4273, 0.9914]
2025-03-11 20:15:18 - Train Iteration 3515: loss: 0.3838, d_k_M range: [0.0121, 0.6003], d_k_M_hat range: [0.4224, 0.9808]
2025-03-11 20:15:18 - Train Iteration 3516: loss: 0.3953, d_k_M range: [0.0019, 0.4337], d_k_M_hat range: [0.3787, 0.9282]
2025-03-11 20:15:19 - Train Iteration 3517: loss: 0.3060, d_k_M range: [0.0126, 0.2725], d_k_M_hat range: [0.4697, 0.7715]
2025-03-11 20:15:19 - Train Iteration 3518: loss: 0.4425, d_k_M range: [0.0010, 0.4187], d_k_M_hat range: [0.3358, 0.8793]
2025-03-11 20:15:20 - Train Iteration 3519: loss: 0.9534, d_k_M range: [0.2428, 0.9756], d_k_M_hat range: [0.6496, 0.9991]
2025-03-11 20:15:20 - Train Iteration 3520: loss: 0.3460, d_k_M range: [0.1570, 0.4371], d_k_M_hat range: [0.7262, 0.9672]
2025-03-11 20:15:20 - Train Iteration 3521: loss: 0.3323, d_k_M range: [0.0305, 0.5546], d_k_M_hat range: [0.4734, 0.9822]
2025-03-11 20:15:21 - Train Iteration 3522: loss: 0.3542, d_k_M range: [0.0038, 0.3602], d_k_M_hat range: [0.4244, 0.9239]
2025-03-11 20:15:21 - Train Iteration 3523: loss: 0.8455, d_k_M range: [0.0958, 0.9135], d_k_M_hat range: [0.6675, 0.9990]
2025-03-11 20:15:22 - Train Iteration 3524: loss: 0.3564, d_k_M range: [0.0025, 0.4712], d_k_M_hat range: [0.4055, 0.9426]
2025-03-11 20:15:22 - Train Iteration 3525: loss: 0.3727, d_k_M range: [0.2000, 0.5236], d_k_M_hat range: [0.7713, 0.9846]
2025-03-11 20:15:23 - Train Iteration 3526: loss: 0.2890, d_k_M range: [0.0243, 0.5115], d_k_M_hat range: [0.5288, 0.9851]
2025-03-11 20:15:23 - Train Iteration 3527: loss: 0.3750, d_k_M range: [0.0055, 0.4684], d_k_M_hat range: [0.3931, 0.9443]
2025-03-11 20:15:23 - Train Iteration 3528: loss: 0.4806, d_k_M range: [0.1221, 0.6893], d_k_M_hat range: [0.5179, 0.9960]
2025-03-11 20:15:24 - Train Iteration 3529: loss: 0.3883, d_k_M range: [0.0011, 0.6073], d_k_M_hat range: [0.4317, 0.9842]
2025-03-11 20:15:24 - Train Iteration 3530: loss: 0.3983, d_k_M range: [0.0049, 0.4235], d_k_M_hat range: [0.3738, 0.9610]
2025-03-11 20:15:25 - Train Iteration 3531: loss: 0.4652, d_k_M range: [0.0582, 0.6705], d_k_M_hat range: [0.6143, 0.9884]
2025-03-11 20:15:25 - Train Iteration 3532: loss: 0.2980, d_k_M range: [0.0083, 0.4128], d_k_M_hat range: [0.4879, 0.9208]
2025-03-11 20:15:25 - Train Iteration 3533: loss: 0.3601, d_k_M range: [0.0022, 0.5066], d_k_M_hat range: [0.4357, 0.9124]
2025-03-11 20:15:26 - Train Iteration 3534: loss: 0.4723, d_k_M range: [0.2843, 0.5170], d_k_M_hat range: [0.6962, 0.9849]
2025-03-11 20:15:26 - Train Iteration 3535: loss: 0.3432, d_k_M range: [0.0074, 0.4243], d_k_M_hat range: [0.4216, 0.9449]
2025-03-11 20:15:27 - Train Iteration 3536: loss: 0.3968, d_k_M range: [0.0576, 0.5951], d_k_M_hat range: [0.5800, 0.9651]
2025-03-11 20:15:27 - Train Iteration 3537: loss: 0.3676, d_k_M range: [0.0071, 0.4723], d_k_M_hat range: [0.4059, 0.8701]
2025-03-11 20:15:28 - Train Iteration 3538: loss: 0.3208, d_k_M range: [0.0238, 0.4475], d_k_M_hat range: [0.5686, 0.9046]
2025-03-11 20:15:28 - Train Iteration 3539: loss: 0.4326, d_k_M range: [0.0027, 0.5773], d_k_M_hat range: [0.4225, 0.9774]
2025-03-11 20:15:28 - Train Iteration 3540: loss: 0.3521, d_k_M range: [0.0744, 0.5889], d_k_M_hat range: [0.6221, 0.9955]
2025-03-11 20:15:29 - Train Iteration 3541: loss: 0.5514, d_k_M range: [0.0072, 0.7249], d_k_M_hat range: [0.3897, 0.9823]
2025-03-11 20:15:29 - Train Iteration 3542: loss: 0.2823, d_k_M range: [0.0177, 0.2551], d_k_M_hat range: [0.4864, 0.7938]
2025-03-11 20:15:30 - Train Iteration 3543: loss: 0.3113, d_k_M range: [0.0109, 0.4798], d_k_M_hat range: [0.4834, 0.9660]
2025-03-11 20:15:30 - Train Iteration 3544: loss: 0.4053, d_k_M range: [0.0411, 0.6230], d_k_M_hat range: [0.4759, 0.9969]
2025-03-11 20:15:30 - Train Iteration 3545: loss: 0.3727, d_k_M range: [0.0016, 0.2107], d_k_M_hat range: [0.3912, 0.7560]
2025-03-11 20:15:31 - Train Iteration 3546: loss: 0.4522, d_k_M range: [0.0074, 0.5036], d_k_M_hat range: [0.4154, 0.9852]
2025-03-11 20:15:31 - Train Iteration 3547: loss: 0.8279, d_k_M range: [0.0114, 0.9070], d_k_M_hat range: [0.5073, 0.9971]
2025-03-11 20:15:32 - Train Iteration 3548: loss: 0.3289, d_k_M range: [0.0038, 0.4771], d_k_M_hat range: [0.4447, 0.9211]
2025-03-11 20:15:32 - Train Iteration 3549: loss: 0.3193, d_k_M range: [0.0037, 0.3404], d_k_M_hat range: [0.4386, 0.9181]
2025-03-11 20:15:33 - Train Iteration 3550: loss: 0.3736, d_k_M range: [0.0013, 0.4915], d_k_M_hat range: [0.3900, 0.9750]
2025-03-11 20:15:33 - Train Iteration 3551: loss: 0.4009, d_k_M range: [0.0055, 0.5333], d_k_M_hat range: [0.4038, 0.9816]
2025-03-11 20:15:33 - Train Iteration 3552: loss: 0.3816, d_k_M range: [0.1307, 0.4019], d_k_M_hat range: [0.7163, 0.9658]
2025-03-11 20:15:34 - Train Iteration 3553: loss: 0.6846, d_k_M range: [0.0051, 0.8237], d_k_M_hat range: [0.4449, 0.9963]
2025-03-11 20:15:34 - Train Iteration 3554: loss: 0.4329, d_k_M range: [0.0085, 0.6248], d_k_M_hat range: [0.4163, 0.9669]
2025-03-11 20:15:35 - Train Iteration 3555: loss: 0.3195, d_k_M range: [0.0696, 0.4260], d_k_M_hat range: [0.6141, 0.9578]
2025-03-11 20:15:35 - Train Iteration 3556: loss: 0.9628, d_k_M range: [0.0063, 0.9807], d_k_M_hat range: [0.3835, 0.9995]
2025-03-11 20:15:36 - Train Iteration 3557: loss: 0.6144, d_k_M range: [0.0015, 0.4265], d_k_M_hat range: [0.2176, 0.8827]
2025-03-11 20:15:36 - Train Iteration 3558: loss: 0.3489, d_k_M range: [0.0018, 0.4144], d_k_M_hat range: [0.4112, 0.9206]
2025-03-11 20:15:37 - Train Iteration 3559: loss: 0.3547, d_k_M range: [0.0805, 0.4460], d_k_M_hat range: [0.6126, 0.8715]
2025-03-11 20:15:37 - Train Iteration 3560: loss: 0.3313, d_k_M range: [0.0135, 0.2019], d_k_M_hat range: [0.5348, 0.8057]
2025-03-11 20:15:37 - Train Iteration 3561: loss: 0.3907, d_k_M range: [0.0206, 0.3790], d_k_M_hat range: [0.4542, 0.8935]
2025-03-11 20:15:38 - Train Iteration 3562: loss: 0.3157, d_k_M range: [0.0049, 0.3043], d_k_M_hat range: [0.4526, 0.8302]
2025-03-11 20:15:38 - Train Iteration 3563: loss: 0.3203, d_k_M range: [0.0212, 0.4842], d_k_M_hat range: [0.5130, 0.9182]
2025-03-11 20:15:39 - Train Iteration 3564: loss: 0.4223, d_k_M range: [0.0006, 0.6212], d_k_M_hat range: [0.3576, 0.9834]
2025-03-11 20:15:39 - Train Iteration 3565: loss: 0.4425, d_k_M range: [0.0184, 0.6611], d_k_M_hat range: [0.5013, 0.9959]
2025-03-11 20:15:40 - Train Iteration 3566: loss: 0.3536, d_k_M range: [0.0016, 0.3473], d_k_M_hat range: [0.4069, 0.8185]
2025-03-11 20:15:40 - Train Iteration 3567: loss: 0.5852, d_k_M range: [0.1781, 0.7548], d_k_M_hat range: [0.6414, 0.9950]
2025-03-11 20:15:41 - Train Iteration 3568: loss: 0.3805, d_k_M range: [0.0031, 0.3570], d_k_M_hat range: [0.3863, 0.8671]
2025-03-11 20:15:41 - Train Iteration 3569: loss: 0.2808, d_k_M range: [0.0049, 0.2945], d_k_M_hat range: [0.4977, 0.9276]
2025-03-11 20:15:41 - Train Iteration 3570: loss: 0.2984, d_k_M range: [0.0101, 0.5223], d_k_M_hat range: [0.4744, 0.9833]
2025-03-11 20:15:42 - Train Iteration 3571: loss: 0.3064, d_k_M range: [0.0072, 0.4961], d_k_M_hat range: [0.4648, 0.9561]
2025-03-11 20:15:43 - Train Iteration 3572: loss: 0.3109, d_k_M range: [0.0042, 0.4882], d_k_M_hat range: [0.5233, 0.9670]
2025-03-11 20:15:43 - Train Iteration 3573: loss: 0.3158, d_k_M range: [0.0226, 0.5446], d_k_M_hat range: [0.6503, 0.9827]
2025-03-11 20:15:44 - Train Iteration 3574: loss: 0.2781, d_k_M range: [0.0093, 0.2256], d_k_M_hat range: [0.5086, 0.7570]
2025-03-11 20:15:44 - Train Iteration 3575: loss: 0.3422, d_k_M range: [0.0454, 0.4409], d_k_M_hat range: [0.5430, 0.9711]
2025-03-11 20:15:44 - Train Iteration 3576: loss: 0.8736, d_k_M range: [0.0004, 0.4410], d_k_M_hat range: [0.0660, 0.9390]
2025-03-11 20:15:45 - Train Iteration 3577: loss: 0.4500, d_k_M range: [0.0871, 0.6583], d_k_M_hat range: [0.6264, 0.9875]
2025-03-11 20:15:45 - Train Iteration 3578: loss: 0.3363, d_k_M range: [0.0043, 0.3192], d_k_M_hat range: [0.4244, 0.9234]
2025-03-11 20:15:46 - Train Iteration 3579: loss: 0.8356, d_k_M range: [0.0600, 0.9136], d_k_M_hat range: [0.6277, 0.9995]
2025-03-11 20:15:46 - Train Iteration 3580: loss: 0.4365, d_k_M range: [0.0315, 0.5545], d_k_M_hat range: [0.5431, 0.9816]
2025-03-11 20:15:47 - Train Iteration 3581: loss: 0.3421, d_k_M range: [0.0774, 0.5094], d_k_M_hat range: [0.6166, 0.9652]
2025-03-11 20:15:47 - Train Iteration 3582: loss: 0.3236, d_k_M range: [0.0733, 0.4745], d_k_M_hat range: [0.5356, 0.9874]
2025-03-11 20:15:47 - Train Iteration 3583: loss: 0.3368, d_k_M range: [0.0011, 0.4596], d_k_M_hat range: [0.4208, 0.9485]
2025-03-11 20:15:48 - Train Iteration 3584: loss: 0.6342, d_k_M range: [0.0222, 0.7952], d_k_M_hat range: [0.4621, 0.9988]
2025-03-11 20:15:48 - Train Iteration 3585: loss: 0.5569, d_k_M range: [0.0009, 0.5038], d_k_M_hat range: [0.2546, 0.9570]
2025-03-11 20:15:49 - Train Iteration 3586: loss: 0.5786, d_k_M range: [0.0587, 0.7593], d_k_M_hat range: [0.6396, 0.9986]
2025-03-11 20:15:49 - Train Iteration 3587: loss: 0.5836, d_k_M range: [0.2388, 0.7575], d_k_M_hat range: [0.7037, 0.9936]
2025-03-11 20:15:50 - Train Iteration 3588: loss: 0.7178, d_k_M range: [0.0877, 0.8425], d_k_M_hat range: [0.6880, 0.9953]
2025-03-11 20:15:50 - Train Iteration 3589: loss: 0.4547, d_k_M range: [0.0042, 0.1896], d_k_M_hat range: [0.3299, 0.6110]
2025-03-11 20:15:51 - Train Iteration 3590: loss: 0.8298, d_k_M range: [0.0361, 0.9066], d_k_M_hat range: [0.6175, 0.9957]
2025-03-11 20:15:51 - Train Iteration 3591: loss: 0.4026, d_k_M range: [0.0690, 0.3689], d_k_M_hat range: [0.6332, 0.8904]
2025-03-11 20:15:51 - Train Iteration 3592: loss: 0.6804, d_k_M range: [0.1802, 0.8192], d_k_M_hat range: [0.6353, 0.9944]
2025-03-11 20:15:52 - Train Iteration 3593: loss: 0.3107, d_k_M range: [0.0216, 0.4265], d_k_M_hat range: [0.5121, 0.8886]
2025-03-11 20:15:52 - Train Iteration 3594: loss: 0.4409, d_k_M range: [0.0290, 0.6438], d_k_M_hat range: [0.5330, 0.9815]
2025-03-11 20:15:53 - Train Iteration 3595: loss: 0.3543, d_k_M range: [0.0016, 0.0924], d_k_M_hat range: [0.4087, 0.7075]
2025-03-11 20:15:53 - Train Iteration 3596: loss: 0.3500, d_k_M range: [0.0629, 0.4879], d_k_M_hat range: [0.6098, 0.9344]
2025-03-11 20:15:54 - Train Iteration 3597: loss: 0.5003, d_k_M range: [0.0010, 0.5703], d_k_M_hat range: [0.3162, 0.9443]
2025-03-11 20:15:54 - Train Iteration 3598: loss: 0.5901, d_k_M range: [0.0568, 0.7615], d_k_M_hat range: [0.5853, 0.9933]
2025-03-11 20:15:54 - Train Iteration 3599: loss: 0.3712, d_k_M range: [0.0017, 0.4035], d_k_M_hat range: [0.4061, 0.9081]
2025-03-11 20:15:55 - Train Iteration 3600: loss: 0.3739, d_k_M range: [0.0879, 0.5723], d_k_M_hat range: [0.5391, 0.9739]
2025-03-11 20:15:55 - Train Iteration 3601: loss: 0.3032, d_k_M range: [0.0076, 0.3740], d_k_M_hat range: [0.5658, 0.9340]
2025-03-11 20:15:56 - Train Iteration 3602: loss: 0.3206, d_k_M range: [0.0397, 0.4299], d_k_M_hat range: [0.6239, 0.9273]
2025-03-11 20:15:56 - Train Iteration 3603: loss: 0.4558, d_k_M range: [0.0380, 0.4510], d_k_M_hat range: [0.5422, 0.9650]
2025-03-11 20:15:57 - Train Iteration 3604: loss: 0.7550, d_k_M range: [0.0014, 0.8642], d_k_M_hat range: [0.2591, 0.9953]
2025-03-11 20:15:57 - Train Iteration 3605: loss: 0.3078, d_k_M range: [0.0070, 0.4081], d_k_M_hat range: [0.4931, 0.8533]
2025-03-11 20:15:58 - Train Iteration 3606: loss: 0.4863, d_k_M range: [0.0048, 0.6834], d_k_M_hat range: [0.5134, 0.9929]
2025-03-11 20:15:58 - Train Iteration 3607: loss: 0.3085, d_k_M range: [0.0559, 0.5188], d_k_M_hat range: [0.6130, 0.9633]
2025-03-11 20:15:59 - Train Iteration 3608: loss: 0.3043, d_k_M range: [0.0016, 0.5275], d_k_M_hat range: [0.4572, 0.9850]
2025-03-11 20:15:59 - Train Iteration 3609: loss: 0.4170, d_k_M range: [0.2755, 0.6426], d_k_M_hat range: [0.8006, 0.9969]
2025-03-11 20:16:00 - Train Iteration 3610: loss: 0.4113, d_k_M range: [0.0007, 0.6308], d_k_M_hat range: [0.4083, 0.9894]
2025-03-11 20:16:00 - Train Iteration 3611: loss: 0.3872, d_k_M range: [0.0010, 0.3154], d_k_M_hat range: [0.3788, 0.8015]
2025-03-11 20:16:01 - Train Iteration 3612: loss: 0.6378, d_k_M range: [0.1038, 0.7926], d_k_M_hat range: [0.5792, 0.9940]
2025-03-11 20:16:01 - Train Iteration 3613: loss: 0.3867, d_k_M range: [0.0007, 0.2191], d_k_M_hat range: [0.3920, 0.6903]
2025-03-11 20:16:02 - Train Iteration 3614: loss: 0.3692, d_k_M range: [0.0032, 0.5895], d_k_M_hat range: [0.5104, 0.9819]
2025-03-11 20:16:02 - Train Iteration 3615: loss: 0.5997, d_k_M range: [0.0004, 0.4707], d_k_M_hat range: [0.2260, 0.9286]
2025-03-11 20:16:02 - Train Iteration 3616: loss: 0.6920, d_k_M range: [0.0024, 0.2647], d_k_M_hat range: [0.1706, 0.7643]
2025-03-11 20:16:03 - Train Iteration 3617: loss: 0.3529, d_k_M range: [0.1719, 0.5470], d_k_M_hat range: [0.7032, 0.9740]
2025-03-11 20:16:03 - Train Iteration 3618: loss: 0.4517, d_k_M range: [0.0493, 0.4150], d_k_M_hat range: [0.5147, 0.9471]
2025-03-11 20:16:04 - Train Iteration 3619: loss: 0.3008, d_k_M range: [0.1358, 0.4613], d_k_M_hat range: [0.6272, 0.9163]
2025-03-11 20:16:04 - Train Iteration 3620: loss: 0.4015, d_k_M range: [0.0040, 0.2228], d_k_M_hat range: [0.4190, 0.7328]
2025-03-11 20:16:05 - Train Iteration 3621: loss: 0.3122, d_k_M range: [0.0102, 0.2112], d_k_M_hat range: [0.5001, 0.8253]
2025-03-11 20:16:05 - Train Iteration 3622: loss: 0.9274, d_k_M range: [0.0012, 0.9626], d_k_M_hat range: [0.2567, 0.9996]
2025-03-11 20:16:06 - Train Iteration 3623: loss: 0.3199, d_k_M range: [0.0387, 0.3615], d_k_M_hat range: [0.5020, 0.8981]
2025-03-11 20:16:06 - Train Iteration 3624: loss: 0.3407, d_k_M range: [0.0266, 0.5806], d_k_M_hat range: [0.6523, 0.9969]
2025-03-11 20:16:07 - Train Iteration 3625: loss: 0.7614, d_k_M range: [0.0033, 0.3396], d_k_M_hat range: [0.1307, 0.9338]
2025-03-11 20:16:07 - Train Iteration 3626: loss: 0.5495, d_k_M range: [0.0166, 0.7338], d_k_M_hat range: [0.5311, 0.9925]
2025-03-11 20:16:08 - Train Iteration 3627: loss: 0.3280, d_k_M range: [0.0007, 0.3047], d_k_M_hat range: [0.4279, 0.8738]
2025-03-11 20:16:08 - Train Iteration 3628: loss: 0.3497, d_k_M range: [0.0216, 0.1758], d_k_M_hat range: [0.4983, 0.7083]
2025-03-11 20:16:08 - Train Iteration 3629: loss: 0.2529, d_k_M range: [0.0053, 0.2502], d_k_M_hat range: [0.5273, 0.8715]
2025-03-11 20:16:09 - Train Iteration 3630: loss: 0.4076, d_k_M range: [0.0010, 0.3963], d_k_M_hat range: [0.3625, 0.9094]
2025-03-11 20:16:09 - Train Iteration 3631: loss: 0.3532, d_k_M range: [0.3896, 0.5673], d_k_M_hat range: [0.8578, 0.9855]
2025-03-11 20:16:10 - Train Iteration 3632: loss: 0.2745, d_k_M range: [0.0071, 0.4997], d_k_M_hat range: [0.4885, 0.9758]
2025-03-11 20:16:10 - Train Iteration 3633: loss: 0.3231, d_k_M range: [0.0048, 0.2573], d_k_M_hat range: [0.4431, 0.7630]
2025-03-11 20:16:11 - Train Iteration 3634: loss: 0.9970, d_k_M range: [0.0001, 0.0320], d_k_M_hat range: [0.0016, 0.6054]
2025-03-11 20:16:11 - Train Iteration 3635: loss: 0.3002, d_k_M range: [0.0052, 0.5266], d_k_M_hat range: [0.5768, 0.9787]
2025-03-11 20:16:12 - Train Iteration 3636: loss: 0.3423, d_k_M range: [0.0115, 0.5725], d_k_M_hat range: [0.5512, 0.9874]
2025-03-11 20:16:12 - Train Iteration 3637: loss: 0.3261, d_k_M range: [0.0047, 0.5476], d_k_M_hat range: [0.4726, 0.9765]
2025-03-11 20:16:13 - Train Iteration 3638: loss: 0.3736, d_k_M range: [0.0008, 0.2464], d_k_M_hat range: [0.3947, 0.8687]
2025-03-11 20:16:13 - Train Iteration 3639: loss: 0.8744, d_k_M range: [0.0470, 0.9338], d_k_M_hat range: [0.5357, 0.9987]
2025-03-11 20:16:14 - Train Iteration 3640: loss: 0.3464, d_k_M range: [0.0024, 0.5652], d_k_M_hat range: [0.5078, 0.9767]
2025-03-11 20:16:14 - Train Iteration 3641: loss: 0.2088, d_k_M range: [0.0065, 0.3470], d_k_M_hat range: [0.5934, 0.9059]
2025-03-11 20:16:15 - Train Iteration 3642: loss: 0.3451, d_k_M range: [0.0043, 0.5641], d_k_M_hat range: [0.5152, 0.9767]
2025-03-11 20:16:15 - Train Iteration 3643: loss: 0.6563, d_k_M range: [0.0002, 0.3175], d_k_M_hat range: [0.1901, 0.8593]
2025-03-11 20:16:16 - Train Iteration 3644: loss: 0.3896, d_k_M range: [0.0234, 0.6207], d_k_M_hat range: [0.5953, 0.9965]
2025-03-11 20:16:16 - Train Iteration 3645: loss: 0.4537, d_k_M range: [0.0276, 0.6640], d_k_M_hat range: [0.6005, 0.9904]
2025-03-11 20:16:17 - Train Iteration 3646: loss: 0.5209, d_k_M range: [0.0081, 0.5452], d_k_M_hat range: [0.2864, 0.9802]
2025-03-11 20:16:17 - Train Iteration 3647: loss: 0.6503, d_k_M range: [0.3902, 0.8039], d_k_M_hat range: [0.9029, 0.9975]
2025-03-11 20:16:18 - Train Iteration 3648: loss: 0.4536, d_k_M range: [0.0027, 0.5347], d_k_M_hat range: [0.3293, 0.9547]
2025-03-11 20:16:18 - Train Iteration 3649: loss: 0.4238, d_k_M range: [0.0075, 0.5048], d_k_M_hat range: [0.4889, 0.9501]
2025-03-11 20:16:18 - Train Iteration 3650: loss: 0.3419, d_k_M range: [0.0037, 0.4216], d_k_M_hat range: [0.4552, 0.9391]
2025-03-11 20:16:19 - Train Iteration 3651: loss: 0.3332, d_k_M range: [0.0497, 0.3995], d_k_M_hat range: [0.5986, 0.9294]
2025-03-11 20:16:19 - Train Iteration 3652: loss: 0.3757, d_k_M range: [0.0018, 0.4389], d_k_M_hat range: [0.3902, 0.9367]
2025-03-11 20:16:20 - Train Iteration 3653: loss: 0.3322, d_k_M range: [0.2662, 0.5350], d_k_M_hat range: [0.7119, 0.9769]
2025-03-11 20:16:20 - Train Iteration 3654: loss: 0.3154, d_k_M range: [0.0329, 0.1821], d_k_M_hat range: [0.5198, 0.7115]
2025-03-11 20:16:21 - Train Iteration 3655: loss: 0.5094, d_k_M range: [0.3398, 0.6992], d_k_M_hat range: [0.7303, 0.9910]
2025-03-11 20:16:21 - Train Iteration 3656: loss: 0.7443, d_k_M range: [0.0005, 0.3275], d_k_M_hat range: [0.1497, 0.9229]
2025-03-11 20:16:22 - Train Iteration 3657: loss: 0.8632, d_k_M range: [0.1019, 0.9259], d_k_M_hat range: [0.5855, 0.9968]
2025-03-11 20:16:22 - Train Iteration 3658: loss: 0.4367, d_k_M range: [0.0066, 0.4599], d_k_M_hat range: [0.4924, 0.9359]
2025-03-11 20:16:23 - Train Iteration 3659: loss: 0.4529, d_k_M range: [0.0584, 0.6632], d_k_M_hat range: [0.5753, 0.9902]
2025-03-11 20:16:23 - Train Iteration 3660: loss: 0.2871, d_k_M range: [0.0130, 0.3844], d_k_M_hat range: [0.5359, 0.8773]
2025-03-11 20:16:24 - Train Iteration 3661: loss: 0.3856, d_k_M range: [0.0568, 0.6120], d_k_M_hat range: [0.6095, 0.9910]
2025-03-11 20:16:24 - Train Iteration 3662: loss: 0.3780, d_k_M range: [0.0272, 0.3514], d_k_M_hat range: [0.4132, 0.8488]
2025-03-11 20:16:24 - Train Iteration 3663: loss: 0.3347, d_k_M range: [0.0068, 0.5666], d_k_M_hat range: [0.5122, 0.9881]
2025-03-11 20:16:25 - Train Iteration 3664: loss: 0.3672, d_k_M range: [0.0092, 0.5890], d_k_M_hat range: [0.6127, 0.9886]
2025-03-11 20:16:25 - Train Iteration 3665: loss: 0.3502, d_k_M range: [0.0014, 0.5374], d_k_M_hat range: [0.4916, 0.9456]
2025-03-11 20:16:26 - Train Iteration 3666: loss: 0.6248, d_k_M range: [0.0043, 0.7848], d_k_M_hat range: [0.4810, 0.9944]
2025-03-11 20:16:26 - Train Iteration 3667: loss: 0.6843, d_k_M range: [0.0001, 0.4519], d_k_M_hat range: [0.1729, 0.9281]
2025-03-11 20:16:26 - Train Iteration 3668: loss: 0.3589, d_k_M range: [0.1099, 0.5843], d_k_M_hat range: [0.7412, 0.9873]
2025-03-11 20:16:27 - Train Iteration 3669: loss: 0.3240, d_k_M range: [0.0191, 0.5484], d_k_M_hat range: [0.5029, 0.9793]
2025-03-11 20:16:27 - Train Iteration 3670: loss: 0.2923, d_k_M range: [0.0379, 0.4688], d_k_M_hat range: [0.5753, 0.9822]
2025-03-11 20:16:28 - Train Iteration 3671: loss: 0.3110, d_k_M range: [0.0220, 0.2263], d_k_M_hat range: [0.5478, 0.7989]
2025-03-11 20:16:28 - Train Iteration 3672: loss: 0.3769, d_k_M range: [0.0031, 0.5831], d_k_M_hat range: [0.3892, 0.9881]
2025-03-11 20:16:29 - Train Iteration 3673: loss: 0.9136, d_k_M range: [0.3860, 0.9555], d_k_M_hat range: [0.9116, 0.9997]
2025-03-11 20:16:29 - Train Iteration 3674: loss: 0.3358, d_k_M range: [0.0034, 0.4913], d_k_M_hat range: [0.4239, 0.9906]
2025-03-11 20:16:30 - Train Iteration 3675: loss: 0.3269, d_k_M range: [0.0366, 0.5291], d_k_M_hat range: [0.5753, 0.9573]
2025-03-11 20:16:30 - Train Iteration 3676: loss: 0.3795, d_k_M range: [0.0120, 0.2932], d_k_M_hat range: [0.4589, 0.7730]
2025-03-11 20:16:30 - Train Iteration 3677: loss: 0.3344, d_k_M range: [0.0019, 0.5134], d_k_M_hat range: [0.4341, 0.9831]
2025-03-11 20:16:31 - Train Iteration 3678: loss: 0.3974, d_k_M range: [0.0746, 0.6287], d_k_M_hat range: [0.6359, 0.9983]
2025-03-11 20:16:31 - Train Iteration 3679: loss: 0.8170, d_k_M range: [0.0028, 0.1807], d_k_M_hat range: [0.0989, 0.8284]
2025-03-11 20:16:32 - Train Iteration 3680: loss: 0.3327, d_k_M range: [0.1576, 0.4914], d_k_M_hat range: [0.5808, 0.9530]
2025-03-11 20:16:32 - Train Iteration 3681: loss: 0.4643, d_k_M range: [0.0180, 0.6320], d_k_M_hat range: [0.5566, 0.9838]
2025-03-11 20:16:33 - Train Iteration 3682: loss: 0.4333, d_k_M range: [0.0034, 0.6407], d_k_M_hat range: [0.3452, 0.9972]
2025-03-11 20:16:33 - Train Iteration 3683: loss: 0.9778, d_k_M range: [0.0297, 0.9886], d_k_M_hat range: [0.5150, 0.9998]
2025-03-11 20:16:34 - Train Iteration 3684: loss: 0.3596, d_k_M range: [0.0616, 0.4022], d_k_M_hat range: [0.5363, 0.9040]
2025-03-11 20:16:34 - Train Iteration 3685: loss: 0.8323, d_k_M range: [0.0061, 0.9087], d_k_M_hat range: [0.5075, 0.9964]
2025-03-11 20:16:35 - Train Iteration 3686: loss: 0.3522, d_k_M range: [0.0025, 0.5129], d_k_M_hat range: [0.4091, 0.9773]
2025-03-11 20:16:35 - Train Iteration 3687: loss: 0.4371, d_k_M range: [0.0742, 0.6344], d_k_M_hat range: [0.6228, 0.9757]
2025-03-11 20:16:36 - Train Iteration 3688: loss: 0.3784, d_k_M range: [0.1827, 0.6041], d_k_M_hat range: [0.7699, 0.9889]
2025-03-11 20:16:36 - Train Iteration 3689: loss: 0.2899, d_k_M range: [0.0307, 0.3279], d_k_M_hat range: [0.5853, 0.8454]
2025-03-11 20:16:36 - Train Iteration 3690: loss: 0.3666, d_k_M range: [0.0227, 0.5408], d_k_M_hat range: [0.5948, 0.9802]
2025-03-11 20:16:37 - Train Iteration 3691: loss: 0.3371, d_k_M range: [0.1079, 0.5154], d_k_M_hat range: [0.6787, 0.9492]
2025-03-11 20:16:37 - Train Iteration 3692: loss: 0.3551, d_k_M range: [0.0035, 0.3144], d_k_M_hat range: [0.4134, 0.8890]
2025-03-11 20:16:38 - Train Iteration 3693: loss: 0.4217, d_k_M range: [0.1140, 0.6417], d_k_M_hat range: [0.5976, 0.9923]
2025-03-11 20:16:38 - Train Iteration 3694: loss: 0.3261, d_k_M range: [0.0038, 0.4933], d_k_M_hat range: [0.4328, 0.9752]
2025-03-11 20:16:39 - Train Iteration 3695: loss: 0.3048, d_k_M range: [0.0024, 0.3485], d_k_M_hat range: [0.4702, 0.9125]
2025-03-11 20:16:39 - Train Iteration 3696: loss: 0.6383, d_k_M range: [0.0857, 0.7958], d_k_M_hat range: [0.5349, 0.9969]
2025-03-11 20:16:40 - Train Iteration 3697: loss: 0.3284, d_k_M range: [0.0053, 0.3003], d_k_M_hat range: [0.4904, 0.8567]
2025-03-11 20:16:40 - Train Iteration 3698: loss: 0.4054, d_k_M range: [0.0011, 0.4400], d_k_M_hat range: [0.3644, 0.9842]
2025-03-11 20:16:40 - Train Iteration 3699: loss: 0.4644, d_k_M range: [0.2492, 0.6775], d_k_M_hat range: [0.6693, 0.9961]
2025-03-11 20:16:41 - Train Iteration 3700: loss: 0.7748, d_k_M range: [0.0004, 0.2836], d_k_M_hat range: [0.1201, 0.8262]
2025-03-11 20:16:41 - Train Iteration 3701: loss: 0.4635, d_k_M range: [0.0315, 0.6414], d_k_M_hat range: [0.5714, 0.9963]
2025-03-11 20:16:42 - Train Iteration 3702: loss: 0.5102, d_k_M range: [0.0004, 0.2121], d_k_M_hat range: [0.2861, 0.8290]
2025-03-11 20:16:42 - Train Iteration 3703: loss: 0.3202, d_k_M range: [0.0451, 0.5084], d_k_M_hat range: [0.6144, 0.9682]
2025-03-11 20:16:43 - Train Iteration 3704: loss: 0.6428, d_k_M range: [0.0004, 0.3479], d_k_M_hat range: [0.1986, 0.8064]
2025-03-11 20:16:43 - Train Iteration 3705: loss: 0.3486, d_k_M range: [0.0309, 0.5708], d_k_M_hat range: [0.5162, 0.9804]
2025-03-11 20:16:43 - Train Iteration 3706: loss: 0.3276, d_k_M range: [0.0163, 0.5078], d_k_M_hat range: [0.4908, 0.9354]
2025-03-11 20:16:44 - Train Iteration 3707: loss: 0.3078, d_k_M range: [0.0088, 0.4122], d_k_M_hat range: [0.4540, 0.9271]
2025-03-11 20:16:44 - Train Iteration 3708: loss: 0.2751, d_k_M range: [0.0424, 0.4230], d_k_M_hat range: [0.5393, 0.9253]
2025-03-11 20:16:45 - Train Iteration 3709: loss: 0.3031, d_k_M range: [0.0431, 0.5170], d_k_M_hat range: [0.6165, 0.9682]
2025-03-11 20:16:45 - Train Iteration 3710: loss: 0.3073, d_k_M range: [0.0228, 0.4985], d_k_M_hat range: [0.5264, 0.9442]
2025-03-11 20:16:46 - Train Iteration 3711: loss: 0.2754, d_k_M range: [0.0278, 0.5008], d_k_M_hat range: [0.5431, 0.9760]
2025-03-11 20:16:46 - Train Iteration 3712: loss: 0.2919, d_k_M range: [0.0223, 0.4398], d_k_M_hat range: [0.5422, 0.9899]
2025-03-11 20:16:47 - Train Iteration 3713: loss: 0.7565, d_k_M range: [0.0014, 0.3739], d_k_M_hat range: [0.1316, 0.8892]
2025-03-11 20:16:47 - Train Iteration 3714: loss: 0.3425, d_k_M range: [0.0257, 0.4081], d_k_M_hat range: [0.5729, 0.9584]
2025-03-11 20:16:48 - Train Iteration 3715: loss: 0.6446, d_k_M range: [0.3130, 0.7995], d_k_M_hat range: [0.8185, 0.9966]
2025-03-11 20:16:48 - Train Iteration 3716: loss: 0.4813, d_k_M range: [0.0009, 0.3440], d_k_M_hat range: [0.3071, 0.8793]
2025-03-11 20:16:49 - Train Iteration 3717: loss: 0.4635, d_k_M range: [0.0509, 0.5530], d_k_M_hat range: [0.5940, 0.9862]
2025-03-11 20:16:49 - Train Iteration 3718: loss: 0.7050, d_k_M range: [0.0004, 0.4517], d_k_M_hat range: [0.1641, 0.8540]
2025-03-11 20:16:49 - Train Iteration 3719: loss: 0.4729, d_k_M range: [0.0636, 0.6787], d_k_M_hat range: [0.5964, 0.9910]
2025-03-11 20:16:50 - Train Iteration 3720: loss: 0.4114, d_k_M range: [0.0022, 0.4460], d_k_M_hat range: [0.3944, 0.9476]
2025-03-11 20:16:50 - Train Iteration 3721: loss: 0.6366, d_k_M range: [0.0007, 0.1028], d_k_M_hat range: [0.2029, 0.7185]
2025-03-11 20:16:51 - Train Iteration 3722: loss: 0.9109, d_k_M range: [0.1631, 0.9509], d_k_M_hat range: [0.6414, 0.9965]
2025-03-11 20:16:51 - Train Iteration 3723: loss: 0.6402, d_k_M range: [0.0114, 0.7982], d_k_M_hat range: [0.4708, 0.9981]
2025-03-11 20:16:52 - Train Iteration 3724: loss: 0.3442, d_k_M range: [0.0063, 0.4771], d_k_M_hat range: [0.4250, 0.9451]
2025-03-11 20:16:52 - Train Iteration 3725: loss: 0.3605, d_k_M range: [0.0020, 0.3347], d_k_M_hat range: [0.4047, 0.8144]
2025-03-11 20:16:53 - Train Iteration 3726: loss: 0.3945, d_k_M range: [0.0060, 0.6016], d_k_M_hat range: [0.4455, 0.9735]
2025-03-11 20:16:53 - Train Iteration 3727: loss: 0.3680, d_k_M range: [0.0006, 0.2269], d_k_M_hat range: [0.3939, 0.8435]
2025-03-11 20:16:53 - Train Iteration 3728: loss: 0.4078, d_k_M range: [0.0018, 0.5126], d_k_M_hat range: [0.3633, 0.9920]
2025-03-11 20:16:54 - Train Iteration 3729: loss: 0.3301, d_k_M range: [0.0914, 0.4253], d_k_M_hat range: [0.5792, 0.9378]
2025-03-11 20:16:54 - Train Iteration 3730: loss: 0.3535, d_k_M range: [0.1539, 0.5562], d_k_M_hat range: [0.6963, 0.9853]
2025-03-11 20:16:55 - Train Iteration 3731: loss: 0.3067, d_k_M range: [0.0027, 0.3436], d_k_M_hat range: [0.4555, 0.8391]
2025-03-11 20:16:55 - Train Iteration 3732: loss: 0.3031, d_k_M range: [0.1447, 0.5193], d_k_M_hat range: [0.6750, 0.9901]
2025-03-11 20:16:56 - Train Iteration 3733: loss: 0.5140, d_k_M range: [0.0016, 0.4244], d_k_M_hat range: [0.2846, 0.9537]
2025-03-11 20:16:56 - Train Iteration 3734: loss: 0.3815, d_k_M range: [0.0061, 0.5579], d_k_M_hat range: [0.4808, 0.9784]
2025-03-11 20:16:57 - Train Iteration 3735: loss: 0.3839, d_k_M range: [0.0004, 0.3006], d_k_M_hat range: [0.3808, 0.7871]
2025-03-11 20:16:57 - Train Iteration 3736: loss: 0.3845, d_k_M range: [0.0229, 0.6103], d_k_M_hat range: [0.4926, 0.9903]
2025-03-11 20:16:57 - Train Iteration 3737: loss: 0.9844, d_k_M range: [0.0003, 0.2833], d_k_M_hat range: [0.0082, 0.8031]
2025-03-11 20:16:58 - Train Iteration 3738: loss: 0.6014, d_k_M range: [0.0007, 0.3352], d_k_M_hat range: [0.2267, 0.8370]
2025-03-11 20:16:58 - Train Iteration 3739: loss: 0.5374, d_k_M range: [0.3716, 0.7237], d_k_M_hat range: [0.8844, 0.9941]
2025-03-11 20:16:59 - Train Iteration 3740: loss: 0.3777, d_k_M range: [0.0064, 0.4792], d_k_M_hat range: [0.4878, 0.9424]
2025-03-11 20:16:59 - Train Iteration 3741: loss: 0.5091, d_k_M range: [0.1292, 0.7120], d_k_M_hat range: [0.6749, 0.9985]
2025-03-11 20:17:00 - Train Iteration 3742: loss: 0.4462, d_k_M range: [0.0328, 0.4416], d_k_M_hat range: [0.4344, 0.9333]
2025-03-11 20:17:00 - Train Iteration 3743: loss: 0.4104, d_k_M range: [0.0512, 0.5838], d_k_M_hat range: [0.4702, 0.9842]
2025-03-11 20:17:01 - Train Iteration 3744: loss: 0.3551, d_k_M range: [0.0024, 0.5601], d_k_M_hat range: [0.4146, 0.9642]
2025-03-11 20:17:01 - Train Iteration 3745: loss: 0.3187, d_k_M range: [0.0130, 0.4496], d_k_M_hat range: [0.4957, 0.9275]
2025-03-11 20:17:02 - Train Iteration 3746: loss: 0.4091, d_k_M range: [0.0013, 0.2384], d_k_M_hat range: [0.3672, 0.7217]
2025-03-11 20:17:02 - Train Iteration 3747: loss: 0.4167, d_k_M range: [0.0034, 0.2698], d_k_M_hat range: [0.3762, 0.8265]
2025-03-11 20:17:03 - Train Iteration 3748: loss: 0.3511, d_k_M range: [0.0065, 0.4440], d_k_M_hat range: [0.4140, 0.9715]
2025-03-11 20:17:03 - Train Iteration 3749: loss: 0.5395, d_k_M range: [0.0712, 0.7302], d_k_M_hat range: [0.6034, 0.9957]
2025-03-11 20:17:04 - Train Iteration 3750: loss: 0.3560, d_k_M range: [0.0299, 0.5357], d_k_M_hat range: [0.5361, 0.9796]
2025-03-11 20:17:04 - Train Iteration 3751: loss: 0.3447, d_k_M range: [0.0884, 0.5400], d_k_M_hat range: [0.6192, 0.9853]
2025-03-11 20:17:05 - Train Iteration 3752: loss: 0.4117, d_k_M range: [0.0142, 0.6284], d_k_M_hat range: [0.6186, 0.9867]
2025-03-11 20:17:05 - Train Iteration 3753: loss: 0.5460, d_k_M range: [0.0042, 0.7380], d_k_M_hat range: [0.4546, 0.9991]
2025-03-11 20:17:06 - Train Iteration 3754: loss: 0.5984, d_k_M range: [0.0008, 0.3539], d_k_M_hat range: [0.2272, 0.9164]
2025-03-11 20:17:06 - Train Iteration 3755: loss: 0.5433, d_k_M range: [0.1565, 0.7334], d_k_M_hat range: [0.7050, 0.9962]
2025-03-11 20:17:06 - Train Iteration 3756: loss: 0.4408, d_k_M range: [0.0090, 0.3699], d_k_M_hat range: [0.4742, 0.8231]
2025-03-11 20:17:07 - Train Iteration 3757: loss: 0.5556, d_k_M range: [0.0003, 0.5024], d_k_M_hat range: [0.2549, 0.9741]
2025-03-11 20:17:07 - Train Iteration 3758: loss: 0.2681, d_k_M range: [0.2918, 0.4721], d_k_M_hat range: [0.8282, 0.9711]
2025-03-11 20:17:08 - Train Iteration 3759: loss: 0.3319, d_k_M range: [0.0008, 0.4218], d_k_M_hat range: [0.4247, 0.9106]
2025-03-11 20:17:08 - Train Iteration 3760: loss: 0.4165, d_k_M range: [0.1004, 0.6422], d_k_M_hat range: [0.6402, 0.9968]
2025-03-11 20:17:09 - Train Iteration 3761: loss: 0.4188, d_k_M range: [0.0005, 0.6315], d_k_M_hat range: [0.4073, 0.9843]
2025-03-11 20:17:09 - Train Iteration 3762: loss: 0.5182, d_k_M range: [0.0048, 0.5515], d_k_M_hat range: [0.4826, 0.8746]
2025-03-11 20:17:09 - Train Iteration 3763: loss: 0.3051, d_k_M range: [0.0030, 0.5413], d_k_M_hat range: [0.4509, 0.9890]
2025-03-11 20:17:10 - Train Iteration 3764: loss: 0.4849, d_k_M range: [0.0017, 0.3237], d_k_M_hat range: [0.3053, 0.8658]
2025-03-11 20:17:10 - Train Iteration 3765: loss: 0.5321, d_k_M range: [0.0559, 0.7278], d_k_M_hat range: [0.5968, 0.9984]
2025-03-11 20:17:11 - Train Iteration 3766: loss: 0.3455, d_k_M range: [0.0581, 0.5634], d_k_M_hat range: [0.5430, 0.9756]
2025-03-11 20:17:11 - Train Iteration 3767: loss: 0.3432, d_k_M range: [0.0115, 0.4978], d_k_M_hat range: [0.5130, 0.9585]
2025-03-11 20:17:12 - Train Iteration 3768: loss: 0.7155, d_k_M range: [0.0700, 0.8434], d_k_M_hat range: [0.6037, 0.9976]
2025-03-11 20:17:12 - Train Iteration 3769: loss: 0.3426, d_k_M range: [0.2508, 0.5768], d_k_M_hat range: [0.7853, 0.9958]
2025-03-11 20:17:13 - Train Iteration 3770: loss: 0.3028, d_k_M range: [0.1002, 0.5422], d_k_M_hat range: [0.5711, 0.9919]
2025-03-11 20:17:13 - Train Iteration 3771: loss: 0.3283, d_k_M range: [0.0024, 0.5340], d_k_M_hat range: [0.4294, 0.9720]
2025-03-11 20:17:14 - Train Iteration 3772: loss: 0.3833, d_k_M range: [0.0015, 0.3527], d_k_M_hat range: [0.3824, 0.9170]
2025-03-11 20:17:14 - Train Iteration 3773: loss: 0.3986, d_k_M range: [0.0046, 0.5926], d_k_M_hat range: [0.4682, 0.9893]
2025-03-11 20:17:14 - Train Iteration 3774: loss: 0.3564, d_k_M range: [0.0648, 0.5752], d_k_M_hat range: [0.5970, 0.9782]
2025-03-11 20:17:15 - Train Iteration 3775: loss: 0.5350, d_k_M range: [0.0255, 0.7243], d_k_M_hat range: [0.5363, 0.9975]
2025-03-11 20:17:15 - Train Iteration 3776: loss: 0.2754, d_k_M range: [0.0180, 0.4079], d_k_M_hat range: [0.5236, 0.9187]
2025-03-11 20:17:16 - Train Iteration 3777: loss: 0.8169, d_k_M range: [0.0004, 0.6348], d_k_M_hat range: [0.0966, 0.9858]
2025-03-11 20:17:16 - Train Iteration 3778: loss: 0.2859, d_k_M range: [0.0547, 0.4979], d_k_M_hat range: [0.6526, 0.9952]
2025-03-11 20:17:17 - Train Iteration 3779: loss: 0.3627, d_k_M range: [0.0092, 0.4201], d_k_M_hat range: [0.4070, 0.9700]
2025-03-11 20:17:17 - Train Iteration 3780: loss: 0.3433, d_k_M range: [0.0059, 0.4601], d_k_M_hat range: [0.4201, 0.9820]
2025-03-11 20:17:18 - Train Iteration 3781: loss: 0.2988, d_k_M range: [0.0434, 0.4786], d_k_M_hat range: [0.6177, 0.9630]
2025-03-11 20:17:18 - Train Iteration 3782: loss: 0.3704, d_k_M range: [0.0384, 0.3759], d_k_M_hat range: [0.5919, 0.8993]
2025-03-11 20:17:18 - Train Iteration 3783: loss: 0.3456, d_k_M range: [0.0119, 0.5796], d_k_M_hat range: [0.5141, 0.9918]
2025-03-11 20:17:19 - Train Iteration 3784: loss: 0.3337, d_k_M range: [0.0028, 0.2923], d_k_M_hat range: [0.4251, 0.8446]
2025-03-11 20:17:19 - Train Iteration 3785: loss: 0.2893, d_k_M range: [0.0831, 0.4023], d_k_M_hat range: [0.6958, 0.9484]
2025-03-11 20:17:20 - Train Iteration 3786: loss: 0.3744, d_k_M range: [0.0244, 0.5946], d_k_M_hat range: [0.5872, 0.9827]
2025-03-11 20:17:20 - Train Iteration 3787: loss: 0.7316, d_k_M range: [0.0001, 0.3831], d_k_M_hat range: [0.1448, 0.9490]
2025-03-11 20:17:21 - Train Iteration 3788: loss: 0.2386, d_k_M range: [0.0544, 0.3878], d_k_M_hat range: [0.6274, 0.9492]
2025-03-11 20:17:21 - Train Iteration 3789: loss: 0.5756, d_k_M range: [0.0008, 0.1996], d_k_M_hat range: [0.2421, 0.8055]
2025-03-11 20:17:22 - Train Iteration 3790: loss: 0.7720, d_k_M range: [0.0219, 0.8716], d_k_M_hat range: [0.5270, 0.9930]
2025-03-11 20:17:22 - Train Iteration 3791: loss: 0.8317, d_k_M range: [0.1686, 0.9069], d_k_M_hat range: [0.7328, 0.9949]
2025-03-11 20:17:22 - Train Iteration 3792: loss: 0.7806, d_k_M range: [0.0007, 0.5188], d_k_M_hat range: [0.1172, 0.9703]
2025-03-11 20:17:23 - Train Iteration 3793: loss: 0.4599, d_k_M range: [0.1571, 0.6739], d_k_M_hat range: [0.5711, 0.9963]
2025-03-11 20:17:23 - Train Iteration 3794: loss: 0.3524, d_k_M range: [0.0040, 0.2135], d_k_M_hat range: [0.4649, 0.6786]
2025-03-11 20:17:24 - Train Iteration 3795: loss: 0.3267, d_k_M range: [0.0082, 0.5497], d_k_M_hat range: [0.4666, 0.9781]
2025-03-11 20:17:24 - Train Iteration 3796: loss: 0.4377, d_k_M range: [0.1632, 0.6380], d_k_M_hat range: [0.7003, 0.9764]
2025-03-11 20:17:24 - Train Iteration 3797: loss: 0.4911, d_k_M range: [0.0001, 0.1993], d_k_M_hat range: [0.2993, 0.7367]
2025-03-11 20:17:25 - Train Iteration 3798: loss: 0.3640, d_k_M range: [0.1703, 0.5223], d_k_M_hat range: [0.7329, 0.9560]
2025-03-11 20:17:25 - Train Iteration 3799: loss: 0.3817, d_k_M range: [0.0196, 0.5942], d_k_M_hat range: [0.5503, 0.9798]
2025-03-11 20:17:26 - Train Iteration 3800: loss: 0.3015, d_k_M range: [0.0151, 0.4902], d_k_M_hat range: [0.4910, 0.9883]
2025-03-11 20:17:26 - Train Iteration 3801: loss: 0.3628, d_k_M range: [0.0669, 0.5501], d_k_M_hat range: [0.4645, 0.9688]
2025-03-11 20:17:27 - Train Iteration 3802: loss: 0.2915, d_k_M range: [0.0440, 0.4909], d_k_M_hat range: [0.5425, 0.9510]
2025-03-11 20:17:27 - Train Iteration 3803: loss: 0.4323, d_k_M range: [0.0235, 0.6403], d_k_M_hat range: [0.5628, 0.9828]
2025-03-11 20:17:27 - Train Iteration 3804: loss: 0.3410, d_k_M range: [0.0027, 0.3683], d_k_M_hat range: [0.4238, 0.9414]
2025-03-11 20:17:28 - Train Iteration 3805: loss: 0.3182, d_k_M range: [0.0184, 0.5073], d_k_M_hat range: [0.4543, 0.9890]
2025-03-11 20:17:28 - Train Iteration 3806: loss: 0.3083, d_k_M range: [0.0299, 0.5404], d_k_M_hat range: [0.5893, 0.9954]
2025-03-11 20:17:29 - Train Iteration 3807: loss: 0.2940, d_k_M range: [0.0179, 0.1584], d_k_M_hat range: [0.5118, 0.7614]
2025-03-11 20:17:29 - Train Iteration 3808: loss: 0.3144, d_k_M range: [0.0204, 0.5461], d_k_M_hat range: [0.5670, 0.9854]
2025-03-11 20:17:30 - Train Iteration 3809: loss: 0.4576, d_k_M range: [0.0278, 0.6664], d_k_M_hat range: [0.4658, 0.9900]
2025-03-11 20:17:30 - Train Iteration 3810: loss: 0.3963, d_k_M range: [0.0006, 0.3687], d_k_M_hat range: [0.3711, 0.8875]
2025-03-11 20:17:30 - Train Iteration 3811: loss: 0.2813, d_k_M range: [0.1286, 0.4334], d_k_M_hat range: [0.6900, 0.9842]
2025-03-11 20:17:31 - Train Iteration 3812: loss: 0.3143, d_k_M range: [0.0206, 0.5089], d_k_M_hat range: [0.5296, 0.9528]
2025-03-11 20:17:31 - Train Iteration 3813: loss: 0.5125, d_k_M range: [0.0064, 0.7111], d_k_M_hat range: [0.5013, 0.9952]
2025-03-11 20:17:32 - Train Iteration 3814: loss: 0.4319, d_k_M range: [0.0019, 0.6187], d_k_M_hat range: [0.4000, 0.9615]
2025-03-11 20:17:32 - Train Iteration 3815: loss: 0.3988, d_k_M range: [0.0004, 0.2268], d_k_M_hat range: [0.3689, 0.7730]
2025-03-11 20:17:33 - Train Iteration 3816: loss: 0.4093, d_k_M range: [0.0119, 0.6227], d_k_M_hat range: [0.5899, 0.9882]
2025-03-11 20:17:33 - Train Iteration 3817: loss: 0.3208, d_k_M range: [0.0796, 0.5249], d_k_M_hat range: [0.6355, 0.9585]
2025-03-11 20:17:34 - Train Iteration 3818: loss: 0.2562, d_k_M range: [0.0080, 0.4343], d_k_M_hat range: [0.5018, 0.9618]
2025-03-11 20:17:34 - Train Iteration 3819: loss: 0.3538, d_k_M range: [0.0052, 0.3366], d_k_M_hat range: [0.4104, 0.9114]
2025-03-11 20:17:35 - Train Iteration 3820: loss: 0.4215, d_k_M range: [0.4320, 0.6166], d_k_M_hat range: [0.9232, 0.9976]
2025-03-11 20:17:35 - Train Iteration 3821: loss: 0.5443, d_k_M range: [0.0591, 0.5688], d_k_M_hat range: [0.6367, 0.9602]
2025-03-11 20:17:35 - Train Iteration 3822: loss: 0.3758, d_k_M range: [0.0146, 0.5661], d_k_M_hat range: [0.5078, 0.9739]
2025-03-11 20:17:36 - Train Iteration 3823: loss: 0.3553, d_k_M range: [0.0045, 0.5917], d_k_M_hat range: [0.4644, 0.9957]
2025-03-11 20:17:36 - Train Iteration 3824: loss: 0.2831, d_k_M range: [0.0013, 0.4675], d_k_M_hat range: [0.5376, 0.9546]
2025-03-11 20:17:37 - Train Iteration 3825: loss: 0.4279, d_k_M range: [0.0341, 0.6297], d_k_M_hat range: [0.6219, 0.9873]
2025-03-11 20:17:37 - Train Iteration 3826: loss: 0.4369, d_k_M range: [0.0013, 0.3969], d_k_M_hat range: [0.3403, 0.9733]
2025-03-11 20:17:38 - Train Iteration 3827: loss: 0.4363, d_k_M range: [0.0448, 0.6410], d_k_M_hat range: [0.6071, 0.9897]
2025-03-11 20:17:38 - Train Iteration 3828: loss: 0.3244, d_k_M range: [0.0098, 0.4925], d_k_M_hat range: [0.4545, 0.9942]
2025-03-11 20:17:38 - Train Iteration 3829: loss: 0.2696, d_k_M range: [0.1545, 0.4689], d_k_M_hat range: [0.8137, 0.9743]
2025-03-11 20:17:39 - Train Iteration 3830: loss: 0.2142, d_k_M range: [0.0497, 0.4041], d_k_M_hat range: [0.6384, 0.9608]
2025-03-11 20:17:39 - Train Iteration 3831: loss: 0.2637, d_k_M range: [0.0017, 0.2629], d_k_M_hat range: [0.4882, 0.8643]
2025-03-11 20:17:40 - Train Iteration 3832: loss: 0.4631, d_k_M range: [0.1348, 0.6791], d_k_M_hat range: [0.6504, 0.9986]
2025-03-11 20:17:40 - Train Iteration 3833: loss: 0.2332, d_k_M range: [0.0660, 0.3904], d_k_M_hat range: [0.5999, 0.9345]
2025-03-11 20:17:41 - Train Iteration 3834: loss: 0.2982, d_k_M range: [0.0068, 0.5253], d_k_M_hat range: [0.4607, 0.9829]
2025-03-11 20:17:41 - Train Iteration 3835: loss: 0.7578, d_k_M range: [0.0237, 0.8665], d_k_M_hat range: [0.5818, 0.9960]
2025-03-11 20:17:42 - Train Iteration 3836: loss: 0.6518, d_k_M range: [0.0004, 0.0857], d_k_M_hat range: [0.1930, 0.7079]
2025-03-11 20:17:42 - Train Iteration 3837: loss: 0.2776, d_k_M range: [0.0709, 0.3990], d_k_M_hat range: [0.6516, 0.9150]
2025-03-11 20:17:42 - Train Iteration 3838: loss: 0.3261, d_k_M range: [0.0006, 0.5287], d_k_M_hat range: [0.4295, 0.9614]
2025-03-11 20:17:43 - Train Iteration 3839: loss: 0.2943, d_k_M range: [0.0154, 0.4907], d_k_M_hat range: [0.5029, 0.9717]
2025-03-11 20:17:43 - Train Iteration 3840: loss: 0.2558, d_k_M range: [0.0049, 0.3426], d_k_M_hat range: [0.5120, 0.9731]
2025-03-11 20:17:44 - Train Iteration 3841: loss: 0.5070, d_k_M range: [0.0407, 0.6936], d_k_M_hat range: [0.6361, 0.9892]
2025-03-11 20:17:44 - Train Iteration 3842: loss: 0.2960, d_k_M range: [0.0050, 0.2063], d_k_M_hat range: [0.4883, 0.6623]
2025-03-11 20:17:45 - Train Iteration 3843: loss: 0.3084, d_k_M range: [0.2403, 0.4509], d_k_M_hat range: [0.7791, 0.9630]
2025-03-11 20:17:45 - Train Iteration 3844: loss: 0.4270, d_k_M range: [0.0102, 0.4814], d_k_M_hat range: [0.3568, 0.9904]
2025-03-11 20:17:46 - Train Iteration 3845: loss: 0.3869, d_k_M range: [0.0019, 0.4002], d_k_M_hat range: [0.3799, 0.9361]
2025-03-11 20:17:46 - Train Iteration 3846: loss: 0.7353, d_k_M range: [0.1110, 0.8568], d_k_M_hat range: [0.7449, 0.9993]
2025-03-11 20:17:46 - Train Iteration 3847: loss: 0.3725, d_k_M range: [0.0625, 0.4050], d_k_M_hat range: [0.5575, 0.9077]
2025-03-11 20:17:47 - Train Iteration 3848: loss: 0.3889, d_k_M range: [0.0175, 0.5451], d_k_M_hat range: [0.5451, 0.9214]
2025-03-11 20:17:47 - Train Iteration 3849: loss: 0.4950, d_k_M range: [0.0237, 0.6837], d_k_M_hat range: [0.5216, 0.9890]
2025-03-11 20:17:48 - Train Iteration 3850: loss: 0.7617, d_k_M range: [0.0007, 0.3920], d_k_M_hat range: [0.1298, 0.9172]
2025-03-11 20:17:48 - Train Iteration 3851: loss: 0.3264, d_k_M range: [0.0280, 0.5395], d_k_M_hat range: [0.5520, 0.9832]
2025-03-11 20:17:49 - Train Iteration 3852: loss: 0.3562, d_k_M range: [0.0007, 0.2306], d_k_M_hat range: [0.4039, 0.7836]
2025-03-11 20:17:49 - Train Iteration 3853: loss: 0.3755, d_k_M range: [0.0223, 0.4955], d_k_M_hat range: [0.4483, 0.9778]
2025-03-11 20:17:49 - Train Iteration 3854: loss: 0.5903, d_k_M range: [0.0400, 0.5975], d_k_M_hat range: [0.5459, 0.9884]
2025-03-11 20:17:50 - Train Iteration 3855: loss: 0.5756, d_k_M range: [0.0031, 0.7492], d_k_M_hat range: [0.4627, 0.9905]
2025-03-11 20:17:50 - Train Iteration 3856: loss: 0.2893, d_k_M range: [0.0282, 0.4599], d_k_M_hat range: [0.5026, 0.9664]
2025-03-11 20:17:51 - Train Iteration 3857: loss: 0.3447, d_k_M range: [0.1909, 0.5686], d_k_M_hat range: [0.7693, 0.9829]
2025-03-11 20:17:51 - Train Iteration 3858: loss: 0.3308, d_k_M range: [0.0042, 0.3979], d_k_M_hat range: [0.4291, 0.8882]
2025-03-11 20:17:52 - Train Iteration 3859: loss: 0.4071, d_k_M range: [0.1898, 0.5752], d_k_M_hat range: [0.8033, 0.9615]
2025-03-11 20:17:52 - Train Iteration 3860: loss: 0.6326, d_k_M range: [0.0001, 0.3367], d_k_M_hat range: [0.2048, 0.9436]
2025-03-11 20:17:52 - Train Iteration 3861: loss: 0.3776, d_k_M range: [0.0156, 0.6081], d_k_M_hat range: [0.5182, 0.9937]
2025-03-11 20:17:53 - Train Iteration 3862: loss: 0.3103, d_k_M range: [0.0027, 0.4723], d_k_M_hat range: [0.4457, 0.9657]
2025-03-11 20:17:53 - Train Iteration 3863: loss: 0.3987, d_k_M range: [0.0089, 0.6022], d_k_M_hat range: [0.4999, 0.9708]
2025-03-11 20:17:54 - Train Iteration 3864: loss: 0.3301, d_k_M range: [0.0018, 0.4004], d_k_M_hat range: [0.4526, 0.9118]
2025-03-11 20:17:54 - Train Iteration 3865: loss: 0.1974, d_k_M range: [0.0264, 0.3887], d_k_M_hat range: [0.6737, 0.9444]
2025-03-11 20:17:55 - Train Iteration 3866: loss: 0.4520, d_k_M range: [0.0003, 0.2537], d_k_M_hat range: [0.3280, 0.8281]
2025-03-11 20:17:55 - Train Iteration 3867: loss: 0.3503, d_k_M range: [0.2057, 0.5632], d_k_M_hat range: [0.8787, 0.9895]
2025-03-11 20:17:56 - Train Iteration 3868: loss: 0.4237, d_k_M range: [0.0004, 0.4468], d_k_M_hat range: [0.3495, 0.9535]
2025-03-11 20:17:56 - Train Iteration 3869: loss: 0.6173, d_k_M range: [0.2116, 0.7807], d_k_M_hat range: [0.8197, 0.9951]
2025-03-11 20:17:57 - Train Iteration 3870: loss: 0.4803, d_k_M range: [0.0014, 0.2647], d_k_M_hat range: [0.3149, 0.7757]
2025-03-11 20:17:57 - Train Iteration 3871: loss: 0.2372, d_k_M range: [0.0175, 0.3845], d_k_M_hat range: [0.5349, 0.9337]
2025-03-11 20:17:58 - Train Iteration 3872: loss: 0.3128, d_k_M range: [0.0021, 0.5266], d_k_M_hat range: [0.4563, 0.9908]
2025-03-11 20:17:58 - Train Iteration 3873: loss: 0.7120, d_k_M range: [0.1091, 0.8384], d_k_M_hat range: [0.7836, 0.9947]
2025-03-11 20:17:59 - Train Iteration 3874: loss: 0.4602, d_k_M range: [0.0014, 0.3053], d_k_M_hat range: [0.3230, 0.8983]
2025-03-11 20:17:59 - Train Iteration 3875: loss: 0.3022, d_k_M range: [0.0901, 0.4825], d_k_M_hat range: [0.5893, 0.9501]
2025-03-11 20:18:00 - Train Iteration 3876: loss: 0.5203, d_k_M range: [0.0014, 0.5034], d_k_M_hat range: [0.2801, 0.9851]
2025-03-11 20:18:00 - Train Iteration 3877: loss: 0.3594, d_k_M range: [0.0164, 0.4085], d_k_M_hat range: [0.5202, 0.9414]
2025-03-11 20:18:00 - Train Iteration 3878: loss: 0.2496, d_k_M range: [0.1981, 0.4130], d_k_M_hat range: [0.7782, 0.9612]
2025-03-11 20:18:01 - Train Iteration 3879: loss: 0.5468, d_k_M range: [0.0126, 0.7315], d_k_M_hat range: [0.5500, 0.9981]
2025-03-11 20:18:01 - Train Iteration 3880: loss: 0.4212, d_k_M range: [0.0006, 0.4875], d_k_M_hat range: [0.3707, 0.9784]
2025-03-11 20:18:02 - Train Iteration 3881: loss: 0.2965, d_k_M range: [0.0067, 0.3874], d_k_M_hat range: [0.4691, 0.9756]
2025-03-11 20:18:02 - Train Iteration 3882: loss: 0.3488, d_k_M range: [0.0010, 0.4569], d_k_M_hat range: [0.4243, 0.9292]
2025-03-11 20:18:03 - Train Iteration 3883: loss: 0.2845, d_k_M range: [0.1762, 0.3923], d_k_M_hat range: [0.6589, 0.9716]
2025-03-11 20:18:03 - Train Iteration 3884: loss: 0.3006, d_k_M range: [0.0057, 0.2588], d_k_M_hat range: [0.5207, 0.8499]
2025-03-11 20:18:04 - Train Iteration 3885: loss: 0.3068, d_k_M range: [0.0060, 0.2463], d_k_M_hat range: [0.4521, 0.9307]
2025-03-11 20:18:04 - Train Iteration 3886: loss: 0.3215, d_k_M range: [0.0029, 0.4477], d_k_M_hat range: [0.5110, 0.8894]
2025-03-11 20:18:04 - Train Iteration 3887: loss: 0.3082, d_k_M range: [0.0029, 0.4716], d_k_M_hat range: [0.4526, 0.9776]
2025-03-11 20:18:05 - Train Iteration 3888: loss: 0.2523, d_k_M range: [0.0022, 0.1724], d_k_M_hat range: [0.5015, 0.8933]
2025-03-11 20:18:05 - Train Iteration 3889: loss: 0.3402, d_k_M range: [0.0666, 0.4856], d_k_M_hat range: [0.6826, 0.9841]
2025-03-11 20:18:06 - Train Iteration 3890: loss: 0.3135, d_k_M range: [0.0048, 0.5340], d_k_M_hat range: [0.5381, 0.9871]
2025-03-11 20:18:06 - Train Iteration 3891: loss: 0.2137, d_k_M range: [0.0263, 0.4148], d_k_M_hat range: [0.5640, 0.9884]
2025-03-11 20:18:07 - Train Iteration 3892: loss: 0.9341, d_k_M range: [0.0591, 0.9661], d_k_M_hat range: [0.6884, 0.9996]
2025-03-11 20:18:07 - Train Iteration 3893: loss: 0.4265, d_k_M range: [0.0020, 0.3329], d_k_M_hat range: [0.3489, 0.9122]
2025-03-11 20:18:07 - Train Iteration 3894: loss: 0.4279, d_k_M range: [0.0132, 0.6514], d_k_M_hat range: [0.5625, 0.9973]
2025-03-11 20:18:08 - Train Iteration 3895: loss: 0.3304, d_k_M range: [0.0130, 0.4702], d_k_M_hat range: [0.5009, 0.9100]
2025-03-11 20:18:08 - Train Iteration 3896: loss: 0.4731, d_k_M range: [0.0020, 0.3312], d_k_M_hat range: [0.3141, 0.8679]
2025-03-11 20:18:09 - Train Iteration 3897: loss: 0.3633, d_k_M range: [0.0032, 0.4923], d_k_M_hat range: [0.4004, 0.9796]
2025-03-11 20:18:09 - Train Iteration 3898: loss: 0.3270, d_k_M range: [0.0216, 0.5094], d_k_M_hat range: [0.4822, 0.9928]
2025-03-11 20:18:10 - Train Iteration 3899: loss: 0.3868, d_k_M range: [0.0021, 0.4212], d_k_M_hat range: [0.3802, 0.9467]
2025-03-11 20:18:10 - Train Iteration 3900: loss: 0.2929, d_k_M range: [0.0053, 0.5082], d_k_M_hat range: [0.5174, 0.9735]
2025-03-11 20:18:10 - Train Iteration 3901: loss: 0.3342, d_k_M range: [0.0011, 0.5104], d_k_M_hat range: [0.4230, 0.9774]
2025-03-11 20:18:11 - Train Iteration 3902: loss: 0.4222, d_k_M range: [0.0036, 0.6314], d_k_M_hat range: [0.3799, 0.9816]
2025-03-11 20:18:11 - Train Iteration 3903: loss: 0.4687, d_k_M range: [0.0005, 0.4964], d_k_M_hat range: [0.3551, 0.9742]
2025-03-11 20:18:12 - Train Iteration 3904: loss: 0.4016, d_k_M range: [0.0012, 0.6250], d_k_M_hat range: [0.4108, 0.9912]
2025-03-11 20:18:12 - Train Iteration 3905: loss: 0.2557, d_k_M range: [0.0113, 0.3722], d_k_M_hat range: [0.5382, 0.9598]
2025-03-11 20:18:12 - Train Iteration 3906: loss: 0.9282, d_k_M range: [0.0805, 0.9625], d_k_M_hat range: [0.5987, 0.9990]
2025-03-11 20:18:13 - Train Iteration 3907: loss: 0.3826, d_k_M range: [0.0076, 0.5047], d_k_M_hat range: [0.3899, 0.9647]
2025-03-11 20:18:13 - Train Iteration 3908: loss: 0.3256, d_k_M range: [0.0485, 0.5603], d_k_M_hat range: [0.6639, 0.9927]
2025-03-11 20:18:14 - Train Iteration 3909: loss: 0.3720, d_k_M range: [0.0010, 0.4197], d_k_M_hat range: [0.3911, 0.9521]
2025-03-11 20:18:14 - Train Iteration 3910: loss: 0.4106, d_k_M range: [0.0994, 0.6068], d_k_M_hat range: [0.6787, 0.9828]
2025-03-11 20:18:15 - Train Iteration 3911: loss: 0.4608, d_k_M range: [0.0012, 0.2669], d_k_M_hat range: [0.3224, 0.8319]
2025-03-11 20:18:15 - Train Iteration 3912: loss: 0.4020, d_k_M range: [0.0252, 0.6232], d_k_M_hat range: [0.5216, 0.9892]
2025-03-11 20:18:15 - Train Iteration 3913: loss: 0.3871, d_k_M range: [0.0013, 0.1722], d_k_M_hat range: [0.3791, 0.8659]
2025-03-11 20:18:16 - Train Iteration 3914: loss: 0.5871, d_k_M range: [0.0482, 0.7576], d_k_M_hat range: [0.6914, 0.9939]
2025-03-11 20:18:16 - Train Iteration 3915: loss: 0.3239, d_k_M range: [0.0031, 0.5504], d_k_M_hat range: [0.4412, 0.9812]
2025-03-11 20:18:17 - Train Iteration 3916: loss: 0.5308, d_k_M range: [0.0007, 0.5614], d_k_M_hat range: [0.2722, 0.9759]
2025-03-11 20:18:17 - Train Iteration 3917: loss: 0.3149, d_k_M range: [0.0882, 0.5021], d_k_M_hat range: [0.7563, 0.9410]
2025-03-11 20:18:17 - Train Iteration 3918: loss: 0.4252, d_k_M range: [0.0039, 0.4989], d_k_M_hat range: [0.3517, 0.9883]
2025-03-11 20:18:18 - Train Iteration 3919: loss: 0.3706, d_k_M range: [0.0015, 0.3020], d_k_M_hat range: [0.3927, 0.9059]
2025-03-11 20:18:18 - Train Iteration 3920: loss: 0.3479, d_k_M range: [0.0007, 0.5851], d_k_M_hat range: [0.4445, 0.9953]
2025-03-11 20:18:19 - Train Iteration 3921: loss: 0.3221, d_k_M range: [0.0268, 0.5087], d_k_M_hat range: [0.5479, 0.9897]
2025-03-11 20:18:19 - Train Iteration 3922: loss: 0.5996, d_k_M range: [0.0021, 0.3961], d_k_M_hat range: [0.2548, 0.9613]
2025-03-11 20:18:20 - Train Iteration 3923: loss: 0.3244, d_k_M range: [0.0007, 0.4458], d_k_M_hat range: [0.4465, 0.9070]
2025-03-11 20:18:20 - Train Iteration 3924: loss: 0.7288, d_k_M range: [0.0772, 0.8417], d_k_M_hat range: [0.6634, 0.9961]
2025-03-11 20:18:21 - Train Iteration 3925: loss: 0.3398, d_k_M range: [0.0023, 0.3527], d_k_M_hat range: [0.4194, 0.9081]
2025-03-11 20:18:21 - Train Iteration 3926: loss: 0.3399, d_k_M range: [0.0008, 0.4562], d_k_M_hat range: [0.4178, 0.9799]
2025-03-11 20:18:22 - Train Iteration 3927: loss: 0.5965, d_k_M range: [0.0002, 0.5643], d_k_M_hat range: [0.2279, 0.9883]
2025-03-11 20:18:22 - Train Iteration 3928: loss: 0.8822, d_k_M range: [0.0423, 0.9388], d_k_M_hat range: [0.4714, 0.9995]
2025-03-11 20:18:23 - Train Iteration 3929: loss: 0.2765, d_k_M range: [0.0118, 0.4427], d_k_M_hat range: [0.6032, 0.9169]
2025-03-11 20:18:23 - Train Iteration 3930: loss: 0.4292, d_k_M range: [0.0210, 0.2106], d_k_M_hat range: [0.4132, 0.8014]
2025-03-11 20:18:24 - Train Iteration 3931: loss: 0.2253, d_k_M range: [0.1794, 0.3980], d_k_M_hat range: [0.7155, 0.9686]
2025-03-11 20:18:24 - Train Iteration 3932: loss: 0.4716, d_k_M range: [0.0015, 0.4173], d_k_M_hat range: [0.3147, 0.9721]
2025-03-11 20:18:25 - Train Iteration 3933: loss: 0.2528, d_k_M range: [0.1050, 0.4410], d_k_M_hat range: [0.6291, 0.9724]
2025-03-11 20:18:25 - Train Iteration 3934: loss: 0.3956, d_k_M range: [0.0140, 0.6236], d_k_M_hat range: [0.4795, 0.9947]
2025-03-11 20:18:25 - Train Iteration 3935: loss: 0.4106, d_k_M range: [0.0103, 0.6334], d_k_M_hat range: [0.5183, 0.9926]
2025-03-11 20:18:26 - Train Iteration 3936: loss: 0.3681, d_k_M range: [0.0055, 0.4072], d_k_M_hat range: [0.4935, 0.9017]
2025-03-11 20:18:26 - Train Iteration 3937: loss: 0.3311, d_k_M range: [0.0660, 0.5461], d_k_M_hat range: [0.6774, 0.9707]
2025-03-11 20:18:27 - Train Iteration 3938: loss: 0.2333, d_k_M range: [0.0123, 0.3950], d_k_M_hat range: [0.5594, 0.9520]
2025-03-11 20:18:27 - Train Iteration 3939: loss: 0.2561, d_k_M range: [0.1110, 0.4770], d_k_M_hat range: [0.7020, 0.9841]
2025-03-11 20:18:28 - Train Iteration 3940: loss: 0.3588, d_k_M range: [0.0226, 0.5939], d_k_M_hat range: [0.5582, 0.9949]
2025-03-11 20:18:28 - Train Iteration 3941: loss: 0.3118, d_k_M range: [0.0059, 0.3716], d_k_M_hat range: [0.4728, 0.9541]
2025-03-11 20:18:29 - Train Iteration 3942: loss: 0.3881, d_k_M range: [0.0208, 0.6013], d_k_M_hat range: [0.5397, 0.9814]
2025-03-11 20:18:29 - Train Iteration 3943: loss: 0.3515, d_k_M range: [0.0055, 0.5897], d_k_M_hat range: [0.5347, 0.9968]
2025-03-11 20:18:30 - Train Iteration 3944: loss: 0.2747, d_k_M range: [0.0024, 0.4810], d_k_M_hat range: [0.5057, 0.9569]
2025-03-11 20:18:30 - Train Iteration 3945: loss: 0.4034, d_k_M range: [0.0307, 0.6272], d_k_M_hat range: [0.5130, 0.9928]
2025-03-11 20:18:30 - Train Iteration 3946: loss: 0.7964, d_k_M range: [0.0001, 0.4059], d_k_M_hat range: [0.1077, 0.9123]
2025-03-11 20:18:31 - Train Iteration 3947: loss: 0.7359, d_k_M range: [0.2084, 0.8553], d_k_M_hat range: [0.8354, 0.9974]
2025-03-11 20:18:31 - Train Iteration 3948: loss: 0.2786, d_k_M range: [0.0103, 0.4801], d_k_M_hat range: [0.5193, 0.9523]
2025-03-11 20:18:32 - Train Iteration 3949: loss: 0.5390, d_k_M range: [0.0053, 0.7250], d_k_M_hat range: [0.3705, 0.9909]
2025-03-11 20:18:32 - Train Iteration 3950: loss: 0.9427, d_k_M range: [0.0277, 0.9696], d_k_M_hat range: [0.6208, 0.9987]
2025-03-11 20:18:33 - Train Iteration 3951: loss: 0.6056, d_k_M range: [0.0035, 0.3636], d_k_M_hat range: [0.2256, 0.8097]
2025-03-11 20:18:33 - Train Iteration 3952: loss: 0.5157, d_k_M range: [0.0043, 0.6980], d_k_M_hat range: [0.5048, 0.9798]
2025-03-11 20:18:33 - Train Iteration 3953: loss: 0.5830, d_k_M range: [0.0017, 0.3445], d_k_M_hat range: [0.2381, 0.7362]
2025-03-11 20:18:34 - Train Iteration 3954: loss: 0.2874, d_k_M range: [0.0393, 0.4925], d_k_M_hat range: [0.5448, 0.9564]
2025-03-11 20:18:34 - Train Iteration 3955: loss: 0.5976, d_k_M range: [0.0104, 0.7708], d_k_M_hat range: [0.4778, 0.9978]
2025-03-11 20:18:35 - Train Iteration 3956: loss: 0.2996, d_k_M range: [0.0094, 0.4986], d_k_M_hat range: [0.4662, 0.9513]
2025-03-11 20:18:35 - Train Iteration 3957: loss: 0.3186, d_k_M range: [0.0439, 0.5394], d_k_M_hat range: [0.5075, 0.9749]
2025-03-11 20:18:36 - Train Iteration 3958: loss: 0.4824, d_k_M range: [0.1575, 0.6826], d_k_M_hat range: [0.7277, 0.9881]
2025-03-11 20:18:36 - Train Iteration 3959: loss: 0.2949, d_k_M range: [0.0125, 0.3850], d_k_M_hat range: [0.4695, 0.8745]
2025-03-11 20:18:36 - Train Iteration 3960: loss: 0.4875, d_k_M range: [0.0091, 0.5232], d_k_M_hat range: [0.5551, 0.9709]
2025-03-11 20:18:37 - Train Iteration 3961: loss: 0.4871, d_k_M range: [0.0015, 0.6941], d_k_M_hat range: [0.4500, 0.9962]
2025-03-11 20:18:37 - Train Iteration 3962: loss: 0.7358, d_k_M range: [0.0002, 0.3193], d_k_M_hat range: [0.1424, 0.7230]
2025-03-11 20:18:38 - Train Iteration 3963: loss: 0.6696, d_k_M range: [0.0153, 0.8180], d_k_M_hat range: [0.2752, 0.9998]
2025-03-11 20:18:38 - Train Iteration 3964: loss: 0.2839, d_k_M range: [0.0055, 0.3626], d_k_M_hat range: [0.5006, 0.8298]
2025-03-11 20:18:39 - Train Iteration 3965: loss: 0.3314, d_k_M range: [0.0076, 0.4148], d_k_M_hat range: [0.4320, 0.9650]
2025-03-11 20:18:39 - Train Iteration 3966: loss: 0.2866, d_k_M range: [0.0077, 0.4345], d_k_M_hat range: [0.4761, 0.9363]
2025-03-11 20:18:40 - Train Iteration 3967: loss: 0.3724, d_k_M range: [0.0074, 0.4643], d_k_M_hat range: [0.4661, 0.9790]
2025-03-11 20:18:40 - Train Iteration 3968: loss: 0.2594, d_k_M range: [0.0150, 0.3352], d_k_M_hat range: [0.5509, 0.8703]
2025-03-11 20:18:40 - Train Iteration 3969: loss: 0.2953, d_k_M range: [0.0094, 0.5371], d_k_M_hat range: [0.5544, 0.9937]
2025-03-11 20:18:41 - Train Iteration 3970: loss: 0.4726, d_k_M range: [0.0288, 0.6808], d_k_M_hat range: [0.5440, 0.9933]
2025-03-11 20:18:41 - Train Iteration 3971: loss: 0.6135, d_k_M range: [0.0173, 0.7653], d_k_M_hat range: [0.5423, 0.9972]
2025-03-11 20:18:42 - Train Iteration 3972: loss: 0.3237, d_k_M range: [0.0026, 0.4389], d_k_M_hat range: [0.4337, 0.8915]
2025-03-11 20:18:42 - Train Iteration 3973: loss: 0.2444, d_k_M range: [0.0014, 0.4306], d_k_M_hat range: [0.5345, 0.9535]
2025-03-11 20:18:43 - Train Iteration 3974: loss: 0.2898, d_k_M range: [0.0060, 0.4986], d_k_M_hat range: [0.4676, 0.9815]
2025-03-11 20:18:43 - Train Iteration 3975: loss: 0.2804, d_k_M range: [0.0048, 0.3110], d_k_M_hat range: [0.4770, 0.8707]
2025-03-11 20:18:44 - Train Iteration 3976: loss: 0.3219, d_k_M range: [0.0121, 0.4497], d_k_M_hat range: [0.5934, 0.9175]
2025-03-11 20:18:44 - Train Iteration 3977: loss: 0.3467, d_k_M range: [0.0580, 0.5683], d_k_M_hat range: [0.6837, 0.9795]
2025-03-11 20:18:44 - Train Iteration 3978: loss: 0.4160, d_k_M range: [0.0022, 0.4736], d_k_M_hat range: [0.3572, 0.9384]
2025-03-11 20:18:45 - Train Iteration 3979: loss: 0.4198, d_k_M range: [0.0029, 0.6317], d_k_M_hat range: [0.5452, 0.9954]
2025-03-11 20:18:45 - Train Iteration 3980: loss: 0.3908, d_k_M range: [0.0070, 0.6118], d_k_M_hat range: [0.5144, 0.9867]
2025-03-11 20:18:46 - Train Iteration 3981: loss: 0.2905, d_k_M range: [0.0285, 0.2469], d_k_M_hat range: [0.5677, 0.7877]
2025-03-11 20:18:46 - Train Iteration 3982: loss: 0.3397, d_k_M range: [0.0059, 0.4225], d_k_M_hat range: [0.4230, 0.9289]
2025-03-11 20:18:47 - Train Iteration 3983: loss: 0.2728, d_k_M range: [0.0551, 0.3855], d_k_M_hat range: [0.5328, 0.9547]
2025-03-11 20:18:47 - Train Iteration 3984: loss: 0.2781, d_k_M range: [0.0023, 0.4427], d_k_M_hat range: [0.4789, 0.9507]
2025-03-11 20:18:47 - Train Iteration 3985: loss: 0.3890, d_k_M range: [0.0051, 0.3844], d_k_M_hat range: [0.3837, 0.9365]
2025-03-11 20:18:48 - Train Iteration 3986: loss: 0.2971, d_k_M range: [0.0044, 0.4492], d_k_M_hat range: [0.5487, 0.9803]
2025-03-11 20:18:48 - Train Iteration 3987: loss: 0.4725, d_k_M range: [0.0326, 0.6797], d_k_M_hat range: [0.5426, 0.9923]
2025-03-11 20:18:49 - Train Iteration 3988: loss: 0.4714, d_k_M range: [0.0034, 0.1039], d_k_M_hat range: [0.3168, 0.7375]
2025-03-11 20:18:49 - Train Iteration 3989: loss: 0.2963, d_k_M range: [0.0670, 0.5157], d_k_M_hat range: [0.6053, 0.9714]
2025-03-11 20:18:50 - Train Iteration 3990: loss: 0.4085, d_k_M range: [0.0021, 0.1911], d_k_M_hat range: [0.3630, 0.8134]
2025-03-11 20:18:50 - Train Iteration 3991: loss: 0.2997, d_k_M range: [0.0210, 0.4689], d_k_M_hat range: [0.5549, 0.9486]
2025-03-11 20:18:50 - Train Iteration 3992: loss: 0.4577, d_k_M range: [0.0049, 0.6740], d_k_M_hat range: [0.4609, 0.9975]
2025-03-11 20:18:51 - Train Iteration 3993: loss: 0.7470, d_k_M range: [0.0236, 0.8570], d_k_M_hat range: [0.4916, 0.9927]
2025-03-11 20:18:51 - Train Iteration 3994: loss: 0.6239, d_k_M range: [0.0011, 0.3035], d_k_M_hat range: [0.2128, 0.8597]
2025-03-11 20:18:52 - Train Iteration 3995: loss: 0.3222, d_k_M range: [0.0127, 0.5585], d_k_M_hat range: [0.5853, 0.9909]
2025-03-11 20:18:52 - Train Iteration 3996: loss: 0.5624, d_k_M range: [0.0005, 0.5694], d_k_M_hat range: [0.2554, 0.9684]
2025-03-11 20:18:52 - Train Iteration 3997: loss: 0.5028, d_k_M range: [0.0264, 0.7032], d_k_M_hat range: [0.6145, 0.9973]
2025-03-11 20:18:53 - Train Iteration 3998: loss: 0.6855, d_k_M range: [0.0012, 0.2112], d_k_M_hat range: [0.1732, 0.7491]
2025-03-11 20:18:53 - Train Iteration 3999: loss: 0.6850, d_k_M range: [0.1293, 0.8253], d_k_M_hat range: [0.7368, 0.9977]
2025-03-11 20:18:54 - Train Iteration 4000: loss: 0.3520, d_k_M range: [0.0014, 0.2944], d_k_M_hat range: [0.4081, 0.8162]
2025-03-11 20:18:54 - Train Iteration 4001: loss: 0.3947, d_k_M range: [0.0490, 0.4151], d_k_M_hat range: [0.5713, 0.9311]
2025-03-11 20:18:55 - Train Iteration 4002: loss: 0.2503, d_k_M range: [0.0644, 0.4555], d_k_M_hat range: [0.6173, 0.9914]
2025-03-11 20:18:55 - Train Iteration 4003: loss: 0.3584, d_k_M range: [0.0726, 0.4828], d_k_M_hat range: [0.4739, 0.9860]
2025-03-11 20:18:55 - Train Iteration 4004: loss: 0.3647, d_k_M range: [0.0041, 0.4671], d_k_M_hat range: [0.4364, 0.9632]
2025-03-11 20:18:56 - Train Iteration 4005: loss: 0.3051, d_k_M range: [0.0095, 0.3851], d_k_M_hat range: [0.4706, 0.9143]
2025-03-11 20:18:56 - Train Iteration 4006: loss: 0.3212, d_k_M range: [0.0102, 0.4915], d_k_M_hat range: [0.5090, 0.9747]
2025-03-11 20:18:57 - Train Iteration 4007: loss: 0.2960, d_k_M range: [0.0099, 0.3131], d_k_M_hat range: [0.4658, 0.8403]
2025-03-11 20:18:57 - Train Iteration 4008: loss: 0.2761, d_k_M range: [0.0056, 0.4030], d_k_M_hat range: [0.5481, 0.9420]
2025-03-11 20:18:58 - Train Iteration 4009: loss: 0.3702, d_k_M range: [0.0176, 0.4832], d_k_M_hat range: [0.5400, 0.9763]
2025-03-11 20:18:58 - Train Iteration 4010: loss: 0.2335, d_k_M range: [0.0216, 0.3302], d_k_M_hat range: [0.6070, 0.8979]
2025-03-11 20:18:58 - Train Iteration 4011: loss: 0.4002, d_k_M range: [0.0426, 0.5224], d_k_M_hat range: [0.5539, 0.9831]
2025-03-11 20:18:59 - Train Iteration 4012: loss: 0.3874, d_k_M range: [0.0152, 0.4727], d_k_M_hat range: [0.3928, 0.9745]
2025-03-11 20:18:59 - Train Iteration 4013: loss: 0.2643, d_k_M range: [0.0014, 0.1514], d_k_M_hat range: [0.4923, 0.8779]
2025-03-11 20:19:00 - Train Iteration 4014: loss: 0.2155, d_k_M range: [0.0136, 0.3662], d_k_M_hat range: [0.5891, 0.9658]
2025-03-11 20:19:00 - Train Iteration 4015: loss: 0.3842, d_k_M range: [0.0410, 0.6134], d_k_M_hat range: [0.6202, 0.9936]
2025-03-11 20:19:01 - Train Iteration 4016: loss: 0.2256, d_k_M range: [0.0089, 0.3088], d_k_M_hat range: [0.5388, 0.9457]
2025-03-11 20:19:01 - Train Iteration 4017: loss: 0.4098, d_k_M range: [0.0047, 0.5470], d_k_M_hat range: [0.5070, 0.9937]
2025-03-11 20:19:01 - Train Iteration 4018: loss: 0.3342, d_k_M range: [0.0604, 0.4979], d_k_M_hat range: [0.6329, 0.9966]
2025-03-11 20:19:02 - Train Iteration 4019: loss: 0.6874, d_k_M range: [0.0000, 0.1207], d_k_M_hat range: [0.1709, 0.8022]
2025-03-11 20:19:02 - Train Iteration 4020: loss: 0.8320, d_k_M range: [0.0192, 0.9090], d_k_M_hat range: [0.5553, 0.9969]
2025-03-11 20:19:03 - Train Iteration 4021: loss: 0.2905, d_k_M range: [0.0271, 0.5287], d_k_M_hat range: [0.4913, 0.9912]
2025-03-11 20:19:03 - Train Iteration 4022: loss: 0.3750, d_k_M range: [0.0013, 0.3591], d_k_M_hat range: [0.3910, 0.9203]
2025-03-11 20:19:04 - Train Iteration 4023: loss: 0.6042, d_k_M range: [0.1492, 0.7719], d_k_M_hat range: [0.8362, 0.9973]
2025-03-11 20:19:04 - Train Iteration 4024: loss: 0.4783, d_k_M range: [0.0004, 0.1689], d_k_M_hat range: [0.3088, 0.8914]
2025-03-11 20:19:05 - Train Iteration 4025: loss: 0.3383, d_k_M range: [0.0015, 0.4759], d_k_M_hat range: [0.4979, 0.9470]
2025-03-11 20:19:05 - Train Iteration 4026: loss: 0.3171, d_k_M range: [0.0017, 0.2049], d_k_M_hat range: [0.4605, 0.9020]
2025-03-11 20:19:05 - Train Iteration 4027: loss: 0.4833, d_k_M range: [0.0470, 0.6897], d_k_M_hat range: [0.5948, 0.9945]
2025-03-11 20:19:06 - Train Iteration 4028: loss: 0.8929, d_k_M range: [0.0000, 0.0519], d_k_M_hat range: [0.0550, 0.6868]
2025-03-11 20:19:06 - Train Iteration 4029: loss: 0.3424, d_k_M range: [0.1221, 0.5731], d_k_M_hat range: [0.7054, 0.9963]
2025-03-11 20:19:07 - Train Iteration 4030: loss: 0.3672, d_k_M range: [0.2134, 0.6012], d_k_M_hat range: [0.7786, 0.9953]
2025-03-11 20:19:07 - Train Iteration 4031: loss: 0.3050, d_k_M range: [0.0032, 0.5006], d_k_M_hat range: [0.4673, 0.9705]
2025-03-11 20:19:07 - Train Iteration 4032: loss: 0.3526, d_k_M range: [0.0026, 0.2823], d_k_M_hat range: [0.4579, 0.7633]
2025-03-11 20:19:08 - Train Iteration 4033: loss: 0.2967, d_k_M range: [0.0121, 0.4465], d_k_M_hat range: [0.5800, 0.9262]
2025-03-11 20:19:08 - Train Iteration 4034: loss: 0.2328, d_k_M range: [0.0246, 0.3996], d_k_M_hat range: [0.6232, 0.9704]
2025-03-11 20:19:09 - Train Iteration 4035: loss: 0.4159, d_k_M range: [0.1486, 0.6369], d_k_M_hat range: [0.6035, 0.9920]
2025-03-11 20:19:09 - Train Iteration 4036: loss: 0.4521, d_k_M range: [0.0018, 0.3198], d_k_M_hat range: [0.3294, 0.8360]
2025-03-11 20:19:10 - Train Iteration 4037: loss: 0.3203, d_k_M range: [0.0012, 0.4921], d_k_M_hat range: [0.5063, 0.9833]
2025-03-11 20:19:10 - Train Iteration 4038: loss: 0.3176, d_k_M range: [0.1037, 0.4527], d_k_M_hat range: [0.6351, 0.9685]
2025-03-11 20:19:10 - Train Iteration 4039: loss: 0.4286, d_k_M range: [0.0046, 0.3468], d_k_M_hat range: [0.3499, 0.8417]
2025-03-11 20:19:11 - Train Iteration 4040: loss: 0.2751, d_k_M range: [0.1970, 0.4937], d_k_M_hat range: [0.8055, 0.9761]
2025-03-11 20:19:11 - Train Iteration 4041: loss: 0.2941, d_k_M range: [0.0040, 0.3031], d_k_M_hat range: [0.4695, 0.8535]
2025-03-11 20:19:12 - Train Iteration 4042: loss: 0.2769, d_k_M range: [0.0132, 0.4570], d_k_M_hat range: [0.5315, 0.9537]
2025-03-11 20:19:12 - Train Iteration 4043: loss: 0.2979, d_k_M range: [0.0048, 0.2281], d_k_M_hat range: [0.4590, 0.8897]
2025-03-11 20:19:13 - Train Iteration 4044: loss: 0.4889, d_k_M range: [0.0177, 0.6982], d_k_M_hat range: [0.5784, 0.9990]
2025-03-11 20:19:13 - Train Iteration 4045: loss: 0.3406, d_k_M range: [0.0115, 0.3855], d_k_M_hat range: [0.5105, 0.8709]
2025-03-11 20:19:14 - Train Iteration 4046: loss: 0.3431, d_k_M range: [0.0284, 0.4339], d_k_M_hat range: [0.4426, 0.9599]
2025-03-11 20:19:14 - Train Iteration 4047: loss: 0.3315, d_k_M range: [0.0154, 0.4289], d_k_M_hat range: [0.4969, 0.9409]
2025-03-11 20:19:15 - Train Iteration 4048: loss: 0.2791, d_k_M range: [0.0061, 0.4728], d_k_M_hat range: [0.5216, 0.9502]
2025-03-11 20:19:15 - Train Iteration 4049: loss: 0.3228, d_k_M range: [0.0051, 0.5477], d_k_M_hat range: [0.5297, 0.9795]
2025-03-11 20:19:15 - Train Iteration 4050: loss: 0.3417, d_k_M range: [0.0168, 0.4369], d_k_M_hat range: [0.4578, 0.9461]
2025-03-11 20:19:16 - Train Iteration 4051: loss: 0.4297, d_k_M range: [0.0143, 0.6450], d_k_M_hat range: [0.5170, 0.9896]
2025-03-11 20:19:16 - Train Iteration 4052: loss: 0.2446, d_k_M range: [0.0436, 0.4321], d_k_M_hat range: [0.6576, 0.9632]
2025-03-11 20:19:17 - Train Iteration 4053: loss: 0.2944, d_k_M range: [0.0050, 0.4082], d_k_M_hat range: [0.4887, 0.9441]
2025-03-11 20:19:17 - Train Iteration 4054: loss: 0.3352, d_k_M range: [0.0030, 0.5328], d_k_M_hat range: [0.4240, 0.9847]
2025-03-11 20:19:18 - Train Iteration 4055: loss: 0.3161, d_k_M range: [0.0281, 0.5470], d_k_M_hat range: [0.5371, 0.9894]
2025-03-11 20:19:18 - Train Iteration 4056: loss: 0.5067, d_k_M range: [0.0043, 0.4107], d_k_M_hat range: [0.2952, 0.9448]
2025-03-11 20:19:19 - Train Iteration 4057: loss: 0.4485, d_k_M range: [0.2134, 0.6638], d_k_M_hat range: [0.6427, 0.9941]
2025-03-11 20:19:19 - Train Iteration 4058: loss: 0.2541, d_k_M range: [0.0088, 0.3901], d_k_M_hat range: [0.5320, 0.9569]
2025-03-11 20:19:20 - Train Iteration 4059: loss: 0.3042, d_k_M range: [0.0016, 0.4181], d_k_M_hat range: [0.5277, 0.8869]
2025-03-11 20:19:20 - Train Iteration 4060: loss: 0.9838, d_k_M range: [0.0003, 0.2772], d_k_M_hat range: [0.0085, 0.8543]
2025-03-11 20:19:21 - Train Iteration 4061: loss: 0.2253, d_k_M range: [0.0257, 0.4063], d_k_M_hat range: [0.5698, 0.9316]
2025-03-11 20:19:21 - Train Iteration 4062: loss: 0.2527, d_k_M range: [0.0351, 0.5000], d_k_M_hat range: [0.7024, 0.9973]
2025-03-11 20:19:22 - Train Iteration 4063: loss: 0.2870, d_k_M range: [0.0128, 0.4103], d_k_M_hat range: [0.4771, 0.9342]
2025-03-11 20:19:22 - Train Iteration 4064: loss: 0.2623, d_k_M range: [0.0059, 0.3720], d_k_M_hat range: [0.4952, 0.9872]
2025-03-11 20:19:23 - Train Iteration 4065: loss: 0.3111, d_k_M range: [0.0137, 0.5385], d_k_M_hat range: [0.7061, 0.9807]
2025-03-11 20:19:23 - Train Iteration 4066: loss: 0.8951, d_k_M range: [0.0131, 0.9453], d_k_M_hat range: [0.6820, 0.9993]
2025-03-11 20:19:23 - Train Iteration 4067: loss: 0.2634, d_k_M range: [0.0115, 0.3811], d_k_M_hat range: [0.7017, 0.9600]
2025-03-11 20:19:24 - Train Iteration 4068: loss: 0.2564, d_k_M range: [0.0027, 0.3676], d_k_M_hat range: [0.5247, 0.9271]
2025-03-11 20:19:24 - Train Iteration 4069: loss: 0.3088, d_k_M range: [0.0653, 0.4170], d_k_M_hat range: [0.5147, 0.9404]
2025-03-11 20:19:25 - Train Iteration 4070: loss: 0.4055, d_k_M range: [0.0034, 0.3738], d_k_M_hat range: [0.3667, 0.9260]
2025-03-11 20:19:25 - Train Iteration 4071: loss: 0.3234, d_k_M range: [0.0083, 0.4716], d_k_M_hat range: [0.4560, 0.9290]
2025-03-11 20:19:26 - Train Iteration 4072: loss: 0.3690, d_k_M range: [0.0009, 0.4376], d_k_M_hat range: [0.3934, 0.9564]
2025-03-11 20:19:26 - Train Iteration 4073: loss: 0.3596, d_k_M range: [0.0384, 0.5878], d_k_M_hat range: [0.6357, 0.9881]
2025-03-11 20:19:27 - Train Iteration 4074: loss: 0.4349, d_k_M range: [0.0002, 0.4770], d_k_M_hat range: [0.3407, 0.9493]
2025-03-11 20:19:27 - Train Iteration 4075: loss: 0.4854, d_k_M range: [0.0034, 0.6873], d_k_M_hat range: [0.5277, 0.9905]
2025-03-11 20:19:28 - Train Iteration 4076: loss: 0.4130, d_k_M range: [0.0061, 0.4890], d_k_M_hat range: [0.3635, 0.9575]
2025-03-11 20:19:28 - Train Iteration 4077: loss: 0.3634, d_k_M range: [0.0015, 0.5825], d_k_M_hat range: [0.3987, 0.9887]
2025-03-11 20:19:29 - Train Iteration 4078: loss: 0.4876, d_k_M range: [0.0002, 0.3595], d_k_M_hat range: [0.3019, 0.9322]
2025-03-11 20:19:29 - Train Iteration 4079: loss: 0.2775, d_k_M range: [0.0078, 0.4096], d_k_M_hat range: [0.4918, 0.9436]
2025-03-11 20:19:30 - Train Iteration 4080: loss: 0.3208, d_k_M range: [0.1073, 0.5623], d_k_M_hat range: [0.6837, 0.9959]
2025-03-11 20:19:30 - Train Iteration 4081: loss: 0.2455, d_k_M range: [0.0328, 0.4071], d_k_M_hat range: [0.5373, 0.9257]
2025-03-11 20:19:30 - Train Iteration 4082: loss: 0.4409, d_k_M range: [0.0741, 0.4496], d_k_M_hat range: [0.6934, 0.9828]
2025-03-11 20:19:31 - Train Iteration 4083: loss: 0.3498, d_k_M range: [0.0375, 0.4601], d_k_M_hat range: [0.4497, 0.9782]
2025-03-11 20:19:31 - Train Iteration 4084: loss: 0.3488, d_k_M range: [0.0011, 0.3491], d_k_M_hat range: [0.4105, 0.9338]
2025-03-11 20:19:32 - Train Iteration 4085: loss: 0.3510, d_k_M range: [0.0107, 0.5716], d_k_M_hat range: [0.5940, 0.9872]
2025-03-11 20:19:32 - Train Iteration 4086: loss: 0.4308, d_k_M range: [0.0010, 0.6486], d_k_M_hat range: [0.4194, 0.9922]
2025-03-11 20:19:33 - Train Iteration 4087: loss: 0.3791, d_k_M range: [0.0036, 0.3745], d_k_M_hat range: [0.3879, 0.9657]
2025-03-11 20:19:33 - Train Iteration 4088: loss: 0.2600, d_k_M range: [0.0074, 0.4353], d_k_M_hat range: [0.5694, 0.9533]
2025-03-11 20:19:33 - Train Iteration 4089: loss: 0.3650, d_k_M range: [0.0009, 0.0576], d_k_M_hat range: [0.3967, 0.5812]
2025-03-11 20:19:34 - Train Iteration 4090: loss: 0.4010, d_k_M range: [0.0430, 0.3746], d_k_M_hat range: [0.5742, 0.9772]
2025-03-11 20:19:34 - Train Iteration 4091: loss: 0.3606, d_k_M range: [0.0019, 0.3798], d_k_M_hat range: [0.4014, 0.9760]
2025-03-11 20:19:35 - Train Iteration 4092: loss: 0.2929, d_k_M range: [0.0139, 0.5019], d_k_M_hat range: [0.5826, 0.9836]
2025-03-11 20:19:35 - Train Iteration 4093: loss: 0.2284, d_k_M range: [0.0073, 0.4063], d_k_M_hat range: [0.5294, 0.9613]
2025-03-11 20:19:36 - Train Iteration 4094: loss: 0.4321, d_k_M range: [0.1178, 0.6502], d_k_M_hat range: [0.7268, 0.9928]
2025-03-11 20:19:36 - Train Iteration 4095: loss: 0.3366, d_k_M range: [0.0105, 0.4031], d_k_M_hat range: [0.4495, 0.9558]
2025-03-11 20:19:37 - Train Iteration 4096: loss: 0.2871, d_k_M range: [0.2711, 0.4962], d_k_M_hat range: [0.8310, 0.9944]
2025-03-11 20:19:37 - Train Iteration 4097: loss: 0.2772, d_k_M range: [0.0232, 0.5117], d_k_M_hat range: [0.6245, 0.9937]
2025-03-11 20:19:38 - Train Iteration 4098: loss: 0.2099, d_k_M range: [0.0065, 0.4517], d_k_M_hat range: [0.5767, 0.9936]
2025-03-11 20:19:38 - Train Iteration 4099: loss: 0.7838, d_k_M range: [0.0002, 0.4609], d_k_M_hat range: [0.1157, 0.9507]
2025-03-11 20:19:39 - Train Iteration 4100: loss: 0.2762, d_k_M range: [0.0101, 0.5213], d_k_M_hat range: [0.6033, 0.9958]
2025-03-11 20:19:39 - Train Iteration 4101: loss: 0.2794, d_k_M range: [0.0083, 0.5069], d_k_M_hat range: [0.5262, 0.9783]
2025-03-11 20:19:40 - Train Iteration 4102: loss: 0.2818, d_k_M range: [0.0059, 0.4888], d_k_M_hat range: [0.5269, 0.9580]
2025-03-11 20:19:40 - Train Iteration 4103: loss: 0.4151, d_k_M range: [0.0008, 0.6184], d_k_M_hat range: [0.4077, 0.9742]
2025-03-11 20:19:40 - Train Iteration 4104: loss: 0.7875, d_k_M range: [0.0007, 0.1325], d_k_M_hat range: [0.1152, 0.8198]
2025-03-11 20:19:41 - Train Iteration 4105: loss: 0.5691, d_k_M range: [0.0049, 0.7415], d_k_M_hat range: [0.5684, 0.9871]
2025-03-11 20:19:41 - Train Iteration 4106: loss: 0.3387, d_k_M range: [0.0024, 0.1931], d_k_M_hat range: [0.4204, 0.8429]
2025-03-11 20:19:42 - Train Iteration 4107: loss: 0.2184, d_k_M range: [0.0253, 0.3680], d_k_M_hat range: [0.5743, 0.9227]
2025-03-11 20:19:42 - Train Iteration 4108: loss: 0.2686, d_k_M range: [0.0020, 0.3341], d_k_M_hat range: [0.4837, 0.8422]
2025-03-11 20:19:43 - Train Iteration 4109: loss: 0.3029, d_k_M range: [0.0011, 0.4729], d_k_M_hat range: [0.4900, 0.9225]
2025-03-11 20:19:43 - Train Iteration 4110: loss: 0.3367, d_k_M range: [0.0124, 0.3985], d_k_M_hat range: [0.5381, 0.9309]
2025-03-11 20:19:44 - Train Iteration 4111: loss: 0.3265, d_k_M range: [0.0097, 0.3908], d_k_M_hat range: [0.5334, 0.8257]
2025-03-11 20:19:44 - Train Iteration 4112: loss: 0.2560, d_k_M range: [0.0119, 0.4487], d_k_M_hat range: [0.5060, 0.9573]
2025-03-11 20:19:45 - Train Iteration 4113: loss: 0.3596, d_k_M range: [0.0084, 0.5764], d_k_M_hat range: [0.5295, 0.9767]
2025-03-11 20:19:45 - Train Iteration 4114: loss: 0.2715, d_k_M range: [0.0058, 0.2518], d_k_M_hat range: [0.5093, 0.7307]
2025-03-11 20:19:46 - Train Iteration 4115: loss: 0.3063, d_k_M range: [0.0016, 0.4841], d_k_M_hat range: [0.4482, 0.9958]
2025-03-11 20:19:46 - Train Iteration 4116: loss: 0.5218, d_k_M range: [0.0328, 0.7146], d_k_M_hat range: [0.7083, 0.9972]
2025-03-11 20:19:47 - Train Iteration 4117: loss: 0.2685, d_k_M range: [0.0055, 0.4692], d_k_M_hat range: [0.5230, 0.9894]
2025-03-11 20:19:47 - Train Iteration 4118: loss: 0.3502, d_k_M range: [0.0149, 0.4940], d_k_M_hat range: [0.5606, 0.9217]
2025-03-11 20:19:48 - Train Iteration 4119: loss: 0.3383, d_k_M range: [0.0043, 0.5214], d_k_M_hat range: [0.4764, 0.9746]
2025-03-11 20:19:48 - Train Iteration 4120: loss: 0.3133, d_k_M range: [0.0470, 0.5427], d_k_M_hat range: [0.6864, 0.9929]
2025-03-11 20:19:48 - Train Iteration 4121: loss: 0.6366, d_k_M range: [0.0090, 0.7862], d_k_M_hat range: [0.5642, 0.9883]
2025-03-11 20:19:49 - Train Iteration 4122: loss: 0.4981, d_k_M range: [0.0003, 0.1295], d_k_M_hat range: [0.2945, 0.6008]
2025-03-11 20:19:49 - Train Iteration 4123: loss: 0.5647, d_k_M range: [0.1455, 0.7501], d_k_M_hat range: [0.7975, 0.9987]
2025-03-11 20:19:50 - Train Iteration 4124: loss: 0.2791, d_k_M range: [0.0077, 0.4313], d_k_M_hat range: [0.4794, 0.9799]
2025-03-11 20:19:50 - Train Iteration 4125: loss: 0.3282, d_k_M range: [0.0054, 0.4485], d_k_M_hat range: [0.4797, 0.9770]
2025-03-11 20:19:51 - Train Iteration 4126: loss: 0.3108, d_k_M range: [0.0069, 0.4265], d_k_M_hat range: [0.4893, 0.9626]
2025-03-11 20:19:51 - Train Iteration 4127: loss: 0.4691, d_k_M range: [0.0018, 0.6788], d_k_M_hat range: [0.4520, 0.9939]
2025-03-11 20:19:52 - Train Iteration 4128: loss: 0.3252, d_k_M range: [0.0004, 0.3500], d_k_M_hat range: [0.4301, 0.9388]
2025-03-11 20:19:52 - Train Iteration 4129: loss: 0.3440, d_k_M range: [0.0233, 0.5528], d_k_M_hat range: [0.4810, 0.9901]
2025-03-11 20:19:52 - Train Iteration 4130: loss: 0.2901, d_k_M range: [0.2724, 0.4947], d_k_M_hat range: [0.8542, 0.9846]
2025-03-11 20:19:53 - Train Iteration 4131: loss: 0.4976, d_k_M range: [0.0001, 0.2532], d_k_M_hat range: [0.2947, 0.9052]
2025-03-11 20:19:53 - Train Iteration 4132: loss: 0.7831, d_k_M range: [0.0623, 0.8832], d_k_M_hat range: [0.6848, 0.9982]
2025-03-11 20:19:54 - Train Iteration 4133: loss: 0.3476, d_k_M range: [0.0148, 0.4940], d_k_M_hat range: [0.5491, 0.9689]
2025-03-11 20:19:54 - Train Iteration 4134: loss: 0.2986, d_k_M range: [0.0025, 0.4965], d_k_M_hat range: [0.4778, 0.9651]
2025-03-11 20:19:55 - Train Iteration 4135: loss: 0.4342, d_k_M range: [0.0490, 0.6576], d_k_M_hat range: [0.5921, 0.9987]
2025-03-11 20:19:55 - Train Iteration 4136: loss: 0.3668, d_k_M range: [0.0014, 0.4621], d_k_M_hat range: [0.3958, 0.9785]
2025-03-11 20:19:56 - Train Iteration 4137: loss: 0.2400, d_k_M range: [0.0126, 0.3685], d_k_M_hat range: [0.5269, 0.9527]
2025-03-11 20:19:56 - Train Iteration 4138: loss: 0.4624, d_k_M range: [0.0956, 0.6718], d_k_M_hat range: [0.6463, 0.9964]
2025-03-11 20:19:57 - Train Iteration 4139: loss: 0.3327, d_k_M range: [0.0038, 0.4108], d_k_M_hat range: [0.4270, 0.9570]
2025-03-11 20:19:57 - Train Iteration 4140: loss: 0.2943, d_k_M range: [0.0514, 0.4907], d_k_M_hat range: [0.5701, 0.9888]
2025-03-11 20:19:57 - Train Iteration 4141: loss: 0.4440, d_k_M range: [0.1940, 0.5569], d_k_M_hat range: [0.6707, 0.9839]
2025-03-11 20:19:58 - Train Iteration 4142: loss: 0.3118, d_k_M range: [0.0236, 0.5429], d_k_M_hat range: [0.5025, 0.9845]
2025-03-11 20:19:58 - Train Iteration 4143: loss: 0.3181, d_k_M range: [0.0013, 0.4657], d_k_M_hat range: [0.4373, 0.9687]
2025-03-11 20:19:59 - Train Iteration 4144: loss: 0.4715, d_k_M range: [0.0089, 0.6809], d_k_M_hat range: [0.5498, 0.9942]
2025-03-11 20:19:59 - Train Iteration 4145: loss: 0.3215, d_k_M range: [0.0152, 0.5620], d_k_M_hat range: [0.5147, 0.9950]
2025-03-11 20:20:00 - Train Iteration 4146: loss: 0.7584, d_k_M range: [0.0009, 0.5182], d_k_M_hat range: [0.1304, 0.9648]
2025-03-11 20:20:00 - Train Iteration 4147: loss: 0.2307, d_k_M range: [0.0275, 0.3903], d_k_M_hat range: [0.5976, 0.9635]
2025-03-11 20:20:01 - Train Iteration 4148: loss: 0.2732, d_k_M range: [0.0173, 0.4625], d_k_M_hat range: [0.5327, 0.9676]
2025-03-11 20:20:01 - Train Iteration 4149: loss: 0.5753, d_k_M range: [0.0353, 0.7519], d_k_M_hat range: [0.5909, 0.9935]
2025-03-11 20:20:01 - Train Iteration 4150: loss: 0.3237, d_k_M range: [0.0017, 0.2970], d_k_M_hat range: [0.4328, 0.8390]
2025-03-11 20:20:02 - Train Iteration 4151: loss: 0.3100, d_k_M range: [0.0329, 0.5429], d_k_M_hat range: [0.6053, 0.9861]
2025-03-11 20:20:02 - Train Iteration 4152: loss: 0.2894, d_k_M range: [0.0037, 0.4038], d_k_M_hat range: [0.4819, 0.9493]
2025-03-11 20:20:03 - Train Iteration 4153: loss: 0.3224, d_k_M range: [0.0021, 0.4952], d_k_M_hat range: [0.4343, 0.9809]
2025-03-11 20:20:03 - Train Iteration 4154: loss: 0.4011, d_k_M range: [0.0035, 0.5116], d_k_M_hat range: [0.3702, 0.9958]
2025-03-11 20:20:04 - Train Iteration 4155: loss: 0.2231, d_k_M range: [0.0166, 0.4487], d_k_M_hat range: [0.7049, 0.9764]
2025-03-11 20:20:04 - Train Iteration 4156: loss: 0.3063, d_k_M range: [0.0075, 0.3538], d_k_M_hat range: [0.4633, 0.8965]
2025-03-11 20:20:05 - Train Iteration 4157: loss: 0.3462, d_k_M range: [0.0079, 0.5128], d_k_M_hat range: [0.4372, 0.9869]
2025-03-11 20:20:05 - Train Iteration 4158: loss: 0.2019, d_k_M range: [0.0109, 0.3970], d_k_M_hat range: [0.5877, 0.9476]
2025-03-11 20:20:06 - Train Iteration 4159: loss: 0.2496, d_k_M range: [0.0111, 0.4019], d_k_M_hat range: [0.6003, 0.9867]
2025-03-11 20:20:06 - Train Iteration 4160: loss: 0.2372, d_k_M range: [0.0115, 0.2308], d_k_M_hat range: [0.5529, 0.8863]
2025-03-11 20:20:07 - Train Iteration 4161: loss: 0.4263, d_k_M range: [0.0577, 0.6509], d_k_M_hat range: [0.7517, 0.9980]
2025-03-11 20:20:07 - Train Iteration 4162: loss: 0.2681, d_k_M range: [0.0103, 0.4725], d_k_M_hat range: [0.5110, 0.9627]
2025-03-11 20:20:08 - Train Iteration 4163: loss: 0.2192, d_k_M range: [0.0134, 0.4044], d_k_M_hat range: [0.5749, 0.9780]
2025-03-11 20:20:08 - Train Iteration 4164: loss: 0.2749, d_k_M range: [0.0623, 0.4862], d_k_M_hat range: [0.5379, 0.9830]
2025-03-11 20:20:09 - Train Iteration 4165: loss: 0.4116, d_k_M range: [0.0372, 0.5227], d_k_M_hat range: [0.5653, 0.9842]
2025-03-11 20:20:09 - Train Iteration 4166: loss: 0.3341, d_k_M range: [0.0032, 0.3367], d_k_M_hat range: [0.4253, 0.8525]
2025-03-11 20:20:10 - Train Iteration 4167: loss: 0.5318, d_k_M range: [0.0993, 0.7006], d_k_M_hat range: [0.6962, 0.9865]
2025-03-11 20:20:10 - Train Iteration 4168: loss: 0.5131, d_k_M range: [0.0029, 0.5399], d_k_M_hat range: [0.2866, 0.9901]
2025-03-11 20:20:11 - Train Iteration 4169: loss: 0.2783, d_k_M range: [0.0025, 0.4986], d_k_M_hat range: [0.4749, 0.9828]
2025-03-11 20:20:11 - Train Iteration 4170: loss: 0.8378, d_k_M range: [0.0025, 0.9138], d_k_M_hat range: [0.5135, 0.9985]
2025-03-11 20:20:12 - Train Iteration 4171: loss: 0.2594, d_k_M range: [0.0004, 0.4416], d_k_M_hat range: [0.4945, 0.9710]
2025-03-11 20:20:12 - Train Iteration 4172: loss: 0.2107, d_k_M range: [0.0780, 0.3758], d_k_M_hat range: [0.7332, 0.9467]
2025-03-11 20:20:13 - Train Iteration 4173: loss: 0.3005, d_k_M range: [0.0016, 0.4401], d_k_M_hat range: [0.4674, 0.9749]
2025-03-11 20:20:13 - Train Iteration 4174: loss: 0.3950, d_k_M range: [0.0051, 0.5709], d_k_M_hat range: [0.5337, 0.9901]
2025-03-11 20:20:13 - Train Iteration 4175: loss: 0.3765, d_k_M range: [0.0112, 0.6112], d_k_M_hat range: [0.5853, 0.9976]
2025-03-11 20:20:14 - Train Iteration 4176: loss: 0.3913, d_k_M range: [0.0015, 0.3132], d_k_M_hat range: [0.3759, 0.8867]
2025-03-11 20:20:14 - Train Iteration 4177: loss: 0.9009, d_k_M range: [0.0005, 0.4344], d_k_M_hat range: [0.0514, 0.9716]
2025-03-11 20:20:15 - Train Iteration 4178: loss: 0.3521, d_k_M range: [0.0905, 0.5830], d_k_M_hat range: [0.8338, 0.9951]
2025-03-11 20:20:15 - Train Iteration 4179: loss: 0.3020, d_k_M range: [0.1069, 0.5335], d_k_M_hat range: [0.7106, 0.9840]
2025-03-11 20:20:16 - Train Iteration 4180: loss: 0.7010, d_k_M range: [0.0669, 0.7807], d_k_M_hat range: [0.5759, 0.9478]
2025-03-11 20:20:16 - Train Iteration 4181: loss: 0.3220, d_k_M range: [0.0039, 0.5423], d_k_M_hat range: [0.5101, 0.9749]
2025-03-11 20:20:16 - Train Iteration 4182: loss: 0.3919, d_k_M range: [0.0018, 0.4940], d_k_M_hat range: [0.4431, 0.9711]
2025-03-11 20:20:17 - Train Iteration 4183: loss: 0.3060, d_k_M range: [0.0091, 0.5050], d_k_M_hat range: [0.5450, 0.9519]
2025-03-11 20:20:17 - Train Iteration 4184: loss: 0.2746, d_k_M range: [0.0198, 0.3582], d_k_M_hat range: [0.5792, 0.8787]
2025-03-11 20:20:18 - Train Iteration 4185: loss: 0.4281, d_k_M range: [0.0014, 0.3609], d_k_M_hat range: [0.3471, 0.8713]
2025-03-11 20:20:18 - Train Iteration 4186: loss: 0.7541, d_k_M range: [0.0005, 0.8643], d_k_M_hat range: [0.4253, 0.9959]
2025-03-11 20:20:19 - Train Iteration 4187: loss: 0.3331, d_k_M range: [0.0033, 0.5414], d_k_M_hat range: [0.4368, 0.9642]
2025-03-11 20:20:19 - Train Iteration 4188: loss: 0.2239, d_k_M range: [0.0018, 0.3926], d_k_M_hat range: [0.5285, 0.9626]
2025-03-11 20:20:20 - Train Iteration 4189: loss: 0.7830, d_k_M range: [0.0072, 0.8834], d_k_M_hat range: [0.3879, 0.9985]
2025-03-11 20:20:20 - Train Iteration 4190: loss: 0.4539, d_k_M range: [0.0002, 0.3841], d_k_M_hat range: [0.3265, 0.8938]
2025-03-11 20:20:21 - Train Iteration 4191: loss: 0.2868, d_k_M range: [0.0182, 0.4742], d_k_M_hat range: [0.4827, 0.9664]
2025-03-11 20:20:21 - Train Iteration 4192: loss: 0.3032, d_k_M range: [0.0031, 0.3793], d_k_M_hat range: [0.4525, 0.9453]
2025-03-11 20:20:21 - Train Iteration 4193: loss: 0.2648, d_k_M range: [0.0023, 0.3802], d_k_M_hat range: [0.4947, 0.9183]
2025-03-11 20:20:22 - Train Iteration 4194: loss: 0.3316, d_k_M range: [0.0139, 0.5541], d_k_M_hat range: [0.4675, 0.9782]
2025-03-11 20:20:22 - Train Iteration 4195: loss: 0.3424, d_k_M range: [0.0018, 0.4486], d_k_M_hat range: [0.4617, 0.9707]
2025-03-11 20:20:23 - Train Iteration 4196: loss: 0.3038, d_k_M range: [0.0047, 0.2759], d_k_M_hat range: [0.5192, 0.7968]
2025-03-11 20:20:23 - Train Iteration 4197: loss: 0.5473, d_k_M range: [0.0015, 0.5135], d_k_M_hat range: [0.2617, 0.9933]
2025-03-11 20:20:24 - Train Iteration 4198: loss: 0.3514, d_k_M range: [0.0024, 0.5790], d_k_M_hat range: [0.4625, 0.9915]
2025-03-11 20:20:24 - Train Iteration 4199: loss: 0.9130, d_k_M range: [0.0031, 0.9549], d_k_M_hat range: [0.4557, 0.9994]
2025-03-11 20:20:24 - Train Iteration 4200: loss: 0.2935, d_k_M range: [0.0084, 0.3650], d_k_M_hat range: [0.4776, 0.8621]
2025-03-11 20:20:25 - Train Iteration 4201: loss: 0.3062, d_k_M range: [0.2263, 0.5484], d_k_M_hat range: [0.6777, 0.9959]
2025-03-11 20:20:25 - Train Iteration 4202: loss: 0.8901, d_k_M range: [0.0015, 0.9426], d_k_M_hat range: [0.3970, 0.9992]
2025-03-11 20:20:26 - Train Iteration 4203: loss: 0.2497, d_k_M range: [0.0191, 0.4275], d_k_M_hat range: [0.5676, 0.9796]
2025-03-11 20:20:26 - Train Iteration 4204: loss: 0.3267, d_k_M range: [0.0089, 0.4906], d_k_M_hat range: [0.4616, 0.9624]
2025-03-11 20:20:27 - Train Iteration 4205: loss: 0.2986, d_k_M range: [0.0025, 0.1951], d_k_M_hat range: [0.4676, 0.8088]
2025-03-11 20:20:27 - Train Iteration 4206: loss: 0.4271, d_k_M range: [0.0640, 0.6515], d_k_M_hat range: [0.7307, 0.9980]
2025-03-11 20:20:28 - Train Iteration 4207: loss: 0.4046, d_k_M range: [0.0003, 0.4154], d_k_M_hat range: [0.3642, 0.8872]
2025-03-11 20:20:28 - Train Iteration 4208: loss: 0.3848, d_k_M range: [0.0347, 0.6058], d_k_M_hat range: [0.6216, 0.9855]
2025-03-11 20:20:29 - Train Iteration 4209: loss: 0.2925, d_k_M range: [0.1748, 0.4803], d_k_M_hat range: [0.6450, 0.9718]
2025-03-11 20:20:29 - Train Iteration 4210: loss: 0.2639, d_k_M range: [0.0069, 0.3634], d_k_M_hat range: [0.5294, 0.8763]
2025-03-11 20:20:30 - Train Iteration 4211: loss: 0.4961, d_k_M range: [0.0311, 0.3374], d_k_M_hat range: [0.4400, 0.9230]
2025-03-11 20:20:30 - Train Iteration 4212: loss: 0.2812, d_k_M range: [0.0117, 0.5234], d_k_M_hat range: [0.5365, 0.9931]
2025-03-11 20:20:31 - Train Iteration 4213: loss: 0.1844, d_k_M range: [0.0069, 0.3586], d_k_M_hat range: [0.6367, 0.9848]
2025-03-11 20:20:31 - Train Iteration 4214: loss: 0.3661, d_k_M range: [0.3921, 0.5942], d_k_M_hat range: [0.9645, 0.9935]
2025-03-11 20:20:32 - Train Iteration 4215: loss: 0.6269, d_k_M range: [0.0004, 0.4211], d_k_M_hat range: [0.2086, 0.9921]
2025-03-11 20:20:32 - Train Iteration 4216: loss: 0.4135, d_k_M range: [0.0708, 0.6300], d_k_M_hat range: [0.6905, 0.9927]
2025-03-11 20:20:32 - Train Iteration 4217: loss: 0.5239, d_k_M range: [0.0006, 0.5307], d_k_M_hat range: [0.2768, 0.9348]
2025-03-11 20:20:33 - Train Iteration 4218: loss: 0.8890, d_k_M range: [0.0392, 0.9410], d_k_M_hat range: [0.6634, 0.9981]
2025-03-11 20:20:33 - Train Iteration 4219: loss: 0.3652, d_k_M range: [0.0015, 0.4140], d_k_M_hat range: [0.4269, 0.9756]
2025-03-11 20:20:34 - Train Iteration 4220: loss: 0.3011, d_k_M range: [0.0062, 0.5230], d_k_M_hat range: [0.4575, 0.9821]
2025-03-11 20:20:34 - Train Iteration 4221: loss: 0.3585, d_k_M range: [0.0144, 0.5694], d_k_M_hat range: [0.5001, 0.9707]
2025-03-11 20:20:35 - Train Iteration 4222: loss: 0.4594, d_k_M range: [0.0072, 0.6550], d_k_M_hat range: [0.4399, 0.9773]
2025-03-11 20:20:35 - Train Iteration 4223: loss: 0.7414, d_k_M range: [0.0002, 0.1242], d_k_M_hat range: [0.1391, 0.7330]
2025-03-11 20:20:36 - Train Iteration 4224: loss: 0.4027, d_k_M range: [0.0127, 0.6273], d_k_M_hat range: [0.5415, 0.9951]
2025-03-11 20:20:36 - Train Iteration 4225: loss: 0.3439, d_k_M range: [0.0732, 0.3794], d_k_M_hat range: [0.5216, 0.9310]
2025-03-11 20:20:37 - Train Iteration 4226: loss: 0.4081, d_k_M range: [0.0013, 0.2037], d_k_M_hat range: [0.3625, 0.7605]
2025-03-11 20:20:37 - Train Iteration 4227: loss: 0.2733, d_k_M range: [0.0816, 0.3958], d_k_M_hat range: [0.6281, 0.9016]
2025-03-11 20:20:37 - Train Iteration 4228: loss: 0.2740, d_k_M range: [0.0116, 0.4913], d_k_M_hat range: [0.5350, 0.9679]
2025-03-11 20:20:38 - Train Iteration 4229: loss: 0.2811, d_k_M range: [0.0983, 0.5103], d_k_M_hat range: [0.6267, 0.9801]
2025-03-11 20:20:38 - Train Iteration 4230: loss: 0.3078, d_k_M range: [0.0009, 0.3126], d_k_M_hat range: [0.4484, 0.9321]
2025-03-11 20:20:39 - Train Iteration 4231: loss: 0.3208, d_k_M range: [0.0129, 0.5225], d_k_M_hat range: [0.4991, 0.9880]
2025-03-11 20:20:39 - Train Iteration 4232: loss: 0.2386, d_k_M range: [0.0103, 0.3550], d_k_M_hat range: [0.5498, 0.9129]
2025-03-11 20:20:40 - Train Iteration 4233: loss: 0.2935, d_k_M range: [0.0082, 0.4312], d_k_M_hat range: [0.5258, 0.9756]
2025-03-11 20:20:40 - Train Iteration 4234: loss: 0.3420, d_k_M range: [0.0027, 0.4662], d_k_M_hat range: [0.5649, 0.9704]
2025-03-11 20:20:41 - Train Iteration 4235: loss: 0.2538, d_k_M range: [0.0301, 0.3941], d_k_M_hat range: [0.5263, 0.9653]
2025-03-11 20:20:41 - Train Iteration 4236: loss: 0.4967, d_k_M range: [0.0024, 0.6778], d_k_M_hat range: [0.4332, 0.9757]
2025-03-11 20:20:41 - Train Iteration 4237: loss: 0.2603, d_k_M range: [0.0047, 0.4260], d_k_M_hat range: [0.5007, 0.9766]
2025-03-11 20:20:42 - Train Iteration 4238: loss: 0.3622, d_k_M range: [0.0019, 0.5112], d_k_M_hat range: [0.4000, 0.9894]
2025-03-11 20:20:42 - Train Iteration 4239: loss: 0.5645, d_k_M range: [0.0010, 0.3646], d_k_M_hat range: [0.2497, 0.9295]
2025-03-11 20:20:43 - Train Iteration 4240: loss: 0.3269, d_k_M range: [0.0064, 0.5417], d_k_M_hat range: [0.4347, 0.9896]
2025-03-11 20:20:43 - Train Iteration 4241: loss: 0.5599, d_k_M range: [0.0079, 0.3921], d_k_M_hat range: [0.2682, 0.9348]
2025-03-11 20:20:44 - Train Iteration 4242: loss: 0.2448, d_k_M range: [0.0024, 0.4066], d_k_M_hat range: [0.5911, 0.9587]
2025-03-11 20:20:44 - Train Iteration 4243: loss: 0.7168, d_k_M range: [0.0000, 0.0490], d_k_M_hat range: [0.1534, 0.5965]
2025-03-11 20:20:45 - Train Iteration 4244: loss: 0.5621, d_k_M range: [0.0019, 0.4524], d_k_M_hat range: [0.2522, 0.9730]
2025-03-11 20:20:45 - Train Iteration 4245: loss: 0.9685, d_k_M range: [0.1038, 0.9841], d_k_M_hat range: [0.6444, 1.0000]
2025-03-11 20:20:46 - Train Iteration 4246: loss: 0.4022, d_k_M range: [0.0012, 0.5417], d_k_M_hat range: [0.3670, 0.9746]
2025-03-11 20:20:46 - Train Iteration 4247: loss: 0.3704, d_k_M range: [0.0017, 0.5306], d_k_M_hat range: [0.4686, 0.9220]
2025-03-11 20:20:46 - Train Iteration 4248: loss: 0.2792, d_k_M range: [0.0009, 0.3061], d_k_M_hat range: [0.4921, 0.9286]
2025-03-11 20:20:47 - Train Iteration 4249: loss: 0.4184, d_k_M range: [0.0025, 0.3927], d_k_M_hat range: [0.3710, 0.8427]
2025-03-11 20:20:47 - Train Iteration 4250: loss: 0.3013, d_k_M range: [0.0425, 0.4107], d_k_M_hat range: [0.6250, 0.9550]
2025-03-11 20:20:48 - Train Iteration 4251: loss: 0.3259, d_k_M range: [0.0094, 0.4127], d_k_M_hat range: [0.4569, 0.9703]
2025-03-11 20:20:48 - Train Iteration 4252: loss: 0.3554, d_k_M range: [0.0869, 0.5754], d_k_M_hat range: [0.5929, 0.9935]
2025-03-11 20:20:49 - Train Iteration 4253: loss: 0.2971, d_k_M range: [0.0060, 0.5356], d_k_M_hat range: [0.4871, 0.9906]
2025-03-11 20:20:49 - Train Iteration 4254: loss: 0.2783, d_k_M range: [0.0060, 0.1451], d_k_M_hat range: [0.4784, 0.7195]
2025-03-11 20:20:49 - Train Iteration 4255: loss: 0.3412, d_k_M range: [0.0065, 0.3842], d_k_M_hat range: [0.4596, 0.9357]
2025-03-11 20:20:50 - Train Iteration 4256: loss: 0.5341, d_k_M range: [0.0018, 0.7236], d_k_M_hat range: [0.5130, 0.9928]
2025-03-11 20:20:50 - Train Iteration 4257: loss: 0.3591, d_k_M range: [0.0002, 0.3510], d_k_M_hat range: [0.4010, 0.8917]
2025-03-11 20:20:51 - Train Iteration 4258: loss: 0.5337, d_k_M range: [0.0034, 0.7265], d_k_M_hat range: [0.3918, 0.9960]
2025-03-11 20:20:51 - Train Iteration 4259: loss: 0.2833, d_k_M range: [0.0147, 0.5167], d_k_M_hat range: [0.5111, 0.9845]
2025-03-11 20:20:52 - Train Iteration 4260: loss: 0.3489, d_k_M range: [0.0078, 0.5885], d_k_M_hat range: [0.5159, 0.9978]
2025-03-11 20:20:52 - Train Iteration 4261: loss: 0.2509, d_k_M range: [0.0240, 0.3750], d_k_M_hat range: [0.5376, 0.9817]
2025-03-11 20:20:53 - Train Iteration 4262: loss: 0.4270, d_k_M range: [0.0039, 0.4482], d_k_M_hat range: [0.5126, 0.9844]
2025-03-11 20:20:53 - Train Iteration 4263: loss: 0.5921, d_k_M range: [0.0061, 0.4375], d_k_M_hat range: [0.2366, 0.9487]
2025-03-11 20:20:54 - Train Iteration 4264: loss: 0.3164, d_k_M range: [0.1485, 0.5506], d_k_M_hat range: [0.7141, 0.9981]
2025-03-11 20:20:54 - Train Iteration 4265: loss: 0.4298, d_k_M range: [0.0392, 0.6319], d_k_M_hat range: [0.6485, 0.9763]
2025-03-11 20:20:54 - Train Iteration 4266: loss: 0.7917, d_k_M range: [0.0005, 0.3034], d_k_M_hat range: [0.1110, 0.8309]
2025-03-11 20:20:55 - Train Iteration 4267: loss: 0.9110, d_k_M range: [0.1290, 0.9539], d_k_M_hat range: [0.7976, 0.9997]
2025-03-11 20:20:55 - Train Iteration 4268: loss: 0.4766, d_k_M range: [0.0429, 0.5875], d_k_M_hat range: [0.5646, 0.9832]
2025-03-11 20:20:56 - Train Iteration 4269: loss: 0.4396, d_k_M range: [0.0021, 0.0939], d_k_M_hat range: [0.3391, 0.6459]
2025-03-11 20:20:56 - Train Iteration 4270: loss: 0.2920, d_k_M range: [0.0142, 0.2770], d_k_M_hat range: [0.5024, 0.8994]
2025-03-11 20:20:57 - Train Iteration 4271: loss: 0.3585, d_k_M range: [0.0094, 0.4319], d_k_M_hat range: [0.4188, 0.9541]
2025-03-11 20:20:57 - Train Iteration 4272: loss: 0.4293, d_k_M range: [0.0242, 0.6373], d_k_M_hat range: [0.5969, 0.9867]
2025-03-11 20:20:58 - Train Iteration 4273: loss: 0.2684, d_k_M range: [0.0146, 0.3586], d_k_M_hat range: [0.4966, 0.8990]
2025-03-11 20:20:58 - Train Iteration 4274: loss: 0.7755, d_k_M range: [0.0210, 0.8801], d_k_M_hat range: [0.4752, 0.9995]
2025-03-11 20:20:59 - Train Iteration 4275: loss: 0.6384, d_k_M range: [0.0016, 0.4979], d_k_M_hat range: [0.2116, 0.9785]
2025-03-11 20:20:59 - Train Iteration 4276: loss: 0.3157, d_k_M range: [0.0971, 0.5280], d_k_M_hat range: [0.5652, 0.9953]
2025-03-11 20:20:59 - Train Iteration 4277: loss: 0.2552, d_k_M range: [0.0059, 0.3867], d_k_M_hat range: [0.5300, 0.8816]
2025-03-11 20:21:00 - Train Iteration 4278: loss: 0.2901, d_k_M range: [0.0175, 0.2809], d_k_M_hat range: [0.4793, 0.7982]
2025-03-11 20:21:00 - Train Iteration 4279: loss: 0.3722, d_k_M range: [0.0039, 0.4028], d_k_M_hat range: [0.4794, 0.9210]
2025-03-11 20:21:01 - Train Iteration 4280: loss: 0.2750, d_k_M range: [0.0369, 0.4583], d_k_M_hat range: [0.5125, 0.9356]
2025-03-11 20:21:01 - Train Iteration 4281: loss: 0.2977, d_k_M range: [0.0615, 0.5121], d_k_M_hat range: [0.7011, 0.9864]
2025-03-11 20:21:02 - Train Iteration 4282: loss: 0.2654, d_k_M range: [0.0010, 0.4553], d_k_M_hat range: [0.5550, 0.9672]
2025-03-11 20:21:02 - Train Iteration 4283: loss: 0.4083, d_k_M range: [0.0002, 0.6137], d_k_M_hat range: [0.4248, 0.9865]
2025-03-11 20:21:03 - Train Iteration 4284: loss: 0.3288, d_k_M range: [0.0011, 0.3767], d_k_M_hat range: [0.4322, 0.9061]
2025-03-11 20:21:03 - Train Iteration 4285: loss: 0.3502, d_k_M range: [0.0074, 0.5831], d_k_M_hat range: [0.4855, 0.9913]
2025-03-11 20:21:03 - Train Iteration 4286: loss: 0.2600, d_k_M range: [0.1413, 0.4996], d_k_M_hat range: [0.7408, 0.9897]
2025-03-11 20:21:04 - Train Iteration 4287: loss: 0.2814, d_k_M range: [0.0096, 0.3829], d_k_M_hat range: [0.5798, 0.9486]
2025-03-11 20:21:04 - Train Iteration 4288: loss: 0.2437, d_k_M range: [0.0210, 0.4350], d_k_M_hat range: [0.5658, 0.9739]
2025-03-11 20:21:05 - Train Iteration 4289: loss: 0.2994, d_k_M range: [0.0013, 0.0382], d_k_M_hat range: [0.4709, 0.7573]
2025-03-11 20:21:05 - Train Iteration 4290: loss: 0.4014, d_k_M range: [0.0295, 0.6227], d_k_M_hat range: [0.6866, 0.9965]
2025-03-11 20:21:06 - Train Iteration 4291: loss: 0.4908, d_k_M range: [0.0004, 0.3925], d_k_M_hat range: [0.3000, 0.9730]
2025-03-11 20:21:06 - Train Iteration 4292: loss: 0.3903, d_k_M range: [0.2243, 0.6082], d_k_M_hat range: [0.9087, 0.9893]
2025-03-11 20:21:07 - Train Iteration 4293: loss: 0.5183, d_k_M range: [0.0014, 0.4975], d_k_M_hat range: [0.2814, 0.9870]
2025-03-11 20:21:07 - Train Iteration 4294: loss: 0.2574, d_k_M range: [0.0117, 0.4252], d_k_M_hat range: [0.5214, 0.9571]
2025-03-11 20:21:08 - Train Iteration 4295: loss: 0.2493, d_k_M range: [0.0340, 0.3856], d_k_M_hat range: [0.5386, 0.9543]
2025-03-11 20:21:08 - Train Iteration 4296: loss: 0.5652, d_k_M range: [0.0018, 0.4515], d_k_M_hat range: [0.2544, 0.9800]
2025-03-11 20:21:08 - Train Iteration 4297: loss: 0.5077, d_k_M range: [0.3357, 0.7118], d_k_M_hat range: [0.8980, 0.9993]
2025-03-11 20:21:09 - Train Iteration 4298: loss: 0.4199, d_k_M range: [0.0056, 0.3080], d_k_M_hat range: [0.4600, 0.8440]
2025-03-11 20:21:09 - Train Iteration 4299: loss: 0.4067, d_k_M range: [0.0189, 0.6275], d_k_M_hat range: [0.5777, 0.9897]
2025-03-11 20:21:10 - Train Iteration 4300: loss: 0.6388, d_k_M range: [0.0001, 0.1627], d_k_M_hat range: [0.2014, 0.7886]
2025-03-11 20:21:10 - Train Iteration 4301: loss: 0.3264, d_k_M range: [0.0267, 0.5545], d_k_M_hat range: [0.5610, 0.9945]
2025-03-11 20:21:11 - Train Iteration 4302: loss: 0.2114, d_k_M range: [0.0612, 0.3364], d_k_M_hat range: [0.6420, 0.8809]
2025-03-11 20:21:11 - Train Iteration 4303: loss: 0.2997, d_k_M range: [0.0199, 0.4763], d_k_M_hat range: [0.4852, 0.9838]
2025-03-11 20:21:12 - Train Iteration 4304: loss: 0.2825, d_k_M range: [0.0024, 0.2654], d_k_M_hat range: [0.4709, 0.8488]
2025-03-11 20:21:12 - Train Iteration 4305: loss: 0.2714, d_k_M range: [0.0053, 0.4967], d_k_M_hat range: [0.5516, 0.9758]
2025-03-11 20:21:12 - Train Iteration 4306: loss: 0.8789, d_k_M range: [0.0007, 0.2918], d_k_M_hat range: [0.0632, 0.9046]
2025-03-11 20:21:13 - Train Iteration 4307: loss: 0.3662, d_k_M range: [0.0197, 0.5722], d_k_M_hat range: [0.5473, 0.9819]
2025-03-11 20:21:13 - Train Iteration 4308: loss: 0.3094, d_k_M range: [0.0128, 0.4669], d_k_M_hat range: [0.5831, 0.9651]
2025-03-11 20:21:14 - Train Iteration 4309: loss: 0.3431, d_k_M range: [0.2235, 0.5802], d_k_M_hat range: [0.7794, 0.9944]
2025-03-11 20:21:14 - Train Iteration 4310: loss: 0.3066, d_k_M range: [0.0012, 0.5424], d_k_M_hat range: [0.4475, 0.9921]
2025-03-11 20:21:15 - Train Iteration 4311: loss: 0.3087, d_k_M range: [0.0049, 0.4676], d_k_M_hat range: [0.4493, 0.9500]
2025-03-11 20:21:15 - Train Iteration 4312: loss: 0.2798, d_k_M range: [0.0070, 0.2342], d_k_M_hat range: [0.6063, 0.8914]
2025-03-11 20:21:16 - Train Iteration 4313: loss: 0.5990, d_k_M range: [0.0087, 0.7665], d_k_M_hat range: [0.5500, 0.9925]
2025-03-11 20:21:16 - Train Iteration 4314: loss: 0.3797, d_k_M range: [0.0001, 0.3154], d_k_M_hat range: [0.3838, 0.9452]
2025-03-11 20:21:17 - Train Iteration 4315: loss: 0.7647, d_k_M range: [0.1016, 0.8704], d_k_M_hat range: [0.7139, 0.9959]
2025-03-11 20:21:17 - Train Iteration 4316: loss: 0.5075, d_k_M range: [0.0002, 0.3023], d_k_M_hat range: [0.2878, 0.8464]
2025-03-11 20:21:17 - Train Iteration 4317: loss: 0.2810, d_k_M range: [0.2924, 0.4906], d_k_M_hat range: [0.8738, 0.9871]
2025-03-11 20:21:18 - Train Iteration 4318: loss: 0.3275, d_k_M range: [0.0015, 0.4384], d_k_M_hat range: [0.4339, 0.9729]
2025-03-11 20:21:18 - Train Iteration 4319: loss: 0.3574, d_k_M range: [0.0030, 0.5951], d_k_M_hat range: [0.4486, 0.9973]
2025-03-11 20:21:19 - Train Iteration 4320: loss: 0.2899, d_k_M range: [0.0133, 0.3344], d_k_M_hat range: [0.5152, 0.9309]
2025-03-11 20:21:19 - Train Iteration 4321: loss: 0.5095, d_k_M range: [0.0509, 0.7098], d_k_M_hat range: [0.7485, 0.9960]
2025-03-11 20:21:20 - Train Iteration 4322: loss: 0.8493, d_k_M range: [0.0004, 0.2958], d_k_M_hat range: [0.0788, 0.8474]
2025-03-11 20:21:20 - Train Iteration 4323: loss: 0.3877, d_k_M range: [0.3074, 0.6065], d_k_M_hat range: [0.8951, 0.9921]
2025-03-11 20:21:21 - Train Iteration 4324: loss: 0.3327, d_k_M range: [0.0395, 0.4977], d_k_M_hat range: [0.5280, 0.9742]
2025-03-11 20:21:21 - Train Iteration 4325: loss: 0.3554, d_k_M range: [0.0774, 0.4662], d_k_M_hat range: [0.7065, 0.9736]
2025-03-11 20:21:21 - Train Iteration 4326: loss: 0.2630, d_k_M range: [0.0831, 0.4767], d_k_M_hat range: [0.6443, 0.9802]
2025-03-11 20:21:22 - Train Iteration 4327: loss: 0.2952, d_k_M range: [0.0038, 0.4491], d_k_M_hat range: [0.5139, 0.9877]
2025-03-11 20:21:22 - Train Iteration 4328: loss: 0.5719, d_k_M range: [0.0004, 0.4736], d_k_M_hat range: [0.2442, 0.9855]
2025-03-11 20:21:23 - Train Iteration 4329: loss: 0.4999, d_k_M range: [0.0486, 0.7017], d_k_M_hat range: [0.6733, 0.9946]
2025-03-11 20:21:23 - Train Iteration 4330: loss: 0.5355, d_k_M range: [0.0027, 0.3177], d_k_M_hat range: [0.2709, 0.9509]
2025-03-11 20:21:24 - Train Iteration 4331: loss: 0.5337, d_k_M range: [0.0678, 0.7043], d_k_M_hat range: [0.5688, 0.9901]
2025-03-11 20:21:24 - Train Iteration 4332: loss: 0.3477, d_k_M range: [0.0010, 0.5423], d_k_M_hat range: [0.4113, 0.9851]
2025-03-11 20:21:24 - Train Iteration 4333: loss: 0.4686, d_k_M range: [0.1378, 0.6809], d_k_M_hat range: [0.6760, 0.9963]
2025-03-11 20:21:25 - Train Iteration 4334: loss: 0.3528, d_k_M range: [0.0025, 0.4611], d_k_M_hat range: [0.4233, 0.9350]
2025-03-11 20:21:25 - Train Iteration 4335: loss: 0.2652, d_k_M range: [0.1132, 0.4790], d_k_M_hat range: [0.7985, 0.9653]
2025-03-11 20:21:26 - Train Iteration 4336: loss: 0.2622, d_k_M range: [0.0065, 0.4887], d_k_M_hat range: [0.5504, 0.9767]
2025-03-11 20:21:26 - Train Iteration 4337: loss: 0.9208, d_k_M range: [0.0007, 0.3376], d_k_M_hat range: [0.0413, 0.9326]
2025-03-11 20:21:27 - Train Iteration 4338: loss: 0.2838, d_k_M range: [0.0214, 0.4272], d_k_M_hat range: [0.5445, 0.9047]
2025-03-11 20:21:27 - Train Iteration 4339: loss: 0.3980, d_k_M range: [0.0356, 0.5929], d_k_M_hat range: [0.5792, 0.9911]
2025-03-11 20:21:28 - Train Iteration 4340: loss: 0.3093, d_k_M range: [0.0010, 0.4785], d_k_M_hat range: [0.4913, 0.9872]
2025-03-11 20:21:28 - Train Iteration 4341: loss: 0.2794, d_k_M range: [0.0013, 0.4492], d_k_M_hat range: [0.4952, 0.9482]
2025-03-11 20:21:29 - Train Iteration 4342: loss: 0.3093, d_k_M range: [0.0019, 0.3922], d_k_M_hat range: [0.5338, 0.9906]
2025-03-11 20:21:29 - Train Iteration 4343: loss: 0.6289, d_k_M range: [0.0092, 0.7892], d_k_M_hat range: [0.6324, 0.9961]
2025-03-11 20:21:29 - Train Iteration 4344: loss: 0.2751, d_k_M range: [0.0642, 0.4308], d_k_M_hat range: [0.6903, 0.9378]
2025-03-11 20:21:30 - Train Iteration 4345: loss: 0.2731, d_k_M range: [0.0182, 0.4531], d_k_M_hat range: [0.5224, 0.9684]
2025-03-11 20:21:30 - Train Iteration 4346: loss: 0.2009, d_k_M range: [0.0058, 0.4394], d_k_M_hat range: [0.6134, 0.9912]
2025-03-11 20:21:31 - Train Iteration 4347: loss: 0.3486, d_k_M range: [0.0008, 0.3136], d_k_M_hat range: [0.4104, 0.9165]
2025-03-11 20:21:31 - Train Iteration 4348: loss: 0.3691, d_k_M range: [0.0100, 0.4995], d_k_M_hat range: [0.4151, 0.9784]
2025-03-11 20:21:32 - Train Iteration 4349: loss: 0.2609, d_k_M range: [0.0080, 0.3488], d_k_M_hat range: [0.4972, 0.9707]
2025-03-11 20:21:32 - Train Iteration 4350: loss: 0.2383, d_k_M range: [0.0107, 0.3536], d_k_M_hat range: [0.5432, 0.9219]
2025-03-11 20:21:32 - Train Iteration 4351: loss: 0.8096, d_k_M range: [0.0536, 0.8994], d_k_M_hat range: [0.6748, 0.9997]
2025-03-11 20:21:33 - Train Iteration 4352: loss: 0.4481, d_k_M range: [0.0005, 0.1807], d_k_M_hat range: [0.3441, 0.7592]
2025-03-11 20:21:33 - Train Iteration 4353: loss: 0.3821, d_k_M range: [0.0111, 0.6115], d_k_M_hat range: [0.5244, 0.9933]
2025-03-11 20:21:34 - Train Iteration 4354: loss: 0.3273, d_k_M range: [0.0043, 0.2415], d_k_M_hat range: [0.4322, 0.7651]
2025-03-11 20:21:34 - Train Iteration 4355: loss: 0.3567, d_k_M range: [0.0148, 0.5610], d_k_M_hat range: [0.5237, 0.9879]
2025-03-11 20:21:35 - Train Iteration 4356: loss: 0.3102, d_k_M range: [0.0058, 0.4581], d_k_M_hat range: [0.4488, 0.9575]
2025-03-11 20:21:35 - Train Iteration 4357: loss: 0.2471, d_k_M range: [0.0761, 0.4850], d_k_M_hat range: [0.7659, 0.9878]
2025-03-11 20:21:35 - Train Iteration 4358: loss: 0.3190, d_k_M range: [0.0273, 0.5538], d_k_M_hat range: [0.6359, 0.9889]
2025-03-11 20:21:36 - Train Iteration 4359: loss: 0.4925, d_k_M range: [0.0577, 0.6992], d_k_M_hat range: [0.5123, 0.9974]
2025-03-11 20:21:36 - Train Iteration 4360: loss: 0.3688, d_k_M range: [0.0009, 0.1017], d_k_M_hat range: [0.3936, 0.7633]
2025-03-11 20:21:37 - Train Iteration 4361: loss: 0.2644, d_k_M range: [0.0583, 0.4824], d_k_M_hat range: [0.6397, 0.9872]
2025-03-11 20:21:37 - Train Iteration 4362: loss: 0.2494, d_k_M range: [0.0082, 0.4115], d_k_M_hat range: [0.5122, 0.9721]
2025-03-11 20:21:38 - Train Iteration 4363: loss: 0.3531, d_k_M range: [0.0412, 0.5897], d_k_M_hat range: [0.6705, 0.9971]
2025-03-11 20:21:38 - Train Iteration 4364: loss: 0.3950, d_k_M range: [0.0203, 0.6107], d_k_M_hat range: [0.5602, 0.9822]
2025-03-11 20:21:39 - Train Iteration 4365: loss: 0.3144, d_k_M range: [0.0099, 0.5388], d_k_M_hat range: [0.5544, 0.9781]
2025-03-11 20:21:39 - Train Iteration 4366: loss: 0.3048, d_k_M range: [0.0069, 0.4535], d_k_M_hat range: [0.4548, 0.9793]
2025-03-11 20:21:40 - Train Iteration 4367: loss: 0.3115, d_k_M range: [0.0559, 0.5523], d_k_M_hat range: [0.5882, 0.9942]
2025-03-11 20:21:40 - Train Iteration 4368: loss: 0.2833, d_k_M range: [0.0052, 0.4279], d_k_M_hat range: [0.4730, 0.9685]
2025-03-11 20:21:41 - Train Iteration 4369: loss: 0.4373, d_k_M range: [0.0015, 0.4912], d_k_M_hat range: [0.3402, 0.9757]
2025-03-11 20:21:41 - Train Iteration 4370: loss: 0.3152, d_k_M range: [0.1023, 0.5457], d_k_M_hat range: [0.6667, 0.9842]
2025-03-11 20:21:41 - Train Iteration 4371: loss: 0.4020, d_k_M range: [0.0023, 0.3184], d_k_M_hat range: [0.3682, 0.9633]
2025-03-11 20:21:42 - Train Iteration 4372: loss: 0.5777, d_k_M range: [0.0374, 0.7533], d_k_M_hat range: [0.6386, 0.9932]
2025-03-11 20:21:42 - Train Iteration 4373: loss: 0.3625, d_k_M range: [0.0012, 0.3937], d_k_M_hat range: [0.3992, 0.9274]
2025-03-11 20:21:43 - Train Iteration 4374: loss: 0.4226, d_k_M range: [0.3480, 0.6434], d_k_M_hat range: [0.8070, 0.9933]
2025-03-11 20:21:43 - Train Iteration 4375: loss: 0.3213, d_k_M range: [0.0426, 0.4091], d_k_M_hat range: [0.5243, 0.8998]
2025-03-11 20:21:44 - Train Iteration 4376: loss: 0.3183, d_k_M range: [0.0148, 0.2880], d_k_M_hat range: [0.5431, 0.8480]
2025-03-11 20:21:44 - Train Iteration 4377: loss: 0.3792, d_k_M range: [0.0070, 0.4259], d_k_M_hat range: [0.3913, 0.9593]
2025-03-11 20:21:44 - Train Iteration 4378: loss: 0.2884, d_k_M range: [0.0841, 0.4147], d_k_M_hat range: [0.5965, 0.9425]
2025-03-11 20:21:45 - Train Iteration 4379: loss: 0.2969, d_k_M range: [0.0059, 0.4656], d_k_M_hat range: [0.4699, 0.9552]
2025-03-11 20:21:45 - Train Iteration 4380: loss: 0.9368, d_k_M range: [0.0733, 0.9677], d_k_M_hat range: [0.5861, 0.9999]
2025-03-11 20:21:46 - Train Iteration 4381: loss: 0.3595, d_k_M range: [0.0014, 0.0992], d_k_M_hat range: [0.4018, 0.6454]
2025-03-11 20:21:46 - Train Iteration 4382: loss: 0.3553, d_k_M range: [0.1695, 0.4650], d_k_M_hat range: [0.5789, 0.9588]
2025-03-11 20:21:47 - Train Iteration 4383: loss: 0.2832, d_k_M range: [0.0062, 0.4886], d_k_M_hat range: [0.4860, 0.9565]
2025-03-11 20:21:47 - Train Iteration 4384: loss: 0.2550, d_k_M range: [0.0307, 0.4858], d_k_M_hat range: [0.6138, 0.9890]
2025-03-11 20:21:47 - Train Iteration 4385: loss: 0.3527, d_k_M range: [0.0009, 0.5597], d_k_M_hat range: [0.4410, 0.9972]
2025-03-11 20:21:48 - Train Iteration 4386: loss: 0.2691, d_k_M range: [0.0754, 0.4031], d_k_M_hat range: [0.6684, 0.9708]
2025-03-11 20:21:48 - Train Iteration 4387: loss: 0.4786, d_k_M range: [0.0008, 0.1997], d_k_M_hat range: [0.3090, 0.6555]
2025-03-11 20:21:49 - Train Iteration 4388: loss: 0.2941, d_k_M range: [0.0154, 0.4569], d_k_M_hat range: [0.4750, 0.9890]
2025-03-11 20:21:49 - Train Iteration 4389: loss: 0.2868, d_k_M range: [0.0214, 0.4781], d_k_M_hat range: [0.5421, 0.9918]
2025-03-11 20:21:50 - Train Iteration 4390: loss: 0.6448, d_k_M range: [0.0030, 0.2284], d_k_M_hat range: [0.2018, 0.8723]
2025-03-11 20:21:50 - Train Iteration 4391: loss: 0.3047, d_k_M range: [0.1028, 0.5446], d_k_M_hat range: [0.5937, 0.9951]
2025-03-11 20:21:51 - Train Iteration 4392: loss: 0.3028, d_k_M range: [0.0028, 0.5371], d_k_M_hat range: [0.4910, 0.9926]
2025-03-11 20:21:51 - Train Iteration 4393: loss: 0.4657, d_k_M range: [0.0002, 0.3601], d_k_M_hat range: [0.3177, 0.8761]
2025-03-11 20:21:51 - Train Iteration 4394: loss: 0.3151, d_k_M range: [0.0022, 0.3019], d_k_M_hat range: [0.4786, 0.7406]
2025-03-11 20:21:52 - Train Iteration 4395: loss: 0.2999, d_k_M range: [0.0791, 0.4733], d_k_M_hat range: [0.6517, 0.9846]
2025-03-11 20:21:52 - Train Iteration 4396: loss: 0.5232, d_k_M range: [0.0656, 0.7221], d_k_M_hat range: [0.5426, 0.9988]
2025-03-11 20:21:53 - Train Iteration 4397: loss: 0.2606, d_k_M range: [0.0289, 0.3963], d_k_M_hat range: [0.5392, 0.9336]
2025-03-11 20:21:53 - Train Iteration 4398: loss: 0.5876, d_k_M range: [0.0068, 0.7633], d_k_M_hat range: [0.5532, 0.9967]
2025-03-11 20:21:54 - Train Iteration 4399: loss: 0.2793, d_k_M range: [0.0136, 0.4384], d_k_M_hat range: [0.5675, 0.9100]
2025-03-11 20:21:54 - Train Iteration 4400: loss: 0.2779, d_k_M range: [0.0331, 0.5160], d_k_M_hat range: [0.5457, 0.9945]
2025-03-11 20:21:54 - Train Iteration 4401: loss: 0.4002, d_k_M range: [0.0064, 0.5133], d_k_M_hat range: [0.3737, 0.9900]
2025-03-11 20:21:55 - Train Iteration 4402: loss: 0.2809, d_k_M range: [0.0143, 0.4579], d_k_M_hat range: [0.5105, 0.9635]
2025-03-11 20:21:55 - Train Iteration 4403: loss: 0.3964, d_k_M range: [0.0184, 0.6285], d_k_M_hat range: [0.6275, 0.9989]
2025-03-11 20:21:56 - Train Iteration 4404: loss: 0.2478, d_k_M range: [0.0277, 0.4486], d_k_M_hat range: [0.5299, 0.9765]
2025-03-11 20:21:56 - Train Iteration 4405: loss: 0.3487, d_k_M range: [0.0195, 0.4624], d_k_M_hat range: [0.4990, 0.9796]
2025-03-11 20:21:56 - Train Iteration 4406: loss: 0.3231, d_k_M range: [0.1877, 0.5529], d_k_M_hat range: [0.7863, 0.9934]
2025-03-11 20:21:57 - Train Iteration 4407: loss: 0.4121, d_k_M range: [0.0008, 0.3230], d_k_M_hat range: [0.3589, 0.9602]
2025-03-11 20:21:57 - Train Iteration 4408: loss: 0.2144, d_k_M range: [0.1907, 0.3936], d_k_M_hat range: [0.8160, 0.9838]
2025-03-11 20:21:58 - Train Iteration 4409: loss: 0.4697, d_k_M range: [0.0474, 0.6816], d_k_M_hat range: [0.5329, 0.9963]
2025-03-11 20:21:58 - Train Iteration 4410: loss: 0.6896, d_k_M range: [0.0001, 0.4097], d_k_M_hat range: [0.1696, 0.9888]
2025-03-11 20:21:59 - Train Iteration 4411: loss: 0.3502, d_k_M range: [0.0566, 0.5912], d_k_M_hat range: [0.6280, 0.9995]
2025-03-11 20:21:59 - Train Iteration 4412: loss: 0.2693, d_k_M range: [0.0099, 0.3859], d_k_M_hat range: [0.5380, 0.9701]
2025-03-11 20:21:59 - Train Iteration 4413: loss: 0.2457, d_k_M range: [0.0413, 0.3669], d_k_M_hat range: [0.5456, 0.9801]
2025-03-11 20:22:00 - Train Iteration 4414: loss: 0.3038, d_k_M range: [0.0051, 0.3185], d_k_M_hat range: [0.5012, 0.9545]
2025-03-11 20:22:00 - Train Iteration 4415: loss: 0.4181, d_k_M range: [0.0105, 0.6459], d_k_M_hat range: [0.5338, 0.9993]
2025-03-11 20:22:01 - Train Iteration 4416: loss: 0.3677, d_k_M range: [0.0008, 0.2530], d_k_M_hat range: [0.3944, 0.8897]
2025-03-11 20:22:01 - Train Iteration 4417: loss: 0.2609, d_k_M range: [0.0191, 0.4937], d_k_M_hat range: [0.5223, 0.9867]
2025-03-11 20:22:02 - Train Iteration 4418: loss: 0.2314, d_k_M range: [0.0040, 0.4790], d_k_M_hat range: [0.6801, 0.9979]
2025-03-11 20:22:02 - Train Iteration 4419: loss: 0.3648, d_k_M range: [0.0009, 0.4910], d_k_M_hat range: [0.3986, 0.9751]
2025-03-11 20:22:03 - Train Iteration 4420: loss: 0.2100, d_k_M range: [0.0218, 0.4494], d_k_M_hat range: [0.6894, 0.9911]
2025-03-11 20:22:03 - Train Iteration 4421: loss: 0.2653, d_k_M range: [0.0041, 0.3962], d_k_M_hat range: [0.4890, 0.9473]
2025-03-11 20:22:04 - Train Iteration 4422: loss: 0.5110, d_k_M range: [0.0145, 0.7140], d_k_M_hat range: [0.5367, 0.9991]
2025-03-11 20:22:04 - Train Iteration 4423: loss: 0.4831, d_k_M range: [0.0075, 0.1933], d_k_M_hat range: [0.3142, 0.8621]
2025-03-11 20:22:04 - Train Iteration 4424: loss: 0.3107, d_k_M range: [0.0075, 0.5466], d_k_M_hat range: [0.4946, 0.9891]
2025-03-11 20:22:05 - Train Iteration 4425: loss: 0.2981, d_k_M range: [0.0068, 0.5450], d_k_M_hat range: [0.5090, 0.9991]
2025-03-11 20:22:05 - Train Iteration 4426: loss: 0.3856, d_k_M range: [0.0016, 0.3532], d_k_M_hat range: [0.3806, 0.9272]
2025-03-11 20:22:06 - Train Iteration 4427: loss: 0.4129, d_k_M range: [0.0072, 0.6407], d_k_M_hat range: [0.5496, 0.9981]
2025-03-11 20:22:06 - Train Iteration 4428: loss: 0.3476, d_k_M range: [0.0006, 0.4257], d_k_M_hat range: [0.4110, 0.9824]
2025-03-11 20:22:07 - Train Iteration 4429: loss: 0.2693, d_k_M range: [0.0021, 0.4403], d_k_M_hat range: [0.4832, 0.9755]
2025-03-11 20:22:07 - Train Iteration 4430: loss: 0.3113, d_k_M range: [0.0422, 0.5433], d_k_M_hat range: [0.6634, 0.9853]
2025-03-11 20:22:07 - Train Iteration 4431: loss: 0.3107, d_k_M range: [0.0135, 0.5175], d_k_M_hat range: [0.5947, 0.9925]
2025-03-11 20:22:08 - Train Iteration 4432: loss: 0.3832, d_k_M range: [0.0039, 0.4778], d_k_M_hat range: [0.3849, 0.9731]
2025-03-11 20:22:08 - Train Iteration 4433: loss: 0.2638, d_k_M range: [0.0287, 0.4467], d_k_M_hat range: [0.5767, 0.9420]
2025-03-11 20:22:09 - Train Iteration 4434: loss: 0.3571, d_k_M range: [0.0213, 0.5856], d_k_M_hat range: [0.5989, 0.9880]
2025-03-11 20:22:09 - Train Iteration 4435: loss: 0.3207, d_k_M range: [0.0005, 0.4741], d_k_M_hat range: [0.4342, 0.9766]
2025-03-11 20:22:10 - Train Iteration 4436: loss: 0.6979, d_k_M range: [0.0145, 0.8322], d_k_M_hat range: [0.5393, 0.9968]
2025-03-11 20:22:10 - Train Iteration 4437: loss: 0.2921, d_k_M range: [0.0056, 0.5369], d_k_M_hat range: [0.6743, 0.9964]
2025-03-11 20:22:11 - Train Iteration 4438: loss: 0.4560, d_k_M range: [0.0013, 0.6641], d_k_M_hat range: [0.4984, 0.9888]
2025-03-11 20:22:11 - Train Iteration 4439: loss: 0.4409, d_k_M range: [0.0004, 0.1783], d_k_M_hat range: [0.3383, 0.9269]
2025-03-11 20:22:11 - Train Iteration 4440: loss: 0.3277, d_k_M range: [0.0111, 0.4121], d_k_M_hat range: [0.4439, 0.9161]
2025-03-11 20:22:12 - Train Iteration 4441: loss: 0.2724, d_k_M range: [0.0138, 0.3994], d_k_M_hat range: [0.4935, 0.8960]
2025-03-11 20:22:12 - Train Iteration 4442: loss: 0.3730, d_k_M range: [0.0012, 0.0914], d_k_M_hat range: [0.3912, 0.7877]
2025-03-11 20:22:13 - Train Iteration 4443: loss: 0.3505, d_k_M range: [0.0378, 0.5900], d_k_M_hat range: [0.6588, 0.9980]
2025-03-11 20:22:13 - Train Iteration 4444: loss: 0.3396, d_k_M range: [0.0290, 0.4038], d_k_M_hat range: [0.4824, 0.9369]
2025-03-11 20:22:14 - Train Iteration 4445: loss: 0.3878, d_k_M range: [0.0026, 0.4173], d_k_M_hat range: [0.4246, 0.9043]
2025-03-11 20:22:14 - Train Iteration 4446: loss: 0.3141, d_k_M range: [0.0048, 0.5298], d_k_M_hat range: [0.6288, 0.9874]
2025-03-11 20:22:14 - Train Iteration 4447: loss: 0.3857, d_k_M range: [0.0005, 0.3790], d_k_M_hat range: [0.3795, 0.8922]
2025-03-11 20:22:15 - Train Iteration 4448: loss: 0.2332, d_k_M range: [0.0024, 0.2382], d_k_M_hat range: [0.5214, 0.8816]
2025-03-11 20:22:15 - Train Iteration 4449: loss: 0.2150, d_k_M range: [0.0271, 0.2854], d_k_M_hat range: [0.6139, 0.8322]
2025-03-11 20:22:16 - Train Iteration 4450: loss: 0.2899, d_k_M range: [0.2205, 0.5151], d_k_M_hat range: [0.8223, 0.9899]
2025-03-11 20:22:16 - Train Iteration 4451: loss: 0.7292, d_k_M range: [0.0007, 0.8493], d_k_M_hat range: [0.3296, 0.9953]
2025-03-11 20:22:17 - Train Iteration 4452: loss: 0.3049, d_k_M range: [0.0018, 0.3437], d_k_M_hat range: [0.4508, 0.8864]
2025-03-11 20:22:17 - Train Iteration 4453: loss: 0.4584, d_k_M range: [0.1662, 0.6724], d_k_M_hat range: [0.8373, 0.9971]
2025-03-11 20:22:17 - Train Iteration 4454: loss: 0.2885, d_k_M range: [0.0026, 0.0917], d_k_M_hat range: [0.4703, 0.7979]
2025-03-11 20:22:18 - Train Iteration 4455: loss: 0.6791, d_k_M range: [0.0320, 0.8209], d_k_M_hat range: [0.6915, 0.9968]
2025-03-11 20:22:18 - Train Iteration 4456: loss: 0.2679, d_k_M range: [0.0008, 0.4990], d_k_M_hat range: [0.4968, 0.9815]
2025-03-11 20:22:19 - Train Iteration 4457: loss: 0.4112, d_k_M range: [0.0011, 0.3961], d_k_M_hat range: [0.3598, 0.9273]
2025-03-11 20:22:19 - Train Iteration 4458: loss: 0.6348, d_k_M range: [0.1387, 0.7904], d_k_M_hat range: [0.8220, 0.9936]
2025-03-11 20:22:19 - Train Iteration 4459: loss: 0.3486, d_k_M range: [0.0013, 0.2404], d_k_M_hat range: [0.4189, 0.8136]
2025-03-11 20:22:20 - Train Iteration 4460: loss: 0.3561, d_k_M range: [0.2477, 0.5809], d_k_M_hat range: [0.8209, 0.9918]
2025-03-11 20:22:20 - Train Iteration 4461: loss: 0.4551, d_k_M range: [0.0161, 0.6699], d_k_M_hat range: [0.5342, 0.9953]
2025-03-11 20:22:21 - Train Iteration 4462: loss: 0.5647, d_k_M range: [0.0001, 0.3577], d_k_M_hat range: [0.2487, 0.7638]
2025-03-11 20:22:21 - Train Iteration 4463: loss: 0.3682, d_k_M range: [0.0438, 0.5752], d_k_M_hat range: [0.5801, 0.9939]
2025-03-11 20:22:22 - Train Iteration 4464: loss: 0.3290, d_k_M range: [0.1740, 0.5104], d_k_M_hat range: [0.7005, 0.9712]
2025-03-11 20:22:22 - Train Iteration 4465: loss: 0.4576, d_k_M range: [0.0270, 0.5559], d_k_M_hat range: [0.3532, 0.9925]
2025-03-11 20:22:22 - Train Iteration 4466: loss: 0.2824, d_k_M range: [0.0322, 0.5227], d_k_M_hat range: [0.6315, 0.9981]
2025-03-11 20:22:23 - Train Iteration 4467: loss: 0.2912, d_k_M range: [0.0021, 0.3088], d_k_M_hat range: [0.4890, 0.8995]
2025-03-11 20:22:23 - Train Iteration 4468: loss: 0.3359, d_k_M range: [0.2831, 0.5782], d_k_M_hat range: [0.8721, 0.9986]
2025-03-11 20:22:24 - Train Iteration 4469: loss: 0.4217, d_k_M range: [0.0050, 0.4386], d_k_M_hat range: [0.4057, 0.9869]
2025-03-11 20:22:24 - Train Iteration 4470: loss: 0.2844, d_k_M range: [0.0023, 0.4219], d_k_M_hat range: [0.4690, 0.9247]
2025-03-11 20:22:25 - Train Iteration 4471: loss: 0.2695, d_k_M range: [0.0060, 0.2185], d_k_M_hat range: [0.5207, 0.8156]
2025-03-11 20:22:25 - Train Iteration 4472: loss: 0.9580, d_k_M range: [0.0228, 0.9785], d_k_M_hat range: [0.5417, 0.9998]
2025-03-11 20:22:25 - Train Iteration 4473: loss: 0.4705, d_k_M range: [0.0839, 0.4892], d_k_M_hat range: [0.6626, 0.9961]
2025-03-11 20:22:26 - Train Iteration 4474: loss: 0.2805, d_k_M range: [0.0127, 0.3459], d_k_M_hat range: [0.5700, 0.8341]
2025-03-11 20:22:26 - Train Iteration 4475: loss: 0.3714, d_k_M range: [0.0006, 0.3497], d_k_M_hat range: [0.3912, 0.9716]
2025-03-11 20:22:27 - Train Iteration 4476: loss: 0.3751, d_k_M range: [0.2061, 0.6114], d_k_M_hat range: [0.7435, 0.9989]
2025-03-11 20:22:27 - Train Iteration 4477: loss: 0.3116, d_k_M range: [0.0027, 0.4239], d_k_M_hat range: [0.4467, 0.9530]
2025-03-11 20:22:27 - Train Iteration 4478: loss: 0.8957, d_k_M range: [0.0315, 0.9436], d_k_M_hat range: [0.6583, 0.9971]
2025-03-11 20:22:28 - Train Iteration 4479: loss: 0.3490, d_k_M range: [0.0027, 0.3145], d_k_M_hat range: [0.4120, 0.8623]
2025-03-11 20:22:28 - Train Iteration 4480: loss: 0.3345, d_k_M range: [0.0094, 0.5773], d_k_M_hat range: [0.5813, 0.9989]
2025-03-11 20:22:29 - Train Iteration 4481: loss: 0.4705, d_k_M range: [0.0162, 0.6793], d_k_M_hat range: [0.6057, 0.9938]
2025-03-11 20:22:29 - Train Iteration 4482: loss: 0.4065, d_k_M range: [0.0046, 0.1703], d_k_M_hat range: [0.3675, 0.7083]
2025-03-11 20:22:30 - Train Iteration 4483: loss: 0.2668, d_k_M range: [0.0065, 0.4810], d_k_M_hat range: [0.6080, 0.9645]
2025-03-11 20:22:30 - Train Iteration 4484: loss: 0.4929, d_k_M range: [0.0009, 0.4917], d_k_M_hat range: [0.2988, 0.9865]
2025-03-11 20:22:30 - Train Iteration 4485: loss: 0.2423, d_k_M range: [0.0026, 0.4625], d_k_M_hat range: [0.5628, 0.9906]
2025-03-11 20:22:31 - Train Iteration 4486: loss: 0.6376, d_k_M range: [0.0001, 0.3647], d_k_M_hat range: [0.2016, 0.8861]
2025-03-11 20:22:31 - Train Iteration 4487: loss: 0.3223, d_k_M range: [0.1741, 0.5552], d_k_M_hat range: [0.7550, 0.9930]
2025-03-11 20:22:32 - Train Iteration 4488: loss: 0.3107, d_k_M range: [0.0172, 0.4026], d_k_M_hat range: [0.6335, 0.9716]
2025-03-11 20:22:32 - Train Iteration 4489: loss: 0.4163, d_k_M range: [0.0013, 0.3002], d_k_M_hat range: [0.3560, 0.8609]
2025-03-11 20:22:32 - Train Iteration 4490: loss: 0.3590, d_k_M range: [0.0067, 0.5105], d_k_M_hat range: [0.4075, 0.9773]
2025-03-11 20:22:33 - Train Iteration 4491: loss: 0.4540, d_k_M range: [0.0007, 0.6437], d_k_M_hat range: [0.4958, 0.9699]
2025-03-11 20:22:33 - Train Iteration 4492: loss: 0.3153, d_k_M range: [0.0028, 0.3937], d_k_M_hat range: [0.4809, 0.8944]
2025-03-11 20:22:34 - Train Iteration 4493: loss: 0.3408, d_k_M range: [0.0145, 0.4032], d_k_M_hat range: [0.5505, 0.9609]
2025-03-11 20:22:34 - Train Iteration 4494: loss: 0.4023, d_k_M range: [0.0007, 0.6316], d_k_M_hat range: [0.4056, 0.9974]
2025-03-11 20:22:35 - Train Iteration 4495: loss: 0.3877, d_k_M range: [0.0014, 0.3612], d_k_M_hat range: [0.3788, 0.9555]
2025-03-11 20:22:35 - Train Iteration 4496: loss: 0.3542, d_k_M range: [0.1928, 0.5779], d_k_M_hat range: [0.7188, 0.9828]
2025-03-11 20:22:35 - Train Iteration 4497: loss: 0.2611, d_k_M range: [0.1308, 0.4073], d_k_M_hat range: [0.6199, 0.9292]
2025-03-11 20:22:36 - Train Iteration 4498: loss: 0.3502, d_k_M range: [0.0053, 0.5018], d_k_M_hat range: [0.4135, 0.9756]
2025-03-11 20:22:36 - Train Iteration 4499: loss: 0.4784, d_k_M range: [0.1230, 0.6893], d_k_M_hat range: [0.6877, 0.9976]
2025-03-11 20:22:37 - Train Iteration 4500: loss: 0.3117, d_k_M range: [0.0039, 0.4420], d_k_M_hat range: [0.4919, 0.9707]
2025-03-11 20:22:37 - Train Iteration 4501: loss: 0.3337, d_k_M range: [0.0125, 0.5201], d_k_M_hat range: [0.4348, 0.9793]
2025-03-11 20:22:38 - Train Iteration 4502: loss: 0.6063, d_k_M range: [0.0076, 0.5102], d_k_M_hat range: [0.2289, 0.9904]
2025-03-11 20:22:38 - Train Iteration 4503: loss: 0.4000, d_k_M range: [0.0003, 0.5079], d_k_M_hat range: [0.3678, 0.9764]
2025-03-11 20:22:38 - Train Iteration 4504: loss: 0.3043, d_k_M range: [0.0952, 0.4762], d_k_M_hat range: [0.7385, 0.9951]
2025-03-11 20:22:39 - Train Iteration 4505: loss: 0.4425, d_k_M range: [0.0135, 0.6572], d_k_M_hat range: [0.6431, 0.9946]
2025-03-11 20:22:39 - Train Iteration 4506: loss: 0.2928, d_k_M range: [0.0032, 0.2359], d_k_M_hat range: [0.4622, 0.8270]
2025-03-11 20:22:40 - Train Iteration 4507: loss: 0.7010, d_k_M range: [0.0017, 0.2156], d_k_M_hat range: [0.1645, 0.8123]
2025-03-11 20:22:40 - Train Iteration 4508: loss: 0.3008, d_k_M range: [0.0342, 0.5413], d_k_M_hat range: [0.6565, 0.9928]
2025-03-11 20:22:41 - Train Iteration 4509: loss: 0.2656, d_k_M range: [0.0086, 0.3445], d_k_M_hat range: [0.5110, 0.8920]
2025-03-11 20:22:41 - Train Iteration 4510: loss: 0.5575, d_k_M range: [0.0053, 0.7350], d_k_M_hat range: [0.5310, 0.9883]
2025-03-11 20:22:41 - Train Iteration 4511: loss: 0.3767, d_k_M range: [0.0001, 0.4604], d_k_M_hat range: [0.3864, 0.9782]
2025-03-11 20:22:42 - Train Iteration 4512: loss: 0.4961, d_k_M range: [0.0036, 0.6901], d_k_M_hat range: [0.5069, 0.9857]
2025-03-11 20:22:42 - Train Iteration 4513: loss: 0.3268, d_k_M range: [0.0013, 0.3119], d_k_M_hat range: [0.4345, 0.9418]
2025-03-11 20:22:43 - Train Iteration 4514: loss: 0.2994, d_k_M range: [0.0059, 0.5051], d_k_M_hat range: [0.4611, 0.9810]
2025-03-11 20:22:43 - Train Iteration 4515: loss: 0.2797, d_k_M range: [0.0009, 0.3405], d_k_M_hat range: [0.4720, 0.9700]
2025-03-11 20:22:44 - Train Iteration 4516: loss: 0.3588, d_k_M range: [0.1056, 0.5926], d_k_M_hat range: [0.8150, 0.9943]
2025-03-11 20:22:44 - Train Iteration 4517: loss: 0.4300, d_k_M range: [0.0002, 0.4232], d_k_M_hat range: [0.3445, 0.8962]
2025-03-11 20:22:45 - Train Iteration 4518: loss: 0.8563, d_k_M range: [0.0000, 0.3868], d_k_M_hat range: [0.0746, 0.9330]
2025-03-11 20:22:45 - Train Iteration 4519: loss: 0.2931, d_k_M range: [0.1950, 0.5192], d_k_M_hat range: [0.7838, 0.9909]
2025-03-11 20:22:45 - Train Iteration 4520: loss: 0.2904, d_k_M range: [0.0256, 0.5011], d_k_M_hat range: [0.6134, 0.9877]
2025-03-11 20:22:46 - Train Iteration 4521: loss: 0.2558, d_k_M range: [0.0332, 0.4233], d_k_M_hat range: [0.5689, 0.9743]
2025-03-11 20:22:46 - Train Iteration 4522: loss: 0.2311, d_k_M range: [0.0030, 0.4412], d_k_M_hat range: [0.5563, 0.9890]
2025-03-11 20:22:47 - Train Iteration 4523: loss: 0.3135, d_k_M range: [0.0020, 0.5274], d_k_M_hat range: [0.4421, 0.9785]
2025-03-11 20:22:47 - Train Iteration 4524: loss: 0.2158, d_k_M range: [0.1013, 0.4416], d_k_M_hat range: [0.8029, 0.9942]
2025-03-11 20:22:47 - Train Iteration 4525: loss: 0.2900, d_k_M range: [0.0889, 0.4181], d_k_M_hat range: [0.5503, 0.9803]
2025-03-11 20:22:48 - Train Iteration 4526: loss: 0.2680, d_k_M range: [0.0199, 0.5017], d_k_M_hat range: [0.6070, 0.9840]
2025-03-11 20:22:48 - Train Iteration 4527: loss: 0.3394, d_k_M range: [0.0064, 0.2498], d_k_M_hat range: [0.5188, 0.9383]
2025-03-11 20:22:49 - Train Iteration 4528: loss: 0.2247, d_k_M range: [0.0037, 0.3906], d_k_M_hat range: [0.5504, 0.9714]
2025-03-11 20:22:49 - Train Iteration 4529: loss: 0.2723, d_k_M range: [0.0006, 0.4324], d_k_M_hat range: [0.4788, 0.9642]
2025-03-11 20:22:50 - Train Iteration 4530: loss: 0.2720, d_k_M range: [0.0190, 0.4963], d_k_M_hat range: [0.7085, 0.9788]
2025-03-11 20:22:50 - Train Iteration 4531: loss: 0.2633, d_k_M range: [0.0428, 0.4937], d_k_M_hat range: [0.5635, 0.9856]
2025-03-11 20:22:50 - Train Iteration 4532: loss: 0.2972, d_k_M range: [0.0073, 0.5260], d_k_M_hat range: [0.4888, 0.9808]
2025-03-11 20:22:51 - Train Iteration 4533: loss: 0.3080, d_k_M range: [0.0033, 0.5526], d_k_M_hat range: [0.4640, 0.9976]
2025-03-11 20:22:51 - Train Iteration 4534: loss: 0.3333, d_k_M range: [0.0004, 0.2264], d_k_M_hat range: [0.4271, 0.8878]
2025-03-11 20:22:52 - Train Iteration 4535: loss: 0.4507, d_k_M range: [0.0039, 0.6693], d_k_M_hat range: [0.6032, 0.9979]
2025-03-11 20:22:52 - Train Iteration 4536: loss: 0.2387, d_k_M range: [0.0078, 0.2592], d_k_M_hat range: [0.5193, 0.8646]
2025-03-11 20:22:52 - Train Iteration 4537: loss: 0.4934, d_k_M range: [0.0001, 0.5256], d_k_M_hat range: [0.2977, 0.9722]
2025-03-11 20:22:53 - Train Iteration 4538: loss: 0.3688, d_k_M range: [0.0245, 0.5993], d_k_M_hat range: [0.6870, 0.9920]
2025-03-11 20:22:53 - Train Iteration 4539: loss: 0.2321, d_k_M range: [0.0097, 0.4270], d_k_M_hat range: [0.5388, 0.9811]
2025-03-11 20:22:54 - Train Iteration 4540: loss: 0.5728, d_k_M range: [0.0639, 0.7535], d_k_M_hat range: [0.7364, 0.9966]
2025-03-11 20:22:54 - Train Iteration 4541: loss: 0.4577, d_k_M range: [0.0001, 0.2184], d_k_M_hat range: [0.3272, 0.9208]
2025-03-11 20:22:55 - Train Iteration 4542: loss: 0.2526, d_k_M range: [0.0172, 0.4063], d_k_M_hat range: [0.5146, 0.9628]
2025-03-11 20:22:55 - Train Iteration 4543: loss: 0.2764, d_k_M range: [0.0029, 0.4185], d_k_M_hat range: [0.4775, 0.9860]
2025-03-11 20:22:55 - Train Iteration 4544: loss: 0.4238, d_k_M range: [0.0264, 0.6127], d_k_M_hat range: [0.3754, 0.9917]
2025-03-11 20:22:56 - Train Iteration 4545: loss: 0.2629, d_k_M range: [0.0401, 0.4908], d_k_M_hat range: [0.5618, 0.9781]
2025-03-11 20:22:56 - Train Iteration 4546: loss: 0.3404, d_k_M range: [0.0463, 0.5210], d_k_M_hat range: [0.5388, 0.9855]
2025-03-11 20:22:57 - Train Iteration 4547: loss: 0.2656, d_k_M range: [0.0045, 0.4197], d_k_M_hat range: [0.4915, 0.9630]
2025-03-11 20:22:57 - Train Iteration 4548: loss: 0.2805, d_k_M range: [0.0057, 0.2401], d_k_M_hat range: [0.4762, 0.9315]
2025-03-11 20:22:58 - Train Iteration 4549: loss: 0.2397, d_k_M range: [0.0031, 0.3698], d_k_M_hat range: [0.5333, 0.9789]
2025-03-11 20:22:58 - Train Iteration 4550: loss: 0.3128, d_k_M range: [0.0050, 0.5556], d_k_M_hat range: [0.4891, 0.9962]
2025-03-11 20:22:58 - Train Iteration 4551: loss: 0.2811, d_k_M range: [0.0447, 0.5056], d_k_M_hat range: [0.6190, 0.9754]
2025-03-11 20:22:59 - Train Iteration 4552: loss: 0.3938, d_k_M range: [0.0102, 0.4694], d_k_M_hat range: [0.3826, 0.9955]
2025-03-11 20:22:59 - Train Iteration 4553: loss: 0.1971, d_k_M range: [0.0083, 0.3417], d_k_M_hat range: [0.5700, 0.9373]
2025-03-11 20:23:00 - Train Iteration 4554: loss: 0.2982, d_k_M range: [0.3124, 0.5402], d_k_M_hat range: [0.8799, 0.9942]
2025-03-11 20:23:00 - Train Iteration 4555: loss: 0.3176, d_k_M range: [0.0154, 0.4160], d_k_M_hat range: [0.5158, 0.9953]
2025-03-11 20:23:00 - Train Iteration 4556: loss: 0.3033, d_k_M range: [0.0134, 0.4946], d_k_M_hat range: [0.4759, 0.9937]
2025-03-11 20:23:01 - Train Iteration 4557: loss: 0.2523, d_k_M range: [0.0046, 0.4908], d_k_M_hat range: [0.5427, 0.9885]
2025-03-11 20:23:01 - Train Iteration 4558: loss: 0.3080, d_k_M range: [0.0002, 0.4892], d_k_M_hat range: [0.4453, 0.9647]
2025-03-11 20:23:02 - Train Iteration 4559: loss: 0.5087, d_k_M range: [0.0618, 0.7103], d_k_M_hat range: [0.7172, 0.9971]
2025-03-11 20:23:02 - Train Iteration 4560: loss: 0.2494, d_k_M range: [0.0116, 0.4211], d_k_M_hat range: [0.5680, 0.9713]
2025-03-11 20:23:03 - Train Iteration 4561: loss: 0.2899, d_k_M range: [0.0081, 0.4294], d_k_M_hat range: [0.5021, 0.9819]
2025-03-11 20:23:03 - Train Iteration 4562: loss: 0.2799, d_k_M range: [0.0085, 0.5025], d_k_M_hat range: [0.5418, 0.9806]
2025-03-11 20:23:04 - Train Iteration 4563: loss: 0.2111, d_k_M range: [0.0019, 0.2110], d_k_M_hat range: [0.5454, 0.8550]
2025-03-11 20:23:04 - Train Iteration 4564: loss: 0.4499, d_k_M range: [0.0044, 0.6571], d_k_M_hat range: [0.5410, 0.9863]
2025-03-11 20:23:04 - Train Iteration 4565: loss: 0.4488, d_k_M range: [0.0004, 0.1866], d_k_M_hat range: [0.3305, 0.8681]
2025-03-11 20:23:05 - Train Iteration 4566: loss: 0.2929, d_k_M range: [0.0032, 0.5388], d_k_M_hat range: [0.4620, 0.9984]
2025-03-11 20:23:05 - Train Iteration 4567: loss: 0.2666, d_k_M range: [0.0310, 0.5043], d_k_M_hat range: [0.5521, 0.9880]
2025-03-11 20:23:06 - Train Iteration 4568: loss: 0.3611, d_k_M range: [0.0289, 0.5967], d_k_M_hat range: [0.5877, 0.9958]
2025-03-11 20:23:06 - Train Iteration 4569: loss: 0.4215, d_k_M range: [0.0006, 0.3423], d_k_M_hat range: [0.3514, 0.9783]
2025-03-11 20:23:06 - Train Iteration 4570: loss: 0.5063, d_k_M range: [0.1857, 0.7046], d_k_M_hat range: [0.8189, 0.9931]
2025-03-11 20:23:07 - Train Iteration 4571: loss: 0.6572, d_k_M range: [0.0007, 0.8079], d_k_M_hat range: [0.3540, 0.9972]
2025-03-11 20:23:07 - Train Iteration 4572: loss: 0.2906, d_k_M range: [0.0111, 0.4051], d_k_M_hat range: [0.4807, 0.9367]
2025-03-11 20:23:08 - Train Iteration 4573: loss: 0.2754, d_k_M range: [0.0049, 0.4526], d_k_M_hat range: [0.4801, 0.9921]
2025-03-11 20:23:08 - Train Iteration 4574: loss: 0.2424, d_k_M range: [0.0142, 0.3728], d_k_M_hat range: [0.5685, 0.9655]
2025-03-11 20:23:09 - Train Iteration 4575: loss: 0.2838, d_k_M range: [0.0034, 0.5125], d_k_M_hat range: [0.4869, 0.9797]
2025-03-11 20:23:09 - Train Iteration 4576: loss: 0.2724, d_k_M range: [0.0107, 0.4753], d_k_M_hat range: [0.5778, 0.9557]
2025-03-11 20:23:09 - Train Iteration 4577: loss: 0.3481, d_k_M range: [0.0006, 0.4793], d_k_M_hat range: [0.4106, 0.9523]
2025-03-11 20:23:10 - Train Iteration 4578: loss: 0.2364, d_k_M range: [0.0135, 0.4640], d_k_M_hat range: [0.5345, 0.9874]
2025-03-11 20:23:10 - Train Iteration 4579: loss: 0.3174, d_k_M range: [0.0103, 0.5271], d_k_M_hat range: [0.5169, 0.9637]
2025-03-11 20:23:11 - Train Iteration 4580: loss: 0.2999, d_k_M range: [0.0003, 0.5126], d_k_M_hat range: [0.4552, 0.9650]
2025-03-11 20:23:11 - Train Iteration 4581: loss: 0.3260, d_k_M range: [0.0023, 0.2069], d_k_M_hat range: [0.4364, 0.9320]
2025-03-11 20:23:11 - Train Iteration 4582: loss: 0.2660, d_k_M range: [0.0132, 0.4260], d_k_M_hat range: [0.4975, 0.9739]
2025-03-11 20:23:12 - Train Iteration 4583: loss: 0.2181, d_k_M range: [0.0063, 0.3709], d_k_M_hat range: [0.5791, 0.9356]
2025-03-11 20:23:12 - Train Iteration 4584: loss: 0.3303, d_k_M range: [0.0002, 0.1811], d_k_M_hat range: [0.4255, 0.8373]
2025-03-11 20:23:13 - Train Iteration 4585: loss: 0.3244, d_k_M range: [0.0095, 0.5493], d_k_M_hat range: [0.4840, 0.9973]
2025-03-11 20:23:13 - Train Iteration 4586: loss: 0.3426, d_k_M range: [0.0031, 0.5739], d_k_M_hat range: [0.5446, 0.9885]
2025-03-11 20:23:14 - Train Iteration 4587: loss: 0.2934, d_k_M range: [0.0021, 0.4025], d_k_M_hat range: [0.4639, 0.9737]
2025-03-11 20:23:14 - Train Iteration 4588: loss: 0.2753, d_k_M range: [0.0951, 0.4480], d_k_M_hat range: [0.7175, 0.9837]
2025-03-11 20:23:15 - Train Iteration 4589: loss: 0.3287, d_k_M range: [0.0029, 0.3650], d_k_M_hat range: [0.4798, 0.9827]
2025-03-11 20:23:15 - Train Iteration 4590: loss: 0.6916, d_k_M range: [0.0012, 0.5013], d_k_M_hat range: [0.1695, 0.9974]
2025-03-11 20:23:15 - Train Iteration 4591: loss: 0.3134, d_k_M range: [0.0069, 0.5527], d_k_M_hat range: [0.4943, 0.9929]
2025-03-11 20:23:16 - Train Iteration 4592: loss: 0.2138, d_k_M range: [0.0059, 0.3633], d_k_M_hat range: [0.5435, 0.9806]
2025-03-11 20:23:16 - Train Iteration 4593: loss: 0.2319, d_k_M range: [0.0071, 0.3586], d_k_M_hat range: [0.5255, 0.9276]
2025-03-11 20:23:17 - Train Iteration 4594: loss: 0.2931, d_k_M range: [0.0039, 0.4361], d_k_M_hat range: [0.4658, 0.9884]
2025-03-11 20:23:17 - Train Iteration 4595: loss: 0.3094, d_k_M range: [0.0026, 0.5279], d_k_M_hat range: [0.4463, 0.9931]
2025-03-11 20:23:17 - Train Iteration 4596: loss: 0.2419, d_k_M range: [0.0107, 0.4298], d_k_M_hat range: [0.5189, 0.9542]
2025-03-11 20:23:18 - Train Iteration 4597: loss: 0.2656, d_k_M range: [0.0018, 0.3747], d_k_M_hat range: [0.5417, 0.9292]
2025-03-11 20:23:18 - Train Iteration 4598: loss: 0.2773, d_k_M range: [0.0501, 0.5050], d_k_M_hat range: [0.6132, 0.9784]
2025-03-11 20:23:19 - Train Iteration 4599: loss: 0.2825, d_k_M range: [0.0021, 0.2851], d_k_M_hat range: [0.4830, 0.9227]
2025-03-11 20:23:19 - Train Iteration 4600: loss: 0.6927, d_k_M range: [0.0145, 0.8249], d_k_M_hat range: [0.5257, 0.9926]
2025-03-11 20:23:19 - Train Iteration 4601: loss: 0.2422, d_k_M range: [0.0064, 0.4594], d_k_M_hat range: [0.6161, 0.9673]
2025-03-11 20:23:20 - Train Iteration 4602: loss: 0.2520, d_k_M range: [0.0303, 0.3048], d_k_M_hat range: [0.5322, 0.8679]
2025-03-11 20:23:20 - Train Iteration 4603: loss: 0.4216, d_k_M range: [0.0024, 0.4555], d_k_M_hat range: [0.3531, 0.9424]
2025-03-11 20:23:21 - Train Iteration 4604: loss: 0.4237, d_k_M range: [0.0317, 0.6503], d_k_M_hat range: [0.6384, 0.9993]
2025-03-11 20:23:21 - Train Iteration 4605: loss: 0.3328, d_k_M range: [0.0025, 0.3978], d_k_M_hat range: [0.4365, 0.9649]
2025-03-11 20:23:22 - Train Iteration 4606: loss: 0.3001, d_k_M range: [0.0271, 0.5274], d_k_M_hat range: [0.7067, 0.9979]
2025-03-11 20:23:22 - Train Iteration 4607: loss: 0.3058, d_k_M range: [0.0096, 0.3409], d_k_M_hat range: [0.4809, 0.7952]
2025-03-11 20:23:22 - Train Iteration 4608: loss: 0.3753, d_k_M range: [0.0092, 0.4437], d_k_M_hat range: [0.4724, 0.9865]
2025-03-11 20:23:23 - Train Iteration 4609: loss: 0.3379, d_k_M range: [0.1206, 0.5565], d_k_M_hat range: [0.8722, 0.9948]
2025-03-11 20:23:23 - Train Iteration 4610: loss: 0.2821, d_k_M range: [0.0005, 0.3997], d_k_M_hat range: [0.4695, 0.9413]
2025-03-11 20:23:24 - Train Iteration 4611: loss: 0.3057, d_k_M range: [0.0334, 0.5215], d_k_M_hat range: [0.5612, 0.9686]
2025-03-11 20:23:24 - Train Iteration 4612: loss: 0.3915, d_k_M range: [0.0006, 0.2225], d_k_M_hat range: [0.3750, 0.9068]
2025-03-11 20:23:25 - Train Iteration 4613: loss: 0.2779, d_k_M range: [0.0971, 0.3339], d_k_M_hat range: [0.6245, 0.9648]
2025-03-11 20:23:25 - Train Iteration 4614: loss: 0.2985, d_k_M range: [0.0013, 0.1912], d_k_M_hat range: [0.4549, 0.7996]
2025-03-11 20:23:26 - Train Iteration 4615: loss: 0.2131, d_k_M range: [0.0459, 0.4198], d_k_M_hat range: [0.6227, 0.9581]
2025-03-11 20:23:26 - Train Iteration 4616: loss: 0.2351, d_k_M range: [0.0432, 0.3750], d_k_M_hat range: [0.6158, 0.9592]
2025-03-11 20:23:26 - Train Iteration 4617: loss: 0.5132, d_k_M range: [0.0003, 0.0518], d_k_M_hat range: [0.2840, 0.7352]
2025-03-11 20:23:27 - Train Iteration 4618: loss: 0.3215, d_k_M range: [0.0149, 0.5594], d_k_M_hat range: [0.5119, 0.9924]
2025-03-11 20:23:27 - Train Iteration 4619: loss: 0.8814, d_k_M range: [0.0004, 0.0617], d_k_M_hat range: [0.0616, 0.6616]
2025-03-11 20:23:28 - Train Iteration 4620: loss: 0.4778, d_k_M range: [0.1285, 0.6616], d_k_M_hat range: [0.8349, 0.9785]
2025-03-11 20:23:28 - Train Iteration 4621: loss: 0.2965, d_k_M range: [0.0130, 0.3734], d_k_M_hat range: [0.5698, 0.8913]
2025-03-11 20:23:28 - Train Iteration 4622: loss: 0.3286, d_k_M range: [0.0006, 0.2403], d_k_M_hat range: [0.4274, 0.8292]
2025-03-11 20:23:29 - Train Iteration 4623: loss: 0.3551, d_k_M range: [0.0442, 0.4643], d_k_M_hat range: [0.6579, 0.9640]
2025-03-11 20:23:29 - Train Iteration 4624: loss: 0.2275, d_k_M range: [0.0019, 0.4442], d_k_M_hat range: [0.5907, 0.9725]
2025-03-11 20:23:30 - Train Iteration 4625: loss: 0.3509, d_k_M range: [0.0020, 0.5041], d_k_M_hat range: [0.5416, 0.9935]
2025-03-11 20:23:30 - Train Iteration 4626: loss: 0.3067, d_k_M range: [0.0127, 0.4697], d_k_M_hat range: [0.5929, 0.9953]
2025-03-11 20:23:30 - Train Iteration 4627: loss: 0.5245, d_k_M range: [0.0101, 0.3505], d_k_M_hat range: [0.2859, 0.9671]
2025-03-11 20:23:31 - Train Iteration 4628: loss: 0.4070, d_k_M range: [0.3306, 0.6332], d_k_M_hat range: [0.9351, 0.9952]
2025-03-11 20:23:31 - Train Iteration 4629: loss: 0.2793, d_k_M range: [0.0229, 0.5195], d_k_M_hat range: [0.6777, 0.9910]
2025-03-11 20:23:32 - Train Iteration 4630: loss: 0.4142, d_k_M range: [0.0072, 0.4689], d_k_M_hat range: [0.4060, 0.9726]
2025-03-11 20:23:32 - Train Iteration 4631: loss: 0.4391, d_k_M range: [0.0297, 0.6483], d_k_M_hat range: [0.6879, 0.9857]
2025-03-11 20:23:33 - Train Iteration 4632: loss: 0.4580, d_k_M range: [0.0006, 0.0665], d_k_M_hat range: [0.3238, 0.7507]
2025-03-11 20:23:33 - Train Iteration 4633: loss: 0.4381, d_k_M range: [0.1432, 0.4879], d_k_M_hat range: [0.5053, 0.9871]
2025-03-11 20:23:33 - Train Iteration 4634: loss: 0.4102, d_k_M range: [0.0217, 0.6384], d_k_M_hat range: [0.6236, 0.9979]
2025-03-11 20:23:34 - Train Iteration 4635: loss: 0.3129, d_k_M range: [0.0003, 0.1020], d_k_M_hat range: [0.4409, 0.8339]
2025-03-11 20:23:34 - Train Iteration 4636: loss: 0.6854, d_k_M range: [0.0142, 0.8260], d_k_M_hat range: [0.5418, 0.9981]
2025-03-11 20:23:35 - Train Iteration 4637: loss: 0.7350, d_k_M range: [0.0001, 0.2828], d_k_M_hat range: [0.1428, 0.6943]
2025-03-11 20:23:35 - Train Iteration 4638: loss: 0.3636, d_k_M range: [0.0178, 0.5939], d_k_M_hat range: [0.6683, 0.9974]
2025-03-11 20:23:35 - Train Iteration 4639: loss: 0.2767, d_k_M range: [0.0017, 0.2936], d_k_M_hat range: [0.4757, 0.8406]
2025-03-11 20:23:36 - Train Iteration 4640: loss: 0.3334, d_k_M range: [0.0052, 0.5693], d_k_M_hat range: [0.4779, 0.9919]
2025-03-11 20:23:36 - Train Iteration 4641: loss: 0.3421, d_k_M range: [0.0038, 0.3570], d_k_M_hat range: [0.4190, 0.9496]
2025-03-11 20:23:37 - Train Iteration 4642: loss: 0.3295, d_k_M range: [0.0541, 0.5667], d_k_M_hat range: [0.6840, 0.9971]
2025-03-11 20:23:37 - Train Iteration 4643: loss: 0.2741, d_k_M range: [0.0059, 0.4455], d_k_M_hat range: [0.4840, 0.9842]
2025-03-11 20:23:38 - Train Iteration 4644: loss: 0.9874, d_k_M range: [0.0002, 0.2763], d_k_M_hat range: [0.0065, 0.8812]
2025-03-11 20:23:38 - Train Iteration 4645: loss: 0.2294, d_k_M range: [0.0025, 0.3457], d_k_M_hat range: [0.5507, 0.9500]
2025-03-11 20:23:38 - Train Iteration 4646: loss: 0.2253, d_k_M range: [0.0086, 0.4468], d_k_M_hat range: [0.5675, 0.9819]
2025-03-11 20:23:39 - Train Iteration 4647: loss: 0.2422, d_k_M range: [0.0039, 0.3909], d_k_M_hat range: [0.5245, 0.9524]
2025-03-11 20:23:39 - Train Iteration 4648: loss: 0.7684, d_k_M range: [0.0232, 0.8756], d_k_M_hat range: [0.7602, 0.9990]
2025-03-11 20:23:40 - Train Iteration 4649: loss: 0.3325, d_k_M range: [0.0050, 0.4933], d_k_M_hat range: [0.5042, 0.9909]
2025-03-11 20:23:40 - Train Iteration 4650: loss: 0.2642, d_k_M range: [0.0642, 0.4789], d_k_M_hat range: [0.7453, 0.9876]
2025-03-11 20:23:40 - Train Iteration 4651: loss: 0.2472, d_k_M range: [0.0011, 0.3607], d_k_M_hat range: [0.5129, 0.9618]
2025-03-11 20:23:41 - Train Iteration 4652: loss: 0.2758, d_k_M range: [0.1663, 0.4718], d_k_M_hat range: [0.7588, 0.9898]
2025-03-11 20:23:41 - Train Iteration 4653: loss: 0.3107, d_k_M range: [0.0178, 0.2985], d_k_M_hat range: [0.4604, 0.9511]
2025-03-11 20:23:42 - Train Iteration 4654: loss: 0.3622, d_k_M range: [0.0015, 0.4586], d_k_M_hat range: [0.3997, 0.9771]
2025-03-11 20:23:42 - Train Iteration 4655: loss: 0.3512, d_k_M range: [0.2900, 0.5311], d_k_M_hat range: [0.8126, 0.9825]
2025-03-11 20:23:42 - Train Iteration 4656: loss: 0.2983, d_k_M range: [0.0029, 0.5250], d_k_M_hat range: [0.5311, 0.9788]
2025-03-11 20:23:43 - Train Iteration 4657: loss: 0.2958, d_k_M range: [0.0043, 0.4245], d_k_M_hat range: [0.4647, 0.9591]
2025-03-11 20:23:43 - Train Iteration 4658: loss: 0.2232, d_k_M range: [0.1650, 0.4190], d_k_M_hat range: [0.8201, 0.9750]
2025-03-11 20:23:44 - Train Iteration 4659: loss: 0.2901, d_k_M range: [0.0021, 0.4035], d_k_M_hat range: [0.4716, 0.8726]
2025-03-11 20:23:44 - Train Iteration 4660: loss: 0.2297, d_k_M range: [0.0015, 0.3541], d_k_M_hat range: [0.5222, 0.9548]
2025-03-11 20:23:45 - Train Iteration 4661: loss: 0.3843, d_k_M range: [0.0044, 0.6041], d_k_M_hat range: [0.4717, 0.9853]
2025-03-11 20:23:45 - Train Iteration 4662: loss: 0.3239, d_k_M range: [0.0186, 0.5452], d_k_M_hat range: [0.7052, 0.9761]
2025-03-11 20:23:45 - Train Iteration 4663: loss: 0.4642, d_k_M range: [0.0452, 0.6755], d_k_M_hat range: [0.5607, 0.9942]
2025-03-11 20:23:46 - Train Iteration 4664: loss: 0.4957, d_k_M range: [0.0016, 0.2586], d_k_M_hat range: [0.2975, 0.9567]
2025-03-11 20:23:46 - Train Iteration 4665: loss: 0.2393, d_k_M range: [0.0217, 0.4858], d_k_M_hat range: [0.5633, 0.9966]
2025-03-11 20:23:47 - Train Iteration 4666: loss: 0.3530, d_k_M range: [0.0005, 0.3895], d_k_M_hat range: [0.4064, 0.9760]
2025-03-11 20:23:47 - Train Iteration 4667: loss: 0.3141, d_k_M range: [0.0026, 0.4690], d_k_M_hat range: [0.4429, 0.9731]
2025-03-11 20:23:48 - Train Iteration 4668: loss: 0.3896, d_k_M range: [0.0238, 0.5148], d_k_M_hat range: [0.6740, 0.9916]
2025-03-11 20:23:48 - Train Iteration 4669: loss: 0.4647, d_k_M range: [0.0023, 0.3077], d_k_M_hat range: [0.3212, 0.9155]
2025-03-11 20:23:48 - Train Iteration 4670: loss: 0.2684, d_k_M range: [0.0006, 0.4249], d_k_M_hat range: [0.4868, 0.9760]
2025-03-11 20:23:49 - Train Iteration 4671: loss: 0.2623, d_k_M range: [0.0349, 0.4576], d_k_M_hat range: [0.5456, 0.9923]
2025-03-11 20:23:49 - Train Iteration 4672: loss: 0.2821, d_k_M range: [0.0106, 0.5018], d_k_M_hat range: [0.4863, 0.9862]
2025-03-11 20:23:50 - Train Iteration 4673: loss: 0.2825, d_k_M range: [0.0064, 0.3669], d_k_M_hat range: [0.4750, 0.9327]
2025-03-11 20:23:50 - Train Iteration 4674: loss: 0.4894, d_k_M range: [0.1043, 0.6974], d_k_M_hat range: [0.9125, 0.9978]
2025-03-11 20:23:51 - Train Iteration 4675: loss: 0.5517, d_k_M range: [0.0003, 0.2179], d_k_M_hat range: [0.2575, 0.9121]
2025-03-11 20:23:51 - Train Iteration 4676: loss: 0.4266, d_k_M range: [0.0273, 0.6471], d_k_M_hat range: [0.7159, 0.9939]
2025-03-11 20:23:51 - Train Iteration 4677: loss: 0.3377, d_k_M range: [0.0201, 0.5772], d_k_M_hat range: [0.5855, 0.9961]
2025-03-11 20:23:52 - Train Iteration 4678: loss: 0.3679, d_k_M range: [0.0099, 0.5573], d_k_M_hat range: [0.5333, 0.9507]
2025-03-11 20:23:52 - Train Iteration 4679: loss: 0.2505, d_k_M range: [0.0331, 0.4453], d_k_M_hat range: [0.5380, 0.9730]
2025-03-11 20:23:53 - Train Iteration 4680: loss: 0.3479, d_k_M range: [0.0701, 0.5754], d_k_M_hat range: [0.6570, 0.9855]
2025-03-11 20:23:53 - Train Iteration 4681: loss: 0.3451, d_k_M range: [0.0733, 0.5625], d_k_M_hat range: [0.6595, 0.9911]
2025-03-11 20:23:53 - Train Iteration 4682: loss: 0.3232, d_k_M range: [0.0170, 0.2807], d_k_M_hat range: [0.5217, 0.8540]
2025-03-11 20:23:54 - Train Iteration 4683: loss: 0.2869, d_k_M range: [0.0022, 0.4077], d_k_M_hat range: [0.4666, 0.9046]
2025-03-11 20:23:54 - Train Iteration 4684: loss: 0.3003, d_k_M range: [0.0528, 0.5319], d_k_M_hat range: [0.6748, 0.9839]
2025-03-11 20:23:55 - Train Iteration 4685: loss: 0.3385, d_k_M range: [0.0300, 0.5786], d_k_M_hat range: [0.5394, 0.9968]
2025-03-11 20:23:55 - Train Iteration 4686: loss: 0.2692, d_k_M range: [0.0033, 0.2441], d_k_M_hat range: [0.5086, 0.8134]
2025-03-11 20:23:55 - Train Iteration 4687: loss: 0.3012, d_k_M range: [0.0005, 0.3292], d_k_M_hat range: [0.4549, 0.8872]
2025-03-11 20:23:56 - Train Iteration 4688: loss: 0.3108, d_k_M range: [0.0007, 0.2912], d_k_M_hat range: [0.4432, 0.9356]
2025-03-11 20:23:56 - Train Iteration 4689: loss: 0.3568, d_k_M range: [0.0035, 0.5386], d_k_M_hat range: [0.4062, 0.9921]
2025-03-11 20:23:57 - Train Iteration 4690: loss: 0.2704, d_k_M range: [0.0213, 0.1542], d_k_M_hat range: [0.5013, 0.8848]
2025-03-11 20:23:57 - Train Iteration 4691: loss: 0.2665, d_k_M range: [0.0047, 0.4229], d_k_M_hat range: [0.5003, 0.9901]
2025-03-11 20:23:57 - Train Iteration 4692: loss: 0.7076, d_k_M range: [0.0247, 0.8405], d_k_M_hat range: [0.5514, 0.9994]
2025-03-11 20:23:58 - Train Iteration 4693: loss: 0.5071, d_k_M range: [0.0001, 0.4552], d_k_M_hat range: [0.2880, 0.9649]
2025-03-11 20:23:58 - Train Iteration 4694: loss: 0.3029, d_k_M range: [0.0039, 0.3802], d_k_M_hat range: [0.5237, 0.8915]
2025-03-11 20:23:59 - Train Iteration 4695: loss: 0.2661, d_k_M range: [0.0003, 0.4708], d_k_M_hat range: [0.5349, 0.9550]
2025-03-11 20:23:59 - Train Iteration 4696: loss: 0.3803, d_k_M range: [0.0020, 0.5282], d_k_M_hat range: [0.3868, 0.9922]
2025-03-11 20:24:00 - Train Iteration 4697: loss: 0.2690, d_k_M range: [0.1547, 0.4508], d_k_M_hat range: [0.7455, 0.9797]
2025-03-11 20:24:00 - Train Iteration 4698: loss: 0.4074, d_k_M range: [0.0118, 0.3685], d_k_M_hat range: [0.3851, 0.9339]
2025-03-11 20:24:00 - Train Iteration 4699: loss: 0.2630, d_k_M range: [0.0040, 0.4026], d_k_M_hat range: [0.4912, 0.9547]
2025-03-11 20:24:01 - Train Iteration 4700: loss: 0.3854, d_k_M range: [0.0038, 0.4493], d_k_M_hat range: [0.3830, 0.9847]
2025-03-11 20:24:01 - Train Iteration 4701: loss: 0.2896, d_k_M range: [0.0116, 0.4783], d_k_M_hat range: [0.4734, 0.9907]
2025-03-11 20:24:02 - Train Iteration 4702: loss: 0.3347, d_k_M range: [0.1211, 0.5780], d_k_M_hat range: [0.8591, 0.9995]
2025-03-11 20:24:02 - Train Iteration 4703: loss: 0.2451, d_k_M range: [0.0120, 0.4778], d_k_M_hat range: [0.5169, 0.9947]
2025-03-11 20:24:03 - Train Iteration 4704: loss: 0.3555, d_k_M range: [0.0001, 0.4432], d_k_M_hat range: [0.4039, 0.9468]
2025-03-11 20:24:03 - Train Iteration 4705: loss: 0.3503, d_k_M range: [0.0002, 0.4250], d_k_M_hat range: [0.4083, 0.9711]
2025-03-11 20:24:03 - Train Iteration 4706: loss: 0.3595, d_k_M range: [0.0040, 0.5880], d_k_M_hat range: [0.4736, 0.9884]
2025-03-11 20:24:04 - Train Iteration 4707: loss: 0.4460, d_k_M range: [0.0010, 0.1961], d_k_M_hat range: [0.3437, 0.7619]
2025-03-11 20:24:04 - Train Iteration 4708: loss: 0.2079, d_k_M range: [0.0116, 0.4363], d_k_M_hat range: [0.5887, 0.9877]
2025-03-11 20:24:05 - Train Iteration 4709: loss: 0.4973, d_k_M range: [0.0013, 0.2505], d_k_M_hat range: [0.2960, 0.8836]
2025-03-11 20:24:05 - Train Iteration 4710: loss: 0.3027, d_k_M range: [0.0113, 0.4051], d_k_M_hat range: [0.4724, 0.9886]
2025-03-11 20:24:05 - Train Iteration 4711: loss: 0.2995, d_k_M range: [0.0031, 0.4064], d_k_M_hat range: [0.4558, 0.9700]
2025-03-11 20:24:06 - Train Iteration 4712: loss: 0.3377, d_k_M range: [0.0025, 0.3925], d_k_M_hat range: [0.4214, 0.9426]
2025-03-11 20:24:06 - Train Iteration 4713: loss: 0.2483, d_k_M range: [0.0519, 0.4861], d_k_M_hat range: [0.7811, 0.9878]
2025-03-11 20:24:07 - Train Iteration 4714: loss: 0.2810, d_k_M range: [0.0044, 0.5026], d_k_M_hat range: [0.5951, 0.9959]
2025-03-11 20:24:07 - Train Iteration 4715: loss: 0.2145, d_k_M range: [0.0313, 0.3743], d_k_M_hat range: [0.5682, 0.9492]
2025-03-11 20:24:08 - Train Iteration 4716: loss: 0.4724, d_k_M range: [0.0524, 0.6190], d_k_M_hat range: [0.6845, 0.9655]
2025-03-11 20:24:08 - Train Iteration 4717: loss: 0.3142, d_k_M range: [0.0147, 0.3901], d_k_M_hat range: [0.4626, 0.9363]
2025-03-11 20:24:09 - Train Iteration 4718: loss: 0.3237, d_k_M range: [0.0190, 0.4554], d_k_M_hat range: [0.6094, 0.9663]
2025-03-11 20:24:09 - Train Iteration 4719: loss: 0.3901, d_k_M range: [0.0015, 0.5272], d_k_M_hat range: [0.3787, 0.9725]
2025-03-11 20:24:09 - Train Iteration 4720: loss: 0.6135, d_k_M range: [0.3693, 0.7822], d_k_M_hat range: [0.9251, 0.9990]
2025-03-11 20:24:10 - Train Iteration 4721: loss: 0.3137, d_k_M range: [0.0096, 0.4071], d_k_M_hat range: [0.5050, 0.9372]
2025-03-11 20:24:10 - Train Iteration 4722: loss: 0.2517, d_k_M range: [0.0095, 0.3122], d_k_M_hat range: [0.5312, 0.8998]
2025-03-11 20:24:11 - Train Iteration 4723: loss: 0.6101, d_k_M range: [0.0005, 0.3607], d_k_M_hat range: [0.2194, 0.9247]
2025-03-11 20:24:11 - Train Iteration 4724: loss: 0.8786, d_k_M range: [0.2406, 0.9362], d_k_M_hat range: [0.8197, 0.9989]
2025-03-11 20:24:12 - Train Iteration 4725: loss: 0.3624, d_k_M range: [0.1746, 0.5946], d_k_M_hat range: [0.6936, 0.9926]
2025-03-11 20:24:12 - Train Iteration 4726: loss: 0.3280, d_k_M range: [0.0087, 0.2668], d_k_M_hat range: [0.4776, 0.8641]
2025-03-11 20:24:13 - Train Iteration 4727: loss: 0.3308, d_k_M range: [0.0003, 0.3041], d_k_M_hat range: [0.4251, 0.7636]
2025-03-11 20:24:13 - Train Iteration 4728: loss: 0.3973, d_k_M range: [0.0168, 0.5829], d_k_M_hat range: [0.5793, 0.9631]
2025-03-11 20:24:13 - Train Iteration 4729: loss: 0.2434, d_k_M range: [0.0057, 0.3437], d_k_M_hat range: [0.5263, 0.9044]
2025-03-11 20:24:14 - Train Iteration 4730: loss: 0.2752, d_k_M range: [0.0218, 0.4781], d_k_M_hat range: [0.6275, 0.9811]
2025-03-11 20:24:14 - Train Iteration 4731: loss: 0.3765, d_k_M range: [0.0009, 0.3991], d_k_M_hat range: [0.3886, 0.8535]
2025-03-11 20:24:15 - Train Iteration 4732: loss: 0.3124, d_k_M range: [0.0007, 0.4314], d_k_M_hat range: [0.4439, 0.9232]
2025-03-11 20:24:15 - Train Iteration 4733: loss: 0.3016, d_k_M range: [0.0034, 0.2931], d_k_M_hat range: [0.5008, 0.8303]
2025-03-11 20:24:15 - Train Iteration 4734: loss: 0.2671, d_k_M range: [0.1072, 0.5081], d_k_M_hat range: [0.7294, 0.9913]
2025-03-11 20:24:16 - Train Iteration 4735: loss: 0.2617, d_k_M range: [0.0070, 0.4319], d_k_M_hat range: [0.5106, 0.9826]
2025-03-11 20:24:16 - Train Iteration 4736: loss: 0.3349, d_k_M range: [0.0288, 0.5773], d_k_M_hat range: [0.5745, 0.9986]
2025-03-11 20:24:17 - Train Iteration 4737: loss: 0.2780, d_k_M range: [0.0069, 0.4646], d_k_M_hat range: [0.5213, 0.9880]
2025-03-11 20:24:17 - Train Iteration 4738: loss: 0.4499, d_k_M range: [0.2174, 0.6680], d_k_M_hat range: [0.8738, 0.9972]
2025-03-11 20:24:18 - Train Iteration 4739: loss: 0.6014, d_k_M range: [0.0001, 0.4131], d_k_M_hat range: [0.2355, 0.9686]
2025-03-11 20:24:18 - Train Iteration 4740: loss: 0.8048, d_k_M range: [0.2551, 0.8946], d_k_M_hat range: [0.8655, 0.9976]
2025-03-11 20:24:18 - Train Iteration 4741: loss: 0.3104, d_k_M range: [0.0003, 0.3454], d_k_M_hat range: [0.4433, 0.9114]
2025-03-11 20:24:19 - Train Iteration 4742: loss: 0.2919, d_k_M range: [0.0012, 0.3949], d_k_M_hat range: [0.4762, 0.9725]
2025-03-11 20:24:19 - Train Iteration 4743: loss: 0.5552, d_k_M range: [0.0069, 0.7421], d_k_M_hat range: [0.5119, 0.9970]
2025-03-11 20:24:20 - Train Iteration 4744: loss: 0.4158, d_k_M range: [0.0002, 0.2098], d_k_M_hat range: [0.3554, 0.7957]
2025-03-11 20:24:20 - Train Iteration 4745: loss: 0.3047, d_k_M range: [0.0013, 0.4894], d_k_M_hat range: [0.4493, 0.9794]
2025-03-11 20:24:20 - Train Iteration 4746: loss: 0.2688, d_k_M range: [0.0025, 0.4109], d_k_M_hat range: [0.4840, 0.9897]
2025-03-11 20:24:21 - Train Iteration 4747: loss: 0.2965, d_k_M range: [0.0040, 0.4399], d_k_M_hat range: [0.4595, 0.9699]
2025-03-11 20:24:21 - Train Iteration 4748: loss: 0.2851, d_k_M range: [0.0051, 0.3811], d_k_M_hat range: [0.4711, 0.9547]
2025-03-11 20:24:22 - Train Iteration 4749: loss: 0.2749, d_k_M range: [0.0076, 0.3232], d_k_M_hat range: [0.5205, 0.9499]
2025-03-11 20:24:22 - Train Iteration 4750: loss: 0.3124, d_k_M range: [0.0066, 0.5558], d_k_M_hat range: [0.5196, 0.9969]
2025-03-11 20:24:22 - Train Iteration 4751: loss: 0.3990, d_k_M range: [0.0026, 0.3499], d_k_M_hat range: [0.3782, 0.9590]
2025-03-11 20:24:23 - Train Iteration 4752: loss: 0.2666, d_k_M range: [0.1374, 0.4969], d_k_M_hat range: [0.8168, 0.9873]
2025-03-11 20:24:23 - Train Iteration 4753: loss: 0.2352, d_k_M range: [0.0176, 0.4671], d_k_M_hat range: [0.5660, 0.9821]
2025-03-11 20:24:24 - Train Iteration 4754: loss: 0.5234, d_k_M range: [0.0004, 0.1490], d_k_M_hat range: [0.2770, 0.7427]
2025-03-11 20:24:24 - Train Iteration 4755: loss: 0.2039, d_k_M range: [0.0221, 0.4296], d_k_M_hat range: [0.7376, 0.9822]
2025-03-11 20:24:25 - Train Iteration 4756: loss: 0.2541, d_k_M range: [0.0023, 0.4203], d_k_M_hat range: [0.4989, 0.9558]
2025-03-11 20:24:25 - Train Iteration 4757: loss: 0.4600, d_k_M range: [0.0028, 0.3907], d_k_M_hat range: [0.3246, 0.9578]
2025-03-11 20:24:26 - Train Iteration 4758: loss: 0.3078, d_k_M range: [0.0029, 0.5419], d_k_M_hat range: [0.5262, 0.9871]
2025-03-11 20:24:26 - Train Iteration 4759: loss: 0.5525, d_k_M range: [0.0013, 0.3830], d_k_M_hat range: [0.2654, 0.9438]
2025-03-11 20:24:27 - Train Iteration 4760: loss: 0.7027, d_k_M range: [0.0155, 0.8357], d_k_M_hat range: [0.5423, 0.9993]
2025-03-11 20:24:27 - Train Iteration 4761: loss: 0.4724, d_k_M range: [0.0171, 0.6835], d_k_M_hat range: [0.5476, 0.9962]
2025-03-11 20:24:27 - Train Iteration 4762: loss: 0.3376, d_k_M range: [0.0012, 0.3763], d_k_M_hat range: [0.4202, 0.9607]
2025-03-11 20:24:28 - Train Iteration 4763: loss: 0.3155, d_k_M range: [0.0024, 0.5050], d_k_M_hat range: [0.4406, 0.9812]
2025-03-11 20:24:28 - Train Iteration 4764: loss: 0.2743, d_k_M range: [0.0302, 0.4173], d_k_M_hat range: [0.5717, 0.9841]
2025-03-11 20:24:29 - Train Iteration 4765: loss: 0.3224, d_k_M range: [0.0133, 0.4678], d_k_M_hat range: [0.4455, 0.9974]
2025-03-11 20:24:29 - Train Iteration 4766: loss: 0.4066, d_k_M range: [0.0005, 0.1622], d_k_M_hat range: [0.3629, 0.8861]
2025-03-11 20:24:30 - Train Iteration 4767: loss: 0.2888, d_k_M range: [0.0220, 0.4401], d_k_M_hat range: [0.4846, 0.9830]
2025-03-11 20:24:30 - Train Iteration 4768: loss: 0.3631, d_k_M range: [0.0002, 0.4213], d_k_M_hat range: [0.3994, 0.9825]
2025-03-11 20:24:31 - Train Iteration 4769: loss: 0.2364, d_k_M range: [0.0019, 0.2070], d_k_M_hat range: [0.5157, 0.7926]
2025-03-11 20:24:31 - Train Iteration 4770: loss: 0.4803, d_k_M range: [0.0135, 0.6914], d_k_M_hat range: [0.5291, 0.9983]
2025-03-11 20:24:31 - Train Iteration 4771: loss: 0.3374, d_k_M range: [0.0078, 0.5671], d_k_M_hat range: [0.5257, 0.9862]
2025-03-11 20:24:32 - Train Iteration 4772: loss: 0.4148, d_k_M range: [0.0001, 0.1534], d_k_M_hat range: [0.3560, 0.9312]
2025-03-11 20:24:32 - Train Iteration 4773: loss: 0.2102, d_k_M range: [0.0063, 0.3108], d_k_M_hat range: [0.5713, 0.8787]
2025-03-11 20:24:33 - Train Iteration 4774: loss: 0.2879, d_k_M range: [0.0030, 0.4829], d_k_M_hat range: [0.5312, 0.9832]
2025-03-11 20:24:33 - Train Iteration 4775: loss: 0.2527, d_k_M range: [0.0471, 0.4838], d_k_M_hat range: [0.7239, 0.9873]
2025-03-11 20:24:34 - Train Iteration 4776: loss: 0.4021, d_k_M range: [0.0706, 0.6166], d_k_M_hat range: [0.6679, 0.9871]
2025-03-11 20:24:34 - Train Iteration 4777: loss: 0.3670, d_k_M range: [0.0016, 0.0772], d_k_M_hat range: [0.3958, 0.6202]
2025-03-11 20:24:35 - Train Iteration 4778: loss: 0.4534, d_k_M range: [0.1322, 0.6686], d_k_M_hat range: [0.7940, 0.9952]
2025-03-11 20:24:35 - Train Iteration 4779: loss: 0.2433, d_k_M range: [0.0015, 0.3145], d_k_M_hat range: [0.5194, 0.9326]
2025-03-11 20:24:35 - Train Iteration 4780: loss: 0.3302, d_k_M range: [0.0090, 0.5480], d_k_M_hat range: [0.6480, 0.9733]
2025-03-11 20:24:36 - Train Iteration 4781: loss: 0.2820, d_k_M range: [0.0022, 0.3389], d_k_M_hat range: [0.4711, 0.9734]
2025-03-11 20:24:36 - Train Iteration 4782: loss: 0.4239, d_k_M range: [0.1340, 0.6492], d_k_M_hat range: [0.8282, 0.9982]
2025-03-11 20:24:37 - Train Iteration 4783: loss: 0.1796, d_k_M range: [0.0151, 0.2916], d_k_M_hat range: [0.5913, 0.8975]
2025-03-11 20:24:37 - Train Iteration 4784: loss: 0.4276, d_k_M range: [0.0420, 0.6266], d_k_M_hat range: [0.6606, 0.9843]
2025-03-11 20:24:38 - Train Iteration 4785: loss: 0.2736, d_k_M range: [0.0031, 0.4993], d_k_M_hat range: [0.5394, 0.9899]
2025-03-11 20:24:38 - Train Iteration 4786: loss: 0.3358, d_k_M range: [0.3174, 0.5781], d_k_M_hat range: [0.8969, 0.9986]
2025-03-11 20:24:38 - Train Iteration 4787: loss: 0.2179, d_k_M range: [0.0566, 0.3814], d_k_M_hat range: [0.6725, 0.9698]
2025-03-11 20:24:39 - Train Iteration 4788: loss: 0.2348, d_k_M range: [0.0033, 0.4733], d_k_M_hat range: [0.5510, 0.9887]
2025-03-11 20:24:39 - Train Iteration 4789: loss: 0.2857, d_k_M range: [0.0018, 0.2591], d_k_M_hat range: [0.4672, 0.9023]
2025-03-11 20:24:40 - Train Iteration 4790: loss: 0.2558, d_k_M range: [0.0081, 0.4325], d_k_M_hat range: [0.5775, 0.9267]
2025-03-11 20:24:40 - Train Iteration 4791: loss: 0.2316, d_k_M range: [0.0011, 0.1209], d_k_M_hat range: [0.5204, 0.8580]
2025-03-11 20:24:40 - Train Iteration 4792: loss: 0.3064, d_k_M range: [0.0549, 0.5097], d_k_M_hat range: [0.7073, 0.9968]
2025-03-11 20:24:41 - Train Iteration 4793: loss: 0.2693, d_k_M range: [0.0021, 0.3645], d_k_M_hat range: [0.4950, 0.9696]
2025-03-11 20:24:41 - Train Iteration 4794: loss: 0.3047, d_k_M range: [0.0038, 0.0539], d_k_M_hat range: [0.4518, 0.8541]
2025-03-11 20:24:42 - Train Iteration 4795: loss: 0.2634, d_k_M range: [0.0020, 0.2701], d_k_M_hat range: [0.4888, 0.9609]
2025-03-11 20:24:42 - Train Iteration 4796: loss: 0.2576, d_k_M range: [0.0060, 0.5019], d_k_M_hat range: [0.5355, 0.9944]
2025-03-11 20:24:43 - Train Iteration 4797: loss: 0.2930, d_k_M range: [0.0035, 0.4910], d_k_M_hat range: [0.4995, 0.9894]
2025-03-11 20:24:43 - Train Iteration 4798: loss: 0.2706, d_k_M range: [0.0162, 0.4445], d_k_M_hat range: [0.6139, 0.9679]
2025-03-11 20:24:43 - Train Iteration 4799: loss: 0.2432, d_k_M range: [0.0045, 0.3617], d_k_M_hat range: [0.5887, 0.9122]
2025-03-11 20:24:44 - Train Iteration 4800: loss: 0.3304, d_k_M range: [0.0001, 0.2936], d_k_M_hat range: [0.4253, 0.9220]
2025-03-11 20:24:44 - Train Iteration 4801: loss: 0.3529, d_k_M range: [0.0012, 0.4502], d_k_M_hat range: [0.4072, 0.9814]
2025-03-11 20:24:45 - Train Iteration 4802: loss: 0.5837, d_k_M range: [0.0006, 0.3471], d_k_M_hat range: [0.2366, 0.9016]
2025-03-11 20:24:45 - Train Iteration 4803: loss: 0.2181, d_k_M range: [0.0109, 0.4521], d_k_M_hat range: [0.7030, 0.9871]
2025-03-11 20:24:45 - Train Iteration 4804: loss: 0.3105, d_k_M range: [0.0008, 0.4874], d_k_M_hat range: [0.4435, 0.9831]
2025-03-11 20:24:46 - Train Iteration 4805: loss: 0.5817, d_k_M range: [0.0003, 0.2155], d_k_M_hat range: [0.2376, 0.9180]
2025-03-11 20:24:46 - Train Iteration 4806: loss: 0.2786, d_k_M range: [0.0042, 0.4858], d_k_M_hat range: [0.4764, 0.9821]
2025-03-11 20:24:47 - Train Iteration 4807: loss: 0.3433, d_k_M range: [0.1252, 0.4779], d_k_M_hat range: [0.7561, 0.9952]
2025-03-11 20:24:47 - Train Iteration 4808: loss: 0.3106, d_k_M range: [0.0045, 0.5445], d_k_M_hat range: [0.4472, 0.9938]
2025-03-11 20:24:48 - Train Iteration 4809: loss: 0.8138, d_k_M range: [0.0112, 0.9017], d_k_M_hat range: [0.4457, 0.9995]
2025-03-11 20:24:48 - Train Iteration 4810: loss: 0.5231, d_k_M range: [0.0007, 0.0906], d_k_M_hat range: [0.2774, 0.7048]
2025-03-11 20:24:48 - Train Iteration 4811: loss: 0.4606, d_k_M range: [0.0351, 0.6555], d_k_M_hat range: [0.6380, 0.9769]
2025-03-11 20:24:49 - Train Iteration 4812: loss: 0.3829, d_k_M range: [0.0010, 0.1587], d_k_M_hat range: [0.3833, 0.7734]
2025-03-11 20:24:49 - Train Iteration 4813: loss: 0.2797, d_k_M range: [0.0004, 0.0862], d_k_M_hat range: [0.4729, 0.7857]
2025-03-11 20:24:50 - Train Iteration 4814: loss: 0.5604, d_k_M range: [0.0016, 0.7473], d_k_M_hat range: [0.5090, 0.9988]
2025-03-11 20:24:50 - Train Iteration 4815: loss: 0.2287, d_k_M range: [0.0100, 0.3879], d_k_M_hat range: [0.6019, 0.9700]
2025-03-11 20:24:50 - Train Iteration 4816: loss: 0.2804, d_k_M range: [0.0285, 0.4811], d_k_M_hat range: [0.6058, 0.9516]
2025-03-11 20:24:51 - Train Iteration 4817: loss: 0.3213, d_k_M range: [0.0000, 0.4628], d_k_M_hat range: [0.4333, 0.9379]
2025-03-11 20:24:51 - Train Iteration 4818: loss: 0.3284, d_k_M range: [0.0038, 0.3723], d_k_M_hat range: [0.4308, 0.9696]
2025-03-11 20:24:52 - Train Iteration 4819: loss: 0.2710, d_k_M range: [0.0491, 0.4878], d_k_M_hat range: [0.7453, 0.9798]
2025-03-11 20:24:52 - Train Iteration 4820: loss: 0.2150, d_k_M range: [0.0009, 0.3367], d_k_M_hat range: [0.5372, 0.9048]
2025-03-11 20:24:53 - Train Iteration 4821: loss: 0.3112, d_k_M range: [0.0029, 0.4450], d_k_M_hat range: [0.5533, 0.9722]
2025-03-11 20:24:53 - Train Iteration 4822: loss: 0.5923, d_k_M range: [0.0034, 0.7690], d_k_M_hat range: [0.5085, 0.9994]
2025-03-11 20:24:53 - Train Iteration 4823: loss: 0.3319, d_k_M range: [0.0004, 0.2903], d_k_M_hat range: [0.4243, 0.8591]
2025-03-11 20:24:54 - Train Iteration 4824: loss: 0.2352, d_k_M range: [0.0042, 0.4802], d_k_M_hat range: [0.5525, 0.9952]
2025-03-11 20:24:54 - Train Iteration 4825: loss: 0.2753, d_k_M range: [0.0074, 0.5192], d_k_M_hat range: [0.5595, 0.9946]
2025-03-11 20:24:55 - Train Iteration 4826: loss: 0.2460, d_k_M range: [0.0069, 0.4295], d_k_M_hat range: [0.5126, 0.9772]
2025-03-11 20:24:55 - Train Iteration 4827: loss: 0.6167, d_k_M range: [0.0056, 0.7820], d_k_M_hat range: [0.5660, 0.9967]
2025-03-11 20:24:56 - Train Iteration 4828: loss: 0.5688, d_k_M range: [0.0009, 0.1879], d_k_M_hat range: [0.2475, 0.8608]
2025-03-11 20:24:56 - Train Iteration 4829: loss: 0.2391, d_k_M range: [0.0013, 0.4472], d_k_M_hat range: [0.5308, 0.9581]
2025-03-11 20:24:57 - Train Iteration 4830: loss: 0.4106, d_k_M range: [0.0005, 0.1754], d_k_M_hat range: [0.3620, 0.8353]
2025-03-11 20:24:57 - Train Iteration 4831: loss: 0.2404, d_k_M range: [0.0009, 0.3946], d_k_M_hat range: [0.5329, 0.9394]
2025-03-11 20:24:57 - Train Iteration 4832: loss: 0.3868, d_k_M range: [0.0002, 0.3799], d_k_M_hat range: [0.3783, 0.9259]
2025-03-11 20:24:58 - Train Iteration 4833: loss: 0.5168, d_k_M range: [0.0039, 0.4131], d_k_M_hat range: [0.2861, 0.9804]
2025-03-11 20:24:58 - Train Iteration 4834: loss: 0.3513, d_k_M range: [0.0027, 0.4001], d_k_M_hat range: [0.4744, 0.9653]
2025-03-11 20:24:59 - Train Iteration 4835: loss: 0.3487, d_k_M range: [0.0017, 0.2616], d_k_M_hat range: [0.4114, 0.8717]
2025-03-11 20:24:59 - Train Iteration 4836: loss: 0.3218, d_k_M range: [0.0235, 0.4594], d_k_M_hat range: [0.7335, 0.9731]
2025-03-11 20:24:59 - Train Iteration 4837: loss: 0.3323, d_k_M range: [0.0121, 0.3128], d_k_M_hat range: [0.4360, 0.9394]
2025-03-11 20:25:00 - Train Iteration 4838: loss: 0.2215, d_k_M range: [0.0058, 0.4047], d_k_M_hat range: [0.5596, 0.9449]
2025-03-11 20:25:00 - Train Iteration 4839: loss: 0.6653, d_k_M range: [0.0524, 0.8127], d_k_M_hat range: [0.6156, 0.9970]
2025-03-11 20:25:01 - Train Iteration 4840: loss: 0.2931, d_k_M range: [0.0189, 0.5161], d_k_M_hat range: [0.5159, 0.9747]
2025-03-11 20:25:01 - Train Iteration 4841: loss: 0.2404, d_k_M range: [0.0397, 0.3775], d_k_M_hat range: [0.5811, 0.9719]
2025-03-11 20:25:02 - Train Iteration 4842: loss: 0.2608, d_k_M range: [0.0142, 0.4841], d_k_M_hat range: [0.6461, 0.9734]
2025-03-11 20:25:02 - Train Iteration 4843: loss: 0.2484, d_k_M range: [0.0326, 0.4583], d_k_M_hat range: [0.5521, 0.9658]
2025-03-11 20:25:02 - Train Iteration 4844: loss: 0.3350, d_k_M range: [0.0006, 0.4863], d_k_M_hat range: [0.4219, 0.9827]
2025-03-11 20:25:03 - Train Iteration 4845: loss: 0.3251, d_k_M range: [0.0446, 0.5680], d_k_M_hat range: [0.7889, 0.9978]
2025-03-11 20:25:03 - Train Iteration 4846: loss: 0.2931, d_k_M range: [0.0021, 0.3138], d_k_M_hat range: [0.4607, 0.9305]
2025-03-11 20:25:04 - Train Iteration 4847: loss: 0.2307, d_k_M range: [0.0017, 0.2432], d_k_M_hat range: [0.5261, 0.8414]
2025-03-11 20:25:04 - Train Iteration 4848: loss: 0.4012, d_k_M range: [0.0026, 0.6255], d_k_M_hat range: [0.4753, 0.9934]
2025-03-11 20:25:05 - Train Iteration 4849: loss: 0.3849, d_k_M range: [0.0026, 0.4913], d_k_M_hat range: [0.3841, 0.8795]
2025-03-11 20:25:05 - Train Iteration 4850: loss: 0.2515, d_k_M range: [0.0004, 0.2942], d_k_M_hat range: [0.5110, 0.8250]
2025-03-11 20:25:05 - Train Iteration 4851: loss: 0.1904, d_k_M range: [0.0010, 0.3711], d_k_M_hat range: [0.5878, 0.9589]
2025-03-11 20:25:06 - Train Iteration 4852: loss: 0.4242, d_k_M range: [0.0005, 0.4573], d_k_M_hat range: [0.3508, 0.9937]
2025-03-11 20:25:06 - Train Iteration 4853: loss: 0.2294, d_k_M range: [0.0068, 0.3002], d_k_M_hat range: [0.5619, 0.9661]
2025-03-11 20:25:07 - Train Iteration 4854: loss: 0.4422, d_k_M range: [0.0002, 0.2771], d_k_M_hat range: [0.3353, 0.9597]
2025-03-11 20:25:07 - Train Iteration 4855: loss: 0.3964, d_k_M range: [0.0317, 0.6264], d_k_M_hat range: [0.6791, 0.9968]
2025-03-11 20:25:08 - Train Iteration 4856: loss: 0.3558, d_k_M range: [0.0008, 0.2633], d_k_M_hat range: [0.4044, 0.9400]
2025-03-11 20:25:08 - Train Iteration 4857: loss: 0.2096, d_k_M range: [0.0060, 0.4289], d_k_M_hat range: [0.6272, 0.9710]
2025-03-11 20:25:08 - Train Iteration 4858: loss: 0.2482, d_k_M range: [0.0249, 0.4651], d_k_M_hat range: [0.7456, 0.9669]
2025-03-11 20:25:09 - Train Iteration 4859: loss: 0.3373, d_k_M range: [0.0002, 0.5692], d_k_M_hat range: [0.4194, 0.9986]
2025-03-11 20:25:09 - Train Iteration 4860: loss: 0.2850, d_k_M range: [0.0087, 0.4761], d_k_M_hat range: [0.6795, 0.9832]
2025-03-11 20:25:10 - Train Iteration 4861: loss: 0.6047, d_k_M range: [0.0053, 0.7671], d_k_M_hat range: [0.5268, 0.9924]
2025-03-11 20:25:10 - Train Iteration 4862: loss: 0.7177, d_k_M range: [0.0000, 0.3041], d_k_M_hat range: [0.1530, 0.9552]
2025-03-11 20:25:11 - Train Iteration 4863: loss: 0.3009, d_k_M range: [0.0094, 0.5187], d_k_M_hat range: [0.4781, 0.9909]
2025-03-11 20:25:11 - Train Iteration 4864: loss: 0.3384, d_k_M range: [0.0424, 0.3473], d_k_M_hat range: [0.6120, 0.9549]
2025-03-11 20:25:11 - Train Iteration 4865: loss: 0.4546, d_k_M range: [0.0008, 0.4297], d_k_M_hat range: [0.3294, 0.9933]
2025-03-11 20:25:12 - Train Iteration 4866: loss: 0.2839, d_k_M range: [0.0010, 0.4622], d_k_M_hat range: [0.4747, 0.9808]
2025-03-11 20:25:12 - Train Iteration 4867: loss: 0.2485, d_k_M range: [0.0092, 0.4358], d_k_M_hat range: [0.6098, 0.9763]
2025-03-11 20:25:13 - Train Iteration 4868: loss: 0.2670, d_k_M range: [0.0021, 0.5096], d_k_M_hat range: [0.5088, 0.9929]
2025-03-11 20:25:13 - Train Iteration 4869: loss: 0.4025, d_k_M range: [0.0025, 0.3494], d_k_M_hat range: [0.3681, 0.9518]
2025-03-11 20:25:13 - Train Iteration 4870: loss: 0.2720, d_k_M range: [0.0020, 0.3249], d_k_M_hat range: [0.4853, 0.9221]
2025-03-11 20:25:14 - Train Iteration 4871: loss: 0.3328, d_k_M range: [0.0378, 0.5514], d_k_M_hat range: [0.8028, 0.9962]
2025-03-11 20:25:14 - Train Iteration 4872: loss: 0.2771, d_k_M range: [0.0314, 0.4677], d_k_M_hat range: [0.7157, 0.9835]
2025-03-11 20:25:15 - Train Iteration 4873: loss: 0.5136, d_k_M range: [0.0010, 0.7106], d_k_M_hat range: [0.5095, 0.9940]
2025-03-11 20:25:15 - Train Iteration 4874: loss: 0.2400, d_k_M range: [0.0115, 0.1567], d_k_M_hat range: [0.5216, 0.9408]
2025-03-11 20:25:16 - Train Iteration 4875: loss: 0.2638, d_k_M range: [0.0021, 0.3758], d_k_M_hat range: [0.4885, 0.9833]
2025-03-11 20:25:16 - Train Iteration 4876: loss: 0.2470, d_k_M range: [0.0013, 0.2666], d_k_M_hat range: [0.5106, 0.9268]
2025-03-11 20:25:16 - Train Iteration 4877: loss: 0.2514, d_k_M range: [0.0267, 0.3902], d_k_M_hat range: [0.5693, 0.9739]
2025-03-11 20:25:17 - Train Iteration 4878: loss: 0.1934, d_k_M range: [0.0026, 0.3751], d_k_M_hat range: [0.5629, 0.9739]
2025-03-11 20:25:17 - Train Iteration 4879: loss: 0.2485, d_k_M range: [0.0034, 0.4429], d_k_M_hat range: [0.5219, 0.9805]
2025-03-11 20:25:18 - Train Iteration 4880: loss: 0.1723, d_k_M range: [0.0254, 0.3462], d_k_M_hat range: [0.6103, 0.9670]
2025-03-11 20:25:18 - Train Iteration 4881: loss: 0.2650, d_k_M range: [0.0070, 0.4531], d_k_M_hat range: [0.5493, 0.9758]
2025-03-11 20:25:19 - Train Iteration 4882: loss: 0.2807, d_k_M range: [0.0036, 0.5238], d_k_M_hat range: [0.5003, 0.9940]
2025-03-11 20:25:19 - Train Iteration 4883: loss: 0.2647, d_k_M range: [0.0023, 0.4288], d_k_M_hat range: [0.4877, 0.9915]
2025-03-11 20:25:20 - Train Iteration 4884: loss: 0.2226, d_k_M range: [0.0287, 0.4061], d_k_M_hat range: [0.7359, 0.9782]
2025-03-11 20:25:20 - Train Iteration 4885: loss: 0.3599, d_k_M range: [0.0025, 0.5196], d_k_M_hat range: [0.4026, 0.9967]
2025-03-11 20:25:20 - Train Iteration 4886: loss: 0.3624, d_k_M range: [0.0001, 0.2831], d_k_M_hat range: [0.3981, 0.8862]
2025-03-11 20:25:21 - Train Iteration 4887: loss: 0.2274, d_k_M range: [0.0119, 0.3955], d_k_M_hat range: [0.6358, 0.9694]
2025-03-11 20:25:21 - Train Iteration 4888: loss: 0.1919, d_k_M range: [0.0235, 0.3842], d_k_M_hat range: [0.7139, 0.9524]
2025-03-11 20:25:22 - Train Iteration 4889: loss: 0.2373, d_k_M range: [0.0024, 0.4863], d_k_M_hat range: [0.6052, 0.9992]
2025-03-11 20:25:22 - Train Iteration 4890: loss: 0.2131, d_k_M range: [0.0081, 0.4426], d_k_M_hat range: [0.5883, 0.9815]
2025-03-11 20:25:23 - Train Iteration 4891: loss: 0.3810, d_k_M range: [0.0001, 0.2629], d_k_M_hat range: [0.3828, 0.9734]
2025-03-11 20:25:23 - Train Iteration 4892: loss: 0.2445, d_k_M range: [0.0688, 0.4053], d_k_M_hat range: [0.7956, 0.9898]
2025-03-11 20:25:24 - Train Iteration 4893: loss: 0.2544, d_k_M range: [0.0040, 0.4860], d_k_M_hat range: [0.5583, 0.9816]
2025-03-11 20:25:24 - Train Iteration 4894: loss: 0.2618, d_k_M range: [0.0194, 0.5037], d_k_M_hat range: [0.6582, 0.9921]
2025-03-11 20:25:24 - Train Iteration 4895: loss: 0.2132, d_k_M range: [0.0050, 0.3601], d_k_M_hat range: [0.5763, 0.9805]
2025-03-11 20:25:25 - Train Iteration 4896: loss: 0.2381, d_k_M range: [0.0241, 0.4486], d_k_M_hat range: [0.6260, 0.9607]
2025-03-11 20:25:25 - Train Iteration 4897: loss: 0.7590, d_k_M range: [0.0000, 0.4029], d_k_M_hat range: [0.1288, 0.9409]
2025-03-11 20:25:26 - Train Iteration 4898: loss: 0.1994, d_k_M range: [0.0049, 0.4427], d_k_M_hat range: [0.6082, 0.9961]
2025-03-11 20:25:26 - Train Iteration 4899: loss: 0.3596, d_k_M range: [0.0030, 0.5986], d_k_M_hat range: [0.4830, 0.9989]
2025-03-11 20:25:27 - Train Iteration 4900: loss: 0.3660, d_k_M range: [0.0020, 0.5981], d_k_M_hat range: [0.6014, 0.9978]
2025-03-11 20:25:27 - Train Iteration 4901: loss: 0.3417, d_k_M range: [0.0304, 0.5835], d_k_M_hat range: [0.5970, 0.9989]
2025-03-11 20:25:27 - Train Iteration 4902: loss: 0.3341, d_k_M range: [0.0000, 0.1264], d_k_M_hat range: [0.4228, 0.8819]
2025-03-11 20:25:28 - Train Iteration 4903: loss: 0.2879, d_k_M range: [0.0008, 0.4804], d_k_M_hat range: [0.4693, 0.9810]
2025-03-11 20:25:28 - Train Iteration 4904: loss: 0.6211, d_k_M range: [0.0004, 0.2732], d_k_M_hat range: [0.2123, 0.9389]
2025-03-11 20:25:29 - Train Iteration 4905: loss: 0.2701, d_k_M range: [0.0002, 0.3187], d_k_M_hat range: [0.4805, 0.9453]
2025-03-11 20:25:29 - Train Iteration 4906: loss: 0.3061, d_k_M range: [0.0009, 0.3959], d_k_M_hat range: [0.4476, 0.9577]
2025-03-11 20:25:29 - Train Iteration 4907: loss: 0.2987, d_k_M range: [0.0009, 0.5389], d_k_M_hat range: [0.5559, 0.9924]
2025-03-11 20:25:30 - Train Iteration 4908: loss: 0.2440, d_k_M range: [0.0019, 0.4769], d_k_M_hat range: [0.6414, 0.9850]
2025-03-11 20:25:30 - Train Iteration 4909: loss: 0.3258, d_k_M range: [0.0004, 0.3986], d_k_M_hat range: [0.4947, 0.9769]
2025-03-11 20:25:31 - Train Iteration 4910: loss: 0.4504, d_k_M range: [0.0002, 0.4937], d_k_M_hat range: [0.3290, 0.9906]
2025-03-11 20:25:31 - Train Iteration 4911: loss: 0.4630, d_k_M range: [0.0127, 0.6790], d_k_M_hat range: [0.6233, 0.9986]
2025-03-11 20:25:31 - Train Iteration 4912: loss: 0.2649, d_k_M range: [0.0258, 0.4130], d_k_M_hat range: [0.6885, 0.9839]
2025-03-11 20:25:32 - Train Iteration 4913: loss: 0.3201, d_k_M range: [0.0004, 0.3778], d_k_M_hat range: [0.4346, 0.9250]
2025-03-11 20:25:32 - Train Iteration 4914: loss: 0.3180, d_k_M range: [0.0018, 0.5604], d_k_M_hat range: [0.4632, 0.9965]
2025-03-11 20:25:33 - Train Iteration 4915: loss: 0.3650, d_k_M range: [0.0562, 0.6030], d_k_M_hat range: [0.7928, 0.9988]
2025-03-11 20:25:33 - Train Iteration 4916: loss: 0.2878, d_k_M range: [0.0025, 0.2018], d_k_M_hat range: [0.4661, 0.8538]
2025-03-11 20:25:34 - Train Iteration 4917: loss: 0.3678, d_k_M range: [0.0455, 0.6020], d_k_M_hat range: [0.6518, 0.9955]
2025-03-11 20:25:34 - Train Iteration 4918: loss: 0.4585, d_k_M range: [0.0001, 0.2878], d_k_M_hat range: [0.3232, 0.9477]
2025-03-11 20:25:34 - Train Iteration 4919: loss: 0.2412, d_k_M range: [0.0066, 0.2914], d_k_M_hat range: [0.5227, 0.8915]
2025-03-11 20:25:35 - Train Iteration 4920: loss: 0.2143, d_k_M range: [0.0528, 0.4581], d_k_M_hat range: [0.6555, 0.9952]
2025-03-11 20:25:35 - Train Iteration 4921: loss: 0.3202, d_k_M range: [0.0010, 0.1092], d_k_M_hat range: [0.4351, 0.7421]
2025-03-11 20:25:36 - Train Iteration 4922: loss: 0.2536, d_k_M range: [0.0015, 0.4557], d_k_M_hat range: [0.4980, 0.9825]
2025-03-11 20:25:36 - Train Iteration 4923: loss: 0.8655, d_k_M range: [0.0014, 0.9289], d_k_M_hat range: [0.5368, 0.9986]
2025-03-11 20:25:37 - Train Iteration 4924: loss: 0.7666, d_k_M range: [0.0001, 0.0669], d_k_M_hat range: [0.1248, 0.7551]
2025-03-11 20:25:37 - Train Iteration 4925: loss: 0.5213, d_k_M range: [0.0833, 0.7202], d_k_M_hat range: [0.7348, 0.9982]
2025-03-11 20:25:37 - Train Iteration 4926: loss: 0.2416, d_k_M range: [0.0035, 0.4275], d_k_M_hat range: [0.5119, 0.9736]
2025-03-11 20:25:38 - Train Iteration 4927: loss: 0.2280, d_k_M range: [0.0066, 0.4646], d_k_M_hat range: [0.6002, 0.9962]
2025-03-11 20:25:38 - Train Iteration 4928: loss: 0.3511, d_k_M range: [0.0739, 0.5886], d_k_M_hat range: [0.7929, 0.9961]
2025-03-11 20:25:39 - Train Iteration 4929: loss: 0.2549, d_k_M range: [0.0061, 0.4002], d_k_M_hat range: [0.5013, 0.9728]
2025-03-11 20:25:39 - Train Iteration 4930: loss: 0.2244, d_k_M range: [0.0268, 0.2794], d_k_M_hat range: [0.5616, 0.9301]
2025-03-11 20:25:40 - Train Iteration 4931: loss: 0.2635, d_k_M range: [0.0019, 0.4580], d_k_M_hat range: [0.4893, 0.9903]
2025-03-11 20:25:40 - Train Iteration 4932: loss: 0.1790, d_k_M range: [0.0185, 0.3693], d_k_M_hat range: [0.6620, 0.9462]
2025-03-11 20:25:41 - Train Iteration 4933: loss: 0.9336, d_k_M range: [0.0006, 0.4419], d_k_M_hat range: [0.0379, 0.9881]
2025-03-11 20:25:41 - Train Iteration 4934: loss: 0.3118, d_k_M range: [0.0220, 0.5422], d_k_M_hat range: [0.6035, 0.9838]
2025-03-11 20:25:41 - Train Iteration 4935: loss: 0.5758, d_k_M range: [0.0594, 0.7551], d_k_M_hat range: [0.5524, 0.9962]
2025-03-11 20:25:42 - Train Iteration 4936: loss: 0.2204, d_k_M range: [0.0161, 0.3881], d_k_M_hat range: [0.5649, 0.9534]
2025-03-11 20:25:42 - Train Iteration 4937: loss: 0.2861, d_k_M range: [0.1524, 0.5198], d_k_M_hat range: [0.7734, 0.9849]
2025-03-11 20:25:43 - Train Iteration 4938: loss: 0.2295, d_k_M range: [0.0238, 0.4781], d_k_M_hat range: [0.6720, 0.9991]
2025-03-11 20:25:43 - Train Iteration 4939: loss: 0.3831, d_k_M range: [0.0008, 0.3246], d_k_M_hat range: [0.3818, 0.9801]
2025-03-11 20:25:44 - Train Iteration 4940: loss: 0.1763, d_k_M range: [0.0048, 0.3636], d_k_M_hat range: [0.5872, 0.9718]
2025-03-11 20:25:44 - Train Iteration 4941: loss: 0.3402, d_k_M range: [0.0073, 0.5811], d_k_M_hat range: [0.4907, 0.9978]
2025-03-11 20:25:44 - Train Iteration 4942: loss: 0.3134, d_k_M range: [0.0015, 0.5448], d_k_M_hat range: [0.4417, 0.9947]
2025-03-11 20:25:45 - Train Iteration 4943: loss: 0.3197, d_k_M range: [0.0002, 0.2009], d_k_M_hat range: [0.4999, 0.8784]
2025-03-11 20:25:45 - Train Iteration 4944: loss: 0.2990, d_k_M range: [0.0037, 0.4939], d_k_M_hat range: [0.5129, 0.9838]
2025-03-11 20:25:46 - Train Iteration 4945: loss: 0.2402, d_k_M range: [0.0642, 0.4624], d_k_M_hat range: [0.6861, 0.9723]
2025-03-11 20:25:46 - Train Iteration 4946: loss: 0.2659, d_k_M range: [0.0032, 0.3986], d_k_M_hat range: [0.4886, 0.9652]
2025-03-11 20:25:47 - Train Iteration 4947: loss: 0.2986, d_k_M range: [0.1133, 0.5381], d_k_M_hat range: [0.7713, 0.9917]
2025-03-11 20:25:47 - Train Iteration 4948: loss: 0.2735, d_k_M range: [0.0039, 0.5092], d_k_M_hat range: [0.4922, 0.9863]
2025-03-11 20:25:48 - Train Iteration 4949: loss: 0.2906, d_k_M range: [0.0056, 0.5375], d_k_M_hat range: [0.5605, 0.9989]
2025-03-11 20:25:48 - Train Iteration 4950: loss: 0.3061, d_k_M range: [0.0045, 0.5052], d_k_M_hat range: [0.4858, 0.9802]
2025-03-11 20:25:48 - Train Iteration 4951: loss: 0.7347, d_k_M range: [0.0220, 0.8550], d_k_M_hat range: [0.7147, 0.9978]
2025-03-11 20:25:49 - Train Iteration 4952: loss: 0.2558, d_k_M range: [0.0096, 0.3173], d_k_M_hat range: [0.5038, 0.9908]
2025-03-11 20:25:49 - Train Iteration 4953: loss: 0.2599, d_k_M range: [0.0041, 0.4356], d_k_M_hat range: [0.5117, 0.9722]
2025-03-11 20:25:50 - Train Iteration 4954: loss: 0.5356, d_k_M range: [0.0039, 0.6343], d_k_M_hat range: [0.2720, 0.9991]
2025-03-11 20:25:50 - Train Iteration 4955: loss: 0.4629, d_k_M range: [0.0163, 0.6764], d_k_M_hat range: [0.5964, 0.9960]
2025-03-11 20:25:51 - Train Iteration 4956: loss: 0.2783, d_k_M range: [0.0057, 0.3619], d_k_M_hat range: [0.5171, 0.9294]
2025-03-11 20:25:51 - Train Iteration 4957: loss: 0.2993, d_k_M range: [0.0090, 0.5275], d_k_M_hat range: [0.5502, 0.9804]
2025-03-11 20:25:51 - Train Iteration 4958: loss: 0.2806, d_k_M range: [0.0016, 0.1119], d_k_M_hat range: [0.4730, 0.7875]
2025-03-11 20:25:52 - Train Iteration 4959: loss: 0.2560, d_k_M range: [0.0699, 0.4886], d_k_M_hat range: [0.5682, 0.9945]
2025-03-11 20:25:52 - Train Iteration 4960: loss: 0.7691, d_k_M range: [0.0466, 0.8748], d_k_M_hat range: [0.6952, 0.9978]
2025-03-11 20:25:53 - Train Iteration 4961: loss: 0.3213, d_k_M range: [0.0004, 0.0552], d_k_M_hat range: [0.4336, 0.7275]
2025-03-11 20:25:53 - Train Iteration 4962: loss: 0.2392, d_k_M range: [0.0183, 0.4503], d_k_M_hat range: [0.5995, 0.9613]
2025-03-11 20:25:53 - Train Iteration 4963: loss: 0.3618, d_k_M range: [0.0003, 0.5988], d_k_M_hat range: [0.4046, 0.9973]
2025-03-11 20:25:54 - Train Iteration 4964: loss: 0.3156, d_k_M range: [0.0041, 0.3670], d_k_M_hat range: [0.4459, 0.9129]
2025-03-11 20:25:54 - Train Iteration 4965: loss: 0.4176, d_k_M range: [0.0010, 0.6413], d_k_M_hat range: [0.5479, 0.9976]
2025-03-11 20:25:55 - Train Iteration 4966: loss: 0.2552, d_k_M range: [0.0010, 0.3544], d_k_M_hat range: [0.4958, 0.9601]
2025-03-11 20:25:55 - Train Iteration 4967: loss: 0.3537, d_k_M range: [0.0149, 0.2047], d_k_M_hat range: [0.4201, 0.8561]
2025-03-11 20:25:56 - Train Iteration 4968: loss: 0.2305, d_k_M range: [0.0064, 0.4211], d_k_M_hat range: [0.5426, 0.9831]
2025-03-11 20:25:56 - Train Iteration 4969: loss: 0.2871, d_k_M range: [0.0013, 0.3670], d_k_M_hat range: [0.4655, 0.9600]
2025-03-11 20:25:56 - Train Iteration 4970: loss: 0.2662, d_k_M range: [0.0110, 0.4103], d_k_M_hat range: [0.5613, 0.9796]
2025-03-11 20:25:57 - Train Iteration 4971: loss: 0.3391, d_k_M range: [0.0045, 0.3697], d_k_M_hat range: [0.5083, 0.9765]
2025-03-11 20:25:57 - Train Iteration 4972: loss: 0.3372, d_k_M range: [0.0376, 0.5732], d_k_M_hat range: [0.8922, 0.9925]
2025-03-11 20:25:58 - Train Iteration 4973: loss: 0.3166, d_k_M range: [0.0061, 0.5533], d_k_M_hat range: [0.4825, 0.9906]
2025-03-11 20:25:58 - Train Iteration 4974: loss: 0.3570, d_k_M range: [0.0007, 0.3075], d_k_M_hat range: [0.4032, 0.9815]
2025-03-11 20:25:59 - Train Iteration 4975: loss: 0.2424, d_k_M range: [0.0271, 0.3236], d_k_M_hat range: [0.5678, 0.9478]
2025-03-11 20:25:59 - Train Iteration 4976: loss: 0.3447, d_k_M range: [0.0004, 0.5767], d_k_M_hat range: [0.5503, 0.9942]
2025-03-11 20:25:59 - Train Iteration 4977: loss: 0.3531, d_k_M range: [0.0008, 0.4460], d_k_M_hat range: [0.4066, 0.9937]
2025-03-11 20:26:00 - Train Iteration 4978: loss: 0.2447, d_k_M range: [0.0030, 0.3945], d_k_M_hat range: [0.5348, 0.9837]
2025-03-11 20:26:00 - Train Iteration 4979: loss: 0.2517, d_k_M range: [0.0272, 0.4445], d_k_M_hat range: [0.6295, 0.9919]
2025-03-11 20:26:01 - Train Iteration 4980: loss: 0.2851, d_k_M range: [0.0004, 0.5164], d_k_M_hat range: [0.4665, 0.9887]
2025-03-11 20:26:01 - Train Iteration 4981: loss: 0.3330, d_k_M range: [0.0030, 0.4926], d_k_M_hat range: [0.4260, 0.9828]
2025-03-11 20:26:02 - Train Iteration 4982: loss: 0.3173, d_k_M range: [0.0048, 0.5062], d_k_M_hat range: [0.4416, 0.9916]
2025-03-11 20:26:02 - Train Iteration 4983: loss: 0.2786, d_k_M range: [0.0107, 0.3352], d_k_M_hat range: [0.5128, 0.9752]
2025-03-11 20:26:02 - Train Iteration 4984: loss: 0.3019, d_k_M range: [0.0018, 0.4557], d_k_M_hat range: [0.5014, 0.9643]
2025-03-11 20:26:03 - Train Iteration 4985: loss: 0.7475, d_k_M range: [0.0078, 0.8616], d_k_M_hat range: [0.6916, 0.9970]
2025-03-11 20:26:03 - Train Iteration 4986: loss: 0.3828, d_k_M range: [0.0003, 0.3116], d_k_M_hat range: [0.3816, 0.8761]
2025-03-11 20:26:04 - Train Iteration 4987: loss: 0.2148, d_k_M range: [0.1290, 0.4502], d_k_M_hat range: [0.8761, 0.9901]
2025-03-11 20:26:04 - Train Iteration 4988: loss: 0.3955, d_k_M range: [0.0014, 0.3291], d_k_M_hat range: [0.3725, 0.9640]
2025-03-11 20:26:05 - Train Iteration 4989: loss: 0.4459, d_k_M range: [0.0045, 0.6670], d_k_M_hat range: [0.5438, 0.9993]
2025-03-11 20:26:05 - Train Iteration 4990: loss: 0.2004, d_k_M range: [0.0041, 0.0521], d_k_M_hat range: [0.5589, 0.7448]
2025-03-11 20:26:05 - Train Iteration 4991: loss: 0.5089, d_k_M range: [0.0002, 0.5980], d_k_M_hat range: [0.2868, 0.9977]
2025-03-11 20:26:06 - Train Iteration 4992: loss: 0.4265, d_k_M range: [0.1686, 0.6521], d_k_M_hat range: [0.6879, 0.9990]
2025-03-11 20:26:06 - Train Iteration 4993: loss: 0.2856, d_k_M range: [0.0039, 0.4293], d_k_M_hat range: [0.4695, 0.9377]
2025-03-11 20:26:07 - Train Iteration 4994: loss: 0.3906, d_k_M range: [0.0117, 0.6238], d_k_M_hat range: [0.5660, 0.9988]
2025-03-11 20:26:07 - Train Iteration 4995: loss: 0.3265, d_k_M range: [0.0020, 0.3295], d_k_M_hat range: [0.4307, 0.9020]
2025-03-11 20:26:08 - Train Iteration 4996: loss: 0.2026, d_k_M range: [0.0150, 0.4072], d_k_M_hat range: [0.5875, 0.9571]
2025-03-11 20:26:08 - Train Iteration 4997: loss: 0.3140, d_k_M range: [0.0004, 0.5408], d_k_M_hat range: [0.4401, 0.9844]
2025-03-11 20:26:09 - Train Iteration 4998: loss: 0.3622, d_k_M range: [0.0007, 0.6009], d_k_M_hat range: [0.5571, 0.9991]
2025-03-11 20:26:09 - Train Iteration 4999: loss: 0.3828, d_k_M range: [0.0050, 0.3826], d_k_M_hat range: [0.3868, 0.8957]
2025-03-11 20:26:09 - Train Iteration 5000: loss: 0.5493, d_k_M range: [0.1229, 0.7384], d_k_M_hat range: [0.8383, 0.9972]
2025-03-11 20:26:10 - Train Iteration 5001: loss: 0.4064, d_k_M range: [0.0006, 0.4572], d_k_M_hat range: [0.3631, 0.9555]
2025-03-11 20:26:10 - Train Iteration 5002: loss: 0.8550, d_k_M range: [0.1746, 0.9243], d_k_M_hat range: [0.8037, 0.9997]
2025-03-11 20:26:11 - Train Iteration 5003: loss: 0.3192, d_k_M range: [0.0004, 0.4018], d_k_M_hat range: [0.4387, 0.8369]
2025-03-11 20:26:11 - Train Iteration 5004: loss: 0.3598, d_k_M range: [0.0001, 0.4501], d_k_M_hat range: [0.4003, 0.9661]
2025-03-11 20:26:11 - Train Iteration 5005: loss: 0.3269, d_k_M range: [0.0041, 0.5660], d_k_M_hat range: [0.5549, 0.9942]
2025-03-11 20:26:12 - Train Iteration 5006: loss: 0.1935, d_k_M range: [0.0149, 0.3861], d_k_M_hat range: [0.5775, 0.9714]
2025-03-11 20:26:12 - Train Iteration 5007: loss: 0.4796, d_k_M range: [0.1175, 0.6905], d_k_M_hat range: [0.7166, 0.9980]
2025-03-11 20:26:13 - Train Iteration 5008: loss: 0.2589, d_k_M range: [0.0018, 0.3537], d_k_M_hat range: [0.5433, 0.9192]
2025-03-11 20:26:13 - Train Iteration 5009: loss: 0.3003, d_k_M range: [0.0472, 0.5358], d_k_M_hat range: [0.6643, 0.9878]
2025-03-11 20:26:13 - Train Iteration 5010: loss: 0.3452, d_k_M range: [0.0013, 0.0968], d_k_M_hat range: [0.4137, 0.6732]
2025-03-11 20:26:14 - Train Iteration 5011: loss: 0.2174, d_k_M range: [0.0050, 0.3817], d_k_M_hat range: [0.6217, 0.9725]
2025-03-11 20:26:14 - Train Iteration 5012: loss: 0.4312, d_k_M range: [0.0023, 0.6562], d_k_M_hat range: [0.5229, 0.9995]
2025-03-11 20:26:15 - Train Iteration 5013: loss: 0.2266, d_k_M range: [0.0041, 0.2145], d_k_M_hat range: [0.5280, 0.8856]
2025-03-11 20:26:15 - Train Iteration 5014: loss: 0.8836, d_k_M range: [0.0891, 0.9390], d_k_M_hat range: [0.6955, 0.9990]
2025-03-11 20:26:16 - Train Iteration 5015: loss: 0.2560, d_k_M range: [0.0103, 0.3894], d_k_M_hat range: [0.5376, 0.9053]
2025-03-11 20:26:16 - Train Iteration 5016: loss: 0.2310, d_k_M range: [0.0013, 0.4363], d_k_M_hat range: [0.5207, 0.9895]
2025-03-11 20:26:16 - Train Iteration 5017: loss: 0.3475, d_k_M range: [0.0175, 0.4591], d_k_M_hat range: [0.5843, 0.9795]
2025-03-11 20:26:17 - Train Iteration 5018: loss: 0.2344, d_k_M range: [0.0005, 0.3650], d_k_M_hat range: [0.5171, 0.8844]
2025-03-11 20:26:17 - Train Iteration 5019: loss: 0.2857, d_k_M range: [0.0021, 0.5198], d_k_M_hat range: [0.4833, 0.9853]
2025-03-11 20:26:18 - Train Iteration 5020: loss: 0.2538, d_k_M range: [0.0049, 0.4385], d_k_M_hat range: [0.5011, 0.9931]
2025-03-11 20:26:18 - Train Iteration 5021: loss: 0.2817, d_k_M range: [0.0074, 0.5152], d_k_M_hat range: [0.5877, 0.9845]
2025-03-11 20:26:19 - Train Iteration 5022: loss: 0.3125, d_k_M range: [0.0008, 0.5540], d_k_M_hat range: [0.4994, 0.9950]
2025-03-11 20:26:19 - Train Iteration 5023: loss: 0.2142, d_k_M range: [0.0197, 0.4513], d_k_M_hat range: [0.7173, 0.9929]
2025-03-11 20:26:19 - Train Iteration 5024: loss: 0.2677, d_k_M range: [0.0021, 0.4685], d_k_M_hat range: [0.5491, 0.9511]
2025-03-11 20:26:20 - Train Iteration 5025: loss: 0.2173, d_k_M range: [0.0123, 0.2689], d_k_M_hat range: [0.5479, 0.8910]
2025-03-11 20:26:20 - Train Iteration 5026: loss: 0.3290, d_k_M range: [0.0019, 0.5616], d_k_M_hat range: [0.4471, 0.9880]
2025-03-11 20:26:21 - Train Iteration 5027: loss: 0.4980, d_k_M range: [0.0004, 0.1092], d_k_M_hat range: [0.2947, 0.6949]
2025-03-11 20:26:21 - Train Iteration 5028: loss: 0.2975, d_k_M range: [0.0021, 0.4637], d_k_M_hat range: [0.6861, 0.9884]
2025-03-11 20:26:21 - Train Iteration 5029: loss: 0.3133, d_k_M range: [0.0568, 0.5592], d_k_M_hat range: [0.7670, 0.9995]
2025-03-11 20:26:22 - Train Iteration 5030: loss: 0.3607, d_k_M range: [0.0081, 0.5945], d_k_M_hat range: [0.5897, 0.9940]
2025-03-11 20:26:22 - Train Iteration 5031: loss: 0.4939, d_k_M range: [0.0053, 0.6905], d_k_M_hat range: [0.5803, 0.9878]
2025-03-11 20:26:23 - Train Iteration 5032: loss: 0.2808, d_k_M range: [0.0221, 0.5108], d_k_M_hat range: [0.5493, 0.9918]
2025-03-11 20:26:23 - Train Iteration 5033: loss: 0.3451, d_k_M range: [0.0035, 0.4455], d_k_M_hat range: [0.4270, 0.9501]
2025-03-11 20:26:24 - Train Iteration 5034: loss: 0.6461, d_k_M range: [0.0003, 0.8017], d_k_M_hat range: [0.4695, 0.9979]
2025-03-11 20:26:24 - Train Iteration 5035: loss: 0.2242, d_k_M range: [0.0063, 0.3817], d_k_M_hat range: [0.5394, 0.9290]
2025-03-11 20:26:25 - Train Iteration 5036: loss: 0.2761, d_k_M range: [0.0005, 0.4249], d_k_M_hat range: [0.4751, 0.9836]
2025-03-11 20:26:25 - Train Iteration 5037: loss: 0.3196, d_k_M range: [0.0002, 0.3303], d_k_M_hat range: [0.4349, 0.9516]
2025-03-11 20:26:26 - Train Iteration 5038: loss: 0.3447, d_k_M range: [0.0002, 0.3410], d_k_M_hat range: [0.4131, 0.9689]
2025-03-11 20:26:26 - Train Iteration 5039: loss: 0.2551, d_k_M range: [0.0700, 0.4641], d_k_M_hat range: [0.6195, 0.9751]
2025-03-11 20:26:27 - Train Iteration 5040: loss: 0.4300, d_k_M range: [0.0013, 0.3265], d_k_M_hat range: [0.3456, 0.9382]
2025-03-11 20:26:27 - Train Iteration 5041: loss: 0.3547, d_k_M range: [0.1697, 0.5932], d_k_M_hat range: [0.7201, 0.9985]
2025-03-11 20:26:27 - Train Iteration 5042: loss: 0.2857, d_k_M range: [0.0042, 0.4551], d_k_M_hat range: [0.4725, 0.9669]
2025-03-11 20:26:28 - Train Iteration 5043: loss: 0.3797, d_k_M range: [0.0905, 0.6141], d_k_M_hat range: [0.7017, 0.9979]
2025-03-11 20:26:28 - Train Iteration 5044: loss: 0.3218, d_k_M range: [0.0034, 0.4401], d_k_M_hat range: [0.4911, 0.9528]
2025-03-11 20:26:29 - Train Iteration 5045: loss: 0.2445, d_k_M range: [0.0017, 0.4544], d_k_M_hat range: [0.5073, 0.9703]
2025-03-11 20:26:29 - Train Iteration 5046: loss: 0.2734, d_k_M range: [0.0161, 0.4451], d_k_M_hat range: [0.5711, 0.9939]
2025-03-11 20:26:29 - Train Iteration 5047: loss: 0.4823, d_k_M range: [0.1088, 0.6862], d_k_M_hat range: [0.7111, 0.9993]
2025-03-11 20:26:30 - Train Iteration 5048: loss: 0.2089, d_k_M range: [0.0022, 0.3825], d_k_M_hat range: [0.5931, 0.9333]
2025-03-11 20:26:30 - Train Iteration 5049: loss: 0.3471, d_k_M range: [0.0001, 0.3656], d_k_M_hat range: [0.4110, 0.9567]
2025-03-11 20:26:31 - Train Iteration 5050: loss: 0.2820, d_k_M range: [0.0019, 0.5170], d_k_M_hat range: [0.5629, 0.9903]
2025-03-11 20:26:31 - Train Iteration 5051: loss: 0.3039, d_k_M range: [0.0004, 0.3996], d_k_M_hat range: [0.4491, 0.9559]
2025-03-11 20:26:31 - Train Iteration 5052: loss: 0.3247, d_k_M range: [0.0024, 0.4594], d_k_M_hat range: [0.4326, 0.9426]
2025-03-11 20:26:32 - Train Iteration 5053: loss: 0.3008, d_k_M range: [0.0106, 0.4489], d_k_M_hat range: [0.5676, 0.9844]
2025-03-11 20:26:32 - Train Iteration 5054: loss: 0.3332, d_k_M range: [0.0152, 0.5514], d_k_M_hat range: [0.7157, 0.9887]
2025-03-11 20:26:33 - Train Iteration 5055: loss: 0.2844, d_k_M range: [0.0058, 0.5114], d_k_M_hat range: [0.5365, 0.9897]
2025-03-11 20:26:33 - Train Iteration 5056: loss: 0.2736, d_k_M range: [0.0039, 0.2977], d_k_M_hat range: [0.5247, 0.8712]
2025-03-11 20:26:34 - Train Iteration 5057: loss: 0.2879, d_k_M range: [0.0017, 0.5225], d_k_M_hat range: [0.4660, 0.9860]
2025-03-11 20:26:34 - Train Iteration 5058: loss: 0.2517, d_k_M range: [0.0175, 0.3909], d_k_M_hat range: [0.5984, 0.9663]
2025-03-11 20:26:34 - Train Iteration 5059: loss: 0.2942, d_k_M range: [0.0005, 0.3109], d_k_M_hat range: [0.4621, 0.9101]
2025-03-11 20:26:35 - Train Iteration 5060: loss: 0.5715, d_k_M range: [0.0026, 0.3609], d_k_M_hat range: [0.2466, 0.9951]
2025-03-11 20:26:35 - Train Iteration 5061: loss: 0.2876, d_k_M range: [0.0027, 0.3886], d_k_M_hat range: [0.5559, 0.9844]
2025-03-11 20:26:36 - Train Iteration 5062: loss: 0.2327, d_k_M range: [0.0017, 0.4537], d_k_M_hat range: [0.5193, 0.9904]
2025-03-11 20:26:36 - Train Iteration 5063: loss: 0.4610, d_k_M range: [0.0054, 0.6784], d_k_M_hat range: [0.4882, 0.9994]
2025-03-11 20:26:37 - Train Iteration 5064: loss: 0.8031, d_k_M range: [0.0000, 0.1199], d_k_M_hat range: [0.1039, 0.6392]
2025-03-11 20:26:37 - Train Iteration 5065: loss: 0.2313, d_k_M range: [0.0104, 0.3942], d_k_M_hat range: [0.6252, 0.9827]
2025-03-11 20:26:37 - Train Iteration 5066: loss: 0.2481, d_k_M range: [0.0008, 0.4903], d_k_M_hat range: [0.5526, 0.9922]
2025-03-11 20:26:38 - Train Iteration 5067: loss: 0.4219, d_k_M range: [0.0070, 0.6475], d_k_M_hat range: [0.6059, 0.9980]
2025-03-11 20:26:38 - Train Iteration 5068: loss: 0.3004, d_k_M range: [0.0003, 0.3791], d_k_M_hat range: [0.4553, 0.9374]
2025-03-11 20:26:39 - Train Iteration 5069: loss: 0.2476, d_k_M range: [0.0063, 0.2300], d_k_M_hat range: [0.5354, 0.8340]
2025-03-11 20:26:39 - Train Iteration 5070: loss: 0.3854, d_k_M range: [0.0002, 0.4056], d_k_M_hat range: [0.4095, 0.9185]
2025-03-11 20:26:40 - Train Iteration 5071: loss: 0.2144, d_k_M range: [0.0064, 0.4517], d_k_M_hat range: [0.6322, 0.9887]
2025-03-11 20:26:40 - Train Iteration 5072: loss: 0.2250, d_k_M range: [0.0057, 0.3802], d_k_M_hat range: [0.5376, 0.9703]
2025-03-11 20:26:40 - Train Iteration 5073: loss: 0.6683, d_k_M range: [0.0006, 0.1114], d_k_M_hat range: [0.1949, 0.8973]
2025-03-11 20:26:41 - Train Iteration 5074: loss: 0.1926, d_k_M range: [0.0095, 0.2692], d_k_M_hat range: [0.5742, 0.9428]
2025-03-11 20:26:41 - Train Iteration 5075: loss: 0.2818, d_k_M range: [0.0290, 0.5279], d_k_M_hat range: [0.6583, 0.9970]
2025-03-11 20:26:42 - Train Iteration 5076: loss: 0.4368, d_k_M range: [0.0054, 0.6378], d_k_M_hat range: [0.6248, 0.9769]
2025-03-11 20:26:42 - Train Iteration 5077: loss: 0.3578, d_k_M range: [0.0076, 0.5054], d_k_M_hat range: [0.6522, 0.9914]
2025-03-11 20:26:43 - Train Iteration 5078: loss: 0.1846, d_k_M range: [0.0069, 0.3898], d_k_M_hat range: [0.5979, 0.9652]
2025-03-11 20:26:43 - Train Iteration 5079: loss: 0.4114, d_k_M range: [0.0071, 0.6007], d_k_M_hat range: [0.6087, 0.9951]
2025-03-11 20:26:43 - Train Iteration 5080: loss: 0.2095, d_k_M range: [0.0019, 0.4515], d_k_M_hat range: [0.6312, 0.9937]
2025-03-11 20:26:44 - Train Iteration 5081: loss: 0.3280, d_k_M range: [0.0123, 0.5722], d_k_M_hat range: [0.6414, 0.9995]
2025-03-11 20:26:44 - Train Iteration 5082: loss: 0.2081, d_k_M range: [0.0038, 0.3336], d_k_M_hat range: [0.5519, 0.9532]
2025-03-11 20:26:45 - Train Iteration 5083: loss: 0.3843, d_k_M range: [0.0041, 0.6188], d_k_M_hat range: [0.5219, 0.9989]
2025-03-11 20:26:45 - Train Iteration 5084: loss: 0.3139, d_k_M range: [0.0005, 0.1271], d_k_M_hat range: [0.4426, 0.7997]
2025-03-11 20:26:46 - Train Iteration 5085: loss: 0.2509, d_k_M range: [0.0029, 0.4575], d_k_M_hat range: [0.5020, 0.9829]
2025-03-11 20:26:46 - Train Iteration 5086: loss: 0.2351, d_k_M range: [0.0062, 0.4692], d_k_M_hat range: [0.6249, 0.9863]
2025-03-11 20:26:47 - Train Iteration 5087: loss: 0.2495, d_k_M range: [0.0136, 0.4913], d_k_M_hat range: [0.5580, 0.9918]
2025-03-11 20:26:47 - Train Iteration 5088: loss: 0.3034, d_k_M range: [0.0054, 0.5426], d_k_M_hat range: [0.6160, 0.9917]
2025-03-11 20:26:48 - Train Iteration 5089: loss: 0.2232, d_k_M range: [0.0060, 0.4556], d_k_M_hat range: [0.5543, 0.9832]
2025-03-11 20:26:48 - Train Iteration 5090: loss: 0.2556, d_k_M range: [0.0483, 0.4956], d_k_M_hat range: [0.7388, 0.9900]
2025-03-11 20:26:49 - Train Iteration 5091: loss: 0.3176, d_k_M range: [0.0126, 0.5583], d_k_M_hat range: [0.6240, 0.9947]
2025-03-11 20:26:49 - Train Iteration 5092: loss: 0.2820, d_k_M range: [0.0004, 0.5117], d_k_M_hat range: [0.5913, 0.9935]
2025-03-11 20:26:49 - Train Iteration 5093: loss: 0.2936, d_k_M range: [0.0017, 0.1736], d_k_M_hat range: [0.4598, 0.8879]
2025-03-11 20:26:50 - Train Iteration 5094: loss: 0.4452, d_k_M range: [0.0145, 0.6651], d_k_M_hat range: [0.5982, 0.9978]
2025-03-11 20:26:50 - Train Iteration 5095: loss: 0.2435, d_k_M range: [0.0040, 0.3893], d_k_M_hat range: [0.5197, 0.9682]
2025-03-11 20:26:51 - Train Iteration 5096: loss: 0.2575, d_k_M range: [0.0024, 0.4976], d_k_M_hat range: [0.5928, 0.9902]
2025-03-11 20:26:51 - Train Iteration 5097: loss: 0.2528, d_k_M range: [0.0262, 0.1176], d_k_M_hat range: [0.5397, 0.8503]
2025-03-11 20:26:51 - Train Iteration 5098: loss: 0.2913, d_k_M range: [0.0034, 0.5259], d_k_M_hat range: [0.5515, 0.9970]
2025-03-11 20:26:52 - Train Iteration 5099: loss: 0.2991, d_k_M range: [0.0011, 0.2374], d_k_M_hat range: [0.4802, 0.6905]
2025-03-11 20:26:52 - Train Iteration 5100: loss: 0.2198, d_k_M range: [0.0038, 0.4479], d_k_M_hat range: [0.5536, 0.9803]
2025-03-11 20:26:53 - Train Iteration 5101: loss: 0.4083, d_k_M range: [0.0006, 0.3718], d_k_M_hat range: [0.3624, 0.9211]
2025-03-11 20:26:53 - Train Iteration 5102: loss: 0.2687, d_k_M range: [0.0373, 0.5073], d_k_M_hat range: [0.5560, 0.9889]
2025-03-11 20:26:54 - Train Iteration 5103: loss: 0.5148, d_k_M range: [0.0001, 0.2281], d_k_M_hat range: [0.2826, 0.8828]
2025-03-11 20:26:54 - Train Iteration 5104: loss: 0.7079, d_k_M range: [0.0060, 0.8395], d_k_M_hat range: [0.4907, 0.9982]
2025-03-11 20:26:54 - Train Iteration 5105: loss: 0.3310, d_k_M range: [0.0099, 0.5674], d_k_M_hat range: [0.6552, 0.9920]
2025-03-11 20:26:55 - Train Iteration 5106: loss: 0.2379, d_k_M range: [0.0048, 0.3873], d_k_M_hat range: [0.5371, 0.9562]
2025-03-11 20:26:55 - Train Iteration 5107: loss: 0.2779, d_k_M range: [0.0024, 0.2152], d_k_M_hat range: [0.4753, 0.8969]
2025-03-11 20:26:56 - Train Iteration 5108: loss: 0.1988, d_k_M range: [0.0178, 0.3894], d_k_M_hat range: [0.6167, 0.9900]
2025-03-11 20:26:56 - Train Iteration 5109: loss: 0.5057, d_k_M range: [0.0006, 0.4079], d_k_M_hat range: [0.2895, 0.9805]
2025-03-11 20:26:56 - Train Iteration 5110: loss: 0.2952, d_k_M range: [0.0211, 0.5371], d_k_M_hat range: [0.6704, 0.9938]
2025-03-11 20:26:57 - Train Iteration 5111: loss: 0.2367, d_k_M range: [0.0069, 0.4694], d_k_M_hat range: [0.5285, 0.9989]
2025-03-11 20:26:57 - Train Iteration 5112: loss: 0.5163, d_k_M range: [0.0728, 0.7182], d_k_M_hat range: [0.7437, 0.9997]
2025-03-11 20:26:58 - Train Iteration 5113: loss: 0.3348, d_k_M range: [0.0019, 0.3211], d_k_M_hat range: [0.4233, 0.9169]
2025-03-11 20:26:58 - Train Iteration 5114: loss: 0.3948, d_k_M range: [0.0173, 0.6212], d_k_M_hat range: [0.6428, 0.9929]
2025-03-11 20:26:59 - Train Iteration 5115: loss: 0.2722, d_k_M range: [0.0010, 0.3761], d_k_M_hat range: [0.4793, 0.9601]
2025-03-11 20:26:59 - Train Iteration 5116: loss: 0.2314, d_k_M range: [0.0006, 0.4029], d_k_M_hat range: [0.5195, 0.9738]
2025-03-11 20:26:59 - Train Iteration 5117: loss: 0.3157, d_k_M range: [0.0014, 0.3958], d_k_M_hat range: [0.4395, 0.9799]
2025-03-11 20:27:00 - Train Iteration 5118: loss: 0.2282, d_k_M range: [0.0032, 0.4708], d_k_M_hat range: [0.6344, 0.9931]
2025-03-11 20:27:00 - Train Iteration 5119: loss: 0.2474, d_k_M range: [0.0007, 0.4418], d_k_M_hat range: [0.5464, 0.9960]
2025-03-11 20:27:01 - Train Iteration 5120: loss: 0.1788, d_k_M range: [0.0071, 0.2876], d_k_M_hat range: [0.6027, 0.9848]
2025-03-11 20:27:01 - Train Iteration 5121: loss: 0.1221, d_k_M range: [0.0078, 0.3402], d_k_M_hat range: [0.7598, 0.9957]
2025-03-11 20:27:02 - Train Iteration 5122: loss: 0.2979, d_k_M range: [0.0038, 0.5396], d_k_M_hat range: [0.5464, 0.9938]
2025-03-11 20:27:02 - Train Iteration 5123: loss: 0.2459, d_k_M range: [0.0226, 0.4727], d_k_M_hat range: [0.5393, 0.9768]
2025-03-11 20:27:02 - Train Iteration 5124: loss: 0.3407, d_k_M range: [0.0000, 0.1309], d_k_M_hat range: [0.4164, 0.7736]
2025-03-11 20:27:03 - Train Iteration 5125: loss: 0.3145, d_k_M range: [0.0018, 0.3933], d_k_M_hat range: [0.4410, 0.9489]
2025-03-11 20:27:03 - Train Iteration 5126: loss: 0.4115, d_k_M range: [0.0074, 0.6353], d_k_M_hat range: [0.7064, 0.9938]
2025-03-11 20:27:04 - Train Iteration 5127: loss: 0.5564, d_k_M range: [0.0010, 0.3971], d_k_M_hat range: [0.2570, 0.9626]
2025-03-11 20:27:04 - Train Iteration 5128: loss: 0.3375, d_k_M range: [0.0546, 0.5754], d_k_M_hat range: [0.7412, 0.9944]
2025-03-11 20:27:05 - Train Iteration 5129: loss: 0.5870, d_k_M range: [0.0000, 0.0633], d_k_M_hat range: [0.2344, 0.7456]
2025-03-11 20:27:05 - Train Iteration 5130: loss: 0.3384, d_k_M range: [0.1163, 0.5072], d_k_M_hat range: [0.7942, 0.9806]
2025-03-11 20:27:05 - Train Iteration 5131: loss: 0.4452, d_k_M range: [0.0056, 0.4359], d_k_M_hat range: [0.3435, 0.9817]
2025-03-11 20:27:06 - Train Iteration 5132: loss: 0.2221, d_k_M range: [0.0307, 0.4576], d_k_M_hat range: [0.7810, 0.9894]
2025-03-11 20:27:06 - Train Iteration 5133: loss: 0.7315, d_k_M range: [0.0003, 0.3275], d_k_M_hat range: [0.1459, 0.9125]
2025-03-11 20:27:07 - Train Iteration 5134: loss: 0.3216, d_k_M range: [0.0002, 0.3774], d_k_M_hat range: [0.4331, 0.9649]
2025-03-11 20:27:07 - Train Iteration 5135: loss: 0.2193, d_k_M range: [0.0103, 0.4033], d_k_M_hat range: [0.5457, 0.9882]
2025-03-11 20:27:08 - Train Iteration 5136: loss: 0.2137, d_k_M range: [0.0148, 0.3349], d_k_M_hat range: [0.5686, 0.9745]
2025-03-11 20:27:08 - Train Iteration 5137: loss: 0.2741, d_k_M range: [0.0084, 0.4587], d_k_M_hat range: [0.4867, 0.9938]
2025-03-11 20:27:09 - Train Iteration 5138: loss: 0.2660, d_k_M range: [0.0033, 0.3511], d_k_M_hat range: [0.5254, 0.9846]
2025-03-11 20:27:09 - Train Iteration 5139: loss: 0.2439, d_k_M range: [0.0151, 0.4818], d_k_M_hat range: [0.6291, 0.9898]
2025-03-11 20:27:10 - Train Iteration 5140: loss: 0.2627, d_k_M range: [0.0055, 0.4019], d_k_M_hat range: [0.5193, 0.9482]
2025-03-11 20:27:10 - Train Iteration 5141: loss: 0.1930, d_k_M range: [0.0011, 0.2460], d_k_M_hat range: [0.5624, 0.9339]
2025-03-11 20:27:10 - Train Iteration 5142: loss: 0.1859, d_k_M range: [0.0019, 0.3719], d_k_M_hat range: [0.5977, 0.9916]
2025-03-11 20:27:11 - Train Iteration 5143: loss: 0.2871, d_k_M range: [0.0057, 0.4463], d_k_M_hat range: [0.4699, 0.9835]
2025-03-11 20:27:11 - Train Iteration 5144: loss: 0.3707, d_k_M range: [0.0135, 0.6081], d_k_M_hat range: [0.6546, 0.9992]
2025-03-11 20:27:12 - Train Iteration 5145: loss: 0.4601, d_k_M range: [0.0003, 0.2916], d_k_M_hat range: [0.3220, 0.8672]
2025-03-11 20:27:12 - Train Iteration 5146: loss: 0.2602, d_k_M range: [0.0030, 0.3694], d_k_M_hat range: [0.5429, 0.9768]
2025-03-11 20:27:13 - Train Iteration 5147: loss: 0.6380, d_k_M range: [0.0034, 0.4926], d_k_M_hat range: [0.2047, 0.9739]
2025-03-11 20:27:13 - Train Iteration 5148: loss: 0.2619, d_k_M range: [0.0328, 0.4696], d_k_M_hat range: [0.5739, 0.9934]
2025-03-11 20:27:14 - Train Iteration 5149: loss: 0.4266, d_k_M range: [0.0018, 0.1911], d_k_M_hat range: [0.3487, 0.9119]
2025-03-11 20:27:14 - Train Iteration 5150: loss: 0.7043, d_k_M range: [0.0233, 0.8377], d_k_M_hat range: [0.6168, 0.9985]
2025-03-11 20:27:15 - Train Iteration 5151: loss: 0.2961, d_k_M range: [0.0001, 0.3011], d_k_M_hat range: [0.4814, 0.9068]
2025-03-11 20:27:15 - Train Iteration 5152: loss: 0.3559, d_k_M range: [0.0042, 0.5872], d_k_M_hat range: [0.5801, 0.9907]
2025-03-11 20:27:16 - Train Iteration 5153: loss: 0.3226, d_k_M range: [0.0044, 0.5333], d_k_M_hat range: [0.4364, 0.9890]
2025-03-11 20:27:16 - Train Iteration 5154: loss: 0.3055, d_k_M range: [0.0031, 0.5486], d_k_M_hat range: [0.6044, 0.9959]
2025-03-11 20:27:17 - Train Iteration 5155: loss: 0.2575, d_k_M range: [0.2209, 0.4472], d_k_M_hat range: [0.7407, 0.9967]
2025-03-11 20:27:17 - Train Iteration 5156: loss: 0.3762, d_k_M range: [0.0072, 0.6100], d_k_M_hat range: [0.5292, 0.9966]
2025-03-11 20:27:17 - Train Iteration 5157: loss: 0.2816, d_k_M range: [0.0081, 0.4304], d_k_M_hat range: [0.4774, 0.9541]
2025-03-11 20:27:18 - Train Iteration 5158: loss: 0.3131, d_k_M range: [0.0012, 0.4430], d_k_M_hat range: [0.4416, 0.9763]
2025-03-11 20:27:18 - Train Iteration 5159: loss: 0.3009, d_k_M range: [0.0027, 0.2461], d_k_M_hat range: [0.4554, 0.8374]
2025-03-11 20:27:19 - Train Iteration 5160: loss: 0.4686, d_k_M range: [0.0027, 0.5559], d_k_M_hat range: [0.3181, 0.9894]
2025-03-11 20:27:19 - Train Iteration 5161: loss: 0.2671, d_k_M range: [0.1347, 0.4937], d_k_M_hat range: [0.6737, 0.9979]
2025-03-11 20:27:19 - Train Iteration 5162: loss: 0.3234, d_k_M range: [0.0323, 0.5667], d_k_M_hat range: [0.6066, 0.9980]
2025-03-11 20:27:20 - Train Iteration 5163: loss: 0.2519, d_k_M range: [0.0109, 0.4851], d_k_M_hat range: [0.5436, 0.9832]
2025-03-11 20:27:20 - Train Iteration 5164: loss: 0.2917, d_k_M range: [0.0008, 0.2258], d_k_M_hat range: [0.4700, 0.9461]
2025-03-11 20:27:21 - Train Iteration 5165: loss: 0.1956, d_k_M range: [0.0102, 0.3955], d_k_M_hat range: [0.5877, 0.9650]
2025-03-11 20:27:21 - Train Iteration 5166: loss: 0.2595, d_k_M range: [0.0006, 0.2216], d_k_M_hat range: [0.4911, 0.7895]
2025-03-11 20:27:22 - Train Iteration 5167: loss: 0.2630, d_k_M range: [0.0115, 0.3793], d_k_M_hat range: [0.5142, 0.9574]
2025-03-11 20:27:22 - Train Iteration 5168: loss: 0.2753, d_k_M range: [0.0107, 0.3744], d_k_M_hat range: [0.5377, 0.9733]
2025-03-11 20:27:23 - Train Iteration 5169: loss: 0.3080, d_k_M range: [0.0010, 0.5366], d_k_M_hat range: [0.4556, 0.9816]
2025-03-11 20:27:23 - Train Iteration 5170: loss: 0.3124, d_k_M range: [0.0021, 0.3003], d_k_M_hat range: [0.4432, 0.9370]
2025-03-11 20:27:24 - Train Iteration 5171: loss: 0.3715, d_k_M range: [0.0000, 0.2722], d_k_M_hat range: [0.3906, 0.9760]
2025-03-11 20:27:24 - Train Iteration 5172: loss: 0.2802, d_k_M range: [0.0011, 0.4048], d_k_M_hat range: [0.4718, 0.9874]
2025-03-11 20:27:24 - Train Iteration 5173: loss: 0.3560, d_k_M range: [0.0136, 0.5942], d_k_M_hat range: [0.5673, 0.9975]
2025-03-11 20:27:25 - Train Iteration 5174: loss: 0.2652, d_k_M range: [0.0123, 0.4904], d_k_M_hat range: [0.6168, 0.9828]
2025-03-11 20:27:25 - Train Iteration 5175: loss: 0.1814, d_k_M range: [0.0144, 0.3812], d_k_M_hat range: [0.6209, 0.9553]
2025-03-11 20:27:26 - Train Iteration 5176: loss: 0.2466, d_k_M range: [0.0060, 0.3987], d_k_M_hat range: [0.5132, 0.9035]
2025-03-11 20:27:26 - Train Iteration 5177: loss: 0.2959, d_k_M range: [0.0343, 0.5266], d_k_M_hat range: [0.5882, 0.9826]
2025-03-11 20:27:27 - Train Iteration 5178: loss: 0.3262, d_k_M range: [0.0002, 0.3219], d_k_M_hat range: [0.4290, 0.9477]
2025-03-11 20:27:27 - Train Iteration 5179: loss: 0.2598, d_k_M range: [0.0060, 0.4934], d_k_M_hat range: [0.5919, 0.9856]
2025-03-11 20:27:27 - Train Iteration 5180: loss: 0.2745, d_k_M range: [0.0073, 0.3995], d_k_M_hat range: [0.5058, 0.9746]
2025-03-11 20:27:28 - Train Iteration 5181: loss: 0.2113, d_k_M range: [0.0058, 0.4445], d_k_M_hat range: [0.6029, 0.9930]
2025-03-11 20:27:28 - Train Iteration 5182: loss: 0.3259, d_k_M range: [0.0036, 0.5560], d_k_M_hat range: [0.5676, 0.9851]
2025-03-11 20:27:29 - Train Iteration 5183: loss: 0.2941, d_k_M range: [0.0017, 0.4725], d_k_M_hat range: [0.5954, 0.9980]
2025-03-11 20:27:29 - Train Iteration 5184: loss: 0.4096, d_k_M range: [0.0011, 0.6320], d_k_M_hat range: [0.5602, 0.9933]
2025-03-11 20:27:30 - Train Iteration 5185: loss: 0.3181, d_k_M range: [0.0038, 0.2915], d_k_M_hat range: [0.5178, 0.9338]
2025-03-11 20:27:30 - Train Iteration 5186: loss: 0.2137, d_k_M range: [0.0031, 0.4171], d_k_M_hat range: [0.5960, 0.9553]
2025-03-11 20:27:30 - Train Iteration 5187: loss: 0.4102, d_k_M range: [0.1354, 0.3885], d_k_M_hat range: [0.7480, 0.9741]
2025-03-11 20:27:31 - Train Iteration 5188: loss: 0.7208, d_k_M range: [0.0051, 0.8489], d_k_M_hat range: [0.5984, 0.9999]
2025-03-11 20:27:31 - Train Iteration 5189: loss: 0.2832, d_k_M range: [0.0005, 0.4096], d_k_M_hat range: [0.4943, 0.9740]
2025-03-11 20:27:32 - Train Iteration 5190: loss: 0.2981, d_k_M range: [0.0105, 0.5268], d_k_M_hat range: [0.6200, 0.9862]
2025-03-11 20:27:32 - Train Iteration 5191: loss: 0.3360, d_k_M range: [0.0300, 0.5755], d_k_M_hat range: [0.7504, 0.9959]
2025-03-11 20:27:32 - Train Iteration 5192: loss: 0.2803, d_k_M range: [0.0020, 0.1903], d_k_M_hat range: [0.4728, 0.8647]
2025-03-11 20:27:33 - Train Iteration 5193: loss: 0.4187, d_k_M range: [0.0314, 0.6338], d_k_M_hat range: [0.7959, 0.9901]
2025-03-11 20:27:33 - Train Iteration 5194: loss: 0.1816, d_k_M range: [0.0051, 0.4108], d_k_M_hat range: [0.5858, 0.9846]
2025-03-11 20:27:34 - Train Iteration 5195: loss: 0.2756, d_k_M range: [0.0005, 0.2793], d_k_M_hat range: [0.4755, 0.8680]
2025-03-11 20:27:34 - Train Iteration 5196: loss: 0.2512, d_k_M range: [0.0010, 0.4411], d_k_M_hat range: [0.5019, 0.9712]
2025-03-11 20:27:35 - Train Iteration 5197: loss: 0.3163, d_k_M range: [0.0104, 0.4167], d_k_M_hat range: [0.4992, 0.9773]
2025-03-11 20:27:35 - Train Iteration 5198: loss: 0.6384, d_k_M range: [0.0098, 0.7951], d_k_M_hat range: [0.4841, 0.9961]
2025-03-11 20:27:36 - Train Iteration 5199: loss: 0.2069, d_k_M range: [0.0134, 0.4464], d_k_M_hat range: [0.6317, 0.9916]
2025-03-11 20:27:36 - Train Iteration 5200: loss: 0.2936, d_k_M range: [0.0006, 0.3007], d_k_M_hat range: [0.4588, 0.8132]
2025-03-11 20:27:37 - Train Iteration 5201: loss: 0.1573, d_k_M range: [0.0028, 0.3148], d_k_M_hat range: [0.6377, 0.9630]
2025-03-11 20:27:37 - Train Iteration 5202: loss: 0.3295, d_k_M range: [0.0053, 0.5688], d_k_M_hat range: [0.6295, 0.9948]
2025-03-11 20:27:37 - Train Iteration 5203: loss: 0.2755, d_k_M range: [0.0005, 0.3592], d_k_M_hat range: [0.4756, 0.9685]
2025-03-11 20:27:38 - Train Iteration 5204: loss: 0.3406, d_k_M range: [0.0124, 0.5806], d_k_M_hat range: [0.5404, 0.9970]
2025-03-11 20:27:38 - Train Iteration 5205: loss: 0.2450, d_k_M range: [0.0019, 0.3385], d_k_M_hat range: [0.5249, 0.9765]
2025-03-11 20:27:39 - Train Iteration 5206: loss: 0.2760, d_k_M range: [0.0248, 0.5030], d_k_M_hat range: [0.8019, 0.9960]
2025-03-11 20:27:39 - Train Iteration 5207: loss: 0.6869, d_k_M range: [0.0009, 0.3338], d_k_M_hat range: [0.1721, 0.8740]
2025-03-11 20:27:40 - Train Iteration 5208: loss: 0.7748, d_k_M range: [0.0110, 0.8791], d_k_M_hat range: [0.5192, 0.9988]
2025-03-11 20:27:40 - Train Iteration 5209: loss: 0.3159, d_k_M range: [0.0023, 0.4094], d_k_M_hat range: [0.4402, 0.9284]
2025-03-11 20:27:41 - Train Iteration 5210: loss: 0.7104, d_k_M range: [0.0277, 0.8425], d_k_M_hat range: [0.6777, 0.9996]
2025-03-11 20:27:41 - Train Iteration 5211: loss: 0.2703, d_k_M range: [0.0049, 0.1068], d_k_M_hat range: [0.5112, 0.6753]
2025-03-11 20:27:42 - Train Iteration 5212: loss: 0.2165, d_k_M range: [0.0191, 0.4512], d_k_M_hat range: [0.5758, 0.9860]
2025-03-11 20:27:42 - Train Iteration 5213: loss: 0.2873, d_k_M range: [0.0020, 0.5069], d_k_M_hat range: [0.4982, 0.9709]
2025-03-11 20:27:43 - Train Iteration 5214: loss: 0.3325, d_k_M range: [0.0016, 0.3573], d_k_M_hat range: [0.4250, 0.7965]
2025-03-11 20:27:43 - Train Iteration 5215: loss: 0.2491, d_k_M range: [0.0028, 0.4904], d_k_M_hat range: [0.5782, 0.9913]
2025-03-11 20:27:44 - Train Iteration 5216: loss: 0.3053, d_k_M range: [0.0002, 0.4939], d_k_M_hat range: [0.5294, 0.9793]
2025-03-11 20:27:44 - Train Iteration 5217: loss: 0.3047, d_k_M range: [0.0058, 0.5372], d_k_M_hat range: [0.4627, 0.9852]
2025-03-11 20:27:44 - Train Iteration 5218: loss: 0.3025, d_k_M range: [0.0054, 0.3339], d_k_M_hat range: [0.4555, 0.9566]
2025-03-11 20:27:45 - Train Iteration 5219: loss: 0.7227, d_k_M range: [0.0431, 0.8491], d_k_M_hat range: [0.7511, 0.9990]
2025-03-11 20:27:45 - Train Iteration 5220: loss: 0.2891, d_k_M range: [0.0021, 0.5072], d_k_M_hat range: [0.5149, 0.9696]
2025-03-11 20:27:46 - Train Iteration 5221: loss: 0.3070, d_k_M range: [0.0057, 0.3990], d_k_M_hat range: [0.4863, 0.9699]
2025-03-11 20:27:46 - Train Iteration 5222: loss: 0.2205, d_k_M range: [0.0114, 0.4651], d_k_M_hat range: [0.6359, 0.9956]
2025-03-11 20:27:46 - Train Iteration 5223: loss: 0.2998, d_k_M range: [0.0035, 0.5427], d_k_M_hat range: [0.5385, 0.9952]
2025-03-11 20:27:47 - Train Iteration 5224: loss: 0.2507, d_k_M range: [0.0038, 0.4733], d_k_M_hat range: [0.5450, 0.9892]
2025-03-11 20:27:47 - Train Iteration 5225: loss: 0.3362, d_k_M range: [0.0053, 0.5381], d_k_M_hat range: [0.5972, 0.9627]
2025-03-11 20:27:48 - Train Iteration 5226: loss: 0.3606, d_k_M range: [0.0006, 0.4266], d_k_M_hat range: [0.4000, 0.9865]
2025-03-11 20:27:48 - Train Iteration 5227: loss: 0.2688, d_k_M range: [0.0102, 0.4610], d_k_M_hat range: [0.5069, 0.9673]
2025-03-11 20:27:48 - Train Iteration 5228: loss: 0.2166, d_k_M range: [0.0206, 0.4443], d_k_M_hat range: [0.6839, 0.9828]
2025-03-11 20:27:49 - Train Iteration 5229: loss: 0.3118, d_k_M range: [0.0239, 0.4921], d_k_M_hat range: [0.5158, 0.9976]
2025-03-11 20:27:49 - Train Iteration 5230: loss: 0.2697, d_k_M range: [0.0191, 0.5095], d_k_M_hat range: [0.6098, 0.9918]
2025-03-11 20:27:50 - Train Iteration 5231: loss: 0.2558, d_k_M range: [0.0098, 0.4981], d_k_M_hat range: [0.5778, 0.9924]
2025-03-11 20:27:50 - Train Iteration 5232: loss: 0.7433, d_k_M range: [0.0003, 0.3370], d_k_M_hat range: [0.1382, 0.9417]
2025-03-11 20:27:51 - Train Iteration 5233: loss: 0.2707, d_k_M range: [0.0458, 0.5141], d_k_M_hat range: [0.6785, 0.9978]
2025-03-11 20:27:51 - Train Iteration 5234: loss: 0.7537, d_k_M range: [0.0260, 0.8675], d_k_M_hat range: [0.6006, 0.9994]
2025-03-11 20:27:52 - Train Iteration 5235: loss: 0.2471, d_k_M range: [0.0021, 0.2811], d_k_M_hat range: [0.5299, 0.8816]
2025-03-11 20:27:52 - Train Iteration 5236: loss: 0.1820, d_k_M range: [0.0480, 0.3835], d_k_M_hat range: [0.6214, 0.9876]
2025-03-11 20:27:53 - Train Iteration 5237: loss: 0.2682, d_k_M range: [0.0013, 0.3553], d_k_M_hat range: [0.4865, 0.9386]
2025-03-11 20:27:53 - Train Iteration 5238: loss: 0.5500, d_k_M range: [0.0279, 0.7406], d_k_M_hat range: [0.7062, 0.9990]
2025-03-11 20:27:54 - Train Iteration 5239: loss: 0.3059, d_k_M range: [0.0237, 0.4830], d_k_M_hat range: [0.6518, 0.9849]
2025-03-11 20:27:54 - Train Iteration 5240: loss: 0.3863, d_k_M range: [0.0001, 0.4132], d_k_M_hat range: [0.3787, 0.9937]
2025-03-11 20:27:54 - Train Iteration 5241: loss: 0.3282, d_k_M range: [0.1188, 0.5548], d_k_M_hat range: [0.9315, 0.9981]
2025-03-11 20:27:55 - Train Iteration 5242: loss: 0.2777, d_k_M range: [0.0278, 0.4997], d_k_M_hat range: [0.8103, 0.9955]
2025-03-11 20:27:55 - Train Iteration 5243: loss: 0.2075, d_k_M range: [0.0069, 0.0969], d_k_M_hat range: [0.5870, 0.8381]
2025-03-11 20:27:56 - Train Iteration 5244: loss: 0.7244, d_k_M range: [0.0198, 0.8487], d_k_M_hat range: [0.4307, 0.9976]
2025-03-11 20:27:56 - Train Iteration 5245: loss: 0.7968, d_k_M range: [0.0005, 0.3118], d_k_M_hat range: [0.1078, 0.9036]
2025-03-11 20:27:57 - Train Iteration 5246: loss: 0.2981, d_k_M range: [0.0006, 0.4286], d_k_M_hat range: [0.4546, 0.9657]
2025-03-11 20:27:57 - Train Iteration 5247: loss: 0.2143, d_k_M range: [0.0150, 0.4154], d_k_M_hat range: [0.5718, 0.9794]
2025-03-11 20:27:58 - Train Iteration 5248: loss: 0.8325, d_k_M range: [0.0009, 0.2905], d_k_M_hat range: [0.0885, 0.9683]
2025-03-11 20:27:58 - Train Iteration 5249: loss: 0.2705, d_k_M range: [0.0075, 0.5152], d_k_M_hat range: [0.5259, 0.9951]
2025-03-11 20:27:59 - Train Iteration 5250: loss: 0.2413, d_k_M range: [0.0101, 0.4528], d_k_M_hat range: [0.5844, 0.9724]
2025-03-11 20:27:59 - Train Iteration 5251: loss: 0.2479, d_k_M range: [0.0055, 0.4743], d_k_M_hat range: [0.5559, 0.9848]
2025-03-11 20:27:59 - Train Iteration 5252: loss: 0.2357, d_k_M range: [0.0280, 0.4721], d_k_M_hat range: [0.5679, 0.9912]
2025-03-11 20:28:00 - Train Iteration 5253: loss: 0.1960, d_k_M range: [0.0025, 0.4192], d_k_M_hat range: [0.5697, 0.9765]
2025-03-11 20:28:00 - Train Iteration 5254: loss: 0.3635, d_k_M range: [0.0569, 0.5125], d_k_M_hat range: [0.7479, 0.9926]
2025-03-11 20:28:01 - Train Iteration 5255: loss: 0.2421, d_k_M range: [0.0173, 0.4666], d_k_M_hat range: [0.5694, 0.9745]
2025-03-11 20:28:01 - Train Iteration 5256: loss: 0.2991, d_k_M range: [0.0066, 0.5285], d_k_M_hat range: [0.5749, 0.9967]
2025-03-11 20:28:02 - Train Iteration 5257: loss: 0.2535, d_k_M range: [0.0237, 0.4757], d_k_M_hat range: [0.5776, 0.9873]
2025-03-11 20:28:02 - Train Iteration 5258: loss: 0.2382, d_k_M range: [0.0025, 0.3961], d_k_M_hat range: [0.5264, 0.9789]
2025-03-11 20:28:03 - Train Iteration 5259: loss: 0.2443, d_k_M range: [0.0157, 0.4925], d_k_M_hat range: [0.6849, 0.9983]
2025-03-11 20:28:03 - Train Iteration 5260: loss: 0.5324, d_k_M range: [0.0001, 0.1440], d_k_M_hat range: [0.2706, 0.8374]
2025-03-11 20:28:04 - Train Iteration 5261: loss: 0.2494, d_k_M range: [0.0109, 0.4828], d_k_M_hat range: [0.7575, 0.9983]
2025-03-11 20:28:04 - Train Iteration 5262: loss: 0.3776, d_k_M range: [0.0011, 0.4076], d_k_M_hat range: [0.3892, 0.9905]
2025-03-11 20:28:05 - Train Iteration 5263: loss: 0.3744, d_k_M range: [0.0011, 0.4600], d_k_M_hat range: [0.5702, 0.9840]
2025-03-11 20:28:06 - Train Iteration 5264: loss: 0.2226, d_k_M range: [0.0033, 0.4087], d_k_M_hat range: [0.5694, 0.9722]
2025-03-11 20:28:06 - Train Iteration 5265: loss: 0.2968, d_k_M range: [0.0128, 0.5370], d_k_M_hat range: [0.5012, 0.9922]
2025-03-11 20:28:06 - Train Iteration 5266: loss: 0.4222, d_k_M range: [0.0042, 0.4425], d_k_M_hat range: [0.4153, 0.9759]
2025-03-11 20:28:07 - Train Iteration 5267: loss: 0.2519, d_k_M range: [0.0512, 0.4942], d_k_M_hat range: [0.6646, 0.9976]
2025-03-11 20:28:07 - Train Iteration 5268: loss: 0.3983, d_k_M range: [0.0007, 0.6214], d_k_M_hat range: [0.4247, 0.9903]
2025-03-11 20:28:08 - Train Iteration 5269: loss: 0.4202, d_k_M range: [0.0001, 0.6400], d_k_M_hat range: [0.3958, 0.9918]
2025-03-11 20:28:08 - Train Iteration 5270: loss: 0.2594, d_k_M range: [0.0003, 0.4139], d_k_M_hat range: [0.4910, 0.9946]
2025-03-11 20:28:09 - Train Iteration 5271: loss: 0.3286, d_k_M range: [0.0144, 0.5723], d_k_M_hat range: [0.6111, 0.9991]
2025-03-11 20:28:09 - Train Iteration 5272: loss: 0.2080, d_k_M range: [0.0011, 0.3947], d_k_M_hat range: [0.5531, 0.9833]
2025-03-11 20:28:09 - Train Iteration 5273: loss: 0.3721, d_k_M range: [0.0026, 0.6065], d_k_M_hat range: [0.5936, 0.9964]
2025-03-11 20:28:10 - Train Iteration 5274: loss: 0.3851, d_k_M range: [0.0000, 0.4656], d_k_M_hat range: [0.3794, 0.9860]
2025-03-11 20:28:10 - Train Iteration 5275: loss: 0.2411, d_k_M range: [0.0136, 0.4716], d_k_M_hat range: [0.6022, 0.9808]
2025-03-11 20:28:11 - Train Iteration 5276: loss: 0.3338, d_k_M range: [0.0053, 0.3309], d_k_M_hat range: [0.4275, 0.9905]
2025-03-11 20:28:11 - Train Iteration 5277: loss: 0.2944, d_k_M range: [0.0149, 0.5294], d_k_M_hat range: [0.6451, 0.9868]
2025-03-11 20:28:12 - Train Iteration 5278: loss: 0.3320, d_k_M range: [0.0010, 0.5195], d_k_M_hat range: [0.4247, 0.9987]
2025-03-11 20:28:12 - Train Iteration 5279: loss: 0.2416, d_k_M range: [0.1487, 0.4479], d_k_M_hat range: [0.9037, 0.9889]
2025-03-11 20:28:13 - Train Iteration 5280: loss: 0.2422, d_k_M range: [0.0004, 0.3185], d_k_M_hat range: [0.5136, 0.9337]
2025-03-11 20:28:13 - Train Iteration 5281: loss: 0.2814, d_k_M range: [0.0641, 0.5293], d_k_M_hat range: [0.5973, 0.9988]
2025-03-11 20:28:14 - Train Iteration 5282: loss: 0.5056, d_k_M range: [0.0001, 0.1415], d_k_M_hat range: [0.2910, 0.7707]
2025-03-11 20:28:14 - Train Iteration 5283: loss: 0.2617, d_k_M range: [0.0215, 0.5028], d_k_M_hat range: [0.6372, 0.9913]
2025-03-11 20:28:15 - Train Iteration 5284: loss: 0.2467, d_k_M range: [0.0061, 0.4682], d_k_M_hat range: [0.6528, 0.9716]
2025-03-11 20:28:15 - Train Iteration 5285: loss: 0.1991, d_k_M range: [0.0583, 0.4204], d_k_M_hat range: [0.7031, 0.9742]
2025-03-11 20:28:16 - Train Iteration 5286: loss: 0.2467, d_k_M range: [0.0018, 0.3580], d_k_M_hat range: [0.5051, 0.9309]
2025-03-11 20:28:16 - Train Iteration 5287: loss: 0.1693, d_k_M range: [0.0048, 0.2461], d_k_M_hat range: [0.6226, 0.9306]
2025-03-11 20:28:17 - Train Iteration 5288: loss: 0.2488, d_k_M range: [0.0037, 0.4620], d_k_M_hat range: [0.5610, 0.9879]
2025-03-11 20:28:17 - Train Iteration 5289: loss: 0.2512, d_k_M range: [0.0021, 0.4935], d_k_M_hat range: [0.5087, 0.9930]
2025-03-11 20:28:18 - Train Iteration 5290: loss: 0.6268, d_k_M range: [0.0016, 0.5232], d_k_M_hat range: [0.2099, 0.9959]
2025-03-11 20:28:18 - Train Iteration 5291: loss: 0.3398, d_k_M range: [0.0003, 0.4509], d_k_M_hat range: [0.4174, 0.9813]
2025-03-11 20:28:19 - Train Iteration 5292: loss: 0.2019, d_k_M range: [0.0005, 0.4126], d_k_M_hat range: [0.5732, 0.9887]
2025-03-11 20:28:19 - Train Iteration 5293: loss: 0.2411, d_k_M range: [0.0003, 0.4003], d_k_M_hat range: [0.5093, 0.9965]
2025-03-11 20:28:19 - Train Iteration 5294: loss: 0.2185, d_k_M range: [0.0029, 0.2424], d_k_M_hat range: [0.5355, 0.9334]
2025-03-11 20:28:20 - Train Iteration 5295: loss: 0.2206, d_k_M range: [0.0025, 0.2492], d_k_M_hat range: [0.5328, 0.9176]
2025-03-11 20:28:20 - Train Iteration 5296: loss: 0.2566, d_k_M range: [0.0020, 0.4946], d_k_M_hat range: [0.5470, 0.9880]
2025-03-11 20:28:21 - Train Iteration 5297: loss: 0.3911, d_k_M range: [0.0074, 0.6199], d_k_M_hat range: [0.5664, 0.9945]
2025-03-11 20:28:21 - Train Iteration 5298: loss: 0.3009, d_k_M range: [0.0635, 0.5402], d_k_M_hat range: [0.6907, 0.9916]
2025-03-11 20:28:22 - Train Iteration 5299: loss: 0.2855, d_k_M range: [0.0002, 0.1450], d_k_M_hat range: [0.4660, 0.8647]
2025-03-11 20:28:22 - Train Iteration 5300: loss: 0.2494, d_k_M range: [0.0064, 0.4585], d_k_M_hat range: [0.5071, 0.9886]
2025-03-11 20:28:23 - Train Iteration 5301: loss: 0.1507, d_k_M range: [0.0165, 0.3006], d_k_M_hat range: [0.6696, 0.9718]
2025-03-11 20:28:23 - Train Iteration 5302: loss: 0.2552, d_k_M range: [0.0030, 0.4983], d_k_M_hat range: [0.5772, 0.9931]
2025-03-11 20:28:24 - Train Iteration 5303: loss: 0.2551, d_k_M range: [0.0060, 0.2538], d_k_M_hat range: [0.5009, 0.9436]
2025-03-11 20:28:24 - Train Iteration 5304: loss: 0.3064, d_k_M range: [0.0026, 0.5146], d_k_M_hat range: [0.4646, 0.9858]
2025-03-11 20:28:25 - Train Iteration 5305: loss: 0.6033, d_k_M range: [0.0011, 0.4344], d_k_M_hat range: [0.2247, 0.9796]
2025-03-11 20:28:25 - Train Iteration 5306: loss: 0.2333, d_k_M range: [0.0007, 0.4463], d_k_M_hat range: [0.5448, 0.9724]
2025-03-11 20:28:26 - Train Iteration 5307: loss: 0.3766, d_k_M range: [0.0002, 0.1229], d_k_M_hat range: [0.3866, 0.9456]
2025-03-11 20:28:26 - Train Iteration 5308: loss: 0.3055, d_k_M range: [0.0197, 0.5495], d_k_M_hat range: [0.7124, 0.9983]
2025-03-11 20:28:27 - Train Iteration 5309: loss: 0.3551, d_k_M range: [0.0002, 0.3316], d_k_M_hat range: [0.4043, 0.9768]
2025-03-11 20:28:27 - Train Iteration 5310: loss: 0.5366, d_k_M range: [0.0076, 0.7318], d_k_M_hat range: [0.6843, 0.9992]
2025-03-11 20:28:28 - Train Iteration 5311: loss: 0.7637, d_k_M range: [0.0005, 0.8683], d_k_M_hat range: [0.3510, 0.9944]
2025-03-11 20:28:28 - Train Iteration 5312: loss: 0.2169, d_k_M range: [0.0024, 0.2000], d_k_M_hat range: [0.5373, 0.9124]
2025-03-11 20:28:28 - Train Iteration 5313: loss: 0.2939, d_k_M range: [0.0032, 0.5367], d_k_M_hat range: [0.5606, 0.9945]
2025-03-11 20:28:29 - Train Iteration 5314: loss: 0.2857, d_k_M range: [0.0013, 0.2673], d_k_M_hat range: [0.4668, 0.9648]
2025-03-11 20:28:29 - Train Iteration 5315: loss: 0.2391, d_k_M range: [0.0014, 0.2848], d_k_M_hat range: [0.5159, 0.9207]
2025-03-11 20:28:30 - Train Iteration 5316: loss: 0.2144, d_k_M range: [0.0171, 0.4553], d_k_M_hat range: [0.7892, 0.9967]
2025-03-11 20:28:30 - Train Iteration 5317: loss: 0.2205, d_k_M range: [0.0128, 0.4321], d_k_M_hat range: [0.5433, 0.9922]
2025-03-11 20:28:31 - Train Iteration 5318: loss: 0.2812, d_k_M range: [0.0069, 0.5075], d_k_M_hat range: [0.6076, 0.9933]
2025-03-11 20:28:32 - Train Iteration 5319: loss: 0.2724, d_k_M range: [0.0043, 0.4978], d_k_M_hat range: [0.5574, 0.9759]
2025-03-11 20:28:32 - Train Iteration 5320: loss: 0.3896, d_k_M range: [0.0027, 0.6236], d_k_M_hat range: [0.5221, 0.9994]
2025-03-11 20:28:33 - Train Iteration 5321: loss: 0.2467, d_k_M range: [0.0105, 0.4935], d_k_M_hat range: [0.5236, 0.9968]
2025-03-11 20:28:33 - Train Iteration 5322: loss: 0.3254, d_k_M range: [0.0000, 0.4767], d_k_M_hat range: [0.4296, 0.9879]
2025-03-11 20:28:34 - Train Iteration 5323: loss: 0.2054, d_k_M range: [0.0011, 0.4221], d_k_M_hat range: [0.5611, 0.9689]
2025-03-11 20:28:34 - Train Iteration 5324: loss: 0.3094, d_k_M range: [0.0007, 0.4555], d_k_M_hat range: [0.4447, 0.9823]
2025-03-11 20:28:35 - Train Iteration 5325: loss: 0.3625, d_k_M range: [0.0898, 0.5899], d_k_M_hat range: [0.7900, 0.9961]
2025-03-11 20:28:35 - Train Iteration 5326: loss: 0.2716, d_k_M range: [0.0006, 0.4881], d_k_M_hat range: [0.4805, 0.9670]
2025-03-11 20:28:36 - Train Iteration 5327: loss: 0.1770, d_k_M range: [0.0027, 0.4006], d_k_M_hat range: [0.6151, 0.9800]
2025-03-11 20:28:36 - Train Iteration 5328: loss: 0.2124, d_k_M range: [0.0024, 0.3795], d_k_M_hat range: [0.5416, 0.9805]
2025-03-11 20:28:37 - Train Iteration 5329: loss: 0.3426, d_k_M range: [0.0568, 0.5822], d_k_M_hat range: [0.8533, 0.9968]
2025-03-11 20:28:37 - Train Iteration 5330: loss: 0.1876, d_k_M range: [0.0051, 0.3658], d_k_M_hat range: [0.5890, 0.9668]
2025-03-11 20:28:37 - Train Iteration 5331: loss: 0.2386, d_k_M range: [0.0029, 0.4287], d_k_M_hat range: [0.5539, 0.9402]
2025-03-11 20:28:38 - Train Iteration 5332: loss: 0.2029, d_k_M range: [0.0198, 0.4298], d_k_M_hat range: [0.7407, 0.9878]
2025-03-11 20:28:38 - Train Iteration 5333: loss: 0.5647, d_k_M range: [0.0011, 0.3696], d_k_M_hat range: [0.2508, 0.9810]
2025-03-11 20:28:39 - Train Iteration 5334: loss: 0.2451, d_k_M range: [0.0078, 0.4938], d_k_M_hat range: [0.5861, 0.9987]
2025-03-11 20:28:39 - Train Iteration 5335: loss: 0.2559, d_k_M range: [0.0008, 0.3022], d_k_M_hat range: [0.4950, 0.8701]
2025-03-11 20:28:40 - Train Iteration 5336: loss: 0.2275, d_k_M range: [0.0494, 0.4556], d_k_M_hat range: [0.6350, 0.9908]
2025-03-11 20:28:40 - Train Iteration 5337: loss: 0.3231, d_k_M range: [0.0102, 0.5669], d_k_M_hat range: [0.5740, 0.9988]
2025-03-11 20:28:41 - Train Iteration 5338: loss: 0.2793, d_k_M range: [0.0006, 0.2309], d_k_M_hat range: [0.4721, 0.9486]
2025-03-11 20:28:41 - Train Iteration 5339: loss: 0.3353, d_k_M range: [0.0010, 0.3917], d_k_M_hat range: [0.4220, 0.9625]
2025-03-11 20:28:41 - Train Iteration 5340: loss: 0.1837, d_k_M range: [0.0124, 0.4041], d_k_M_hat range: [0.6321, 0.9853]
2025-03-11 20:28:42 - Train Iteration 5341: loss: 0.3574, d_k_M range: [0.0010, 0.4749], d_k_M_hat range: [0.4032, 0.9922]
2025-03-11 20:28:42 - Train Iteration 5342: loss: 0.3435, d_k_M range: [0.0012, 0.0166], d_k_M_hat range: [0.4152, 0.6821]
2025-03-11 20:28:43 - Train Iteration 5343: loss: 0.2528, d_k_M range: [0.0055, 0.4987], d_k_M_hat range: [0.5562, 0.9958]
2025-03-11 20:28:43 - Train Iteration 5344: loss: 0.2497, d_k_M range: [0.0049, 0.1355], d_k_M_hat range: [0.5052, 0.9409]
2025-03-11 20:28:44 - Train Iteration 5345: loss: 0.3095, d_k_M range: [0.0041, 0.5302], d_k_M_hat range: [0.4969, 0.9739]
2025-03-11 20:28:44 - Train Iteration 5346: loss: 0.1996, d_k_M range: [0.0077, 0.4262], d_k_M_hat range: [0.5815, 0.9892]
2025-03-11 20:28:45 - Train Iteration 5347: loss: 0.2095, d_k_M range: [0.0029, 0.3037], d_k_M_hat range: [0.5509, 0.9435]
2025-03-11 20:28:45 - Train Iteration 5348: loss: 0.3339, d_k_M range: [0.0015, 0.5036], d_k_M_hat range: [0.4237, 0.9912]
2025-03-11 20:28:45 - Train Iteration 5349: loss: 0.3044, d_k_M range: [0.0016, 0.4829], d_k_M_hat range: [0.5452, 0.9803]
2025-03-11 20:28:46 - Train Iteration 5350: loss: 0.1994, d_k_M range: [0.0065, 0.2903], d_k_M_hat range: [0.5600, 0.9643]
2025-03-11 20:28:46 - Train Iteration 5351: loss: 0.2110, d_k_M range: [0.0069, 0.4368], d_k_M_hat range: [0.5879, 0.9774]
2025-03-11 20:28:47 - Train Iteration 5352: loss: 0.2920, d_k_M range: [0.0118, 0.5268], d_k_M_hat range: [0.7278, 0.9986]
2025-03-11 20:28:47 - Train Iteration 5353: loss: 0.2235, d_k_M range: [0.0001, 0.2346], d_k_M_hat range: [0.5274, 0.8647]
2025-03-11 20:28:48 - Train Iteration 5354: loss: 0.3131, d_k_M range: [0.0002, 0.5534], d_k_M_hat range: [0.4727, 0.9939]
2025-03-11 20:28:48 - Train Iteration 5355: loss: 0.2319, d_k_M range: [0.0080, 0.4687], d_k_M_hat range: [0.7021, 0.9968]
2025-03-11 20:28:49 - Train Iteration 5356: loss: 0.6489, d_k_M range: [0.0006, 0.2958], d_k_M_hat range: [0.1951, 0.9615]
2025-03-11 20:28:49 - Train Iteration 5357: loss: 0.2703, d_k_M range: [0.0020, 0.4350], d_k_M_hat range: [0.4826, 0.9644]
2025-03-11 20:28:49 - Train Iteration 5358: loss: 0.2964, d_k_M range: [0.0019, 0.4740], d_k_M_hat range: [0.4591, 0.9879]
2025-03-11 20:28:50 - Train Iteration 5359: loss: 0.2192, d_k_M range: [0.0141, 0.4531], d_k_M_hat range: [0.7977, 0.9886]
2025-03-11 20:28:50 - Train Iteration 5360: loss: 0.2529, d_k_M range: [0.0100, 0.4575], d_k_M_hat range: [0.5461, 0.9642]
2025-03-11 20:28:51 - Train Iteration 5361: loss: 0.2726, d_k_M range: [0.0004, 0.4461], d_k_M_hat range: [0.4998, 0.9845]
2025-03-11 20:28:51 - Train Iteration 5362: loss: 0.2189, d_k_M range: [0.0026, 0.3292], d_k_M_hat range: [0.5356, 0.9919]
2025-03-11 20:28:52 - Train Iteration 5363: loss: 0.2871, d_k_M range: [0.0030, 0.5303], d_k_M_hat range: [0.5653, 0.9956]
2025-03-11 20:28:52 - Train Iteration 5364: loss: 0.3955, d_k_M range: [0.0018, 0.6283], d_k_M_hat range: [0.4843, 0.9994]
2025-03-11 20:28:52 - Train Iteration 5365: loss: 0.2300, d_k_M range: [0.0033, 0.4426], d_k_M_hat range: [0.5306, 0.9701]
2025-03-11 20:28:53 - Train Iteration 5366: loss: 0.3984, d_k_M range: [0.0023, 0.6265], d_k_M_hat range: [0.4533, 0.9953]
2025-03-11 20:28:53 - Train Iteration 5367: loss: 0.2816, d_k_M range: [0.0221, 0.4806], d_k_M_hat range: [0.6428, 0.9944]
2025-03-11 20:28:54 - Train Iteration 5368: loss: 0.2442, d_k_M range: [0.0019, 0.2807], d_k_M_hat range: [0.5080, 0.8783]
2025-03-11 20:28:54 - Train Iteration 5369: loss: 0.3619, d_k_M range: [0.0155, 0.5969], d_k_M_hat range: [0.6335, 0.9953]
2025-03-11 20:28:55 - Train Iteration 5370: loss: 0.4377, d_k_M range: [0.0003, 0.5207], d_k_M_hat range: [0.4549, 0.9826]
2025-03-11 20:28:55 - Train Iteration 5371: loss: 0.7248, d_k_M range: [0.0000, 0.3489], d_k_M_hat range: [0.1487, 0.9198]
2025-03-11 20:28:56 - Train Iteration 5372: loss: 0.2120, d_k_M range: [0.0208, 0.4001], d_k_M_hat range: [0.6379, 0.9857]
2025-03-11 20:28:56 - Train Iteration 5373: loss: 0.4338, d_k_M range: [0.0564, 0.4326], d_k_M_hat range: [0.6475, 0.9952]
2025-03-11 20:28:57 - Train Iteration 5374: loss: 0.2819, d_k_M range: [0.0216, 0.5203], d_k_M_hat range: [0.6199, 0.9894]
2025-03-11 20:28:57 - Train Iteration 5375: loss: 0.2506, d_k_M range: [0.0224, 0.4897], d_k_M_hat range: [0.5705, 0.9907]
2025-03-11 20:28:58 - Train Iteration 5376: loss: 0.7212, d_k_M range: [0.0000, 0.5029], d_k_M_hat range: [0.1508, 0.9761]
2025-03-11 20:28:58 - Train Iteration 5377: loss: 0.9755, d_k_M range: [0.0889, 0.9867], d_k_M_hat range: [0.8503, 0.9990]
2025-03-11 20:28:58 - Train Iteration 5378: loss: 0.2964, d_k_M range: [0.0225, 0.5394], d_k_M_hat range: [0.6485, 0.9949]
2025-03-11 20:28:59 - Train Iteration 5379: loss: 0.3853, d_k_M range: [0.0142, 0.6050], d_k_M_hat range: [0.6258, 0.9843]
2025-03-11 20:28:59 - Train Iteration 5380: loss: 0.3792, d_k_M range: [0.0033, 0.4003], d_k_M_hat range: [0.3875, 0.9914]
2025-03-11 20:29:00 - Train Iteration 5381: loss: 0.3493, d_k_M range: [0.0337, 0.4543], d_k_M_hat range: [0.4449, 0.9842]
2025-03-11 20:29:00 - Train Iteration 5382: loss: 0.2742, d_k_M range: [0.0182, 0.5198], d_k_M_hat range: [0.5955, 0.9962]
2025-03-11 20:29:01 - Train Iteration 5383: loss: 0.3759, d_k_M range: [0.0004, 0.4071], d_k_M_hat range: [0.3873, 0.9452]
2025-03-11 20:29:01 - Train Iteration 5384: loss: 0.2607, d_k_M range: [0.0020, 0.4959], d_k_M_hat range: [0.5181, 0.9853]
2025-03-11 20:29:02 - Train Iteration 5385: loss: 0.2768, d_k_M range: [0.0003, 0.1934], d_k_M_hat range: [0.4741, 0.7741]
2025-03-11 20:29:02 - Train Iteration 5386: loss: 0.2444, d_k_M range: [0.0017, 0.4085], d_k_M_hat range: [0.5073, 0.9604]
2025-03-11 20:29:03 - Train Iteration 5387: loss: 0.2907, d_k_M range: [0.0230, 0.4143], d_k_M_hat range: [0.6816, 0.9612]
2025-03-11 20:29:03 - Train Iteration 5388: loss: 0.7894, d_k_M range: [0.0007, 0.3378], d_k_M_hat range: [0.1189, 0.9227]
2025-03-11 20:29:04 - Train Iteration 5389: loss: 0.2161, d_k_M range: [0.0151, 0.4478], d_k_M_hat range: [0.5622, 0.9829]
2025-03-11 20:29:04 - Train Iteration 5390: loss: 0.2150, d_k_M range: [0.0085, 0.4590], d_k_M_hat range: [0.5985, 0.9953]
2025-03-11 20:29:05 - Train Iteration 5391: loss: 0.4975, d_k_M range: [0.0001, 0.4214], d_k_M_hat range: [0.2947, 0.9491]
2025-03-11 20:29:05 - Train Iteration 5392: loss: 0.5321, d_k_M range: [0.0510, 0.7194], d_k_M_hat range: [0.8010, 0.9991]
2025-03-11 20:29:06 - Train Iteration 5393: loss: 0.3903, d_k_M range: [0.0006, 0.5113], d_k_M_hat range: [0.3758, 0.9983]
2025-03-11 20:29:06 - Train Iteration 5394: loss: 0.4658, d_k_M range: [0.0337, 0.6824], d_k_M_hat range: [0.6907, 0.9999]
2025-03-11 20:29:06 - Train Iteration 5395: loss: 0.2422, d_k_M range: [0.0188, 0.4575], d_k_M_hat range: [0.5419, 0.9952]
2025-03-11 20:29:07 - Train Iteration 5396: loss: 0.2975, d_k_M range: [0.0057, 0.3599], d_k_M_hat range: [0.4769, 0.9706]
2025-03-11 20:29:07 - Train Iteration 5397: loss: 0.2230, d_k_M range: [0.0045, 0.4603], d_k_M_hat range: [0.5968, 0.9902]
2025-03-11 20:29:08 - Train Iteration 5398: loss: 0.3001, d_k_M range: [0.0067, 0.4950], d_k_M_hat range: [0.4668, 0.9962]
2025-03-11 20:29:08 - Train Iteration 5399: loss: 0.2434, d_k_M range: [0.0033, 0.4651], d_k_M_hat range: [0.5120, 0.9957]
2025-03-11 20:29:09 - Train Iteration 5400: loss: 0.4885, d_k_M range: [0.0102, 0.6931], d_k_M_hat range: [0.5190, 0.9942]
2025-03-11 20:29:09 - Train Iteration 5401: loss: 0.3682, d_k_M range: [0.0002, 0.0485], d_k_M_hat range: [0.3934, 0.7241]
2025-03-11 20:29:10 - Train Iteration 5402: loss: 0.3373, d_k_M range: [0.0002, 0.4375], d_k_M_hat range: [0.4195, 0.9813]
2025-03-11 20:29:10 - Train Iteration 5403: loss: 0.2610, d_k_M range: [0.0115, 0.4821], d_k_M_hat range: [0.6259, 0.9969]
2025-03-11 20:29:10 - Train Iteration 5404: loss: 0.5619, d_k_M range: [0.0009, 0.3442], d_k_M_hat range: [0.2534, 0.9569]
2025-03-11 20:29:11 - Train Iteration 5405: loss: 0.3627, d_k_M range: [0.0278, 0.3666], d_k_M_hat range: [0.5908, 0.9706]
2025-03-11 20:29:11 - Train Iteration 5406: loss: 0.8644, d_k_M range: [0.0000, 0.2449], d_k_M_hat range: [0.0703, 0.7185]
2025-03-11 20:29:12 - Train Iteration 5407: loss: 0.2190, d_k_M range: [0.0309, 0.4635], d_k_M_hat range: [0.5709, 0.9980]
2025-03-11 20:29:12 - Train Iteration 5408: loss: 0.2957, d_k_M range: [0.0051, 0.4626], d_k_M_hat range: [0.4613, 0.9857]
2025-03-11 20:29:13 - Train Iteration 5409: loss: 0.2614, d_k_M range: [0.0004, 0.4455], d_k_M_hat range: [0.5039, 0.9821]
2025-03-11 20:29:13 - Train Iteration 5410: loss: 0.2736, d_k_M range: [0.0038, 0.5050], d_k_M_hat range: [0.4943, 0.9820]
2025-03-11 20:29:13 - Train Iteration 5411: loss: 0.2608, d_k_M range: [0.0683, 0.5056], d_k_M_hat range: [0.8188, 0.9948]
2025-03-11 20:29:14 - Train Iteration 5412: loss: 0.3374, d_k_M range: [0.0842, 0.5777], d_k_M_hat range: [0.6008, 0.9970]
2025-03-11 20:29:14 - Train Iteration 5413: loss: 0.4177, d_k_M range: [0.0010, 0.5487], d_k_M_hat range: [0.3581, 0.9957]
2025-03-11 20:29:15 - Train Iteration 5414: loss: 0.2621, d_k_M range: [0.0030, 0.4600], d_k_M_hat range: [0.4911, 0.9626]
2025-03-11 20:29:15 - Train Iteration 5415: loss: 0.3073, d_k_M range: [0.0648, 0.5451], d_k_M_hat range: [0.8017, 0.9958]
2025-03-11 20:29:16 - Train Iteration 5416: loss: 0.3504, d_k_M range: [0.0002, 0.4936], d_k_M_hat range: [0.4083, 0.9647]
2025-03-11 20:29:16 - Train Iteration 5417: loss: 0.2444, d_k_M range: [0.0009, 0.1721], d_k_M_hat range: [0.5151, 0.9521]
2025-03-11 20:29:16 - Train Iteration 5418: loss: 0.2149, d_k_M range: [0.0264, 0.3709], d_k_M_hat range: [0.6801, 0.9884]
2025-03-11 20:29:17 - Train Iteration 5419: loss: 0.4950, d_k_M range: [0.0005, 0.4644], d_k_M_hat range: [0.3004, 0.9913]
2025-03-11 20:29:17 - Train Iteration 5420: loss: 0.2860, d_k_M range: [0.0930, 0.5296], d_k_M_hat range: [0.7566, 0.9965]
2025-03-11 20:29:18 - Train Iteration 5421: loss: 0.2801, d_k_M range: [0.0040, 0.4394], d_k_M_hat range: [0.5633, 0.9286]
2025-03-11 20:29:18 - Train Iteration 5422: loss: 0.4768, d_k_M range: [0.0153, 0.3600], d_k_M_hat range: [0.3248, 0.9649]
2025-03-11 20:29:19 - Train Iteration 5423: loss: 0.2020, d_k_M range: [0.0029, 0.4022], d_k_M_hat range: [0.5814, 0.9948]
2025-03-11 20:29:19 - Train Iteration 5424: loss: 0.2779, d_k_M range: [0.0746, 0.5178], d_k_M_hat range: [0.6957, 0.9946]
2025-03-11 20:29:20 - Train Iteration 5425: loss: 0.2843, d_k_M range: [0.0002, 0.0763], d_k_M_hat range: [0.4709, 0.8066]
2025-03-11 20:29:20 - Train Iteration 5426: loss: 0.2833, d_k_M range: [0.0015, 0.5031], d_k_M_hat range: [0.5243, 0.9952]
2025-03-11 20:29:21 - Train Iteration 5427: loss: 0.2885, d_k_M range: [0.0005, 0.5061], d_k_M_hat range: [0.4989, 0.9690]
2025-03-11 20:29:21 - Train Iteration 5428: loss: 0.2380, d_k_M range: [0.0071, 0.4202], d_k_M_hat range: [0.5439, 0.9475]
2025-03-11 20:29:22 - Train Iteration 5429: loss: 0.3352, d_k_M range: [0.0004, 0.3723], d_k_M_hat range: [0.4230, 0.9089]
2025-03-11 20:29:22 - Train Iteration 5430: loss: 0.2196, d_k_M range: [0.0091, 0.2679], d_k_M_hat range: [0.5405, 0.8630]
2025-03-11 20:29:23 - Train Iteration 5431: loss: 0.3849, d_k_M range: [0.0366, 0.6189], d_k_M_hat range: [0.6307, 0.9984]
2025-03-11 20:29:23 - Train Iteration 5432: loss: 0.2424, d_k_M range: [0.0032, 0.4572], d_k_M_hat range: [0.5588, 0.9891]
2025-03-11 20:29:23 - Train Iteration 5433: loss: 0.2679, d_k_M range: [0.0027, 0.4624], d_k_M_hat range: [0.4851, 0.9775]
2025-03-11 20:29:24 - Train Iteration 5434: loss: 0.2613, d_k_M range: [0.0013, 0.1264], d_k_M_hat range: [0.4915, 0.9308]
2025-03-11 20:29:24 - Train Iteration 5435: loss: 0.2679, d_k_M range: [0.0844, 0.4834], d_k_M_hat range: [0.6755, 0.9910]
2025-03-11 20:29:25 - Train Iteration 5436: loss: 0.3004, d_k_M range: [0.0003, 0.3067], d_k_M_hat range: [0.4637, 0.9820]
2025-03-11 20:29:25 - Train Iteration 5437: loss: 0.2397, d_k_M range: [0.0002, 0.4642], d_k_M_hat range: [0.5106, 0.9931]
2025-03-11 20:29:26 - Train Iteration 5438: loss: 0.2265, d_k_M range: [0.0034, 0.4099], d_k_M_hat range: [0.5347, 0.9680]
2025-03-11 20:29:26 - Train Iteration 5439: loss: 0.2078, d_k_M range: [0.0256, 0.4317], d_k_M_hat range: [0.6963, 0.9840]
2025-03-11 20:29:26 - Train Iteration 5440: loss: 0.2518, d_k_M range: [0.0018, 0.4463], d_k_M_hat range: [0.5001, 0.9679]
2025-03-11 20:29:27 - Train Iteration 5441: loss: 0.4009, d_k_M range: [0.0001, 0.2688], d_k_M_hat range: [0.3669, 0.8774]
2025-03-11 20:29:27 - Train Iteration 5442: loss: 0.2782, d_k_M range: [0.0020, 0.5073], d_k_M_hat range: [0.5893, 0.9875]
2025-03-11 20:29:28 - Train Iteration 5443: loss: 0.2076, d_k_M range: [0.0036, 0.3812], d_k_M_hat range: [0.5483, 0.9705]
2025-03-11 20:29:28 - Train Iteration 5444: loss: 0.3349, d_k_M range: [0.0021, 0.3766], d_k_M_hat range: [0.4233, 0.9775]
2025-03-11 20:29:29 - Train Iteration 5445: loss: 0.1855, d_k_M range: [0.0135, 0.3512], d_k_M_hat range: [0.7063, 0.9649]
2025-03-11 20:29:29 - Train Iteration 5446: loss: 0.3372, d_k_M range: [0.0035, 0.5681], d_k_M_hat range: [0.7212, 0.9987]
2025-03-11 20:29:29 - Train Iteration 5447: loss: 0.3000, d_k_M range: [0.0013, 0.4919], d_k_M_hat range: [0.4535, 0.9802]
2025-03-11 20:29:30 - Train Iteration 5448: loss: 0.2782, d_k_M range: [0.0007, 0.5254], d_k_M_hat range: [0.5550, 0.9984]
2025-03-11 20:29:30 - Train Iteration 5449: loss: 0.4616, d_k_M range: [0.0021, 0.4472], d_k_M_hat range: [0.3248, 0.9962]
2025-03-11 20:29:31 - Train Iteration 5450: loss: 0.3536, d_k_M range: [0.0108, 0.5920], d_k_M_hat range: [0.6394, 0.9973]
2025-03-11 20:29:31 - Train Iteration 5451: loss: 0.3702, d_k_M range: [0.0274, 0.6056], d_k_M_hat range: [0.6083, 0.9971]
2025-03-11 20:29:32 - Train Iteration 5452: loss: 0.2156, d_k_M range: [0.0059, 0.4142], d_k_M_hat range: [0.5415, 0.9773]
2025-03-11 20:29:32 - Train Iteration 5453: loss: 0.2962, d_k_M range: [0.0277, 0.5335], d_k_M_hat range: [0.7592, 0.9892]
2025-03-11 20:29:32 - Train Iteration 5454: loss: 0.2507, d_k_M range: [0.0012, 0.3847], d_k_M_hat range: [0.6240, 0.9946]
2025-03-11 20:29:33 - Train Iteration 5455: loss: 0.2721, d_k_M range: [0.0003, 0.1332], d_k_M_hat range: [0.4888, 0.9292]
2025-03-11 20:29:33 - Train Iteration 5456: loss: 0.2673, d_k_M range: [0.1175, 0.5157], d_k_M_hat range: [0.8722, 0.9987]
2025-03-11 20:29:34 - Train Iteration 5457: loss: 0.2827, d_k_M range: [0.0002, 0.5045], d_k_M_hat range: [0.4733, 0.9869]
2025-03-11 20:29:34 - Train Iteration 5458: loss: 0.2633, d_k_M range: [0.0001, 0.5049], d_k_M_hat range: [0.4947, 0.9918]
2025-03-11 20:29:34 - Train Iteration 5459: loss: 0.3050, d_k_M range: [0.0007, 0.0877], d_k_M_hat range: [0.4485, 0.8822]
2025-03-11 20:29:35 - Train Iteration 5460: loss: 0.2686, d_k_M range: [0.0299, 0.5080], d_k_M_hat range: [0.7036, 0.9967]
2025-03-11 20:29:35 - Train Iteration 5461: loss: 0.2839, d_k_M range: [0.0033, 0.1943], d_k_M_hat range: [0.4726, 0.9411]
2025-03-11 20:29:36 - Train Iteration 5462: loss: 0.3085, d_k_M range: [0.2048, 0.5541], d_k_M_hat range: [0.9548, 0.9986]
2025-03-11 20:29:36 - Train Iteration 5463: loss: 0.2596, d_k_M range: [0.0123, 0.5025], d_k_M_hat range: [0.6154, 0.9930]
2025-03-11 20:29:37 - Train Iteration 5464: loss: 0.1777, d_k_M range: [0.0068, 0.3993], d_k_M_hat range: [0.7472, 0.9777]
2025-03-11 20:29:37 - Train Iteration 5465: loss: 0.5082, d_k_M range: [0.0001, 0.2548], d_k_M_hat range: [0.2884, 0.9138]
2025-03-11 20:29:37 - Train Iteration 5466: loss: 0.1633, d_k_M range: [0.0017, 0.3693], d_k_M_hat range: [0.6121, 0.9744]
2025-03-11 20:29:38 - Train Iteration 5467: loss: 0.4791, d_k_M range: [0.0005, 0.3603], d_k_M_hat range: [0.3084, 0.9555]
2025-03-11 20:29:38 - Train Iteration 5468: loss: 0.4033, d_k_M range: [0.1611, 0.6079], d_k_M_hat range: [0.8462, 0.9991]
2025-03-11 20:29:39 - Train Iteration 5469: loss: 0.2720, d_k_M range: [0.0005, 0.5105], d_k_M_hat range: [0.5568, 0.9889]
2025-03-11 20:29:39 - Train Iteration 5470: loss: 0.2926, d_k_M range: [0.0011, 0.2878], d_k_M_hat range: [0.4602, 0.9785]
2025-03-11 20:29:40 - Train Iteration 5471: loss: 0.1776, d_k_M range: [0.0216, 0.2101], d_k_M_hat range: [0.7124, 0.9578]
2025-03-11 20:29:40 - Train Iteration 5472: loss: 0.2847, d_k_M range: [0.1176, 0.5333], d_k_M_hat range: [0.9513, 0.9997]
2025-03-11 20:29:41 - Train Iteration 5473: loss: 0.2407, d_k_M range: [0.0113, 0.4815], d_k_M_hat range: [0.6914, 0.9910]
2025-03-11 20:29:41 - Train Iteration 5474: loss: 0.2828, d_k_M range: [0.0427, 0.5306], d_k_M_hat range: [0.6736, 0.9988]
2025-03-11 20:29:42 - Train Iteration 5475: loss: 0.2674, d_k_M range: [0.0009, 0.2826], d_k_M_hat range: [0.5262, 0.9794]
2025-03-11 20:29:42 - Train Iteration 5476: loss: 0.2856, d_k_M range: [0.0001, 0.3625], d_k_M_hat range: [0.4657, 0.9899]
2025-03-11 20:29:43 - Train Iteration 5477: loss: 0.2291, d_k_M range: [0.0168, 0.4537], d_k_M_hat range: [0.8124, 0.9751]
2025-03-11 20:29:43 - Train Iteration 5478: loss: 0.4131, d_k_M range: [0.0020, 0.6382], d_k_M_hat range: [0.4718, 0.9955]
2025-03-11 20:29:44 - Train Iteration 5479: loss: 0.3193, d_k_M range: [0.0001, 0.3845], d_k_M_hat range: [0.4450, 0.9255]
2025-03-11 20:29:44 - Train Iteration 5480: loss: 0.2687, d_k_M range: [0.0026, 0.5174], d_k_M_hat range: [0.6353, 0.9990]
2025-03-11 20:29:45 - Train Iteration 5481: loss: 0.3735, d_k_M range: [0.0001, 0.1850], d_k_M_hat range: [0.3890, 0.9204]
2025-03-11 20:29:45 - Train Iteration 5482: loss: 0.3621, d_k_M range: [0.0095, 0.4426], d_k_M_hat range: [0.4077, 0.9893]
2025-03-11 20:29:45 - Train Iteration 5483: loss: 0.2261, d_k_M range: [0.0047, 0.3486], d_k_M_hat range: [0.5327, 0.9150]
2025-03-11 20:29:46 - Train Iteration 5484: loss: 0.2682, d_k_M range: [0.0012, 0.1185], d_k_M_hat range: [0.4834, 0.9592]
2025-03-11 20:29:46 - Train Iteration 5485: loss: 0.3392, d_k_M range: [0.0028, 0.5797], d_k_M_hat range: [0.5320, 0.9980]
2025-03-11 20:29:47 - Train Iteration 5486: loss: 0.2637, d_k_M range: [0.0014, 0.0696], d_k_M_hat range: [0.4939, 0.9530]
2025-03-11 20:29:47 - Train Iteration 5487: loss: 0.1977, d_k_M range: [0.0063, 0.3540], d_k_M_hat range: [0.5655, 0.9577]
2025-03-11 20:29:48 - Train Iteration 5488: loss: 0.5291, d_k_M range: [0.1162, 0.7244], d_k_M_hat range: [0.7797, 0.9970]
2025-03-11 20:29:48 - Train Iteration 5489: loss: 0.4510, d_k_M range: [0.0005, 0.1922], d_k_M_hat range: [0.3362, 0.8634]
2025-03-11 20:29:48 - Train Iteration 5490: loss: 0.2474, d_k_M range: [0.0848, 0.4832], d_k_M_hat range: [0.6108, 0.9973]
2025-03-11 20:29:49 - Train Iteration 5491: loss: 0.3049, d_k_M range: [0.0006, 0.3874], d_k_M_hat range: [0.4484, 0.9711]
2025-03-11 20:29:49 - Train Iteration 5492: loss: 0.3556, d_k_M range: [0.0012, 0.5588], d_k_M_hat range: [0.5859, 0.9950]
2025-03-11 20:29:50 - Train Iteration 5493: loss: 0.2557, d_k_M range: [0.0181, 0.4996], d_k_M_hat range: [0.5843, 0.9958]
2025-03-11 20:29:50 - Train Iteration 5494: loss: 0.2582, d_k_M range: [0.0015, 0.2179], d_k_M_hat range: [0.5034, 0.9139]
2025-03-11 20:29:51 - Train Iteration 5495: loss: 0.2707, d_k_M range: [0.0033, 0.5115], d_k_M_hat range: [0.5702, 0.9912]
2025-03-11 20:29:51 - Train Iteration 5496: loss: 0.5247, d_k_M range: [0.0003, 0.4838], d_k_M_hat range: [0.2760, 0.9909]
2025-03-11 20:29:51 - Train Iteration 5497: loss: 0.4576, d_k_M range: [0.2534, 0.6722], d_k_M_hat range: [0.8993, 0.9981]
2025-03-11 20:29:52 - Train Iteration 5498: loss: 0.3067, d_k_M range: [0.0013, 0.1993], d_k_M_hat range: [0.4475, 0.9222]
2025-03-11 20:29:52 - Train Iteration 5499: loss: 0.4002, d_k_M range: [0.0024, 0.1018], d_k_M_hat range: [0.3698, 0.8351]
2025-03-11 20:29:53 - Train Iteration 5500: loss: 0.2784, d_k_M range: [0.0182, 0.5148], d_k_M_hat range: [0.4905, 0.9982]
2025-03-11 20:29:53 - Train Iteration 5501: loss: 0.2608, d_k_M range: [0.0028, 0.4440], d_k_M_hat range: [0.5702, 0.9455]
2025-03-11 20:29:53 - Train Iteration 5502: loss: 0.2389, d_k_M range: [0.0100, 0.4841], d_k_M_hat range: [0.7663, 0.9953]
2025-03-11 20:29:54 - Train Iteration 5503: loss: 0.3860, d_k_M range: [0.0012, 0.1885], d_k_M_hat range: [0.3800, 0.9676]
2025-03-11 20:29:54 - Train Iteration 5504: loss: 0.1823, d_k_M range: [0.0214, 0.3137], d_k_M_hat range: [0.5945, 0.9125]
2025-03-11 20:29:55 - Train Iteration 5505: loss: 0.2449, d_k_M range: [0.0006, 0.0855], d_k_M_hat range: [0.5057, 0.7798]
2025-03-11 20:29:55 - Train Iteration 5506: loss: 0.2783, d_k_M range: [0.0002, 0.5194], d_k_M_hat range: [0.4766, 0.9954]
2025-03-11 20:29:56 - Train Iteration 5507: loss: 0.2910, d_k_M range: [0.0004, 0.4892], d_k_M_hat range: [0.4609, 0.9850]
2025-03-11 20:29:56 - Train Iteration 5508: loss: 0.2658, d_k_M range: [0.0160, 0.5040], d_k_M_hat range: [0.5381, 0.9942]
2025-03-11 20:29:56 - Train Iteration 5509: loss: 0.3706, d_k_M range: [0.0012, 0.1534], d_k_M_hat range: [0.3924, 0.9365]
2025-03-11 20:29:57 - Train Iteration 5510: loss: 0.3402, d_k_M range: [0.1015, 0.5780], d_k_M_hat range: [0.7644, 0.9985]
2025-03-11 20:29:57 - Train Iteration 5511: loss: 0.2047, d_k_M range: [0.0039, 0.3264], d_k_M_hat range: [0.5842, 0.9386]
2025-03-11 20:29:58 - Train Iteration 5512: loss: 0.3093, d_k_M range: [0.0001, 0.5226], d_k_M_hat range: [0.4440, 0.9956]
2025-03-11 20:29:58 - Train Iteration 5513: loss: 0.2271, d_k_M range: [0.0045, 0.4035], d_k_M_hat range: [0.5739, 0.9929]
2025-03-11 20:29:58 - Train Iteration 5514: loss: 0.2900, d_k_M range: [0.0007, 0.5342], d_k_M_hat range: [0.5227, 0.9957]
2025-03-11 20:29:59 - Train Iteration 5515: loss: 0.2728, d_k_M range: [0.0001, 0.5207], d_k_M_hat range: [0.4934, 0.9983]
2025-03-11 20:29:59 - Train Iteration 5516: loss: 0.1932, d_k_M range: [0.0003, 0.3561], d_k_M_hat range: [0.5739, 0.9370]
2025-03-11 20:30:00 - Train Iteration 5517: loss: 0.2496, d_k_M range: [0.0050, 0.3895], d_k_M_hat range: [0.5062, 0.9764]
2025-03-11 20:30:00 - Train Iteration 5518: loss: 0.3489, d_k_M range: [0.0082, 0.3407], d_k_M_hat range: [0.4332, 0.9849]
2025-03-11 20:30:01 - Train Iteration 5519: loss: 0.5887, d_k_M range: [0.0154, 0.7661], d_k_M_hat range: [0.4569, 0.9988]
2025-03-11 20:30:01 - Train Iteration 5520: loss: 0.1954, d_k_M range: [0.0016, 0.3814], d_k_M_hat range: [0.5596, 0.9489]
2025-03-11 20:30:02 - Train Iteration 5521: loss: 0.3056, d_k_M range: [0.2201, 0.5509], d_k_M_hat range: [0.8840, 0.9981]
2025-03-11 20:30:02 - Train Iteration 5522: loss: 0.3270, d_k_M range: [0.0008, 0.5331], d_k_M_hat range: [0.4307, 0.9973]
2025-03-11 20:30:02 - Train Iteration 5523: loss: 0.2096, d_k_M range: [0.0772, 0.4265], d_k_M_hat range: [0.9019, 0.9879]
2025-03-11 20:30:03 - Train Iteration 5524: loss: 0.1754, d_k_M range: [0.0135, 0.4065], d_k_M_hat range: [0.6229, 0.9877]
2025-03-11 20:30:03 - Train Iteration 5525: loss: 0.3046, d_k_M range: [0.0016, 0.1309], d_k_M_hat range: [0.4560, 0.8596]
2025-03-11 20:30:04 - Train Iteration 5526: loss: 0.2948, d_k_M range: [0.0022, 0.4387], d_k_M_hat range: [0.4992, 0.9687]
2025-03-11 20:30:04 - Train Iteration 5527: loss: 0.3149, d_k_M range: [0.0022, 0.5567], d_k_M_hat range: [0.5473, 0.9956]
2025-03-11 20:30:05 - Train Iteration 5528: loss: 0.4101, d_k_M range: [0.0011, 0.3791], d_k_M_hat range: [0.3702, 0.9389]
2025-03-11 20:30:05 - Train Iteration 5529: loss: 0.5489, d_k_M range: [0.0138, 0.7281], d_k_M_hat range: [0.7059, 0.9948]
2025-03-11 20:30:06 - Train Iteration 5530: loss: 0.1885, d_k_M range: [0.0071, 0.4158], d_k_M_hat range: [0.6355, 0.9816]
2025-03-11 20:30:06 - Train Iteration 5531: loss: 0.4792, d_k_M range: [0.0062, 0.5038], d_k_M_hat range: [0.5700, 0.9977]
2025-03-11 20:30:07 - Train Iteration 5532: loss: 0.3814, d_k_M range: [0.0015, 0.4839], d_k_M_hat range: [0.3839, 0.9818]
2025-03-11 20:30:07 - Train Iteration 5533: loss: 0.2182, d_k_M range: [0.0056, 0.4421], d_k_M_hat range: [0.5384, 0.9953]
2025-03-11 20:30:07 - Train Iteration 5534: loss: 0.2575, d_k_M range: [0.0841, 0.5044], d_k_M_hat range: [0.6248, 0.9970]
2025-03-11 20:30:08 - Train Iteration 5535: loss: 0.4208, d_k_M range: [0.0002, 0.1667], d_k_M_hat range: [0.3515, 0.8079]
2025-03-11 20:30:08 - Train Iteration 5536: loss: 0.3758, d_k_M range: [0.0088, 0.6128], d_k_M_hat range: [0.5405, 0.9997]
2025-03-11 20:30:09 - Train Iteration 5537: loss: 0.2232, d_k_M range: [0.0031, 0.1687], d_k_M_hat range: [0.5313, 0.8894]
2025-03-11 20:30:09 - Train Iteration 5538: loss: 0.2012, d_k_M range: [0.0384, 0.4310], d_k_M_hat range: [0.6439, 0.9824]
2025-03-11 20:30:09 - Train Iteration 5539: loss: 0.1790, d_k_M range: [0.0049, 0.2748], d_k_M_hat range: [0.6205, 0.9579]
2025-03-11 20:30:10 - Train Iteration 5540: loss: 0.8595, d_k_M range: [0.0002, 0.1944], d_k_M_hat range: [0.0731, 0.9488]
2025-03-11 20:30:10 - Train Iteration 5541: loss: 0.3796, d_k_M range: [0.1116, 0.6156], d_k_M_hat range: [0.8092, 0.9994]
2025-03-11 20:30:11 - Train Iteration 5542: loss: 0.2473, d_k_M range: [0.0007, 0.4722], d_k_M_hat range: [0.5367, 0.9786]
2025-03-11 20:30:11 - Train Iteration 5543: loss: 0.4169, d_k_M range: [0.0005, 0.4159], d_k_M_hat range: [0.3548, 0.9930]
2025-03-11 20:30:12 - Train Iteration 5544: loss: 0.4286, d_k_M range: [0.0018, 0.4010], d_k_M_hat range: [0.4156, 0.9865]
2025-03-11 20:30:12 - Train Iteration 5545: loss: 0.2520, d_k_M range: [0.0171, 0.4138], d_k_M_hat range: [0.5978, 0.9576]
2025-03-11 20:30:12 - Train Iteration 5546: loss: 0.4109, d_k_M range: [0.0001, 0.3498], d_k_M_hat range: [0.3590, 0.9780]
2025-03-11 20:30:13 - Train Iteration 5547: loss: 0.2917, d_k_M range: [0.0885, 0.5397], d_k_M_hat range: [0.7697, 0.9995]
2025-03-11 20:30:13 - Train Iteration 5548: loss: 0.3194, d_k_M range: [0.0006, 0.4476], d_k_M_hat range: [0.4980, 0.9957]
2025-03-11 20:30:14 - Train Iteration 5549: loss: 0.2739, d_k_M range: [0.0009, 0.4760], d_k_M_hat range: [0.5070, 0.9527]
2025-03-11 20:30:14 - Train Iteration 5550: loss: 0.2911, d_k_M range: [0.0032, 0.5291], d_k_M_hat range: [0.6501, 0.9928]
2025-03-11 20:30:15 - Train Iteration 5551: loss: 0.3270, d_k_M range: [0.0024, 0.5205], d_k_M_hat range: [0.4306, 0.9858]
2025-03-11 20:30:15 - Train Iteration 5552: loss: 0.2335, d_k_M range: [0.0460, 0.4797], d_k_M_hat range: [0.8128, 0.9964]
2025-03-11 20:30:15 - Train Iteration 5553: loss: 0.2410, d_k_M range: [0.0027, 0.0867], d_k_M_hat range: [0.5122, 0.7966]
2025-03-11 20:30:16 - Train Iteration 5554: loss: 0.2840, d_k_M range: [0.0014, 0.5148], d_k_M_hat range: [0.5031, 0.9834]
2025-03-11 20:30:16 - Train Iteration 5555: loss: 0.2095, d_k_M range: [0.0149, 0.2773], d_k_M_hat range: [0.6559, 0.9325]
2025-03-11 20:30:17 - Train Iteration 5556: loss: 0.3631, d_k_M range: [0.0010, 0.4113], d_k_M_hat range: [0.3984, 0.9825]
2025-03-11 20:30:17 - Train Iteration 5557: loss: 0.2491, d_k_M range: [0.0002, 0.3988], d_k_M_hat range: [0.5011, 0.9920]
2025-03-11 20:30:18 - Train Iteration 5558: loss: 0.3332, d_k_M range: [0.0039, 0.5740], d_k_M_hat range: [0.8487, 0.9968]
2025-03-11 20:30:18 - Train Iteration 5559: loss: 0.3063, d_k_M range: [0.0006, 0.5471], d_k_M_hat range: [0.5456, 0.9983]
2025-03-11 20:30:18 - Train Iteration 5560: loss: 0.2747, d_k_M range: [0.0001, 0.3558], d_k_M_hat range: [0.4827, 0.9380]
2025-03-11 20:30:19 - Train Iteration 5561: loss: 0.2559, d_k_M range: [0.0031, 0.5030], d_k_M_hat range: [0.5347, 0.9972]
2025-03-11 20:30:19 - Train Iteration 5562: loss: 0.4407, d_k_M range: [0.0002, 0.2033], d_k_M_hat range: [0.3368, 0.9655]
2025-03-11 20:30:20 - Train Iteration 5563: loss: 0.2195, d_k_M range: [0.0042, 0.4630], d_k_M_hat range: [0.8071, 0.9945]
2025-03-11 20:30:20 - Train Iteration 5564: loss: 0.3170, d_k_M range: [0.0001, 0.4542], d_k_M_hat range: [0.4371, 0.9865]
2025-03-11 20:30:21 - Train Iteration 5565: loss: 0.2455, d_k_M range: [0.0003, 0.3082], d_k_M_hat range: [0.5048, 0.9463]
2025-03-11 20:30:21 - Train Iteration 5566: loss: 0.2411, d_k_M range: [0.0025, 0.1108], d_k_M_hat range: [0.5126, 0.8520]
2025-03-11 20:30:22 - Train Iteration 5567: loss: 0.2920, d_k_M range: [0.0006, 0.2416], d_k_M_hat range: [0.4603, 0.9636]
2025-03-11 20:30:22 - Train Iteration 5568: loss: 0.2969, d_k_M range: [0.0007, 0.4444], d_k_M_hat range: [0.4557, 0.9759]
2025-03-11 20:30:22 - Train Iteration 5569: loss: 0.1678, d_k_M range: [0.0542, 0.3278], d_k_M_hat range: [0.7565, 0.9767]
2025-03-11 20:30:23 - Train Iteration 5570: loss: 0.1626, d_k_M range: [0.0039, 0.3670], d_k_M_hat range: [0.6179, 0.9749]
2025-03-11 20:30:23 - Train Iteration 5571: loss: 0.2728, d_k_M range: [0.0087, 0.5146], d_k_M_hat range: [0.6021, 0.9963]
2025-03-11 20:30:24 - Train Iteration 5572: loss: 0.2546, d_k_M range: [0.0299, 0.4673], d_k_M_hat range: [0.6016, 0.9985]
2025-03-11 20:30:24 - Train Iteration 5573: loss: 0.2466, d_k_M range: [0.0088, 0.4910], d_k_M_hat range: [0.6738, 0.9944]
2025-03-11 20:30:25 - Train Iteration 5574: loss: 0.3584, d_k_M range: [0.0027, 0.5983], d_k_M_hat range: [0.5448, 0.9996]
2025-03-11 20:30:25 - Train Iteration 5575: loss: 0.2578, d_k_M range: [0.0221, 0.4708], d_k_M_hat range: [0.5209, 0.9905]
2025-03-11 20:30:26 - Train Iteration 5576: loss: 0.4639, d_k_M range: [0.0319, 0.6804], d_k_M_hat range: [0.7917, 0.9993]
2025-03-11 20:30:26 - Train Iteration 5577: loss: 0.7593, d_k_M range: [0.0001, 0.0730], d_k_M_hat range: [0.1291, 0.7563]
2025-03-11 20:30:27 - Train Iteration 5578: loss: 0.2589, d_k_M range: [0.0005, 0.4953], d_k_M_hat range: [0.5831, 0.9865]
2025-03-11 20:30:27 - Train Iteration 5579: loss: 0.2883, d_k_M range: [0.0032, 0.2913], d_k_M_hat range: [0.4663, 0.9700]
2025-03-11 20:30:28 - Train Iteration 5580: loss: 0.2830, d_k_M range: [0.0911, 0.4505], d_k_M_hat range: [0.8156, 0.9954]
2025-03-11 20:30:28 - Train Iteration 5581: loss: 0.2583, d_k_M range: [0.0194, 0.5070], d_k_M_hat range: [0.7311, 0.9987]
2025-03-11 20:30:29 - Train Iteration 5582: loss: 0.2585, d_k_M range: [0.0023, 0.2953], d_k_M_hat range: [0.4939, 0.9557]
2025-03-11 20:30:29 - Train Iteration 5583: loss: 0.2773, d_k_M range: [0.0244, 0.3479], d_k_M_hat range: [0.4983, 0.9383]
2025-03-11 20:30:30 - Train Iteration 5584: loss: 0.2436, d_k_M range: [0.0106, 0.4580], d_k_M_hat range: [0.5181, 0.9903]
2025-03-11 20:30:30 - Train Iteration 5585: loss: 0.2601, d_k_M range: [0.0017, 0.4433], d_k_M_hat range: [0.4953, 0.9918]
2025-03-11 20:30:30 - Train Iteration 5586: loss: 0.2449, d_k_M range: [0.0037, 0.4804], d_k_M_hat range: [0.5187, 0.9931]
2025-03-11 20:30:31 - Train Iteration 5587: loss: 0.2713, d_k_M range: [0.0029, 0.1849], d_k_M_hat range: [0.4820, 0.9217]
2025-03-11 20:30:31 - Train Iteration 5588: loss: 0.2534, d_k_M range: [0.0032, 0.4998], d_k_M_hat range: [0.5585, 0.9964]
2025-03-11 20:30:32 - Train Iteration 5589: loss: 0.5795, d_k_M range: [0.0012, 0.7488], d_k_M_hat range: [0.4363, 0.9902]
2025-03-11 20:30:32 - Train Iteration 5590: loss: 0.2801, d_k_M range: [0.0014, 0.5232], d_k_M_hat range: [0.5249, 0.9939]
2025-03-11 20:30:33 - Train Iteration 5591: loss: 0.4237, d_k_M range: [0.0921, 0.6468], d_k_M_hat range: [0.7480, 0.9958]
2025-03-11 20:30:33 - Train Iteration 5592: loss: 0.2687, d_k_M range: [0.0004, 0.2629], d_k_M_hat range: [0.5868, 0.9481]
2025-03-11 20:30:33 - Train Iteration 5593: loss: 0.2115, d_k_M range: [0.0035, 0.3577], d_k_M_hat range: [0.5638, 0.9618]
2025-03-11 20:30:34 - Train Iteration 5594: loss: 0.2098, d_k_M range: [0.0311, 0.4433], d_k_M_hat range: [0.7013, 0.9852]
2025-03-11 20:30:34 - Train Iteration 5595: loss: 0.2886, d_k_M range: [0.0026, 0.3688], d_k_M_hat range: [0.4655, 0.9721]
2025-03-11 20:30:35 - Train Iteration 5596: loss: 0.2926, d_k_M range: [0.0048, 0.5274], d_k_M_hat range: [0.5703, 0.9865]
2025-03-11 20:30:35 - Train Iteration 5597: loss: 0.2216, d_k_M range: [0.0008, 0.2254], d_k_M_hat range: [0.5301, 0.9319]
2025-03-11 20:30:35 - Train Iteration 5598: loss: 0.3468, d_k_M range: [0.0005, 0.3145], d_k_M_hat range: [0.4117, 0.9731]
2025-03-11 20:30:36 - Train Iteration 5599: loss: 0.2218, d_k_M range: [0.0037, 0.4696], d_k_M_hat range: [0.5947, 0.9987]
2025-03-11 20:30:36 - Train Iteration 5600: loss: 0.1428, d_k_M range: [0.0054, 0.2304], d_k_M_hat range: [0.6276, 0.9049]
2025-03-11 20:30:37 - Train Iteration 5601: loss: 0.2288, d_k_M range: [0.0008, 0.4263], d_k_M_hat range: [0.5660, 0.9840]
2025-03-11 20:30:37 - Train Iteration 5602: loss: 0.3641, d_k_M range: [0.0009, 0.4905], d_k_M_hat range: [0.3975, 0.9876]
2025-03-11 20:30:38 - Train Iteration 5603: loss: 0.2469, d_k_M range: [0.0709, 0.4670], d_k_M_hat range: [0.8750, 0.9981]
2025-03-11 20:30:38 - Train Iteration 5604: loss: 0.2298, d_k_M range: [0.0012, 0.4618], d_k_M_hat range: [0.5396, 0.9857]
2025-03-11 20:30:39 - Train Iteration 5605: loss: 0.3235, d_k_M range: [0.0160, 0.5676], d_k_M_hat range: [0.6624, 0.9988]
2025-03-11 20:30:39 - Train Iteration 5606: loss: 0.2431, d_k_M range: [0.0059, 0.4924], d_k_M_hat range: [0.7690, 0.9993]
2025-03-11 20:30:40 - Train Iteration 5607: loss: 0.5163, d_k_M range: [0.0000, 0.2561], d_k_M_hat range: [0.2822, 0.9426]
2025-03-11 20:30:40 - Train Iteration 5608: loss: 0.5392, d_k_M range: [0.1215, 0.7293], d_k_M_hat range: [0.7794, 0.9950]
2025-03-11 20:30:40 - Train Iteration 5609: loss: 0.2605, d_k_M range: [0.0048, 0.3515], d_k_M_hat range: [0.4944, 0.9504]
2025-03-11 20:30:41 - Train Iteration 5610: loss: 0.3149, d_k_M range: [0.1337, 0.5559], d_k_M_hat range: [0.8945, 0.9982]
2025-03-11 20:30:41 - Train Iteration 5611: loss: 0.3902, d_k_M range: [0.0002, 0.3799], d_k_M_hat range: [0.3756, 0.9566]
2025-03-11 20:30:42 - Train Iteration 5612: loss: 0.3167, d_k_M range: [0.0058, 0.5536], d_k_M_hat range: [0.6376, 0.9976]
2025-03-11 20:30:42 - Train Iteration 5613: loss: 0.1918, d_k_M range: [0.0054, 0.3778], d_k_M_hat range: [0.5675, 0.9909]
2025-03-11 20:30:43 - Train Iteration 5614: loss: 0.2133, d_k_M range: [0.0002, 0.2751], d_k_M_hat range: [0.5384, 0.9228]
2025-03-11 20:30:43 - Train Iteration 5615: loss: 0.2830, d_k_M range: [0.0015, 0.5267], d_k_M_hat range: [0.5683, 0.9947]
2025-03-11 20:30:43 - Train Iteration 5616: loss: 0.2991, d_k_M range: [0.0050, 0.3221], d_k_M_hat range: [0.4585, 0.9720]
2025-03-11 20:30:44 - Train Iteration 5617: loss: 0.3849, d_k_M range: [0.0025, 0.5555], d_k_M_hat range: [0.5767, 0.9885]
2025-03-11 20:30:44 - Train Iteration 5618: loss: 0.3158, d_k_M range: [0.0017, 0.3842], d_k_M_hat range: [0.4428, 0.9741]
2025-03-11 20:30:45 - Train Iteration 5619: loss: 0.5572, d_k_M range: [0.0417, 0.7449], d_k_M_hat range: [0.7022, 0.9985]
2025-03-11 20:30:45 - Train Iteration 5620: loss: 0.2099, d_k_M range: [0.0003, 0.4560], d_k_M_hat range: [0.5666, 0.9978]
2025-03-11 20:30:46 - Train Iteration 5621: loss: 0.2448, d_k_M range: [0.0139, 0.1730], d_k_M_hat range: [0.5566, 0.8491]
2025-03-11 20:30:46 - Train Iteration 5622: loss: 0.3046, d_k_M range: [0.0033, 0.3496], d_k_M_hat range: [0.4576, 0.9274]
2025-03-11 20:30:47 - Train Iteration 5623: loss: 0.4074, d_k_M range: [0.0050, 0.5395], d_k_M_hat range: [0.3667, 0.9990]
2025-03-11 20:30:47 - Train Iteration 5624: loss: 0.2820, d_k_M range: [0.0022, 0.4232], d_k_M_hat range: [0.4731, 0.9633]
2025-03-11 20:30:48 - Train Iteration 5625: loss: 0.2306, d_k_M range: [0.0126, 0.3991], d_k_M_hat range: [0.5695, 0.9955]
2025-03-11 20:30:48 - Train Iteration 5626: loss: 0.3020, d_k_M range: [0.0007, 0.5489], d_k_M_hat range: [0.5934, 0.9993]
2025-03-11 20:30:49 - Train Iteration 5627: loss: 0.1961, d_k_M range: [0.0030, 0.1724], d_k_M_hat range: [0.5601, 0.9134]
2025-03-11 20:30:49 - Train Iteration 5628: loss: 0.8581, d_k_M range: [0.0001, 0.4507], d_k_M_hat range: [0.0738, 0.9795]
2025-03-11 20:30:49 - Train Iteration 5629: loss: 0.5172, d_k_M range: [0.0025, 0.7180], d_k_M_hat range: [0.6634, 0.9989]
2025-03-11 20:30:50 - Train Iteration 5630: loss: 0.2825, d_k_M range: [0.0043, 0.1304], d_k_M_hat range: [0.4727, 0.8926]
2025-03-11 20:30:50 - Train Iteration 5631: loss: 0.2162, d_k_M range: [0.0026, 0.4287], d_k_M_hat range: [0.5920, 0.9637]
2025-03-11 20:30:51 - Train Iteration 5632: loss: 0.3481, d_k_M range: [0.0002, 0.3129], d_k_M_hat range: [0.4102, 0.9898]
2025-03-11 20:30:51 - Train Iteration 5633: loss: 0.3660, d_k_M range: [0.0398, 0.6046], d_k_M_hat range: [0.5462, 0.9996]
2025-03-11 20:30:52 - Train Iteration 5634: loss: 0.2344, d_k_M range: [0.0020, 0.4281], d_k_M_hat range: [0.5185, 0.9686]
2025-03-11 20:30:52 - Train Iteration 5635: loss: 0.4790, d_k_M range: [0.0085, 0.6904], d_k_M_hat range: [0.5351, 0.9983]
2025-03-11 20:30:53 - Train Iteration 5636: loss: 0.3484, d_k_M range: [0.0001, 0.0992], d_k_M_hat range: [0.4099, 0.7537]
2025-03-11 20:30:53 - Train Iteration 5637: loss: 0.2644, d_k_M range: [0.0631, 0.5073], d_k_M_hat range: [0.7619, 0.9946]
2025-03-11 20:30:53 - Train Iteration 5638: loss: 0.2471, d_k_M range: [0.0234, 0.4814], d_k_M_hat range: [0.5453, 0.9964]
2025-03-11 20:30:54 - Train Iteration 5639: loss: 0.2236, d_k_M range: [0.0083, 0.4202], d_k_M_hat range: [0.5432, 0.9691]
2025-03-11 20:30:54 - Train Iteration 5640: loss: 0.2468, d_k_M range: [0.0062, 0.3951], d_k_M_hat range: [0.5096, 0.9808]
2025-03-11 20:30:55 - Train Iteration 5641: loss: 0.3415, d_k_M range: [0.0108, 0.5751], d_k_M_hat range: [0.6190, 0.9907]
2025-03-11 20:30:55 - Train Iteration 5642: loss: 0.4703, d_k_M range: [0.0004, 0.3876], d_k_M_hat range: [0.3147, 0.9189]
2025-03-11 20:30:56 - Train Iteration 5643: loss: 0.2732, d_k_M range: [0.0063, 0.5177], d_k_M_hat range: [0.6021, 0.9950]
2025-03-11 20:30:56 - Train Iteration 5644: loss: 0.6218, d_k_M range: [0.0172, 0.7875], d_k_M_hat range: [0.6362, 0.9990]
2025-03-11 20:30:56 - Train Iteration 5645: loss: 0.3520, d_k_M range: [0.0003, 0.0548], d_k_M_hat range: [0.4099, 0.7584]
2025-03-11 20:30:57 - Train Iteration 5646: loss: 0.9052, d_k_M range: [0.0324, 0.9498], d_k_M_hat range: [0.5097, 0.9984]
2025-03-11 20:30:57 - Train Iteration 5647: loss: 0.2438, d_k_M range: [0.0051, 0.3363], d_k_M_hat range: [0.5148, 0.9727]
2025-03-11 20:30:58 - Train Iteration 5648: loss: 0.2400, d_k_M range: [0.0286, 0.4123], d_k_M_hat range: [0.5387, 0.9556]
2025-03-11 20:30:58 - Train Iteration 5649: loss: 0.4242, d_k_M range: [0.0264, 0.6509], d_k_M_hat range: [0.7303, 0.9995]
2025-03-11 20:30:59 - Train Iteration 5650: loss: 0.2531, d_k_M range: [0.0006, 0.4098], d_k_M_hat range: [0.4992, 0.9569]
2025-03-11 20:30:59 - Train Iteration 5651: loss: 0.1793, d_k_M range: [0.0031, 0.2203], d_k_M_hat range: [0.5977, 0.9021]
2025-03-11 20:30:59 - Train Iteration 5652: loss: 0.2973, d_k_M range: [0.0067, 0.4871], d_k_M_hat range: [0.5884, 0.9942]
2025-03-11 20:31:00 - Train Iteration 5653: loss: 0.2746, d_k_M range: [0.0033, 0.5191], d_k_M_hat range: [0.5496, 0.9951]
2025-03-11 20:31:00 - Train Iteration 5654: loss: 0.3641, d_k_M range: [0.0003, 0.2921], d_k_M_hat range: [0.4134, 0.9029]
2025-03-11 20:31:01 - Train Iteration 5655: loss: 0.1559, d_k_M range: [0.0020, 0.2435], d_k_M_hat range: [0.6407, 0.8813]
2025-03-11 20:31:01 - Train Iteration 5656: loss: 0.2251, d_k_M range: [0.0059, 0.4101], d_k_M_hat range: [0.5314, 0.9571]
2025-03-11 20:31:01 - Train Iteration 5657: loss: 0.2792, d_k_M range: [0.0031, 0.4275], d_k_M_hat range: [0.4747, 0.9943]
2025-03-11 20:31:02 - Train Iteration 5658: loss: 0.3114, d_k_M range: [0.0011, 0.4136], d_k_M_hat range: [0.4431, 0.9877]
2025-03-11 20:31:02 - Train Iteration 5659: loss: 0.2562, d_k_M range: [0.0004, 0.4927], d_k_M_hat range: [0.5865, 0.9865]
2025-03-11 20:31:03 - Train Iteration 5660: loss: 0.2270, d_k_M range: [0.0059, 0.2656], d_k_M_hat range: [0.5670, 0.9757]
2025-03-11 20:31:03 - Train Iteration 5661: loss: 0.3189, d_k_M range: [0.0021, 0.4403], d_k_M_hat range: [0.4374, 0.9783]
2025-03-11 20:31:04 - Train Iteration 5662: loss: 0.2725, d_k_M range: [0.0006, 0.4279], d_k_M_hat range: [0.4785, 0.9815]
2025-03-11 20:31:04 - Train Iteration 5663: loss: 0.2809, d_k_M range: [0.0020, 0.3472], d_k_M_hat range: [0.4720, 0.9752]
2025-03-11 20:31:04 - Train Iteration 5664: loss: 0.4310, d_k_M range: [0.0006, 0.6507], d_k_M_hat range: [0.5375, 0.9971]
2025-03-11 20:31:05 - Train Iteration 5665: loss: 0.2843, d_k_M range: [0.0023, 0.5188], d_k_M_hat range: [0.5285, 0.9856]
2025-03-11 20:31:05 - Train Iteration 5666: loss: 0.2960, d_k_M range: [0.0008, 0.3811], d_k_M_hat range: [0.4580, 0.9879]
2025-03-11 20:31:06 - Train Iteration 5667: loss: 0.2448, d_k_M range: [0.0081, 0.4923], d_k_M_hat range: [0.6431, 0.9981]
2025-03-11 20:31:06 - Train Iteration 5668: loss: 0.2060, d_k_M range: [0.0089, 0.4439], d_k_M_hat range: [0.6387, 0.9900]
2025-03-11 20:31:07 - Train Iteration 5669: loss: 0.3143, d_k_M range: [0.0178, 0.5412], d_k_M_hat range: [0.6306, 0.9970]
2025-03-11 20:31:07 - Train Iteration 5670: loss: 0.9804, d_k_M range: [0.0159, 0.9901], d_k_M_hat range: [0.6686, 1.0000]
2025-03-11 20:31:08 - Train Iteration 5671: loss: 0.1713, d_k_M range: [0.0045, 0.3583], d_k_M_hat range: [0.5945, 0.9646]
2025-03-11 20:31:08 - Train Iteration 5672: loss: 0.3814, d_k_M range: [0.1090, 0.6151], d_k_M_hat range: [0.6883, 0.9992]
2025-03-11 20:31:09 - Train Iteration 5673: loss: 0.5132, d_k_M range: [0.0006, 0.1879], d_k_M_hat range: [0.2842, 0.9684]
2025-03-11 20:31:09 - Train Iteration 5674: loss: 0.2644, d_k_M range: [0.0213, 0.4912], d_k_M_hat range: [0.6479, 0.9827]
2025-03-11 20:31:10 - Train Iteration 5675: loss: 0.2822, d_k_M range: [0.0011, 0.4189], d_k_M_hat range: [0.4699, 0.9789]
2025-03-11 20:31:10 - Train Iteration 5676: loss: 0.2474, d_k_M range: [0.0065, 0.4942], d_k_M_hat range: [0.6424, 0.9968]
2025-03-11 20:31:11 - Train Iteration 5677: loss: 0.2386, d_k_M range: [0.0033, 0.3848], d_k_M_hat range: [0.5157, 0.9432]
2025-03-11 20:31:11 - Train Iteration 5678: loss: 0.2490, d_k_M range: [0.0039, 0.4794], d_k_M_hat range: [0.5661, 0.9923]
2025-03-11 20:31:12 - Train Iteration 5679: loss: 0.1749, d_k_M range: [0.0305, 0.3806], d_k_M_hat range: [0.6122, 0.9927]
2025-03-11 20:31:12 - Train Iteration 5680: loss: 0.3057, d_k_M range: [0.1155, 0.5509], d_k_M_hat range: [0.8690, 0.9979]
2025-03-11 20:31:13 - Train Iteration 5681: loss: 0.2323, d_k_M range: [0.0036, 0.3363], d_k_M_hat range: [0.5836, 0.9425]
2025-03-11 20:31:13 - Train Iteration 5682: loss: 0.3158, d_k_M range: [0.0218, 0.4683], d_k_M_hat range: [0.4863, 0.9867]
2025-03-11 20:31:14 - Train Iteration 5683: loss: 0.2662, d_k_M range: [0.0007, 0.4306], d_k_M_hat range: [0.4847, 0.9515]
2025-03-11 20:31:14 - Train Iteration 5684: loss: 0.2288, d_k_M range: [0.1269, 0.4637], d_k_M_hat range: [0.7599, 0.9911]
2025-03-11 20:31:14 - Train Iteration 5685: loss: 0.3137, d_k_M range: [0.0208, 0.5582], d_k_M_hat range: [0.5725, 0.9981]
2025-03-11 20:31:15 - Train Iteration 5686: loss: 0.2314, d_k_M range: [0.0057, 0.4381], d_k_M_hat range: [0.5614, 0.9924]
2025-03-11 20:31:15 - Train Iteration 5687: loss: 0.6144, d_k_M range: [0.0726, 0.7802], d_k_M_hat range: [0.6968, 0.9970]
2025-03-11 20:31:16 - Train Iteration 5688: loss: 0.3133, d_k_M range: [0.0001, 0.1984], d_k_M_hat range: [0.4403, 0.9150]
2025-03-11 20:31:16 - Train Iteration 5689: loss: 0.2588, d_k_M range: [0.1815, 0.5059], d_k_M_hat range: [0.8782, 0.9972]
2025-03-11 20:31:17 - Train Iteration 5690: loss: 0.2763, d_k_M range: [0.0028, 0.5215], d_k_M_hat range: [0.5517, 0.9959]
2025-03-11 20:31:17 - Train Iteration 5691: loss: 0.1847, d_k_M range: [0.0031, 0.1713], d_k_M_hat range: [0.5734, 0.9470]
2025-03-11 20:31:18 - Train Iteration 5692: loss: 0.2598, d_k_M range: [0.0062, 0.4994], d_k_M_hat range: [0.5347, 0.9897]
2025-03-11 20:31:18 - Train Iteration 5693: loss: 0.1856, d_k_M range: [0.0050, 0.3604], d_k_M_hat range: [0.5894, 0.9316]
2025-03-11 20:31:19 - Train Iteration 5694: loss: 0.2546, d_k_M range: [0.0004, 0.2736], d_k_M_hat range: [0.4958, 0.9747]
2025-03-11 20:31:19 - Train Iteration 5695: loss: 0.6676, d_k_M range: [0.0166, 0.8162], d_k_M_hat range: [0.6647, 0.9991]
2025-03-11 20:31:19 - Train Iteration 5696: loss: 0.2450, d_k_M range: [0.0008, 0.0718], d_k_M_hat range: [0.5473, 0.7789]
2025-03-11 20:31:20 - Train Iteration 5697: loss: 0.3532, d_k_M range: [0.0034, 0.4850], d_k_M_hat range: [0.5393, 0.9858]
2025-03-11 20:31:20 - Train Iteration 5698: loss: 0.2895, d_k_M range: [0.0028, 0.4370], d_k_M_hat range: [0.4648, 0.9860]
2025-03-11 20:31:21 - Train Iteration 5699: loss: 0.3044, d_k_M range: [0.0045, 0.2788], d_k_M_hat range: [0.4528, 0.9855]
2025-03-11 20:31:21 - Train Iteration 5700: loss: 0.2449, d_k_M range: [0.0089, 0.4945], d_k_M_hat range: [0.6257, 0.9996]
2025-03-11 20:31:22 - Train Iteration 5701: loss: 0.2290, d_k_M range: [0.0046, 0.4397], d_k_M_hat range: [0.5260, 0.9911]
2025-03-11 20:31:22 - Train Iteration 5702: loss: 0.2129, d_k_M range: [0.0102, 0.3790], d_k_M_hat range: [0.5559, 0.9898]
2025-03-11 20:31:23 - Train Iteration 5703: loss: 0.2591, d_k_M range: [0.0058, 0.4917], d_k_M_hat range: [0.7203, 0.9826]
2025-03-11 20:31:23 - Train Iteration 5704: loss: 0.2564, d_k_M range: [0.0002, 0.3793], d_k_M_hat range: [0.4941, 0.9710]
2025-03-11 20:31:23 - Train Iteration 5705: loss: 0.2637, d_k_M range: [0.0122, 0.4985], d_k_M_hat range: [0.5146, 0.9942]
2025-03-11 20:31:24 - Train Iteration 5706: loss: 0.5541, d_k_M range: [0.0258, 0.7412], d_k_M_hat range: [0.7611, 0.9994]
2025-03-11 20:31:24 - Train Iteration 5707: loss: 0.1808, d_k_M range: [0.0016, 0.3436], d_k_M_hat range: [0.5763, 0.9687]
2025-03-11 20:31:25 - Train Iteration 5708: loss: 0.2975, d_k_M range: [0.0004, 0.5147], d_k_M_hat range: [0.4697, 0.9692]
2025-03-11 20:31:25 - Train Iteration 5709: loss: 0.5567, d_k_M range: [0.0001, 0.2366], d_k_M_hat range: [0.2540, 0.9150]
2025-03-11 20:31:26 - Train Iteration 5710: loss: 0.2498, d_k_M range: [0.0245, 0.4281], d_k_M_hat range: [0.5799, 0.9983]
2025-03-11 20:31:26 - Train Iteration 5711: loss: 0.2189, d_k_M range: [0.0026, 0.4088], d_k_M_hat range: [0.5348, 0.9801]
2025-03-11 20:31:27 - Train Iteration 5712: loss: 0.1822, d_k_M range: [0.0084, 0.3881], d_k_M_hat range: [0.7103, 0.9718]
2025-03-11 20:31:27 - Train Iteration 5713: loss: 0.6562, d_k_M range: [0.0001, 0.0940], d_k_M_hat range: [0.1900, 0.8026]
2025-03-11 20:31:27 - Train Iteration 5714: loss: 0.3770, d_k_M range: [0.0162, 0.5889], d_k_M_hat range: [0.5965, 0.9981]
2025-03-11 20:31:28 - Train Iteration 5715: loss: 0.2235, d_k_M range: [0.0026, 0.4543], d_k_M_hat range: [0.5299, 0.9976]
2025-03-11 20:31:28 - Train Iteration 5716: loss: 0.2706, d_k_M range: [0.0120, 0.4638], d_k_M_hat range: [0.6248, 0.9927]
2025-03-11 20:31:29 - Train Iteration 5717: loss: 0.2655, d_k_M range: [0.0002, 0.4207], d_k_M_hat range: [0.4850, 0.9864]
2025-03-11 20:31:29 - Train Iteration 5718: loss: 0.1866, d_k_M range: [0.0058, 0.4184], d_k_M_hat range: [0.6646, 0.9865]
2025-03-11 20:31:30 - Train Iteration 5719: loss: 0.2319, d_k_M range: [0.0041, 0.3018], d_k_M_hat range: [0.5641, 0.8853]
2025-03-11 20:31:30 - Train Iteration 5720: loss: 0.2269, d_k_M range: [0.0019, 0.2203], d_k_M_hat range: [0.5255, 0.9681]
2025-03-11 20:31:31 - Train Iteration 5721: loss: 0.2793, d_k_M range: [0.0005, 0.4833], d_k_M_hat range: [0.4931, 0.9853]
2025-03-11 20:31:31 - Train Iteration 5722: loss: 0.2174, d_k_M range: [0.0008, 0.3082], d_k_M_hat range: [0.5352, 0.9750]
2025-03-11 20:31:32 - Train Iteration 5723: loss: 0.3105, d_k_M range: [0.0257, 0.5550], d_k_M_hat range: [0.7886, 0.9978]
2025-03-11 20:31:32 - Train Iteration 5724: loss: 0.2805, d_k_M range: [0.0310, 0.5259], d_k_M_hat range: [0.6365, 0.9987]
2025-03-11 20:31:33 - Train Iteration 5725: loss: 0.3133, d_k_M range: [0.0003, 0.1494], d_k_M_hat range: [0.4405, 0.8800]
2025-03-11 20:31:33 - Train Iteration 5726: loss: 0.5127, d_k_M range: [0.0677, 0.7159], d_k_M_hat range: [0.7960, 0.9999]
2025-03-11 20:31:34 - Train Iteration 5727: loss: 0.2032, d_k_M range: [0.0069, 0.2779], d_k_M_hat range: [0.5561, 0.8784]
2025-03-11 20:31:34 - Train Iteration 5728: loss: 0.2446, d_k_M range: [0.0020, 0.4312], d_k_M_hat range: [0.5074, 0.9842]
2025-03-11 20:31:35 - Train Iteration 5729: loss: 0.3456, d_k_M range: [0.0083, 0.5858], d_k_M_hat range: [0.7550, 0.9979]
2025-03-11 20:31:35 - Train Iteration 5730: loss: 0.2773, d_k_M range: [0.0069, 0.5164], d_k_M_hat range: [0.5403, 0.9898]
2025-03-11 20:31:36 - Train Iteration 5731: loss: 0.3789, d_k_M range: [0.0005, 0.2580], d_k_M_hat range: [0.3850, 0.9657]
2025-03-11 20:31:36 - Train Iteration 5732: loss: 0.2623, d_k_M range: [0.0039, 0.4961], d_k_M_hat range: [0.7048, 0.9988]
2025-03-11 20:31:37 - Train Iteration 5733: loss: 0.3530, d_k_M range: [0.0003, 0.4294], d_k_M_hat range: [0.4062, 0.9735]
2025-03-11 20:31:37 - Train Iteration 5734: loss: 0.2650, d_k_M range: [0.0050, 0.3566], d_k_M_hat range: [0.5303, 0.9796]
2025-03-11 20:31:37 - Train Iteration 5735: loss: 0.2504, d_k_M range: [0.0004, 0.3072], d_k_M_hat range: [0.5000, 0.9698]
2025-03-11 20:31:38 - Train Iteration 5736: loss: 0.3187, d_k_M range: [0.0007, 0.4881], d_k_M_hat range: [0.5207, 0.9236]
2025-03-11 20:31:38 - Train Iteration 5737: loss: 0.2404, d_k_M range: [0.0037, 0.3669], d_k_M_hat range: [0.5173, 0.9539]
2025-03-11 20:31:39 - Train Iteration 5738: loss: 0.2560, d_k_M range: [0.2368, 0.5035], d_k_M_hat range: [0.9066, 0.9975]
2025-03-11 20:31:39 - Train Iteration 5739: loss: 0.2508, d_k_M range: [0.0020, 0.2234], d_k_M_hat range: [0.5039, 0.8746]
2025-03-11 20:31:40 - Train Iteration 5740: loss: 0.3571, d_k_M range: [0.0109, 0.5940], d_k_M_hat range: [0.5906, 0.9964]
2025-03-11 20:31:40 - Train Iteration 5741: loss: 0.2488, d_k_M range: [0.0016, 0.4588], d_k_M_hat range: [0.5030, 0.9784]
2025-03-11 20:31:41 - Train Iteration 5742: loss: 0.1725, d_k_M range: [0.0167, 0.3218], d_k_M_hat range: [0.6221, 0.9417]
2025-03-11 20:31:41 - Train Iteration 5743: loss: 0.5137, d_k_M range: [0.0002, 0.0887], d_k_M_hat range: [0.2836, 0.8134]
2025-03-11 20:31:42 - Train Iteration 5744: loss: 0.3521, d_k_M range: [0.0952, 0.5915], d_k_M_hat range: [0.8289, 0.9982]
2025-03-11 20:31:42 - Train Iteration 5745: loss: 0.3142, d_k_M range: [0.0035, 0.4511], d_k_M_hat range: [0.4430, 0.9875]
2025-03-11 20:31:43 - Train Iteration 5746: loss: 0.3854, d_k_M range: [0.0017, 0.5375], d_k_M_hat range: [0.3809, 0.9945]
2025-03-11 20:31:43 - Train Iteration 5747: loss: 0.2920, d_k_M range: [0.0196, 0.5393], d_k_M_hat range: [0.7140, 0.9990]
2025-03-11 20:31:43 - Train Iteration 5748: loss: 0.5947, d_k_M range: [0.0001, 0.5335], d_k_M_hat range: [0.2290, 0.9954]
2025-03-11 20:31:44 - Train Iteration 5749: loss: 0.2482, d_k_M range: [0.0419, 0.4849], d_k_M_hat range: [0.6638, 0.9925]
2025-03-11 20:31:44 - Train Iteration 5750: loss: 0.3878, d_k_M range: [0.0100, 0.6223], d_k_M_hat range: [0.6495, 0.9996]
2025-03-11 20:31:45 - Train Iteration 5751: loss: 0.2154, d_k_M range: [0.0015, 0.0477], d_k_M_hat range: [0.5374, 0.8161]
2025-03-11 20:31:45 - Train Iteration 5752: loss: 0.2179, d_k_M range: [0.0193, 0.4552], d_k_M_hat range: [0.6545, 0.9884]
2025-03-11 20:31:45 - Train Iteration 5753: loss: 0.3185, d_k_M range: [0.0027, 0.5617], d_k_M_hat range: [0.5255, 0.9974]
2025-03-11 20:31:46 - Train Iteration 5754: loss: 0.2535, d_k_M range: [0.0007, 0.4276], d_k_M_hat range: [0.4971, 0.9740]
2025-03-11 20:31:46 - Train Iteration 5755: loss: 0.2389, d_k_M range: [0.0030, 0.0606], d_k_M_hat range: [0.5231, 0.8112]
2025-03-11 20:31:47 - Train Iteration 5756: loss: 0.1961, d_k_M range: [0.0063, 0.4355], d_k_M_hat range: [0.6259, 0.9927]
2025-03-11 20:31:47 - Train Iteration 5757: loss: 0.2404, d_k_M range: [0.0003, 0.3434], d_k_M_hat range: [0.5099, 0.9908]
2025-03-11 20:31:48 - Train Iteration 5758: loss: 0.2445, d_k_M range: [0.0037, 0.4840], d_k_M_hat range: [0.5836, 0.9895]
2025-03-11 20:31:48 - Train Iteration 5759: loss: 0.2462, d_k_M range: [0.0034, 0.4423], d_k_M_hat range: [0.6261, 0.9461]
2025-03-11 20:31:48 - Train Iteration 5760: loss: 0.4556, d_k_M range: [0.0001, 0.1270], d_k_M_hat range: [0.3251, 0.9232]
2025-03-11 20:31:49 - Train Iteration 5761: loss: 0.2846, d_k_M range: [0.0687, 0.5294], d_k_M_hat range: [0.9142, 0.9989]
2025-03-11 20:31:49 - Train Iteration 5762: loss: 0.2563, d_k_M range: [0.0002, 0.1869], d_k_M_hat range: [0.4939, 0.8893]
2025-03-11 20:31:50 - Train Iteration 5763: loss: 0.2623, d_k_M range: [0.0026, 0.5040], d_k_M_hat range: [0.5075, 0.9952]
2025-03-11 20:31:50 - Train Iteration 5764: loss: 0.3631, d_k_M range: [0.0012, 0.5991], d_k_M_hat range: [0.5589, 0.9965]
2025-03-11 20:31:51 - Train Iteration 5765: loss: 0.2409, d_k_M range: [0.0051, 0.4272], d_k_M_hat range: [0.5288, 0.9862]
2025-03-11 20:31:51 - Train Iteration 5766: loss: 0.2595, d_k_M range: [0.0025, 0.3600], d_k_M_hat range: [0.4930, 0.9282]
2025-03-11 20:31:52 - Train Iteration 5767: loss: 0.2317, d_k_M range: [0.0507, 0.4550], d_k_M_hat range: [0.6149, 0.9737]
2025-03-11 20:31:52 - Train Iteration 5768: loss: 0.2535, d_k_M range: [0.0588, 0.4832], d_k_M_hat range: [0.7437, 0.9943]
2025-03-11 20:31:53 - Train Iteration 5769: loss: 0.3127, d_k_M range: [0.0004, 0.3289], d_k_M_hat range: [0.4412, 0.9536]
2025-03-11 20:31:53 - Train Iteration 5770: loss: 0.2489, d_k_M range: [0.0048, 0.4593], d_k_M_hat range: [0.5868, 0.9781]
2025-03-11 20:31:54 - Train Iteration 5771: loss: 0.1928, d_k_M range: [0.0073, 0.4151], d_k_M_hat range: [0.6194, 0.9760]
2025-03-11 20:31:54 - Train Iteration 5772: loss: 0.3996, d_k_M range: [0.0000, 0.4438], d_k_M_hat range: [0.4530, 0.9800]
2025-03-11 20:31:55 - Train Iteration 5773: loss: 0.3530, d_k_M range: [0.0128, 0.5935], d_k_M_hat range: [0.7824, 0.9995]
2025-03-11 20:31:55 - Train Iteration 5774: loss: 0.2448, d_k_M range: [0.0056, 0.4829], d_k_M_hat range: [0.5108, 0.9896]
2025-03-11 20:31:56 - Train Iteration 5775: loss: 0.2846, d_k_M range: [0.1684, 0.5291], d_k_M_hat range: [0.8311, 0.9971]
2025-03-11 20:31:56 - Train Iteration 5776: loss: 0.2221, d_k_M range: [0.0009, 0.4672], d_k_M_hat range: [0.5619, 0.9959]
2025-03-11 20:31:57 - Train Iteration 5777: loss: 0.2487, d_k_M range: [0.0091, 0.4890], d_k_M_hat range: [0.5425, 0.9903]
2025-03-11 20:31:57 - Train Iteration 5778: loss: 0.3501, d_k_M range: [0.0003, 0.3231], d_k_M_hat range: [0.4121, 0.9924]
2025-03-11 20:31:58 - Train Iteration 5779: loss: 0.3582, d_k_M range: [0.1420, 0.5658], d_k_M_hat range: [0.6896, 0.9986]
2025-03-11 20:31:58 - Train Iteration 5780: loss: 0.7817, d_k_M range: [0.0302, 0.8841], d_k_M_hat range: [0.7066, 1.0000]
2025-03-11 20:31:59 - Train Iteration 5781: loss: 0.2994, d_k_M range: [0.0014, 0.3813], d_k_M_hat range: [0.4541, 0.9767]
2025-03-11 20:31:59 - Train Iteration 5782: loss: 0.2898, d_k_M range: [0.0007, 0.0775], d_k_M_hat range: [0.4624, 0.8850]
2025-03-11 20:31:59 - Train Iteration 5783: loss: 0.2931, d_k_M range: [0.0016, 0.5343], d_k_M_hat range: [0.5433, 0.9930]
2025-03-11 20:32:00 - Train Iteration 5784: loss: 0.2928, d_k_M range: [0.0057, 0.3552], d_k_M_hat range: [0.4688, 0.9704]
2025-03-11 20:32:00 - Train Iteration 5785: loss: 0.2116, d_k_M range: [0.0177, 0.4438], d_k_M_hat range: [0.5998, 0.9838]
2025-03-11 20:32:01 - Train Iteration 5786: loss: 0.3857, d_k_M range: [0.0007, 0.4067], d_k_M_hat range: [0.3796, 0.9557]
2025-03-11 20:32:01 - Train Iteration 5787: loss: 0.3370, d_k_M range: [0.1354, 0.5801], d_k_M_hat range: [0.8368, 0.9995]
2025-03-11 20:32:02 - Train Iteration 5788: loss: 0.3700, d_k_M range: [0.0271, 0.6075], d_k_M_hat range: [0.6048, 0.9992]
2025-03-11 20:32:02 - Train Iteration 5789: loss: 0.2306, d_k_M range: [0.0020, 0.4213], d_k_M_hat range: [0.5218, 0.9932]
2025-03-11 20:32:03 - Train Iteration 5790: loss: 0.3189, d_k_M range: [0.0111, 0.4319], d_k_M_hat range: [0.6056, 0.9846]
2025-03-11 20:32:03 - Train Iteration 5791: loss: 0.1714, d_k_M range: [0.0111, 0.4072], d_k_M_hat range: [0.6880, 0.9932]
2025-03-11 20:32:04 - Train Iteration 5792: loss: 0.2643, d_k_M range: [0.0090, 0.4153], d_k_M_hat range: [0.5392, 0.9817]
2025-03-11 20:32:04 - Train Iteration 5793: loss: 0.3103, d_k_M range: [0.0073, 0.4972], d_k_M_hat range: [0.5250, 0.9949]
2025-03-11 20:32:05 - Train Iteration 5794: loss: 0.2745, d_k_M range: [0.0015, 0.4689], d_k_M_hat range: [0.4806, 0.9915]
2025-03-11 20:32:05 - Train Iteration 5795: loss: 0.3357, d_k_M range: [0.0001, 0.4458], d_k_M_hat range: [0.4207, 0.9922]
2025-03-11 20:32:06 - Train Iteration 5796: loss: 0.3176, d_k_M range: [0.0003, 0.1431], d_k_M_hat range: [0.4367, 0.9106]
2025-03-11 20:32:06 - Train Iteration 5797: loss: 0.2872, d_k_M range: [0.0029, 0.5331], d_k_M_hat range: [0.5112, 0.9993]
2025-03-11 20:32:07 - Train Iteration 5798: loss: 0.2555, d_k_M range: [0.0025, 0.4087], d_k_M_hat range: [0.4970, 0.9555]
2025-03-11 20:32:07 - Train Iteration 5799: loss: 0.2145, d_k_M range: [0.0008, 0.3945], d_k_M_hat range: [0.5377, 0.9973]
2025-03-11 20:32:07 - Train Iteration 5800: loss: 0.4554, d_k_M range: [0.0024, 0.6746], d_k_M_hat range: [0.6113, 0.9998]
2025-03-11 20:32:08 - Train Iteration 5801: loss: 0.2351, d_k_M range: [0.0087, 0.3630], d_k_M_hat range: [0.5395, 0.9793]
2025-03-11 20:32:08 - Train Iteration 5802: loss: 0.2813, d_k_M range: [0.0163, 0.5177], d_k_M_hat range: [0.6758, 0.9873]
2025-03-11 20:32:09 - Train Iteration 5803: loss: 0.2464, d_k_M range: [0.0008, 0.4480], d_k_M_hat range: [0.5044, 0.9557]
2025-03-11 20:32:09 - Train Iteration 5804: loss: 0.3728, d_k_M range: [0.0415, 0.5567], d_k_M_hat range: [0.7711, 0.9653]
2025-03-11 20:32:09 - Train Iteration 5805: loss: 0.2707, d_k_M range: [0.0003, 0.1121], d_k_M_hat range: [0.4812, 0.8854]
2025-03-11 20:32:10 - Train Iteration 5806: loss: 0.2353, d_k_M range: [0.0004, 0.4639], d_k_M_hat range: [0.5154, 0.9876]
2025-03-11 20:32:10 - Train Iteration 5807: loss: 0.2176, d_k_M range: [0.0379, 0.4603], d_k_M_hat range: [0.6150, 0.9968]
2025-03-11 20:32:11 - Train Iteration 5808: loss: 0.2427, d_k_M range: [0.0011, 0.4698], d_k_M_hat range: [0.5085, 0.9969]
2025-03-11 20:32:11 - Train Iteration 5809: loss: 0.2193, d_k_M range: [0.1641, 0.4678], d_k_M_hat range: [0.8997, 0.9996]
2025-03-11 20:32:12 - Train Iteration 5810: loss: 0.9848, d_k_M range: [0.0337, 0.9923], d_k_M_hat range: [0.8046, 0.9999]
2025-03-11 20:32:12 - Train Iteration 5811: loss: 0.1507, d_k_M range: [0.0127, 0.2380], d_k_M_hat range: [0.6263, 0.9131]
2025-03-11 20:32:13 - Train Iteration 5812: loss: 0.4440, d_k_M range: [0.0019, 0.3904], d_k_M_hat range: [0.3356, 0.9708]
2025-03-11 20:32:13 - Train Iteration 5813: loss: 0.2886, d_k_M range: [0.0004, 0.3739], d_k_M_hat range: [0.4635, 0.9941]
2025-03-11 20:32:14 - Train Iteration 5814: loss: 0.3848, d_k_M range: [0.0003, 0.4371], d_k_M_hat range: [0.3800, 0.9964]
2025-03-11 20:32:14 - Train Iteration 5815: loss: 0.2673, d_k_M range: [0.0012, 0.4806], d_k_M_hat range: [0.5908, 0.9968]
2025-03-11 20:32:15 - Train Iteration 5816: loss: 0.2817, d_k_M range: [0.0028, 0.4285], d_k_M_hat range: [0.5859, 0.9910]
2025-03-11 20:32:15 - Train Iteration 5817: loss: 0.2473, d_k_M range: [0.0009, 0.3321], d_k_M_hat range: [0.5036, 0.9715]
2025-03-11 20:32:16 - Train Iteration 5818: loss: 0.3630, d_k_M range: [0.0112, 0.5967], d_k_M_hat range: [0.5902, 0.9943]
2025-03-11 20:32:16 - Train Iteration 5819: loss: 0.2860, d_k_M range: [0.0008, 0.2285], d_k_M_hat range: [0.4661, 0.9622]
2025-03-11 20:32:17 - Train Iteration 5820: loss: 0.1916, d_k_M range: [0.0214, 0.4328], d_k_M_hat range: [0.6521, 0.9951]
2025-03-11 20:32:17 - Train Iteration 5821: loss: 0.5075, d_k_M range: [0.0029, 0.7111], d_k_M_hat range: [0.5332, 0.9987]
2025-03-11 20:32:18 - Train Iteration 5822: loss: 0.3409, d_k_M range: [0.0005, 0.5816], d_k_M_hat range: [0.5331, 0.9977]
2025-03-11 20:32:18 - Train Iteration 5823: loss: 0.2071, d_k_M range: [0.0055, 0.3818], d_k_M_hat range: [0.5524, 0.9581]
2025-03-11 20:32:18 - Train Iteration 5824: loss: 0.4202, d_k_M range: [0.0001, 0.5045], d_k_M_hat range: [0.3518, 0.9877]
2025-03-11 20:32:19 - Train Iteration 5825: loss: 0.2409, d_k_M range: [0.0066, 0.4095], d_k_M_hat range: [0.5412, 0.9818]
2025-03-11 20:32:19 - Train Iteration 5826: loss: 0.2533, d_k_M range: [0.0052, 0.4963], d_k_M_hat range: [0.5284, 0.9930]
2025-03-11 20:32:20 - Train Iteration 5827: loss: 0.2891, d_k_M range: [0.0018, 0.5322], d_k_M_hat range: [0.5013, 0.9945]
2025-03-11 20:32:20 - Train Iteration 5828: loss: 0.2326, d_k_M range: [0.0006, 0.1760], d_k_M_hat range: [0.5183, 0.8778]
2025-03-11 20:32:21 - Train Iteration 5829: loss: 0.5203, d_k_M range: [0.0094, 0.7195], d_k_M_hat range: [0.6336, 0.9992]
2025-03-11 20:32:21 - Train Iteration 5830: loss: 0.3805, d_k_M range: [0.0001, 0.0790], d_k_M_hat range: [0.3834, 0.7190]
2025-03-11 20:32:22 - Train Iteration 5831: loss: 0.2424, d_k_M range: [0.0006, 0.2260], d_k_M_hat range: [0.5139, 0.9188]
2025-03-11 20:32:22 - Train Iteration 5832: loss: 0.5014, d_k_M range: [0.0333, 0.7079], d_k_M_hat range: [0.6072, 0.9998]
2025-03-11 20:32:23 - Train Iteration 5833: loss: 0.2319, d_k_M range: [0.0006, 0.4556], d_k_M_hat range: [0.5190, 0.9797]
2025-03-11 20:32:23 - Train Iteration 5834: loss: 0.2907, d_k_M range: [0.0218, 0.5341], d_k_M_hat range: [0.5765, 0.9960]
2025-03-11 20:32:23 - Train Iteration 5835: loss: 0.2771, d_k_M range: [0.0038, 0.3515], d_k_M_hat range: [0.6319, 0.9110]
2025-03-11 20:32:24 - Train Iteration 5836: loss: 0.2425, d_k_M range: [0.0320, 0.4310], d_k_M_hat range: [0.6478, 0.9385]
2025-03-11 20:32:24 - Train Iteration 5837: loss: 0.2602, d_k_M range: [0.0009, 0.1706], d_k_M_hat range: [0.4915, 0.8810]
2025-03-11 20:32:25 - Train Iteration 5838: loss: 0.2203, d_k_M range: [0.0100, 0.4638], d_k_M_hat range: [0.6536, 0.9944]
2025-03-11 20:32:25 - Train Iteration 5839: loss: 0.3670, d_k_M range: [0.0000, 0.3233], d_k_M_hat range: [0.3943, 0.8574]
2025-03-11 20:32:26 - Train Iteration 5840: loss: 0.2150, d_k_M range: [0.0004, 0.3166], d_k_M_hat range: [0.5367, 0.9816]
2025-03-11 20:32:26 - Train Iteration 5841: loss: 0.2780, d_k_M range: [0.0001, 0.3842], d_k_M_hat range: [0.4728, 0.9952]
2025-03-11 20:32:26 - Train Iteration 5842: loss: 0.2812, d_k_M range: [0.0002, 0.3981], d_k_M_hat range: [0.4711, 0.9833]
2025-03-11 20:32:27 - Train Iteration 5843: loss: 0.2972, d_k_M range: [0.0018, 0.2669], d_k_M_hat range: [0.4566, 0.9491]
2025-03-11 20:32:27 - Train Iteration 5844: loss: 0.1914, d_k_M range: [0.0044, 0.1935], d_k_M_hat range: [0.5670, 0.9330]
2025-03-11 20:32:28 - Train Iteration 5845: loss: 0.2182, d_k_M range: [0.0015, 0.4188], d_k_M_hat range: [0.5348, 0.9798]
2025-03-11 20:32:28 - Train Iteration 5846: loss: 0.3625, d_k_M range: [0.0003, 0.5003], d_k_M_hat range: [0.3987, 0.9945]
2025-03-11 20:32:29 - Train Iteration 5847: loss: 0.2379, d_k_M range: [0.0055, 0.4629], d_k_M_hat range: [0.5531, 0.9838]
2025-03-11 20:32:29 - Train Iteration 5848: loss: 0.1714, d_k_M range: [0.0003, 0.3088], d_k_M_hat range: [0.5863, 0.9561]
2025-03-11 20:32:30 - Train Iteration 5849: loss: 0.3247, d_k_M range: [0.0939, 0.5655], d_k_M_hat range: [0.8817, 0.9964]
2025-03-11 20:32:30 - Train Iteration 5850: loss: 0.2251, d_k_M range: [0.0171, 0.4606], d_k_M_hat range: [0.6526, 0.9911]
2025-03-11 20:32:30 - Train Iteration 5851: loss: 0.2616, d_k_M range: [0.0014, 0.3425], d_k_M_hat range: [0.5020, 0.9825]
2025-03-11 20:32:31 - Train Iteration 5852: loss: 0.2862, d_k_M range: [0.0027, 0.5232], d_k_M_hat range: [0.5402, 0.9891]
2025-03-11 20:32:31 - Train Iteration 5853: loss: 0.5590, d_k_M range: [0.0000, 0.2664], d_k_M_hat range: [0.2524, 0.9502]
2025-03-11 20:32:32 - Train Iteration 5854: loss: 0.2461, d_k_M range: [0.0060, 0.4917], d_k_M_hat range: [0.5231, 0.9957]
2025-03-11 20:32:32 - Train Iteration 5855: loss: 0.2810, d_k_M range: [0.0001, 0.2094], d_k_M_hat range: [0.4700, 0.8998]
2025-03-11 20:32:32 - Train Iteration 5856: loss: 0.5693, d_k_M range: [0.0077, 0.5670], d_k_M_hat range: [0.2532, 0.9944]
2025-03-11 20:32:33 - Train Iteration 5857: loss: 0.2836, d_k_M range: [0.0139, 0.5259], d_k_M_hat range: [0.6547, 0.9980]
2025-03-11 20:32:33 - Train Iteration 5858: loss: 0.1896, d_k_M range: [0.0130, 0.3987], d_k_M_hat range: [0.6128, 0.9846]
2025-03-11 20:32:34 - Train Iteration 5859: loss: 0.2203, d_k_M range: [0.0406, 0.4650], d_k_M_hat range: [0.7772, 0.9955]
2025-03-11 20:32:34 - Train Iteration 5860: loss: 0.3308, d_k_M range: [0.0754, 0.5744], d_k_M_hat range: [0.8873, 0.9992]
2025-03-11 20:32:35 - Train Iteration 5861: loss: 0.7394, d_k_M range: [0.0004, 0.0206], d_k_M_hat range: [0.1414, 0.8254]
2025-03-11 20:32:35 - Train Iteration 5862: loss: 0.7327, d_k_M range: [0.0094, 0.8550], d_k_M_hat range: [0.5369, 0.9990]
2025-03-11 20:32:36 - Train Iteration 5863: loss: 0.2871, d_k_M range: [0.0010, 0.3647], d_k_M_hat range: [0.4985, 0.9073]
2025-03-11 20:32:36 - Train Iteration 5864: loss: 0.6050, d_k_M range: [0.0001, 0.5426], d_k_M_hat range: [0.2241, 0.9952]
2025-03-11 20:32:37 - Train Iteration 5865: loss: 0.1754, d_k_M range: [0.0197, 0.3971], d_k_M_hat range: [0.6499, 0.9812]
2025-03-11 20:32:37 - Train Iteration 5866: loss: 0.4671, d_k_M range: [0.0281, 0.6805], d_k_M_hat range: [0.5753, 0.9971]
2025-03-11 20:32:38 - Train Iteration 5867: loss: 0.2260, d_k_M range: [0.0454, 0.4660], d_k_M_hat range: [0.7989, 0.9906]
2025-03-11 20:32:38 - Train Iteration 5868: loss: 0.2307, d_k_M range: [0.0078, 0.2873], d_k_M_hat range: [0.5275, 0.9521]
2025-03-11 20:32:38 - Train Iteration 5869: loss: 0.2137, d_k_M range: [0.0037, 0.2297], d_k_M_hat range: [0.5414, 0.9110]
2025-03-11 20:32:39 - Train Iteration 5870: loss: 0.2604, d_k_M range: [0.0222, 0.4377], d_k_M_hat range: [0.8119, 0.9901]
2025-03-11 20:32:39 - Train Iteration 5871: loss: 0.1411, d_k_M range: [0.0099, 0.3318], d_k_M_hat range: [0.6343, 0.9818]
2025-03-11 20:32:40 - Train Iteration 5872: loss: 0.3074, d_k_M range: [0.0109, 0.5542], d_k_M_hat range: [0.8949, 0.9997]
2025-03-11 20:32:40 - Train Iteration 5873: loss: 0.3569, d_k_M range: [0.0002, 0.2926], d_k_M_hat range: [0.4028, 0.9836]
2025-03-11 20:32:41 - Train Iteration 5874: loss: 0.2156, d_k_M range: [0.0103, 0.4239], d_k_M_hat range: [0.5525, 0.9984]
2025-03-11 20:32:41 - Train Iteration 5875: loss: 0.2331, d_k_M range: [0.0025, 0.4544], d_k_M_hat range: [0.5198, 0.9897]
2025-03-11 20:32:42 - Train Iteration 5876: loss: 0.2818, d_k_M range: [0.1010, 0.5288], d_k_M_hat range: [0.6909, 0.9979]
2025-03-11 20:32:42 - Train Iteration 5877: loss: 0.2833, d_k_M range: [0.0067, 0.5278], d_k_M_hat range: [0.6823, 0.9955]
2025-03-11 20:32:43 - Train Iteration 5878: loss: 0.2517, d_k_M range: [0.0143, 0.4980], d_k_M_hat range: [0.5894, 0.9963]
2025-03-11 20:32:43 - Train Iteration 5879: loss: 0.1887, d_k_M range: [0.0035, 0.4001], d_k_M_hat range: [0.5866, 0.9742]
2025-03-11 20:32:43 - Train Iteration 5880: loss: 0.2104, d_k_M range: [0.0065, 0.3373], d_k_M_hat range: [0.5478, 0.9699]
2025-03-11 20:32:44 - Train Iteration 5881: loss: 0.2748, d_k_M range: [0.0008, 0.5218], d_k_M_hat range: [0.5678, 0.9976]
2025-03-11 20:32:44 - Train Iteration 5882: loss: 0.2788, d_k_M range: [0.0009, 0.2216], d_k_M_hat range: [0.4728, 0.9451]
2025-03-11 20:32:45 - Train Iteration 5883: loss: 0.3315, d_k_M range: [0.0357, 0.5740], d_k_M_hat range: [0.8079, 0.9987]
2025-03-11 20:32:45 - Train Iteration 5884: loss: 0.1742, d_k_M range: [0.0118, 0.2546], d_k_M_hat range: [0.6030, 0.9676]
2025-03-11 20:32:46 - Train Iteration 5885: loss: 0.3072, d_k_M range: [0.1063, 0.5462], d_k_M_hat range: [0.6792, 0.9986]
2025-03-11 20:32:46 - Train Iteration 5886: loss: 0.2543, d_k_M range: [0.0011, 0.3992], d_k_M_hat range: [0.4967, 0.9814]
2025-03-11 20:32:46 - Train Iteration 5887: loss: 0.3264, d_k_M range: [0.0004, 0.5707], d_k_M_hat range: [0.4377, 0.9994]
2025-03-11 20:32:47 - Train Iteration 5888: loss: 0.3634, d_k_M range: [0.0005, 0.5071], d_k_M_hat range: [0.4116, 0.9648]
2025-03-11 20:32:47 - Train Iteration 5889: loss: 0.2854, d_k_M range: [0.0010, 0.5249], d_k_M_hat range: [0.6446, 0.9969]
2025-03-11 20:32:48 - Train Iteration 5890: loss: 0.2198, d_k_M range: [0.0012, 0.1793], d_k_M_hat range: [0.5331, 0.9204]
2025-03-11 20:32:48 - Train Iteration 5891: loss: 0.2562, d_k_M range: [0.0011, 0.4962], d_k_M_hat range: [0.5156, 0.9941]
2025-03-11 20:32:49 - Train Iteration 5892: loss: 0.2063, d_k_M range: [0.0008, 0.3010], d_k_M_hat range: [0.5548, 0.9439]
2025-03-11 20:32:49 - Train Iteration 5893: loss: 0.2769, d_k_M range: [0.0004, 0.4615], d_k_M_hat range: [0.4744, 0.9845]
2025-03-11 20:32:50 - Train Iteration 5894: loss: 0.2566, d_k_M range: [0.0027, 0.4287], d_k_M_hat range: [0.5045, 0.9856]
2025-03-11 20:32:50 - Train Iteration 5895: loss: 0.7763, d_k_M range: [0.0057, 0.8797], d_k_M_hat range: [0.7753, 0.9987]
2025-03-11 20:32:51 - Train Iteration 5896: loss: 0.2809, d_k_M range: [0.0003, 0.0389], d_k_M_hat range: [0.4707, 0.7320]
2025-03-11 20:32:51 - Train Iteration 5897: loss: 0.2939, d_k_M range: [0.0007, 0.4758], d_k_M_hat range: [0.4863, 0.9891]
2025-03-11 20:32:51 - Train Iteration 5898: loss: 0.4216, d_k_M range: [0.1344, 0.6461], d_k_M_hat range: [0.7822, 0.9968]
2025-03-11 20:32:52 - Train Iteration 5899: loss: 0.2760, d_k_M range: [0.0008, 0.3310], d_k_M_hat range: [0.4754, 0.9766]
2025-03-11 20:32:52 - Train Iteration 5900: loss: 0.2895, d_k_M range: [0.0024, 0.5106], d_k_M_hat range: [0.4871, 0.9928]
2025-03-11 20:32:53 - Train Iteration 5901: loss: 0.2608, d_k_M range: [0.0001, 0.4067], d_k_M_hat range: [0.4894, 0.9872]
2025-03-11 20:32:53 - Train Iteration 5902: loss: 0.3236, d_k_M range: [0.0006, 0.5674], d_k_M_hat range: [0.5865, 0.9986]
2025-03-11 20:32:54 - Train Iteration 5903: loss: 0.4845, d_k_M range: [0.0004, 0.0364], d_k_M_hat range: [0.3044, 0.6943]
2025-03-11 20:32:54 - Train Iteration 5904: loss: 0.2379, d_k_M range: [0.1516, 0.4649], d_k_M_hat range: [0.8039, 0.9949]
2025-03-11 20:32:55 - Train Iteration 5905: loss: 0.2976, d_k_M range: [0.0152, 0.5429], d_k_M_hat range: [0.6430, 0.9973]
2025-03-11 20:32:55 - Train Iteration 5906: loss: 0.2913, d_k_M range: [0.0126, 0.3265], d_k_M_hat range: [0.5234, 0.9903]
2025-03-11 20:32:56 - Train Iteration 5907: loss: 0.5982, d_k_M range: [0.0002, 0.4722], d_k_M_hat range: [0.2267, 0.9877]
2025-03-11 20:32:56 - Train Iteration 5908: loss: 0.2559, d_k_M range: [0.0011, 0.4912], d_k_M_hat range: [0.5709, 0.9870]
2025-03-11 20:32:56 - Train Iteration 5909: loss: 0.5330, d_k_M range: [0.0001, 0.5113], d_k_M_hat range: [0.2702, 0.9847]
2025-03-11 20:32:57 - Train Iteration 5910: loss: 0.2527, d_k_M range: [0.0172, 0.4949], d_k_M_hat range: [0.5512, 0.9923]
2025-03-11 20:32:57 - Train Iteration 5911: loss: 0.2961, d_k_M range: [0.0008, 0.5187], d_k_M_hat range: [0.5266, 0.9746]
2025-03-11 20:32:58 - Train Iteration 5912: loss: 0.2781, d_k_M range: [0.0012, 0.3581], d_k_M_hat range: [0.4770, 0.9850]
2025-03-11 20:32:58 - Train Iteration 5913: loss: 0.2842, d_k_M range: [0.0020, 0.4750], d_k_M_hat range: [0.5513, 0.9866]
2025-03-11 20:32:59 - Train Iteration 5914: loss: 0.2421, d_k_M range: [0.0087, 0.4848], d_k_M_hat range: [0.5881, 0.9928]
2025-03-11 20:32:59 - Train Iteration 5915: loss: 0.3050, d_k_M range: [0.0047, 0.0904], d_k_M_hat range: [0.4619, 0.9807]
2025-03-11 20:33:00 - Train Iteration 5916: loss: 0.2816, d_k_M range: [0.0044, 0.4075], d_k_M_hat range: [0.4737, 0.9508]
2025-03-11 20:33:00 - Train Iteration 5917: loss: 0.2444, d_k_M range: [0.0099, 0.4753], d_k_M_hat range: [0.5382, 0.9885]
2025-03-11 20:33:01 - Train Iteration 5918: loss: 0.2930, d_k_M range: [0.0008, 0.5132], d_k_M_hat range: [0.4595, 0.9891]
2025-03-11 20:33:01 - Train Iteration 5919: loss: 0.3731, d_k_M range: [0.0189, 0.6096], d_k_M_hat range: [0.6972, 0.9988]
2025-03-11 20:33:01 - Train Iteration 5920: loss: 0.3182, d_k_M range: [0.0011, 0.3815], d_k_M_hat range: [0.4371, 0.9767]
2025-03-11 20:33:02 - Train Iteration 5921: loss: 0.3464, d_k_M range: [0.0039, 0.5786], d_k_M_hat range: [0.6728, 0.9910]
2025-03-11 20:33:02 - Train Iteration 5922: loss: 0.1881, d_k_M range: [0.0101, 0.3000], d_k_M_hat range: [0.6079, 0.9918]
2025-03-11 20:33:03 - Train Iteration 5923: loss: 0.2600, d_k_M range: [0.0026, 0.5084], d_k_M_hat range: [0.5932, 0.9985]
2025-03-11 20:33:03 - Train Iteration 5924: loss: 0.2983, d_k_M range: [0.0062, 0.1545], d_k_M_hat range: [0.4654, 0.8931]
2025-03-11 20:33:04 - Train Iteration 5925: loss: 0.3232, d_k_M range: [0.0069, 0.5644], d_k_M_hat range: [0.7797, 0.9959]
2025-03-11 20:33:04 - Train Iteration 5926: loss: 0.2773, d_k_M range: [0.0213, 0.5254], d_k_M_hat range: [0.6497, 0.9988]
2025-03-11 20:33:04 - Train Iteration 5927: loss: 0.1843, d_k_M range: [0.0061, 0.3701], d_k_M_hat range: [0.5810, 0.9408]
2025-03-11 20:33:05 - Train Iteration 5928: loss: 0.1892, d_k_M range: [0.0022, 0.4244], d_k_M_hat range: [0.5904, 0.9980]
2025-03-11 20:33:05 - Train Iteration 5929: loss: 0.1409, d_k_M range: [0.0025, 0.1015], d_k_M_hat range: [0.6462, 0.9343]
2025-03-11 20:33:06 - Train Iteration 5930: loss: 0.3790, d_k_M range: [0.0022, 0.3817], d_k_M_hat range: [0.3877, 0.9873]
2025-03-11 20:33:06 - Train Iteration 5931: loss: 0.2575, d_k_M range: [0.0133, 0.4998], d_k_M_hat range: [0.7369, 0.9923]
2025-03-11 20:33:07 - Train Iteration 5932: loss: 0.2519, d_k_M range: [0.0017, 0.3238], d_k_M_hat range: [0.5082, 0.9678]
2025-03-11 20:33:07 - Train Iteration 5933: loss: 0.1839, d_k_M range: [0.0459, 0.4105], d_k_M_hat range: [0.8256, 0.9961]
2025-03-11 20:33:08 - Train Iteration 5934: loss: 0.3070, d_k_M range: [0.0025, 0.3635], d_k_M_hat range: [0.4929, 0.9786]
2025-03-11 20:33:08 - Train Iteration 5935: loss: 0.2283, d_k_M range: [0.0010, 0.3270], d_k_M_hat range: [0.5232, 0.9723]
2025-03-11 20:33:09 - Train Iteration 5936: loss: 0.4481, d_k_M range: [0.0005, 0.2390], d_k_M_hat range: [0.3311, 0.9548]
2025-03-11 20:33:09 - Train Iteration 5937: loss: 0.3056, d_k_M range: [0.0018, 0.5025], d_k_M_hat range: [0.4506, 0.9989]
2025-03-11 20:33:09 - Train Iteration 5938: loss: 0.1851, d_k_M range: [0.0220, 0.3114], d_k_M_hat range: [0.7072, 0.9329]
2025-03-11 20:33:10 - Train Iteration 5939: loss: 0.3583, d_k_M range: [0.0002, 0.3482], d_k_M_hat range: [0.4016, 0.9656]
2025-03-11 20:33:10 - Train Iteration 5940: loss: 0.2315, d_k_M range: [0.0135, 0.4595], d_k_M_hat range: [0.7317, 0.9947]
2025-03-11 20:33:11 - Train Iteration 5941: loss: 0.1977, d_k_M range: [0.0048, 0.4248], d_k_M_hat range: [0.5602, 0.9903]
2025-03-11 20:33:11 - Train Iteration 5942: loss: 0.2939, d_k_M range: [0.0001, 0.4378], d_k_M_hat range: [0.4580, 0.9821]
2025-03-11 20:33:12 - Train Iteration 5943: loss: 0.3371, d_k_M range: [0.0086, 0.5795], d_k_M_hat range: [0.5292, 0.9989]
2025-03-11 20:33:12 - Train Iteration 5944: loss: 0.2380, d_k_M range: [0.0193, 0.4241], d_k_M_hat range: [0.5315, 0.9932]
2025-03-11 20:33:13 - Train Iteration 5945: loss: 0.3518, d_k_M range: [0.0041, 0.5776], d_k_M_hat range: [0.6090, 0.9991]
2025-03-11 20:33:13 - Train Iteration 5946: loss: 0.9005, d_k_M range: [0.0000, 0.0073], d_k_M_hat range: [0.0511, 0.5688]
2025-03-11 20:33:14 - Train Iteration 5947: loss: 0.1813, d_k_M range: [0.0042, 0.3366], d_k_M_hat range: [0.5816, 0.9629]
2025-03-11 20:33:14 - Train Iteration 5948: loss: 0.4495, d_k_M range: [0.0149, 0.6645], d_k_M_hat range: [0.6518, 0.9940]
2025-03-11 20:33:14 - Train Iteration 5949: loss: 0.2895, d_k_M range: [0.0424, 0.5254], d_k_M_hat range: [0.6702, 0.9874]
2025-03-11 20:33:15 - Train Iteration 5950: loss: 0.3548, d_k_M range: [0.0027, 0.2955], d_k_M_hat range: [0.5622, 0.9664]
2025-03-11 20:33:15 - Train Iteration 5951: loss: 0.7802, d_k_M range: [0.0101, 0.8649], d_k_M_hat range: [0.6415, 0.9816]
2025-03-11 20:33:16 - Train Iteration 5952: loss: 0.3447, d_k_M range: [0.0002, 0.4732], d_k_M_hat range: [0.4131, 0.9960]
2025-03-11 20:33:16 - Train Iteration 5953: loss: 0.2218, d_k_M range: [0.0007, 0.4679], d_k_M_hat range: [0.5639, 0.9969]
2025-03-11 20:33:17 - Train Iteration 5954: loss: 0.2202, d_k_M range: [0.0034, 0.4665], d_k_M_hat range: [0.5387, 0.9972]
2025-03-11 20:33:17 - Train Iteration 5955: loss: 0.2197, d_k_M range: [0.0042, 0.4289], d_k_M_hat range: [0.5586, 0.9763]
2025-03-11 20:33:17 - Train Iteration 5956: loss: 0.4947, d_k_M range: [0.0023, 0.7023], d_k_M_hat range: [0.5164, 0.9990]
2025-03-11 20:33:18 - Train Iteration 5957: loss: 0.2835, d_k_M range: [0.0005, 0.0661], d_k_M_hat range: [0.4681, 0.7029]
2025-03-11 20:33:18 - Train Iteration 5958: loss: 0.1996, d_k_M range: [0.0977, 0.4402], d_k_M_hat range: [0.6723, 0.9964]
2025-03-11 20:33:19 - Train Iteration 5959: loss: 0.2513, d_k_M range: [0.0009, 0.1735], d_k_M_hat range: [0.5001, 0.9338]
2025-03-11 20:33:19 - Train Iteration 5960: loss: 0.4490, d_k_M range: [0.0003, 0.3734], d_k_M_hat range: [0.3335, 0.9823]
2025-03-11 20:33:20 - Train Iteration 5961: loss: 0.2891, d_k_M range: [0.0018, 0.3428], d_k_M_hat range: [0.4776, 0.9358]
2025-03-11 20:33:20 - Train Iteration 5962: loss: 0.2783, d_k_M range: [0.0014, 0.3964], d_k_M_hat range: [0.5162, 0.9779]
2025-03-11 20:33:21 - Train Iteration 5963: loss: 0.2251, d_k_M range: [0.0014, 0.4671], d_k_M_hat range: [0.5407, 0.9926]
2025-03-11 20:33:21 - Train Iteration 5964: loss: 0.2523, d_k_M range: [0.0012, 0.5016], d_k_M_hat range: [0.5220, 0.9993]
2025-03-11 20:33:22 - Train Iteration 5965: loss: 0.2576, d_k_M range: [0.0014, 0.3529], d_k_M_hat range: [0.5211, 0.9866]
2025-03-11 20:33:22 - Train Iteration 5966: loss: 0.3111, d_k_M range: [0.0016, 0.1974], d_k_M_hat range: [0.4448, 0.9496]
2025-03-11 20:33:23 - Train Iteration 5967: loss: 0.7227, d_k_M range: [0.0008, 0.8500], d_k_M_hat range: [0.4619, 0.9998]
2025-03-11 20:33:23 - Train Iteration 5968: loss: 0.5729, d_k_M range: [0.0002, 0.0255], d_k_M_hat range: [0.2433, 0.7697]
2025-03-11 20:33:24 - Train Iteration 5969: loss: 0.4255, d_k_M range: [0.0034, 0.6467], d_k_M_hat range: [0.6309, 0.9962]
2025-03-11 20:33:24 - Train Iteration 5970: loss: 0.2270, d_k_M range: [0.0080, 0.3724], d_k_M_hat range: [0.5438, 0.9862]
2025-03-11 20:33:24 - Train Iteration 5971: loss: 0.2149, d_k_M range: [0.0015, 0.3768], d_k_M_hat range: [0.5380, 0.9961]
2025-03-11 20:33:25 - Train Iteration 5972: loss: 0.3503, d_k_M range: [0.0020, 0.5891], d_k_M_hat range: [0.6053, 0.9972]
2025-03-11 20:33:25 - Train Iteration 5973: loss: 0.3662, d_k_M range: [0.0002, 0.3013], d_k_M_hat range: [0.3951, 0.9304]
2025-03-11 20:33:26 - Train Iteration 5974: loss: 0.2536, d_k_M range: [0.0026, 0.4953], d_k_M_hat range: [0.5649, 0.9918]
2025-03-11 20:33:26 - Train Iteration 5975: loss: 0.1899, d_k_M range: [0.0082, 0.4304], d_k_M_hat range: [0.6948, 0.9946]
2025-03-11 20:33:27 - Train Iteration 5976: loss: 0.3447, d_k_M range: [0.0009, 0.0176], d_k_M_hat range: [0.4138, 0.6979]
2025-03-11 20:33:27 - Train Iteration 5977: loss: 0.3395, d_k_M range: [0.0055, 0.5820], d_k_M_hat range: [0.5803, 0.9993]
2025-03-11 20:33:28 - Train Iteration 5978: loss: 0.3325, d_k_M range: [0.0002, 0.2569], d_k_M_hat range: [0.4238, 0.9522]
2025-03-11 20:33:28 - Train Iteration 5979: loss: 0.4270, d_k_M range: [0.0206, 0.6510], d_k_M_hat range: [0.5992, 0.9980]
2025-03-11 20:33:29 - Train Iteration 5980: loss: 0.8912, d_k_M range: [0.0002, 0.3464], d_k_M_hat range: [0.0562, 0.9920]
2025-03-11 20:33:29 - Train Iteration 5981: loss: 0.3029, d_k_M range: [0.0057, 0.5417], d_k_M_hat range: [0.5635, 0.9913]
2025-03-11 20:33:29 - Train Iteration 5982: loss: 0.2589, d_k_M range: [0.0401, 0.4891], d_k_M_hat range: [0.7638, 0.9807]
2025-03-11 20:33:30 - Train Iteration 5983: loss: 0.1895, d_k_M range: [0.0144, 0.3868], d_k_M_hat range: [0.6557, 0.9673]
2025-03-11 20:33:30 - Train Iteration 5984: loss: 0.2686, d_k_M range: [0.0003, 0.5160], d_k_M_hat range: [0.5344, 0.9978]
2025-03-11 20:33:31 - Train Iteration 5985: loss: 0.3160, d_k_M range: [0.0157, 0.5542], d_k_M_hat range: [0.6659, 0.9921]
2025-03-11 20:33:31 - Train Iteration 5986: loss: 0.6208, d_k_M range: [0.0001, 0.0816], d_k_M_hat range: [0.2122, 0.7795]
2025-03-11 20:33:32 - Train Iteration 5987: loss: 0.3893, d_k_M range: [0.0033, 0.6203], d_k_M_hat range: [0.7120, 0.9964]
2025-03-11 20:33:32 - Train Iteration 5988: loss: 0.3387, d_k_M range: [0.0002, 0.4441], d_k_M_hat range: [0.4186, 0.9860]
2025-03-11 20:33:33 - Train Iteration 5989: loss: 0.2809, d_k_M range: [0.0050, 0.4630], d_k_M_hat range: [0.4772, 0.9770]
2025-03-11 20:33:33 - Train Iteration 5990: loss: 0.2617, d_k_M range: [0.0004, 0.4443], d_k_M_hat range: [0.5016, 0.9790]
2025-03-11 20:33:34 - Train Iteration 5991: loss: 0.2748, d_k_M range: [0.0060, 0.4629], d_k_M_hat range: [0.4818, 0.9811]
2025-03-11 20:33:34 - Train Iteration 5992: loss: 0.1743, d_k_M range: [0.0008, 0.4075], d_k_M_hat range: [0.6210, 0.9900]
2025-03-11 20:33:35 - Train Iteration 5993: loss: 0.3505, d_k_M range: [0.0046, 0.5900], d_k_M_hat range: [0.5599, 0.9980]
2025-03-11 20:33:35 - Train Iteration 5994: loss: 0.2160, d_k_M range: [0.0030, 0.4025], d_k_M_hat range: [0.5473, 0.9795]
2025-03-11 20:33:35 - Train Iteration 5995: loss: 0.3344, d_k_M range: [0.0011, 0.5724], d_k_M_hat range: [0.5613, 0.9941]
2025-03-11 20:33:36 - Train Iteration 5996: loss: 0.2211, d_k_M range: [0.0178, 0.4302], d_k_M_hat range: [0.5559, 0.9599]
2025-03-11 20:33:36 - Train Iteration 5997: loss: 0.2265, d_k_M range: [0.0005, 0.3492], d_k_M_hat range: [0.5246, 0.9631]
2025-03-11 20:33:37 - Train Iteration 5998: loss: 0.2621, d_k_M range: [0.0094, 0.4552], d_k_M_hat range: [0.5304, 0.9625]
2025-03-11 20:33:37 - Train Iteration 5999: loss: 0.2118, d_k_M range: [0.0024, 0.3801], d_k_M_hat range: [0.5542, 0.9674]
2025-03-11 20:33:38 - Train Iteration 6000: loss: 0.2201, d_k_M range: [0.0013, 0.4322], d_k_M_hat range: [0.5794, 0.9929]
2025-03-11 20:33:38 - Train Iteration 6001: loss: 0.1978, d_k_M range: [0.0063, 0.4263], d_k_M_hat range: [0.6044, 0.9815]
2025-03-11 20:33:39 - Train Iteration 6002: loss: 0.3820, d_k_M range: [0.0345, 0.6169], d_k_M_hat range: [0.7303, 0.9988]
2025-03-11 20:33:39 - Train Iteration 6003: loss: 0.2586, d_k_M range: [0.0005, 0.3880], d_k_M_hat range: [0.4926, 0.9868]
2025-03-11 20:33:40 - Train Iteration 6004: loss: 0.1805, d_k_M range: [0.0037, 0.4127], d_k_M_hat range: [0.5797, 0.9879]
2025-03-11 20:33:40 - Train Iteration 6005: loss: 0.2603, d_k_M range: [0.0133, 0.5018], d_k_M_hat range: [0.6645, 0.9990]
2025-03-11 20:33:40 - Train Iteration 6006: loss: 0.3455, d_k_M range: [0.0376, 0.5832], d_k_M_hat range: [0.6746, 0.9954]
2025-03-11 20:33:41 - Train Iteration 6007: loss: 0.3316, d_k_M range: [0.0001, 0.2660], d_k_M_hat range: [0.4242, 0.9535]
2025-03-11 20:33:41 - Train Iteration 6008: loss: 0.2432, d_k_M range: [0.0009, 0.4818], d_k_M_hat range: [0.5286, 0.9886]
2025-03-11 20:33:42 - Train Iteration 6009: loss: 0.2418, d_k_M range: [0.0034, 0.4857], d_k_M_hat range: [0.5482, 0.9940]
2025-03-11 20:33:42 - Train Iteration 6010: loss: 0.9408, d_k_M range: [0.0044, 0.9698], d_k_M_hat range: [0.6295, 0.9999]
2025-03-11 20:33:43 - Train Iteration 6011: loss: 0.2429, d_k_M range: [0.0034, 0.3978], d_k_M_hat range: [0.5106, 0.9168]
2025-03-11 20:33:43 - Train Iteration 6012: loss: 0.3939, d_k_M range: [0.0544, 0.6168], d_k_M_hat range: [0.7537, 0.9940]
2025-03-11 20:33:44 - Train Iteration 6013: loss: 0.2202, d_k_M range: [0.0174, 0.4568], d_k_M_hat range: [0.6584, 0.9895]
2025-03-11 20:33:44 - Train Iteration 6014: loss: 0.2857, d_k_M range: [0.0084, 0.2651], d_k_M_hat range: [0.4746, 0.9688]
2025-03-11 20:33:45 - Train Iteration 6015: loss: 0.2117, d_k_M range: [0.0084, 0.4225], d_k_M_hat range: [0.5484, 0.9652]
2025-03-11 20:33:45 - Train Iteration 6016: loss: 0.3804, d_k_M range: [0.0231, 0.6118], d_k_M_hat range: [0.8016, 0.9951]
2025-03-11 20:33:46 - Train Iteration 6017: loss: 0.4409, d_k_M range: [0.0005, 0.4465], d_k_M_hat range: [0.3368, 0.9976]
2025-03-11 20:33:46 - Train Iteration 6018: loss: 0.2153, d_k_M range: [0.0102, 0.4351], d_k_M_hat range: [0.8842, 0.9836]
2025-03-11 20:33:46 - Train Iteration 6019: loss: 0.2399, d_k_M range: [0.0059, 0.3384], d_k_M_hat range: [0.5161, 0.9671]
2025-03-11 20:33:47 - Train Iteration 6020: loss: 0.2926, d_k_M range: [0.0016, 0.1851], d_k_M_hat range: [0.4607, 0.9448]
2025-03-11 20:33:47 - Train Iteration 6021: loss: 0.2295, d_k_M range: [0.0034, 0.4404], d_k_M_hat range: [0.5306, 0.9817]
2025-03-11 20:33:48 - Train Iteration 6022: loss: 0.3201, d_k_M range: [0.0512, 0.5645], d_k_M_hat range: [0.7412, 0.9988]
2025-03-11 20:33:48 - Train Iteration 6023: loss: 0.5287, d_k_M range: [0.0043, 0.7221], d_k_M_hat range: [0.5486, 0.9949]
2025-03-11 20:33:49 - Train Iteration 6024: loss: 0.2589, d_k_M range: [0.0001, 0.0765], d_k_M_hat range: [0.4913, 0.8099]
2025-03-11 20:33:49 - Train Iteration 6025: loss: 0.2158, d_k_M range: [0.0020, 0.4622], d_k_M_hat range: [0.6120, 0.9976]
2025-03-11 20:33:50 - Train Iteration 6026: loss: 0.2954, d_k_M range: [0.0031, 0.5374], d_k_M_hat range: [0.4658, 0.9939]
2025-03-11 20:33:50 - Train Iteration 6027: loss: 0.2610, d_k_M range: [0.0030, 0.4072], d_k_M_hat range: [0.4986, 0.9839]
2025-03-11 20:33:51 - Train Iteration 6028: loss: 0.4471, d_k_M range: [0.0120, 0.6667], d_k_M_hat range: [0.5968, 0.9980]
2025-03-11 20:33:51 - Train Iteration 6029: loss: 0.3262, d_k_M range: [0.0054, 0.4758], d_k_M_hat range: [0.4828, 0.9958]
2025-03-11 20:33:52 - Train Iteration 6030: loss: 0.2605, d_k_M range: [0.0201, 0.4073], d_k_M_hat range: [0.5117, 0.9974]
2025-03-11 20:33:52 - Train Iteration 6031: loss: 0.1888, d_k_M range: [0.0009, 0.3824], d_k_M_hat range: [0.5664, 0.9942]
2025-03-11 20:33:52 - Train Iteration 6032: loss: 0.2855, d_k_M range: [0.0412, 0.5300], d_k_M_hat range: [0.8490, 0.9970]
2025-03-11 20:33:53 - Train Iteration 6033: loss: 0.2645, d_k_M range: [0.0147, 0.4461], d_k_M_hat range: [0.7254, 0.9966]
2025-03-11 20:33:53 - Train Iteration 6034: loss: 0.2292, d_k_M range: [0.0016, 0.3684], d_k_M_hat range: [0.5281, 0.9876]
2025-03-11 20:33:54 - Train Iteration 6035: loss: 0.2498, d_k_M range: [0.0289, 0.4964], d_k_M_hat range: [0.7709, 0.9965]
2025-03-11 20:33:54 - Train Iteration 6036: loss: 0.2035, d_k_M range: [0.0429, 0.4499], d_k_M_hat range: [0.6761, 0.9988]
2025-03-11 20:33:55 - Train Iteration 6037: loss: 0.5862, d_k_M range: [0.0006, 0.6690], d_k_M_hat range: [0.2349, 1.0000]
2025-03-11 20:33:55 - Train Iteration 6038: loss: 0.2197, d_k_M range: [0.0009, 0.4551], d_k_M_hat range: [0.5513, 0.9994]
2025-03-11 20:33:56 - Train Iteration 6039: loss: 0.1413, d_k_M range: [0.0036, 0.3503], d_k_M_hat range: [0.7391, 0.9952]
2025-03-11 20:33:56 - Train Iteration 6040: loss: 0.2303, d_k_M range: [0.0068, 0.3699], d_k_M_hat range: [0.5269, 0.9793]
2025-03-11 20:33:57 - Train Iteration 6041: loss: 0.2270, d_k_M range: [0.0017, 0.4392], d_k_M_hat range: [0.5254, 0.9970]
2025-03-11 20:33:57 - Train Iteration 6042: loss: 0.1520, d_k_M range: [0.0559, 0.3839], d_k_M_hat range: [0.9121, 0.9940]
2025-03-11 20:33:57 - Train Iteration 6043: loss: 0.2062, d_k_M range: [0.0071, 0.4163], d_k_M_hat range: [0.5543, 0.9804]
2025-03-11 20:33:58 - Train Iteration 6044: loss: 0.6361, d_k_M range: [0.0002, 0.0313], d_k_M_hat range: [0.2028, 0.8970]
2025-03-11 20:33:58 - Train Iteration 6045: loss: 0.3265, d_k_M range: [0.1477, 0.5708], d_k_M_hat range: [0.8858, 0.9993]
2025-03-11 20:33:59 - Train Iteration 6046: loss: 0.2742, d_k_M range: [0.0006, 0.0892], d_k_M_hat range: [0.4827, 0.7849]
2025-03-11 20:33:59 - Train Iteration 6047: loss: 0.3352, d_k_M range: [0.0070, 0.5661], d_k_M_hat range: [0.8131, 0.9877]
2025-03-11 20:34:00 - Train Iteration 6048: loss: 0.1352, d_k_M range: [0.0152, 0.3580], d_k_M_hat range: [0.6568, 0.9902]
2025-03-11 20:34:00 - Train Iteration 6049: loss: 0.3037, d_k_M range: [0.0002, 0.4578], d_k_M_hat range: [0.4491, 0.9925]
2025-03-11 20:34:01 - Train Iteration 6050: loss: 0.2306, d_k_M range: [0.0032, 0.4798], d_k_M_hat range: [0.5740, 0.9996]
2025-03-11 20:34:01 - Train Iteration 6051: loss: 0.2677, d_k_M range: [0.0016, 0.4855], d_k_M_hat range: [0.4842, 0.9993]
2025-03-11 20:34:01 - Train Iteration 6052: loss: 0.1771, d_k_M range: [0.2248, 0.4082], d_k_M_hat range: [0.9657, 0.9942]
2025-03-11 20:34:02 - Train Iteration 6053: loss: 0.4938, d_k_M range: [0.0314, 0.7018], d_k_M_hat range: [0.8065, 0.9991]
2025-03-11 20:34:02 - Train Iteration 6054: loss: 0.3787, d_k_M range: [0.0001, 0.0838], d_k_M_hat range: [0.3876, 0.7819]
2025-03-11 20:34:03 - Train Iteration 6055: loss: 0.2332, d_k_M range: [0.0013, 0.4300], d_k_M_hat range: [0.5645, 0.9537]
2025-03-11 20:34:03 - Train Iteration 6056: loss: 0.2713, d_k_M range: [0.0464, 0.5140], d_k_M_hat range: [0.8235, 0.9982]
2025-03-11 20:34:04 - Train Iteration 6057: loss: 0.5112, d_k_M range: [0.0035, 0.7126], d_k_M_hat range: [0.5735, 0.9976]
2025-03-11 20:34:04 - Train Iteration 6058: loss: 0.4027, d_k_M range: [0.0001, 0.5098], d_k_M_hat range: [0.3655, 0.9867]
2025-03-11 20:34:04 - Train Iteration 6059: loss: 0.2481, d_k_M range: [0.0137, 0.1695], d_k_M_hat range: [0.5353, 0.8858]
2025-03-11 20:34:05 - Train Iteration 6060: loss: 0.2245, d_k_M range: [0.0054, 0.2926], d_k_M_hat range: [0.5315, 0.9382]
2025-03-11 20:34:05 - Train Iteration 6061: loss: 0.1857, d_k_M range: [0.0042, 0.3844], d_k_M_hat range: [0.6782, 0.9750]
2025-03-11 20:34:06 - Train Iteration 6062: loss: 0.2126, d_k_M range: [0.0089, 0.4468], d_k_M_hat range: [0.5689, 0.9857]
2025-03-11 20:34:06 - Train Iteration 6063: loss: 0.3322, d_k_M range: [0.0005, 0.5564], d_k_M_hat range: [0.4242, 0.9999]
2025-03-11 20:34:07 - Train Iteration 6064: loss: 0.2015, d_k_M range: [0.0104, 0.3808], d_k_M_hat range: [0.5742, 0.9726]
2025-03-11 20:34:07 - Train Iteration 6065: loss: 0.8587, d_k_M range: [0.0113, 0.9264], d_k_M_hat range: [0.7470, 0.9997]
2025-03-11 20:34:08 - Train Iteration 6066: loss: 0.2447, d_k_M range: [0.0005, 0.3380], d_k_M_hat range: [0.5077, 0.9894]
2025-03-11 20:34:08 - Train Iteration 6067: loss: 0.2433, d_k_M range: [0.0066, 0.4908], d_k_M_hat range: [0.5651, 0.9976]
2025-03-11 20:34:09 - Train Iteration 6068: loss: 0.4486, d_k_M range: [0.0034, 0.6663], d_k_M_hat range: [0.6900, 0.9991]
2025-03-11 20:34:09 - Train Iteration 6069: loss: 0.1833, d_k_M range: [0.0084, 0.2214], d_k_M_hat range: [0.5803, 0.9805]
2025-03-11 20:34:10 - Train Iteration 6070: loss: 0.2383, d_k_M range: [0.0331, 0.4720], d_k_M_hat range: [0.8490, 0.9904]
2025-03-11 20:34:10 - Train Iteration 6071: loss: 0.1886, d_k_M range: [0.0110, 0.2881], d_k_M_hat range: [0.6669, 0.9662]
2025-03-11 20:34:10 - Train Iteration 6072: loss: 0.2731, d_k_M range: [0.0012, 0.3596], d_k_M_hat range: [0.4787, 0.9838]
2025-03-11 20:34:11 - Train Iteration 6073: loss: 0.2584, d_k_M range: [0.0141, 0.5051], d_k_M_hat range: [0.6094, 0.9969]
2025-03-11 20:34:11 - Train Iteration 6074: loss: 0.1916, d_k_M range: [0.0005, 0.2762], d_k_M_hat range: [0.5628, 0.9661]
2025-03-11 20:34:12 - Train Iteration 6075: loss: 0.3425, d_k_M range: [0.0010, 0.5795], d_k_M_hat range: [0.5888, 0.9943]
2025-03-11 20:34:12 - Train Iteration 6076: loss: 0.2901, d_k_M range: [0.0012, 0.5379], d_k_M_hat range: [0.4829, 0.9993]
2025-03-11 20:34:13 - Train Iteration 6077: loss: 0.3037, d_k_M range: [0.0014, 0.2772], d_k_M_hat range: [0.4785, 0.9715]
2025-03-11 20:34:13 - Train Iteration 6078: loss: 0.2290, d_k_M range: [0.0021, 0.4582], d_k_M_hat range: [0.5294, 0.9949]
2025-03-11 20:34:14 - Train Iteration 6079: loss: 0.2339, d_k_M range: [0.0006, 0.4194], d_k_M_hat range: [0.5254, 0.9905]
2025-03-11 20:34:14 - Train Iteration 6080: loss: 0.2475, d_k_M range: [0.0199, 0.4929], d_k_M_hat range: [0.7336, 0.9981]
2025-03-11 20:34:15 - Train Iteration 6081: loss: 0.5869, d_k_M range: [0.0002, 0.7651], d_k_M_hat range: [0.4608, 0.9990]
2025-03-11 20:34:15 - Train Iteration 6082: loss: 0.3303, d_k_M range: [0.0005, 0.0309], d_k_M_hat range: [0.4271, 0.8842]
2025-03-11 20:34:16 - Train Iteration 6083: loss: 0.2376, d_k_M range: [0.0001, 0.4602], d_k_M_hat range: [0.5487, 0.9863]
2025-03-11 20:34:16 - Train Iteration 6084: loss: 0.2622, d_k_M range: [0.0023, 0.5107], d_k_M_hat range: [0.5866, 0.9986]
2025-03-11 20:34:16 - Train Iteration 6085: loss: 0.2809, d_k_M range: [0.0011, 0.0756], d_k_M_hat range: [0.4711, 0.8920]
2025-03-11 20:34:17 - Train Iteration 6086: loss: 0.3283, d_k_M range: [0.0009, 0.5693], d_k_M_hat range: [0.5329, 0.9964]
2025-03-11 20:34:17 - Train Iteration 6087: loss: 0.2191, d_k_M range: [0.0003, 0.2741], d_k_M_hat range: [0.5322, 0.9697]
2025-03-11 20:34:18 - Train Iteration 6088: loss: 0.2002, d_k_M range: [0.0037, 0.4306], d_k_M_hat range: [0.6906, 0.9973]
2025-03-11 20:34:18 - Train Iteration 6089: loss: 0.2259, d_k_M range: [0.0001, 0.1641], d_k_M_hat range: [0.5248, 0.9755]
2025-03-11 20:34:19 - Train Iteration 6090: loss: 0.5263, d_k_M range: [0.0003, 0.4204], d_k_M_hat range: [0.2748, 0.9883]
2025-03-11 20:34:19 - Train Iteration 6091: loss: 0.3010, d_k_M range: [0.1280, 0.5200], d_k_M_hat range: [0.9103, 0.9993]
2025-03-11 20:34:20 - Train Iteration 6092: loss: 0.2117, d_k_M range: [0.0034, 0.2500], d_k_M_hat range: [0.5451, 0.9788]
2025-03-11 20:34:20 - Train Iteration 6093: loss: 0.2170, d_k_M range: [0.0070, 0.3937], d_k_M_hat range: [0.5412, 0.9918]
2025-03-11 20:34:21 - Train Iteration 6094: loss: 0.7705, d_k_M range: [0.0018, 0.4057], d_k_M_hat range: [0.1241, 0.9874]
2025-03-11 20:34:21 - Train Iteration 6095: loss: 0.2326, d_k_M range: [0.0005, 0.4715], d_k_M_hat range: [0.5487, 0.9892]
2025-03-11 20:34:21 - Train Iteration 6096: loss: 0.7093, d_k_M range: [0.0016, 0.8417], d_k_M_hat range: [0.5356, 0.9995]
2025-03-11 20:34:22 - Train Iteration 6097: loss: 0.2199, d_k_M range: [0.0008, 0.2525], d_k_M_hat range: [0.5318, 0.9293]
2025-03-11 20:34:22 - Train Iteration 6098: loss: 0.3028, d_k_M range: [0.0011, 0.3520], d_k_M_hat range: [0.4508, 0.9954]
2025-03-11 20:34:23 - Train Iteration 6099: loss: 0.3979, d_k_M range: [0.0149, 0.6282], d_k_M_hat range: [0.6131, 0.9974]
2025-03-11 20:34:23 - Train Iteration 6100: loss: 0.2690, d_k_M range: [0.0002, 0.2869], d_k_M_hat range: [0.5046, 0.9469]
2025-03-11 20:34:24 - Train Iteration 6101: loss: 0.3443, d_k_M range: [0.0034, 0.5778], d_k_M_hat range: [0.6321, 0.9910]
2025-03-11 20:34:24 - Train Iteration 6102: loss: 0.3345, d_k_M range: [0.0005, 0.0529], d_k_M_hat range: [0.4221, 0.8923]
2025-03-11 20:34:24 - Train Iteration 6103: loss: 0.4553, d_k_M range: [0.0295, 0.6716], d_k_M_hat range: [0.5560, 0.9968]
2025-03-11 20:34:25 - Train Iteration 6104: loss: 0.3059, d_k_M range: [0.0001, 0.2720], d_k_M_hat range: [0.4469, 0.8645]
2025-03-11 20:34:25 - Train Iteration 6105: loss: 0.5462, d_k_M range: [0.0009, 0.7380], d_k_M_hat range: [0.5506, 0.9989]
2025-03-11 20:34:26 - Train Iteration 6106: loss: 0.2832, d_k_M range: [0.0005, 0.1468], d_k_M_hat range: [0.5683, 0.6805]
2025-03-11 20:34:26 - Train Iteration 6107: loss: 0.1911, d_k_M range: [0.0021, 0.2824], d_k_M_hat range: [0.5650, 0.9726]
2025-03-11 20:34:27 - Train Iteration 6108: loss: 0.2421, d_k_M range: [0.0032, 0.4884], d_k_M_hat range: [0.5290, 0.9991]
2025-03-11 20:34:27 - Train Iteration 6109: loss: 0.1916, d_k_M range: [0.0006, 0.3210], d_k_M_hat range: [0.5792, 0.9866]
2025-03-11 20:34:28 - Train Iteration 6110: loss: 0.6738, d_k_M range: [0.0007, 0.2672], d_k_M_hat range: [0.1799, 0.8636]
2025-03-11 20:34:28 - Train Iteration 6111: loss: 0.3073, d_k_M range: [0.0090, 0.5537], d_k_M_hat range: [0.5011, 0.9993]
2025-03-11 20:34:28 - Train Iteration 6112: loss: 0.3113, d_k_M range: [0.0009, 0.1224], d_k_M_hat range: [0.4475, 0.9324]
2025-03-11 20:34:29 - Train Iteration 6113: loss: 0.2034, d_k_M range: [0.0125, 0.4344], d_k_M_hat range: [0.6290, 0.9914]
2025-03-11 20:34:29 - Train Iteration 6114: loss: 0.2141, d_k_M range: [0.0047, 0.3764], d_k_M_hat range: [0.5447, 0.9760]
2025-03-11 20:34:30 - Train Iteration 6115: loss: 0.3687, d_k_M range: [0.0037, 0.6035], d_k_M_hat range: [0.6182, 0.9964]
2025-03-11 20:34:30 - Train Iteration 6116: loss: 0.2116, d_k_M range: [0.0011, 0.1380], d_k_M_hat range: [0.5430, 0.8828]
2025-03-11 20:34:31 - Train Iteration 6117: loss: 0.4915, d_k_M range: [0.0005, 0.6480], d_k_M_hat range: [0.5478, 0.9768]
2025-03-11 20:34:31 - Train Iteration 6118: loss: 0.3792, d_k_M range: [0.0001, 0.3077], d_k_M_hat range: [0.3855, 0.9827]
2025-03-11 20:34:32 - Train Iteration 6119: loss: 0.2326, d_k_M range: [0.0029, 0.4715], d_k_M_hat range: [0.5372, 0.9892]
2025-03-11 20:34:32 - Train Iteration 6120: loss: 0.2470, d_k_M range: [0.0009, 0.4819], d_k_M_hat range: [0.6213, 0.9918]
2025-03-11 20:34:33 - Train Iteration 6121: loss: 0.2834, d_k_M range: [0.0077, 0.5195], d_k_M_hat range: [0.5749, 0.9958]
2025-03-11 20:34:33 - Train Iteration 6122: loss: 0.2682, d_k_M range: [0.0002, 0.3814], d_k_M_hat range: [0.4823, 0.9818]
2025-03-11 20:34:33 - Train Iteration 6123: loss: 0.1972, d_k_M range: [0.0248, 0.4324], d_k_M_hat range: [0.7896, 0.9883]
2025-03-11 20:34:34 - Train Iteration 6124: loss: 0.1321, d_k_M range: [0.0010, 0.1350], d_k_M_hat range: [0.6375, 0.9054]
2025-03-11 20:34:34 - Train Iteration 6125: loss: 0.2380, d_k_M range: [0.0055, 0.3832], d_k_M_hat range: [0.5179, 0.9918]
2025-03-11 20:34:35 - Train Iteration 6126: loss: 0.1931, d_k_M range: [0.0375, 0.4345], d_k_M_hat range: [0.8210, 0.9951]
2025-03-11 20:34:35 - Train Iteration 6127: loss: 0.3691, d_k_M range: [0.0002, 0.1789], d_k_M_hat range: [0.3929, 0.8265]
2025-03-11 20:34:35 - Train Iteration 6128: loss: 0.3362, d_k_M range: [0.0010, 0.3529], d_k_M_hat range: [0.4236, 0.9759]
2025-03-11 20:34:36 - Train Iteration 6129: loss: 0.4461, d_k_M range: [0.1241, 0.6639], d_k_M_hat range: [0.7328, 0.9976]
2025-03-11 20:34:36 - Train Iteration 6130: loss: 0.2598, d_k_M range: [0.0004, 0.3648], d_k_M_hat range: [0.4907, 0.9693]
2025-03-11 20:34:37 - Train Iteration 6131: loss: 0.2544, d_k_M range: [0.0028, 0.5027], d_k_M_hat range: [0.6436, 0.9983]
2025-03-11 20:34:37 - Train Iteration 6132: loss: 0.2438, d_k_M range: [0.0028, 0.3721], d_k_M_hat range: [0.5326, 0.9264]
2025-03-11 20:34:38 - Train Iteration 6133: loss: 0.2331, d_k_M range: [0.0070, 0.4578], d_k_M_hat range: [0.6223, 0.9750]
2025-03-11 20:34:38 - Train Iteration 6134: loss: 0.2570, d_k_M range: [0.0062, 0.4915], d_k_M_hat range: [0.5848, 0.9983]
2025-03-11 20:34:39 - Train Iteration 6135: loss: 0.2705, d_k_M range: [0.0219, 0.5190], d_k_M_hat range: [0.5470, 0.9989]
2025-03-11 20:34:39 - Train Iteration 6136: loss: 0.2154, d_k_M range: [0.0003, 0.4150], d_k_M_hat range: [0.5362, 0.9916]
2025-03-11 20:34:39 - Train Iteration 6137: loss: 0.3935, d_k_M range: [0.0066, 0.6250], d_k_M_hat range: [0.5603, 0.9977]
2025-03-11 20:34:40 - Train Iteration 6138: loss: 0.4707, d_k_M range: [0.0006, 0.3984], d_k_M_hat range: [0.3145, 0.9937]
2025-03-11 20:34:40 - Train Iteration 6139: loss: 0.2195, d_k_M range: [0.0033, 0.4016], d_k_M_hat range: [0.5583, 0.9884]
2025-03-11 20:34:41 - Train Iteration 6140: loss: 0.2226, d_k_M range: [0.0005, 0.4080], d_k_M_hat range: [0.5287, 0.9416]
2025-03-11 20:34:42 - Train Iteration 6141: loss: 0.2512, d_k_M range: [0.0286, 0.4948], d_k_M_hat range: [0.6551, 0.9954]
2025-03-11 20:34:42 - Train Iteration 6142: loss: 0.3804, d_k_M range: [0.0000, 0.1831], d_k_M_hat range: [0.3832, 0.9146]
2025-03-11 20:34:42 - Train Iteration 6143: loss: 0.2306, d_k_M range: [0.0026, 0.3467], d_k_M_hat range: [0.5272, 0.9869]
2025-03-11 20:34:43 - Train Iteration 6144: loss: 0.2483, d_k_M range: [0.0067, 0.4310], d_k_M_hat range: [0.5084, 0.9885]
2025-03-11 20:34:43 - Train Iteration 6145: loss: 0.2952, d_k_M range: [0.0005, 0.5018], d_k_M_hat range: [0.5896, 0.9936]
2025-03-11 20:34:44 - Train Iteration 6146: loss: 0.3148, d_k_M range: [0.0032, 0.4848], d_k_M_hat range: [0.4421, 0.9954]
2025-03-11 20:34:44 - Train Iteration 6147: loss: 0.3850, d_k_M range: [0.0659, 0.6167], d_k_M_hat range: [0.8192, 0.9963]
2025-03-11 20:34:45 - Train Iteration 6148: loss: 0.2001, d_k_M range: [0.0184, 0.2486], d_k_M_hat range: [0.5849, 0.9692]
2025-03-11 20:34:45 - Train Iteration 6149: loss: 0.2622, d_k_M range: [0.0001, 0.4932], d_k_M_hat range: [0.4880, 0.9878]
2025-03-11 20:34:46 - Train Iteration 6150: loss: 0.3830, d_k_M range: [0.0028, 0.6181], d_k_M_hat range: [0.5423, 0.9993]
2025-03-11 20:34:46 - Train Iteration 6151: loss: 0.2318, d_k_M range: [0.0040, 0.4562], d_k_M_hat range: [0.5257, 0.9955]
2025-03-11 20:34:46 - Train Iteration 6152: loss: 0.2318, d_k_M range: [0.0181, 0.4622], d_k_M_hat range: [0.7799, 0.9973]
2025-03-11 20:34:47 - Train Iteration 6153: loss: 0.2265, d_k_M range: [0.0005, 0.2534], d_k_M_hat range: [0.5246, 0.8969]
2025-03-11 20:34:47 - Train Iteration 6154: loss: 0.2312, d_k_M range: [0.0516, 0.4571], d_k_M_hat range: [0.8191, 0.9944]
2025-03-11 20:34:48 - Train Iteration 6155: loss: 0.3247, d_k_M range: [0.0018, 0.2352], d_k_M_hat range: [0.4320, 0.9527]
2025-03-11 20:34:48 - Train Iteration 6156: loss: 0.2757, d_k_M range: [0.0089, 0.5144], d_k_M_hat range: [0.6448, 0.9893]
2025-03-11 20:34:49 - Train Iteration 6157: loss: 0.2539, d_k_M range: [0.0214, 0.4800], d_k_M_hat range: [0.5796, 0.9761]
2025-03-11 20:34:49 - Train Iteration 6158: loss: 0.2802, d_k_M range: [0.1682, 0.5196], d_k_M_hat range: [0.8547, 0.9949]
2025-03-11 20:34:50 - Train Iteration 6159: loss: 0.2559, d_k_M range: [0.0147, 0.4919], d_k_M_hat range: [0.6408, 0.9860]
2025-03-11 20:34:50 - Train Iteration 6160: loss: 0.9189, d_k_M range: [0.0023, 0.9585], d_k_M_hat range: [0.6145, 0.9999]
2025-03-11 20:34:50 - Train Iteration 6161: loss: 0.2528, d_k_M range: [0.0012, 0.1479], d_k_M_hat range: [0.5061, 0.9477]
2025-03-11 20:34:51 - Train Iteration 6162: loss: 0.2656, d_k_M range: [0.0003, 0.4324], d_k_M_hat range: [0.4849, 0.9892]
2025-03-11 20:34:51 - Train Iteration 6163: loss: 0.2406, d_k_M range: [0.0065, 0.3188], d_k_M_hat range: [0.5231, 0.9700]
2025-03-11 20:34:52 - Train Iteration 6164: loss: 0.2783, d_k_M range: [0.0008, 0.4637], d_k_M_hat range: [0.5536, 0.9964]
2025-03-11 20:34:52 - Train Iteration 6165: loss: 0.3528, d_k_M range: [0.0081, 0.5908], d_k_M_hat range: [0.4477, 0.9968]
2025-03-11 20:34:53 - Train Iteration 6166: loss: 0.2345, d_k_M range: [0.0024, 0.4835], d_k_M_hat range: [0.5338, 0.9992]
2025-03-11 20:34:53 - Train Iteration 6167: loss: 0.2545, d_k_M range: [0.0088, 0.4412], d_k_M_hat range: [0.5043, 0.9944]
2025-03-11 20:34:53 - Train Iteration 6168: loss: 0.2209, d_k_M range: [0.0215, 0.4290], d_k_M_hat range: [0.6892, 0.9692]
2025-03-11 20:34:54 - Train Iteration 6169: loss: 0.3130, d_k_M range: [0.0006, 0.4722], d_k_M_hat range: [0.5828, 0.9687]
2025-03-11 20:34:54 - Train Iteration 6170: loss: 0.3191, d_k_M range: [0.0016, 0.5602], d_k_M_hat range: [0.5747, 0.9954]
2025-03-11 20:34:55 - Train Iteration 6171: loss: 0.3898, d_k_M range: [0.0004, 0.4822], d_k_M_hat range: [0.3760, 0.9683]
2025-03-11 20:34:55 - Train Iteration 6172: loss: 0.2689, d_k_M range: [0.0031, 0.5154], d_k_M_hat range: [0.5716, 0.9969]
2025-03-11 20:34:56 - Train Iteration 6173: loss: 0.1631, d_k_M range: [0.0053, 0.3695], d_k_M_hat range: [0.6057, 0.9677]
2025-03-11 20:34:56 - Train Iteration 6174: loss: 0.1725, d_k_M range: [0.0121, 0.3931], d_k_M_hat range: [0.6202, 0.9797]
2025-03-11 20:34:57 - Train Iteration 6175: loss: 0.2993, d_k_M range: [0.0005, 0.3360], d_k_M_hat range: [0.4534, 0.9442]
2025-03-11 20:34:57 - Train Iteration 6176: loss: 0.2421, d_k_M range: [0.0006, 0.0881], d_k_M_hat range: [0.5086, 0.8629]
2025-03-11 20:34:58 - Train Iteration 6177: loss: 0.5089, d_k_M range: [0.3131, 0.7130], d_k_M_hat range: [0.9537, 0.9998]
2025-03-11 20:34:58 - Train Iteration 6178: loss: 0.2081, d_k_M range: [0.0061, 0.0515], d_k_M_hat range: [0.5500, 0.8311]
2025-03-11 20:34:59 - Train Iteration 6179: loss: 0.3813, d_k_M range: [0.0036, 0.6125], d_k_M_hat range: [0.5895, 0.9950]
2025-03-11 20:34:59 - Train Iteration 6180: loss: 0.2557, d_k_M range: [0.0024, 0.4600], d_k_M_hat range: [0.5442, 0.9852]
2025-03-11 20:34:59 - Train Iteration 6181: loss: 0.2084, d_k_M range: [0.0197, 0.4522], d_k_M_hat range: [0.5788, 0.9957]
2025-03-11 20:35:00 - Train Iteration 6182: loss: 0.2038, d_k_M range: [0.0006, 0.4492], d_k_M_hat range: [0.5911, 0.9977]
2025-03-11 20:35:00 - Train Iteration 6183: loss: 0.2793, d_k_M range: [0.0008, 0.1560], d_k_M_hat range: [0.4723, 0.8918]
2025-03-11 20:35:01 - Train Iteration 6184: loss: 0.2485, d_k_M range: [0.0008, 0.4955], d_k_M_hat range: [0.5433, 0.9970]
2025-03-11 20:35:01 - Train Iteration 6185: loss: 0.2322, d_k_M range: [0.0011, 0.3008], d_k_M_hat range: [0.5192, 0.9385]
2025-03-11 20:35:02 - Train Iteration 6186: loss: 0.2322, d_k_M range: [0.0179, 0.4316], d_k_M_hat range: [0.6223, 0.9903]
2025-03-11 20:35:02 - Train Iteration 6187: loss: 0.3363, d_k_M range: [0.0117, 0.5796], d_k_M_hat range: [0.7687, 0.9996]
2025-03-11 20:35:03 - Train Iteration 6188: loss: 0.2441, d_k_M range: [0.0064, 0.4333], d_k_M_hat range: [0.5132, 0.9768]
2025-03-11 20:35:03 - Train Iteration 6189: loss: 0.2030, d_k_M range: [0.0044, 0.4466], d_k_M_hat range: [0.5837, 0.9960]
2025-03-11 20:35:04 - Train Iteration 6190: loss: 0.3107, d_k_M range: [0.0003, 0.4480], d_k_M_hat range: [0.4429, 0.9838]
2025-03-11 20:35:04 - Train Iteration 6191: loss: 0.3167, d_k_M range: [0.0009, 0.4921], d_k_M_hat range: [0.4382, 0.9894]
2025-03-11 20:35:04 - Train Iteration 6192: loss: 0.5639, d_k_M range: [0.0938, 0.7508], d_k_M_hat range: [0.7292, 0.9998]
2025-03-11 20:35:05 - Train Iteration 6193: loss: 0.3112, d_k_M range: [0.0004, 0.1901], d_k_M_hat range: [0.4455, 0.9221]
2025-03-11 20:35:05 - Train Iteration 6194: loss: 0.2033, d_k_M range: [0.0008, 0.3540], d_k_M_hat range: [0.5500, 0.9406]
2025-03-11 20:35:06 - Train Iteration 6195: loss: 0.1810, d_k_M range: [0.0021, 0.3366], d_k_M_hat range: [0.6201, 0.9218]
2025-03-11 20:35:06 - Train Iteration 6196: loss: 0.1781, d_k_M range: [0.0018, 0.3291], d_k_M_hat range: [0.5797, 0.9749]
2025-03-11 20:35:07 - Train Iteration 6197: loss: 0.3558, d_k_M range: [0.0001, 0.3988], d_k_M_hat range: [0.4150, 0.9884]
2025-03-11 20:35:07 - Train Iteration 6198: loss: 0.2059, d_k_M range: [0.0034, 0.2275], d_k_M_hat range: [0.5575, 0.9362]
2025-03-11 20:35:08 - Train Iteration 6199: loss: 0.1801, d_k_M range: [0.0069, 0.4155], d_k_M_hat range: [0.6543, 0.9911]
2025-03-11 20:35:08 - Train Iteration 6200: loss: 0.2093, d_k_M range: [0.0009, 0.4315], d_k_M_hat range: [0.5450, 0.9763]
2025-03-11 20:35:09 - Train Iteration 6201: loss: 0.4136, d_k_M range: [0.0006, 0.4096], d_k_M_hat range: [0.3574, 0.9902]
2025-03-11 20:35:09 - Train Iteration 6202: loss: 0.4509, d_k_M range: [0.0000, 0.1753], d_k_M_hat range: [0.3285, 0.9736]
2025-03-11 20:35:09 - Train Iteration 6203: loss: 0.3370, d_k_M range: [0.0216, 0.5773], d_k_M_hat range: [0.7079, 0.9980]
2025-03-11 20:35:10 - Train Iteration 6204: loss: 0.2489, d_k_M range: [0.0008, 0.4914], d_k_M_hat range: [0.6077, 0.9938]
2025-03-11 20:35:10 - Train Iteration 6205: loss: 0.2657, d_k_M range: [0.0004, 0.5128], d_k_M_hat range: [0.5001, 0.9973]
2025-03-11 20:35:11 - Train Iteration 6206: loss: 0.3164, d_k_M range: [0.0009, 0.5624], d_k_M_hat range: [0.4823, 0.9999]
2025-03-11 20:35:11 - Train Iteration 6207: loss: 0.2927, d_k_M range: [0.0000, 0.3167], d_k_M_hat range: [0.4590, 0.9835]
2025-03-11 20:35:12 - Train Iteration 6208: loss: 0.1960, d_k_M range: [0.0024, 0.4178], d_k_M_hat range: [0.5597, 0.9937]
2025-03-11 20:35:12 - Train Iteration 6209: loss: 0.2123, d_k_M range: [0.0211, 0.4539], d_k_M_hat range: [0.7717, 0.9932]
2025-03-11 20:35:12 - Train Iteration 6210: loss: 0.2350, d_k_M range: [0.0014, 0.3712], d_k_M_hat range: [0.5166, 0.9963]
2025-03-11 20:35:13 - Train Iteration 6211: loss: 0.2039, d_k_M range: [0.0432, 0.4139], d_k_M_hat range: [0.7980, 0.9753]
2025-03-11 20:35:13 - Train Iteration 6212: loss: 0.2215, d_k_M range: [0.0001, 0.3875], d_k_M_hat range: [0.5307, 0.9986]
2025-03-11 20:35:14 - Train Iteration 6213: loss: 0.2649, d_k_M range: [0.0812, 0.5141], d_k_M_hat range: [0.7209, 0.9994]
2025-03-11 20:35:14 - Train Iteration 6214: loss: 0.2222, d_k_M range: [0.0047, 0.4529], d_k_M_hat range: [0.5554, 0.9921]
2025-03-11 20:35:15 - Train Iteration 6215: loss: 0.2632, d_k_M range: [0.0350, 0.5060], d_k_M_hat range: [0.8214, 0.9930]
2025-03-11 20:35:15 - Train Iteration 6216: loss: 0.3584, d_k_M range: [0.0025, 0.3888], d_k_M_hat range: [0.4089, 0.9688]
2025-03-11 20:35:16 - Train Iteration 6217: loss: 0.4335, d_k_M range: [0.0038, 0.6577], d_k_M_hat range: [0.5673, 0.9993]
2025-03-11 20:35:16 - Train Iteration 6218: loss: 0.2524, d_k_M range: [0.0023, 0.3098], d_k_M_hat range: [0.4999, 0.9457]
2025-03-11 20:35:17 - Train Iteration 6219: loss: 0.3300, d_k_M range: [0.0645, 0.5739], d_k_M_hat range: [0.7346, 0.9994]
2025-03-11 20:35:17 - Train Iteration 6220: loss: 0.2379, d_k_M range: [0.0011, 0.1746], d_k_M_hat range: [0.5209, 0.9198]
2025-03-11 20:35:17 - Train Iteration 6221: loss: 0.3616, d_k_M range: [0.0062, 0.6005], d_k_M_hat range: [0.5920, 0.9991]
2025-03-11 20:35:18 - Train Iteration 6222: loss: 0.3130, d_k_M range: [0.0002, 0.2387], d_k_M_hat range: [0.4407, 0.9372]
2025-03-11 20:35:18 - Train Iteration 6223: loss: 0.3021, d_k_M range: [0.0090, 0.5489], d_k_M_hat range: [0.5151, 0.9993]
2025-03-11 20:35:19 - Train Iteration 6224: loss: 0.3840, d_k_M range: [0.0142, 0.3457], d_k_M_hat range: [0.5818, 0.9609]
2025-03-11 20:35:19 - Train Iteration 6225: loss: 0.3585, d_k_M range: [0.0002, 0.2508], d_k_M_hat range: [0.4014, 0.9446]
2025-03-11 20:35:20 - Train Iteration 6226: loss: 0.1766, d_k_M range: [0.0123, 0.4024], d_k_M_hat range: [0.8490, 0.9967]
2025-03-11 20:35:20 - Train Iteration 6227: loss: 0.4840, d_k_M range: [0.0044, 0.6931], d_k_M_hat range: [0.6422, 0.9974]
2025-03-11 20:35:20 - Train Iteration 6228: loss: 0.1877, d_k_M range: [0.0041, 0.4157], d_k_M_hat range: [0.6247, 0.9824]
2025-03-11 20:35:21 - Train Iteration 6229: loss: 0.2450, d_k_M range: [0.0180, 0.4435], d_k_M_hat range: [0.7552, 0.9978]
2025-03-11 20:35:21 - Train Iteration 6230: loss: 0.2156, d_k_M range: [0.0034, 0.2323], d_k_M_hat range: [0.5390, 0.9096]
2025-03-11 20:35:22 - Train Iteration 6231: loss: 0.3433, d_k_M range: [0.0006, 0.5214], d_k_M_hat range: [0.4147, 0.9976]
2025-03-11 20:35:22 - Train Iteration 6232: loss: 0.2303, d_k_M range: [0.0019, 0.4766], d_k_M_hat range: [0.6810, 0.9967]
2025-03-11 20:35:23 - Train Iteration 6233: loss: 0.2373, d_k_M range: [0.0014, 0.4687], d_k_M_hat range: [0.5223, 0.9949]
2025-03-11 20:35:23 - Train Iteration 6234: loss: 0.3150, d_k_M range: [0.0167, 0.5603], d_k_M_hat range: [0.7302, 0.9990]
2025-03-11 20:35:24 - Train Iteration 6235: loss: 0.3215, d_k_M range: [0.0254, 0.5554], d_k_M_hat range: [0.8330, 0.9918]
2025-03-11 20:35:24 - Train Iteration 6236: loss: 0.2759, d_k_M range: [0.0001, 0.4492], d_k_M_hat range: [0.4748, 0.9884]
2025-03-11 20:35:24 - Train Iteration 6237: loss: 0.2734, d_k_M range: [0.0003, 0.4640], d_k_M_hat range: [0.5006, 0.9950]
2025-03-11 20:35:25 - Train Iteration 6238: loss: 0.1097, d_k_M range: [0.0073, 0.2284], d_k_M_hat range: [0.6953, 0.9879]
2025-03-11 20:35:25 - Train Iteration 6239: loss: 0.3430, d_k_M range: [0.0026, 0.5840], d_k_M_hat range: [0.6532, 0.9994]
2025-03-11 20:35:26 - Train Iteration 6240: loss: 0.4246, d_k_M range: [0.0004, 0.2681], d_k_M_hat range: [0.3488, 0.9855]
2025-03-11 20:35:26 - Train Iteration 6241: loss: 0.5891, d_k_M range: [0.2481, 0.7674], d_k_M_hat range: [0.9308, 0.9999]
2025-03-11 20:35:27 - Train Iteration 6242: loss: 0.3194, d_k_M range: [0.0010, 0.3836], d_k_M_hat range: [0.4819, 0.9933]
2025-03-11 20:35:27 - Train Iteration 6243: loss: 0.1364, d_k_M range: [0.0033, 0.3567], d_k_M_hat range: [0.7160, 0.9874]
2025-03-11 20:35:27 - Train Iteration 6244: loss: 0.3846, d_k_M range: [0.0000, 0.4554], d_k_M_hat range: [0.3798, 0.9986]
2025-03-11 20:35:28 - Train Iteration 6245: loss: 0.2131, d_k_M range: [0.0002, 0.4606], d_k_M_hat range: [0.5477, 0.9989]
2025-03-11 20:35:28 - Train Iteration 6246: loss: 0.2192, d_k_M range: [0.0008, 0.4095], d_k_M_hat range: [0.5766, 0.9414]
2025-03-11 20:35:29 - Train Iteration 6247: loss: 0.2494, d_k_M range: [0.0003, 0.4444], d_k_M_hat range: [0.5010, 0.9910]
2025-03-11 20:35:29 - Train Iteration 6248: loss: 0.2512, d_k_M range: [0.1156, 0.4963], d_k_M_hat range: [0.9031, 0.9979]
2025-03-11 20:35:30 - Train Iteration 6249: loss: 0.6215, d_k_M range: [0.0002, 0.3592], d_k_M_hat range: [0.2127, 0.9746]
2025-03-11 20:35:30 - Train Iteration 6250: loss: 0.2557, d_k_M range: [0.0051, 0.4970], d_k_M_hat range: [0.6093, 0.9913]
2025-03-11 20:35:30 - Train Iteration 6251: loss: 0.3644, d_k_M range: [0.0021, 0.6011], d_k_M_hat range: [0.5747, 0.9974]
2025-03-11 20:35:31 - Train Iteration 6252: loss: 0.2481, d_k_M range: [0.0001, 0.3891], d_k_M_hat range: [0.5320, 0.9926]
2025-03-11 20:35:31 - Train Iteration 6253: loss: 0.2476, d_k_M range: [0.0018, 0.4540], d_k_M_hat range: [0.6788, 0.9934]
2025-03-11 20:35:32 - Train Iteration 6254: loss: 0.3282, d_k_M range: [0.0008, 0.0629], d_k_M_hat range: [0.4280, 0.8995]
2025-03-11 20:35:32 - Train Iteration 6255: loss: 0.2408, d_k_M range: [0.0011, 0.4896], d_k_M_hat range: [0.5749, 0.9988]
2025-03-11 20:35:32 - Train Iteration 6256: loss: 0.2590, d_k_M range: [0.0003, 0.3701], d_k_M_hat range: [0.4916, 0.9907]
2025-03-11 20:35:33 - Train Iteration 6257: loss: 0.3087, d_k_M range: [0.0001, 0.0690], d_k_M_hat range: [0.4445, 0.9840]
2025-03-11 20:35:33 - Train Iteration 6258: loss: 0.3292, d_k_M range: [0.0954, 0.5722], d_k_M_hat range: [0.8245, 0.9998]
2025-03-11 20:35:34 - Train Iteration 6259: loss: 0.2178, d_k_M range: [0.0008, 0.3790], d_k_M_hat range: [0.5460, 0.9825]
2025-03-11 20:35:34 - Train Iteration 6260: loss: 0.2275, d_k_M range: [0.0096, 0.4640], d_k_M_hat range: [0.7092, 0.9902]
2025-03-11 20:35:35 - Train Iteration 6261: loss: 0.3487, d_k_M range: [0.0005, 0.3923], d_k_M_hat range: [0.4335, 0.9775]
2025-03-11 20:35:35 - Train Iteration 6262: loss: 0.2052, d_k_M range: [0.0079, 0.3761], d_k_M_hat range: [0.5549, 0.9880]
2025-03-11 20:35:35 - Train Iteration 6263: loss: 0.3702, d_k_M range: [0.0004, 0.4291], d_k_M_hat range: [0.3919, 0.9993]
2025-03-11 20:35:36 - Train Iteration 6264: loss: 0.3360, d_k_M range: [0.0246, 0.5730], d_k_M_hat range: [0.8008, 0.9955]
2025-03-11 20:35:36 - Train Iteration 6265: loss: 0.2384, d_k_M range: [0.0011, 0.3104], d_k_M_hat range: [0.5129, 0.9605]
2025-03-11 20:35:37 - Train Iteration 6266: loss: 0.2418, d_k_M range: [0.0062, 0.4043], d_k_M_hat range: [0.5144, 0.9252]
2025-03-11 20:35:37 - Train Iteration 6267: loss: 0.2048, d_k_M range: [0.0039, 0.4192], d_k_M_hat range: [0.6980, 0.9710]
2025-03-11 20:35:38 - Train Iteration 6268: loss: 0.3191, d_k_M range: [0.0129, 0.5563], d_k_M_hat range: [0.6606, 0.9922]
2025-03-11 20:35:38 - Train Iteration 6269: loss: 0.1451, d_k_M range: [0.0096, 0.3593], d_k_M_hat range: [0.6353, 0.9784]
2025-03-11 20:35:39 - Train Iteration 6270: loss: 0.4204, d_k_M range: [0.0011, 0.4592], d_k_M_hat range: [0.3527, 0.9681]
2025-03-11 20:35:39 - Train Iteration 6271: loss: 0.1195, d_k_M range: [0.0092, 0.3396], d_k_M_hat range: [0.7460, 0.9939]
2025-03-11 20:35:39 - Train Iteration 6272: loss: 0.2402, d_k_M range: [0.0025, 0.0849], d_k_M_hat range: [0.5124, 0.8734]
2025-03-11 20:35:40 - Train Iteration 6273: loss: 0.2742, d_k_M range: [0.0098, 0.5181], d_k_M_hat range: [0.8566, 0.9982]
2025-03-11 20:35:40 - Train Iteration 6274: loss: 0.3341, d_k_M range: [0.0027, 0.5739], d_k_M_hat range: [0.5562, 0.9959]
2025-03-11 20:35:41 - Train Iteration 6275: loss: 0.2195, d_k_M range: [0.0150, 0.4492], d_k_M_hat range: [0.7220, 0.9947]
2025-03-11 20:35:41 - Train Iteration 6276: loss: 0.2629, d_k_M range: [0.0014, 0.3576], d_k_M_hat range: [0.4893, 0.9775]
2025-03-11 20:35:42 - Train Iteration 6277: loss: 0.6344, d_k_M range: [0.0145, 0.7946], d_k_M_hat range: [0.7772, 0.9981]
2025-03-11 20:35:42 - Train Iteration 6278: loss: 0.4177, d_k_M range: [0.0001, 0.3395], d_k_M_hat range: [0.3539, 0.8522]
2025-03-11 20:35:42 - Train Iteration 6279: loss: 0.2912, d_k_M range: [0.0025, 0.4350], d_k_M_hat range: [0.4904, 0.9861]
2025-03-11 20:35:43 - Train Iteration 6280: loss: 0.2401, d_k_M range: [0.0323, 0.4883], d_k_M_hat range: [0.7174, 0.9983]
2025-03-11 20:35:43 - Train Iteration 6281: loss: 0.2396, d_k_M range: [0.0011, 0.4793], d_k_M_hat range: [0.5430, 0.9898]
2025-03-11 20:35:44 - Train Iteration 6282: loss: 0.2440, d_k_M range: [0.0010, 0.1749], d_k_M_hat range: [0.5071, 0.9599]
2025-03-11 20:35:44 - Train Iteration 6283: loss: 0.2741, d_k_M range: [0.0025, 0.5229], d_k_M_hat range: [0.5925, 0.9994]
2025-03-11 20:35:45 - Train Iteration 6284: loss: 0.3230, d_k_M range: [0.0171, 0.5633], d_k_M_hat range: [0.5566, 0.9950]
2025-03-11 20:35:45 - Train Iteration 6285: loss: 0.2559, d_k_M range: [0.0000, 0.4229], d_k_M_hat range: [0.4942, 0.9801]
2025-03-11 20:35:45 - Train Iteration 6286: loss: 0.2536, d_k_M range: [0.0017, 0.2616], d_k_M_hat range: [0.4982, 0.9279]
2025-03-11 20:35:46 - Train Iteration 6287: loss: 0.3031, d_k_M range: [0.0130, 0.5459], d_k_M_hat range: [0.5980, 0.9992]
2025-03-11 20:35:46 - Train Iteration 6288: loss: 0.1433, d_k_M range: [0.0162, 0.3568], d_k_M_hat range: [0.6555, 0.9813]
2025-03-11 20:35:47 - Train Iteration 6289: loss: 0.2429, d_k_M range: [0.0035, 0.4573], d_k_M_hat range: [0.5107, 0.9868]
2025-03-11 20:35:47 - Train Iteration 6290: loss: 0.2575, d_k_M range: [0.0605, 0.4687], d_k_M_hat range: [0.9059, 0.9938]
2025-03-11 20:35:47 - Train Iteration 6291: loss: 0.2245, d_k_M range: [0.0005, 0.1187], d_k_M_hat range: [0.5267, 0.9297]
2025-03-11 20:35:48 - Train Iteration 6292: loss: 0.2395, d_k_M range: [0.0025, 0.4667], d_k_M_hat range: [0.7095, 0.9773]
2025-03-11 20:35:48 - Train Iteration 6293: loss: 0.2112, d_k_M range: [0.0017, 0.4161], d_k_M_hat range: [0.5466, 0.9783]
2025-03-11 20:35:49 - Train Iteration 6294: loss: 0.2938, d_k_M range: [0.0213, 0.5285], d_k_M_hat range: [0.7064, 0.9966]
2025-03-11 20:35:49 - Train Iteration 6295: loss: 0.1968, d_k_M range: [0.0049, 0.4429], d_k_M_hat range: [0.5768, 0.9993]
2025-03-11 20:35:50 - Train Iteration 6296: loss: 0.2308, d_k_M range: [0.0001, 0.4573], d_k_M_hat range: [0.5207, 0.9934]
2025-03-11 20:35:50 - Train Iteration 6297: loss: 0.3357, d_k_M range: [0.0018, 0.4798], d_k_M_hat range: [0.4257, 0.9822]
2025-03-11 20:35:50 - Train Iteration 6298: loss: 0.1669, d_k_M range: [0.0176, 0.3907], d_k_M_hat range: [0.7740, 0.9984]
2025-03-11 20:35:51 - Train Iteration 6299: loss: 0.2442, d_k_M range: [0.0007, 0.4854], d_k_M_hat range: [0.5066, 0.9936]
2025-03-11 20:35:51 - Train Iteration 6300: loss: 0.2200, d_k_M range: [0.0027, 0.4634], d_k_M_hat range: [0.6358, 0.9944]
2025-03-11 20:35:52 - Train Iteration 6301: loss: 0.2587, d_k_M range: [0.0087, 0.2508], d_k_M_hat range: [0.5000, 0.8670]
2025-03-11 20:35:52 - Train Iteration 6302: loss: 0.2292, d_k_M range: [0.0064, 0.3767], d_k_M_hat range: [0.6353, 0.9621]
2025-03-11 20:35:53 - Train Iteration 6303: loss: 0.3222, d_k_M range: [0.0005, 0.4979], d_k_M_hat range: [0.4329, 0.9979]
2025-03-11 20:35:53 - Train Iteration 6304: loss: 0.1895, d_k_M range: [0.0052, 0.3709], d_k_M_hat range: [0.6297, 0.9851]
2025-03-11 20:35:53 - Train Iteration 6305: loss: 0.2255, d_k_M range: [0.0192, 0.4622], d_k_M_hat range: [0.7233, 0.9880]
2025-03-11 20:35:54 - Train Iteration 6306: loss: 0.1695, d_k_M range: [0.0117, 0.4067], d_k_M_hat range: [0.8931, 0.9950]
2025-03-11 20:35:54 - Train Iteration 6307: loss: 0.3754, d_k_M range: [0.0004, 0.2844], d_k_M_hat range: [0.3877, 0.9765]
2025-03-11 20:35:55 - Train Iteration 6308: loss: 0.6473, d_k_M range: [0.0518, 0.8043], d_k_M_hat range: [0.9021, 0.9997]
2025-03-11 20:35:55 - Train Iteration 6309: loss: 0.2089, d_k_M range: [0.0023, 0.4351], d_k_M_hat range: [0.6474, 0.9974]
2025-03-11 20:35:55 - Train Iteration 6310: loss: 0.2813, d_k_M range: [0.0002, 0.3635], d_k_M_hat range: [0.4706, 0.9125]
2025-03-11 20:35:56 - Train Iteration 6311: loss: 0.2846, d_k_M range: [0.0010, 0.5298], d_k_M_hat range: [0.5379, 0.9963]
2025-03-11 20:35:56 - Train Iteration 6312: loss: 0.3145, d_k_M range: [0.0001, 0.2752], d_k_M_hat range: [0.4392, 0.9662]
2025-03-11 20:35:57 - Train Iteration 6313: loss: 0.5017, d_k_M range: [0.0008, 0.3790], d_k_M_hat range: [0.3001, 0.9854]
2025-03-11 20:35:57 - Train Iteration 6314: loss: 0.1695, d_k_M range: [0.0129, 0.3973], d_k_M_hat range: [0.8872, 0.9856]
2025-03-11 20:35:58 - Train Iteration 6315: loss: 0.3017, d_k_M range: [0.0009, 0.2150], d_k_M_hat range: [0.4518, 0.8867]
2025-03-11 20:35:58 - Train Iteration 6316: loss: 0.2378, d_k_M range: [0.0108, 0.2718], d_k_M_hat range: [0.5413, 0.9401]
2025-03-11 20:35:58 - Train Iteration 6317: loss: 0.2651, d_k_M range: [0.0152, 0.5115], d_k_M_hat range: [0.8189, 0.9988]
2025-03-11 20:35:59 - Train Iteration 6318: loss: 0.4694, d_k_M range: [0.0020, 0.1963], d_k_M_hat range: [0.3169, 0.9290]
2025-03-11 20:35:59 - Train Iteration 6319: loss: 0.3078, d_k_M range: [0.0001, 0.4786], d_k_M_hat range: [0.4615, 0.9238]
2025-03-11 20:36:00 - Train Iteration 6320: loss: 0.3551, d_k_M range: [0.0002, 0.2287], d_k_M_hat range: [0.4042, 0.9228]
2025-03-11 20:36:00 - Train Iteration 6321: loss: 0.2018, d_k_M range: [0.0228, 0.4472], d_k_M_hat range: [0.7423, 0.9980]
2025-03-11 20:36:01 - Train Iteration 6322: loss: 0.3424, d_k_M range: [0.0348, 0.4370], d_k_M_hat range: [0.4519, 0.9804]
2025-03-11 20:36:01 - Train Iteration 6323: loss: 0.2726, d_k_M range: [0.0007, 0.2210], d_k_M_hat range: [0.4786, 0.9561]
2025-03-11 20:36:01 - Train Iteration 6324: loss: 0.7680, d_k_M range: [0.0048, 0.8759], d_k_M_hat range: [0.6878, 0.9996]
2025-03-11 20:36:02 - Train Iteration 6325: loss: 0.3475, d_k_M range: [0.0103, 0.5689], d_k_M_hat range: [0.5101, 0.9794]
2025-03-11 20:36:02 - Train Iteration 6326: loss: 0.3542, d_k_M range: [0.0035, 0.5831], d_k_M_hat range: [0.6086, 0.9883]
2025-03-11 20:36:03 - Train Iteration 6327: loss: 0.2992, d_k_M range: [0.0104, 0.4612], d_k_M_hat range: [0.6216, 0.9882]
2025-03-11 20:36:03 - Train Iteration 6328: loss: 0.2131, d_k_M range: [0.0155, 0.4356], d_k_M_hat range: [0.6530, 0.9867]
2025-03-11 20:36:04 - Train Iteration 6329: loss: 0.2363, d_k_M range: [0.0118, 0.4688], d_k_M_hat range: [0.6861, 0.9950]
2025-03-11 20:36:04 - Train Iteration 6330: loss: 0.4423, d_k_M range: [0.0037, 0.6625], d_k_M_hat range: [0.5318, 0.9974]
2025-03-11 20:36:05 - Train Iteration 6331: loss: 0.3105, d_k_M range: [0.0015, 0.5222], d_k_M_hat range: [0.4442, 0.9964]
2025-03-11 20:36:05 - Train Iteration 6332: loss: 0.2503, d_k_M range: [0.0013, 0.4839], d_k_M_hat range: [0.6407, 0.9940]
2025-03-11 20:36:05 - Train Iteration 6333: loss: 0.3475, d_k_M range: [0.0004, 0.1984], d_k_M_hat range: [0.4109, 0.9226]
2025-03-11 20:36:06 - Train Iteration 6334: loss: 0.2829, d_k_M range: [0.0174, 0.5286], d_k_M_hat range: [0.6999, 0.9967]
2025-03-11 20:36:06 - Train Iteration 6335: loss: 0.3392, d_k_M range: [0.0004, 0.5741], d_k_M_hat range: [0.4550, 0.9917]
2025-03-11 20:36:07 - Train Iteration 6336: loss: 0.2721, d_k_M range: [0.0001, 0.2158], d_k_M_hat range: [0.4790, 0.9458]
2025-03-11 20:36:07 - Train Iteration 6337: loss: 0.1800, d_k_M range: [0.0030, 0.4172], d_k_M_hat range: [0.6320, 0.9930]
2025-03-11 20:36:08 - Train Iteration 6338: loss: 0.2671, d_k_M range: [0.0050, 0.4603], d_k_M_hat range: [0.5498, 0.9871]
2025-03-11 20:36:08 - Train Iteration 6339: loss: 0.1989, d_k_M range: [0.0059, 0.4370], d_k_M_hat range: [0.6579, 0.9916]
2025-03-11 20:36:08 - Train Iteration 6340: loss: 0.7787, d_k_M range: [0.0007, 0.8294], d_k_M_hat range: [0.1183, 1.0000]
2025-03-11 20:36:09 - Train Iteration 6341: loss: 0.2089, d_k_M range: [0.0009, 0.3655], d_k_M_hat range: [0.5439, 0.9909]
2025-03-11 20:36:09 - Train Iteration 6342: loss: 0.3331, d_k_M range: [0.0001, 0.5205], d_k_M_hat range: [0.4230, 0.9971]
2025-03-11 20:36:10 - Train Iteration 6343: loss: 0.3519, d_k_M range: [0.0100, 0.5891], d_k_M_hat range: [0.7266, 0.9959]
2025-03-11 20:36:10 - Train Iteration 6344: loss: 0.3985, d_k_M range: [0.0001, 0.3776], d_k_M_hat range: [0.3689, 0.9616]
2025-03-11 20:36:11 - Train Iteration 6345: loss: 0.2280, d_k_M range: [0.0087, 0.4508], d_k_M_hat range: [0.5924, 0.9733]
2025-03-11 20:36:11 - Train Iteration 6346: loss: 0.2188, d_k_M range: [0.0035, 0.4655], d_k_M_hat range: [0.6028, 0.9977]
2025-03-11 20:36:11 - Train Iteration 6347: loss: 0.4376, d_k_M range: [0.0031, 0.0589], d_k_M_hat range: [0.3416, 0.8259]
2025-03-11 20:36:12 - Train Iteration 6348: loss: 0.1480, d_k_M range: [0.0037, 0.3572], d_k_M_hat range: [0.6396, 0.9848]
2025-03-11 20:36:12 - Train Iteration 6349: loss: 0.2548, d_k_M range: [0.0019, 0.3934], d_k_M_hat range: [0.4983, 0.9878]
2025-03-11 20:36:13 - Train Iteration 6350: loss: 0.2226, d_k_M range: [0.0001, 0.3962], d_k_M_hat range: [0.5290, 0.9908]
2025-03-11 20:36:13 - Train Iteration 6351: loss: 0.2745, d_k_M range: [0.0024, 0.0452], d_k_M_hat range: [0.4784, 0.7913]
2025-03-11 20:36:14 - Train Iteration 6352: loss: 0.4259, d_k_M range: [0.0809, 0.6497], d_k_M_hat range: [0.8247, 0.9976]
2025-03-11 20:36:14 - Train Iteration 6353: loss: 0.2249, d_k_M range: [0.0010, 0.3185], d_k_M_hat range: [0.5274, 0.9491]
2025-03-11 20:36:14 - Train Iteration 6354: loss: 0.1779, d_k_M range: [0.0018, 0.3887], d_k_M_hat range: [0.5914, 0.9816]
2025-03-11 20:36:15 - Train Iteration 6355: loss: 0.3947, d_k_M range: [0.0324, 0.6264], d_k_M_hat range: [0.6684, 0.9981]
2025-03-11 20:36:15 - Train Iteration 6356: loss: 0.2557, d_k_M range: [0.0050, 0.4376], d_k_M_hat range: [0.5005, 0.9839]
2025-03-11 20:36:16 - Train Iteration 6357: loss: 0.3644, d_k_M range: [0.0215, 0.5808], d_k_M_hat range: [0.8840, 0.9954]
2025-03-11 20:36:16 - Train Iteration 6358: loss: 0.3269, d_k_M range: [0.0032, 0.4347], d_k_M_hat range: [0.4314, 0.9953]
2025-03-11 20:36:17 - Train Iteration 6359: loss: 0.2047, d_k_M range: [0.0160, 0.4323], d_k_M_hat range: [0.6551, 0.9927]
2025-03-11 20:36:17 - Train Iteration 6360: loss: 0.2631, d_k_M range: [0.0001, 0.4107], d_k_M_hat range: [0.4871, 0.9801]
2025-03-11 20:36:17 - Train Iteration 6361: loss: 0.2305, d_k_M range: [0.0620, 0.4702], d_k_M_hat range: [0.7582, 0.9901]
2025-03-11 20:36:18 - Train Iteration 6362: loss: 0.2886, d_k_M range: [0.0045, 0.5365], d_k_M_hat range: [0.5360, 0.9992]
2025-03-11 20:36:18 - Train Iteration 6363: loss: 0.2616, d_k_M range: [0.0026, 0.4853], d_k_M_hat range: [0.5713, 0.9966]
2025-03-11 20:36:19 - Train Iteration 6364: loss: 0.3024, d_k_M range: [0.0009, 0.2212], d_k_M_hat range: [0.4510, 0.9353]
2025-03-11 20:36:19 - Train Iteration 6365: loss: 0.1828, d_k_M range: [0.0293, 0.4067], d_k_M_hat range: [0.7609, 0.9897]
2025-03-11 20:36:20 - Train Iteration 6366: loss: 0.1608, d_k_M range: [0.0080, 0.1676], d_k_M_hat range: [0.6654, 0.9016]
2025-03-11 20:36:20 - Train Iteration 6367: loss: 0.2490, d_k_M range: [0.0199, 0.4901], d_k_M_hat range: [0.5893, 0.9924]
2025-03-11 20:36:20 - Train Iteration 6368: loss: 0.1791, d_k_M range: [0.0005, 0.1875], d_k_M_hat range: [0.5792, 0.9479]
2025-03-11 20:36:21 - Train Iteration 6369: loss: 0.3376, d_k_M range: [0.0090, 0.5792], d_k_M_hat range: [0.5795, 0.9982]
2025-03-11 20:36:21 - Train Iteration 6370: loss: 0.2155, d_k_M range: [0.0002, 0.1838], d_k_M_hat range: [0.5360, 0.9789]
2025-03-11 20:36:22 - Train Iteration 6371: loss: 0.6150, d_k_M range: [0.0070, 0.7755], d_k_M_hat range: [0.6703, 0.9955]
2025-03-11 20:36:22 - Train Iteration 6372: loss: 0.3048, d_k_M range: [0.0002, 0.2124], d_k_M_hat range: [0.4480, 0.8836]
2025-03-11 20:36:23 - Train Iteration 6373: loss: 0.1434, d_k_M range: [0.0037, 0.3210], d_k_M_hat range: [0.6333, 0.9423]
2025-03-11 20:36:23 - Train Iteration 6374: loss: 0.4811, d_k_M range: [0.0002, 0.0779], d_k_M_hat range: [0.3066, 0.8740]
2025-03-11 20:36:23 - Train Iteration 6375: loss: 0.2416, d_k_M range: [0.0143, 0.4751], d_k_M_hat range: [0.7696, 0.9972]
2025-03-11 20:36:24 - Train Iteration 6376: loss: 0.1750, d_k_M range: [0.0003, 0.2202], d_k_M_hat range: [0.5823, 0.9569]
2025-03-11 20:36:24 - Train Iteration 6377: loss: 0.2613, d_k_M range: [0.0060, 0.3090], d_k_M_hat range: [0.5694, 0.9357]
2025-03-11 20:36:25 - Train Iteration 6378: loss: 0.2693, d_k_M range: [0.0013, 0.4508], d_k_M_hat range: [0.4823, 0.9794]
2025-03-11 20:36:25 - Train Iteration 6379: loss: 0.3993, d_k_M range: [0.0100, 0.6315], d_k_M_hat range: [0.6666, 0.9996]
2025-03-11 20:36:26 - Train Iteration 6380: loss: 0.4026, d_k_M range: [0.0005, 0.2133], d_k_M_hat range: [0.3676, 0.8746]
2025-03-11 20:36:26 - Train Iteration 6381: loss: 0.2123, d_k_M range: [0.0105, 0.4242], d_k_M_hat range: [0.5989, 0.9907]
2025-03-11 20:36:27 - Train Iteration 6382: loss: 0.2575, d_k_M range: [0.0008, 0.4646], d_k_M_hat range: [0.5091, 0.9832]
2025-03-11 20:36:27 - Train Iteration 6383: loss: 0.2995, d_k_M range: [0.0002, 0.3457], d_k_M_hat range: [0.4530, 0.9782]
2025-03-11 20:36:27 - Train Iteration 6384: loss: 0.3422, d_k_M range: [0.0021, 0.5809], d_k_M_hat range: [0.6513, 0.9959]
2025-03-11 20:36:28 - Train Iteration 6385: loss: 0.4102, d_k_M range: [0.0001, 0.4368], d_k_M_hat range: [0.3597, 0.9925]
2025-03-11 20:36:28 - Train Iteration 6386: loss: 0.2571, d_k_M range: [0.0001, 0.3332], d_k_M_hat range: [0.4930, 0.9909]
2025-03-11 20:36:29 - Train Iteration 6387: loss: 0.3045, d_k_M range: [0.0005, 0.5479], d_k_M_hat range: [0.5106, 0.9960]
2025-03-11 20:36:29 - Train Iteration 6388: loss: 0.2743, d_k_M range: [0.0040, 0.5197], d_k_M_hat range: [0.6261, 0.9959]
2025-03-11 20:36:30 - Train Iteration 6389: loss: 0.2701, d_k_M range: [0.0005, 0.2259], d_k_M_hat range: [0.4808, 0.9160]
2025-03-11 20:36:30 - Train Iteration 6390: loss: 0.2299, d_k_M range: [0.0009, 0.4325], d_k_M_hat range: [0.5214, 0.9848]
2025-03-11 20:36:31 - Train Iteration 6391: loss: 0.1782, d_k_M range: [0.0135, 0.4028], d_k_M_hat range: [0.7497, 0.9807]
2025-03-11 20:36:31 - Train Iteration 6392: loss: 0.2333, d_k_M range: [0.0005, 0.3885], d_k_M_hat range: [0.5178, 0.9724]
2025-03-11 20:36:32 - Train Iteration 6393: loss: 0.2178, d_k_M range: [0.0023, 0.4465], d_k_M_hat range: [0.5818, 0.9798]
2025-03-11 20:36:32 - Train Iteration 6394: loss: 0.4982, d_k_M range: [0.0000, 0.4776], d_k_M_hat range: [0.2942, 0.9873]
2025-03-11 20:36:32 - Train Iteration 6395: loss: 0.3044, d_k_M range: [0.0037, 0.5511], d_k_M_hat range: [0.6376, 0.9994]
2025-03-11 20:36:33 - Train Iteration 6396: loss: 0.1977, d_k_M range: [0.0001, 0.3474], d_k_M_hat range: [0.5633, 0.9815]
2025-03-11 20:36:33 - Train Iteration 6397: loss: 0.1743, d_k_M range: [0.0201, 0.3155], d_k_M_hat range: [0.6788, 0.9924]
2025-03-11 20:36:34 - Train Iteration 6398: loss: 0.2073, d_k_M range: [0.0006, 0.1723], d_k_M_hat range: [0.5503, 0.9405]
2025-03-11 20:36:34 - Train Iteration 6399: loss: 0.2766, d_k_M range: [0.0010, 0.5031], d_k_M_hat range: [0.5895, 0.9905]
2025-03-11 20:36:35 - Train Iteration 6400: loss: 0.2293, d_k_M range: [0.0006, 0.3301], d_k_M_hat range: [0.5427, 0.9865]
2025-03-11 20:36:35 - Train Iteration 6401: loss: 0.2042, d_k_M range: [0.0000, 0.4503], d_k_M_hat range: [0.6053, 0.9984]
2025-03-11 20:36:36 - Train Iteration 6402: loss: 0.2152, d_k_M range: [0.0003, 0.2608], d_k_M_hat range: [0.5369, 0.9774]
2025-03-11 20:36:36 - Train Iteration 6403: loss: 0.2623, d_k_M range: [0.0128, 0.5055], d_k_M_hat range: [0.7129, 0.9933]
2025-03-11 20:36:37 - Train Iteration 6404: loss: 0.2446, d_k_M range: [0.0003, 0.2658], d_k_M_hat range: [0.5095, 0.9444]
2025-03-11 20:36:37 - Train Iteration 6405: loss: 0.1991, d_k_M range: [0.0150, 0.4322], d_k_M_hat range: [0.7023, 0.9860]
2025-03-11 20:36:37 - Train Iteration 6406: loss: 0.2410, d_k_M range: [0.0002, 0.2617], d_k_M_hat range: [0.5093, 0.9489]
2025-03-11 20:36:38 - Train Iteration 6407: loss: 0.7191, d_k_M range: [0.1313, 0.8479], d_k_M_hat range: [0.9344, 0.9999]
2025-03-11 20:36:38 - Train Iteration 6408: loss: 0.2523, d_k_M range: [0.0010, 0.3802], d_k_M_hat range: [0.5018, 0.9718]
2025-03-11 20:36:39 - Train Iteration 6409: loss: 0.3272, d_k_M range: [0.0057, 0.5709], d_k_M_hat range: [0.5851, 0.9989]
2025-03-11 20:36:39 - Train Iteration 6410: loss: 0.1677, d_k_M range: [0.0078, 0.3833], d_k_M_hat range: [0.6186, 0.9737]
2025-03-11 20:36:40 - Train Iteration 6411: loss: 0.2844, d_k_M range: [0.0000, 0.0823], d_k_M_hat range: [0.4675, 0.7506]
2025-03-11 20:36:40 - Train Iteration 6412: loss: 0.3102, d_k_M range: [0.0003, 0.5541], d_k_M_hat range: [0.5592, 0.9971]
2025-03-11 20:36:40 - Train Iteration 6413: loss: 0.3837, d_k_M range: [0.0138, 0.6163], d_k_M_hat range: [0.6448, 0.9968]
2025-03-11 20:36:41 - Train Iteration 6414: loss: 0.3077, d_k_M range: [0.0266, 0.5242], d_k_M_hat range: [0.7432, 0.9695]
2025-03-11 20:36:41 - Train Iteration 6415: loss: 0.4440, d_k_M range: [0.0011, 0.4857], d_k_M_hat range: [0.3348, 0.9984]
2025-03-11 20:36:42 - Train Iteration 6416: loss: 0.2342, d_k_M range: [0.0213, 0.4772], d_k_M_hat range: [0.6555, 0.9970]
2025-03-11 20:36:42 - Train Iteration 6417: loss: 0.3760, d_k_M range: [0.0000, 0.1974], d_k_M_hat range: [0.3870, 0.9656]
2025-03-11 20:36:43 - Train Iteration 6418: loss: 0.2641, d_k_M range: [0.0098, 0.4955], d_k_M_hat range: [0.6275, 0.9816]
2025-03-11 20:36:43 - Train Iteration 6419: loss: 0.2726, d_k_M range: [0.0008, 0.4891], d_k_M_hat range: [0.5747, 0.9909]
2025-03-11 20:36:43 - Train Iteration 6420: loss: 0.2676, d_k_M range: [0.0007, 0.4897], d_k_M_hat range: [0.5423, 0.9814]
2025-03-11 20:36:44 - Train Iteration 6421: loss: 0.6093, d_k_M range: [0.0486, 0.7793], d_k_M_hat range: [0.8085, 0.9988]
2025-03-11 20:36:44 - Train Iteration 6422: loss: 0.2213, d_k_M range: [0.0009, 0.1289], d_k_M_hat range: [0.5425, 0.8637]
2025-03-11 20:36:45 - Train Iteration 6423: loss: 0.1845, d_k_M range: [0.0217, 0.3699], d_k_M_hat range: [0.8790, 0.9852]
2025-03-11 20:36:45 - Train Iteration 6424: loss: 0.2156, d_k_M range: [0.0004, 0.3173], d_k_M_hat range: [0.5393, 0.9711]
2025-03-11 20:36:46 - Train Iteration 6425: loss: 0.3200, d_k_M range: [0.0015, 0.3867], d_k_M_hat range: [0.4362, 0.9811]
2025-03-11 20:36:46 - Train Iteration 6426: loss: 0.2731, d_k_M range: [0.0005, 0.5162], d_k_M_hat range: [0.6272, 0.9938]
2025-03-11 20:36:47 - Train Iteration 6427: loss: 0.2314, d_k_M range: [0.0003, 0.1599], d_k_M_hat range: [0.5193, 0.9231]
2025-03-11 20:36:47 - Train Iteration 6428: loss: 0.3614, d_k_M range: [0.0010, 0.5995], d_k_M_hat range: [0.6663, 0.9983]
2025-03-11 20:36:47 - Train Iteration 6429: loss: 0.3413, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.4162, 0.6809]
2025-03-11 20:36:48 - Train Iteration 6430: loss: 0.2996, d_k_M range: [0.0223, 0.5469], d_k_M_hat range: [0.8015, 0.9995]
2025-03-11 20:36:48 - Train Iteration 6431: loss: 0.2246, d_k_M range: [0.0071, 0.4296], d_k_M_hat range: [0.6771, 0.9935]
2025-03-11 20:36:49 - Train Iteration 6432: loss: 0.6732, d_k_M range: [0.0001, 0.4639], d_k_M_hat range: [0.1803, 0.9967]
2025-03-11 20:36:49 - Train Iteration 6433: loss: 0.1673, d_k_M range: [0.0137, 0.4067], d_k_M_hat range: [0.7647, 0.9977]
2025-03-11 20:36:50 - Train Iteration 6434: loss: 0.4807, d_k_M range: [0.0006, 0.6933], d_k_M_hat range: [0.5743, 0.9999]
2025-03-11 20:36:50 - Train Iteration 6435: loss: 0.7147, d_k_M range: [0.0001, 0.0561], d_k_M_hat range: [0.1547, 0.8207]
2025-03-11 20:36:51 - Train Iteration 6436: loss: 0.4031, d_k_M range: [0.0245, 0.6347], d_k_M_hat range: [0.8665, 0.9998]
2025-03-11 20:36:51 - Train Iteration 6437: loss: 0.3730, d_k_M range: [0.0103, 0.6050], d_k_M_hat range: [0.7114, 0.9970]
2025-03-11 20:36:51 - Train Iteration 6438: loss: 0.2485, d_k_M range: [0.0002, 0.4596], d_k_M_hat range: [0.5034, 0.9971]
2025-03-11 20:36:52 - Train Iteration 6439: loss: 0.7485, d_k_M range: [0.0000, 0.3676], d_k_M_hat range: [0.1349, 0.9816]
2025-03-11 20:36:52 - Train Iteration 6440: loss: 0.2393, d_k_M range: [0.0025, 0.3803], d_k_M_hat range: [0.6552, 0.9842]
2025-03-11 20:36:53 - Train Iteration 6441: loss: 0.1125, d_k_M range: [0.0001, 0.3113], d_k_M_hat range: [0.6648, 0.9920]
2025-03-11 20:36:53 - Train Iteration 6442: loss: 0.1895, d_k_M range: [0.0020, 0.3295], d_k_M_hat range: [0.5667, 0.9762]
2025-03-11 20:36:54 - Train Iteration 6443: loss: 0.9655, d_k_M range: [0.0277, 0.9824], d_k_M_hat range: [0.8973, 0.9998]
2025-03-11 20:36:54 - Train Iteration 6444: loss: 0.1889, d_k_M range: [0.0163, 0.4289], d_k_M_hat range: [0.7289, 0.9970]
2025-03-11 20:36:55 - Train Iteration 6445: loss: 0.3340, d_k_M range: [0.0015, 0.5701], d_k_M_hat range: [0.5746, 0.9921]
2025-03-11 20:36:55 - Train Iteration 6446: loss: 0.4926, d_k_M range: [0.0005, 0.7010], d_k_M_hat range: [0.6072, 0.9992]
2025-03-11 20:36:56 - Train Iteration 6447: loss: 0.4388, d_k_M range: [0.0002, 0.1752], d_k_M_hat range: [0.3380, 0.8929]
2025-03-11 20:36:56 - Train Iteration 6448: loss: 0.2108, d_k_M range: [0.0024, 0.4111], d_k_M_hat range: [0.5752, 0.9936]
2025-03-11 20:36:57 - Train Iteration 6449: loss: 0.3160, d_k_M range: [0.0009, 0.4919], d_k_M_hat range: [0.4387, 0.9981]
2025-03-11 20:36:57 - Train Iteration 6450: loss: 0.1925, d_k_M range: [0.0147, 0.4114], d_k_M_hat range: [0.6803, 0.9976]
2025-03-11 20:36:57 - Train Iteration 6451: loss: 0.1993, d_k_M range: [0.0024, 0.1770], d_k_M_hat range: [0.5559, 0.9525]
2025-03-11 20:36:58 - Train Iteration 6452: loss: 0.2671, d_k_M range: [0.0135, 0.5122], d_k_M_hat range: [0.7874, 0.9992]
2025-03-11 20:36:58 - Train Iteration 6453: loss: 0.1506, d_k_M range: [0.0024, 0.2100], d_k_M_hat range: [0.6143, 0.9762]
2025-03-11 20:36:59 - Train Iteration 6454: loss: 0.3945, d_k_M range: [0.0233, 0.6281], d_k_M_hat range: [0.7130, 0.9999]
2025-03-11 20:36:59 - Train Iteration 6455: loss: 0.3037, d_k_M range: [0.0005, 0.2769], d_k_M_hat range: [0.4511, 0.9359]
2025-03-11 20:37:00 - Train Iteration 6456: loss: 0.2884, d_k_M range: [0.0002, 0.5335], d_k_M_hat range: [0.5781, 0.9965]
2025-03-11 20:37:00 - Train Iteration 6457: loss: 0.2048, d_k_M range: [0.0028, 0.0487], d_k_M_hat range: [0.5550, 0.8281]
2025-03-11 20:37:01 - Train Iteration 6458: loss: 0.1531, d_k_M range: [0.0076, 0.3516], d_k_M_hat range: [0.6763, 0.9752]
2025-03-11 20:37:01 - Train Iteration 6459: loss: 0.3073, d_k_M range: [0.0040, 0.5503], d_k_M_hat range: [0.4621, 0.9959]
2025-03-11 20:37:02 - Train Iteration 6460: loss: 0.3101, d_k_M range: [0.0006, 0.4843], d_k_M_hat range: [0.4599, 0.9975]
2025-03-11 20:37:02 - Train Iteration 6461: loss: 0.2460, d_k_M range: [0.0016, 0.4852], d_k_M_hat range: [0.5056, 0.9930]
2025-03-11 20:37:02 - Train Iteration 6462: loss: 0.3844, d_k_M range: [0.0003, 0.6173], d_k_M_hat range: [0.5857, 0.9973]
2025-03-11 20:37:03 - Train Iteration 6463: loss: 0.3957, d_k_M range: [0.0000, 0.0669], d_k_M_hat range: [0.3709, 0.7942]
2025-03-11 20:37:03 - Train Iteration 6464: loss: 0.1366, d_k_M range: [0.0010, 0.3624], d_k_M_hat range: [0.7775, 0.9929]
2025-03-11 20:37:04 - Train Iteration 6465: loss: 0.2588, d_k_M range: [0.0016, 0.4991], d_k_M_hat range: [0.6027, 0.9904]
2025-03-11 20:37:04 - Train Iteration 6466: loss: 0.2435, d_k_M range: [0.0004, 0.2995], d_k_M_hat range: [0.5070, 0.9435]
2025-03-11 20:37:05 - Train Iteration 6467: loss: 0.2405, d_k_M range: [0.0008, 0.1530], d_k_M_hat range: [0.5104, 0.8709]
2025-03-11 20:37:05 - Train Iteration 6468: loss: 0.3765, d_k_M range: [0.0256, 0.6115], d_k_M_hat range: [0.7677, 0.9979]
2025-03-11 20:37:05 - Train Iteration 6469: loss: 0.2205, d_k_M range: [0.0007, 0.4687], d_k_M_hat range: [0.5881, 0.9991]
2025-03-11 20:37:06 - Train Iteration 6470: loss: 0.5187, d_k_M range: [0.0002, 0.3919], d_k_M_hat range: [0.2803, 0.9876]
2025-03-11 20:37:06 - Train Iteration 6471: loss: 0.1674, d_k_M range: [0.0069, 0.3793], d_k_M_hat range: [0.6205, 0.9702]
2025-03-11 20:37:07 - Train Iteration 6472: loss: 0.2329, d_k_M range: [0.0072, 0.4792], d_k_M_hat range: [0.6860, 0.9967]
2025-03-11 20:37:07 - Train Iteration 6473: loss: 0.2516, d_k_M range: [0.0006, 0.3697], d_k_M_hat range: [0.4990, 0.9569]
2025-03-11 20:37:08 - Train Iteration 6474: loss: 0.2450, d_k_M range: [0.0174, 0.4481], d_k_M_hat range: [0.7425, 0.9596]
2025-03-11 20:37:08 - Train Iteration 6475: loss: 0.2531, d_k_M range: [0.0008, 0.5028], d_k_M_hat range: [0.5542, 0.9997]
2025-03-11 20:37:09 - Train Iteration 6476: loss: 0.2977, d_k_M range: [0.0035, 0.5286], d_k_M_hat range: [0.6594, 0.9874]
2025-03-11 20:37:09 - Train Iteration 6477: loss: 0.1748, d_k_M range: [0.0023, 0.3959], d_k_M_hat range: [0.6781, 0.9907]
2025-03-11 20:37:10 - Train Iteration 6478: loss: 0.5386, d_k_M range: [0.0001, 0.4215], d_k_M_hat range: [0.2662, 0.9828]
2025-03-11 20:37:10 - Train Iteration 6479: loss: 0.2881, d_k_M range: [0.0002, 0.3035], d_k_M_hat range: [0.4635, 0.9642]
2025-03-11 20:37:10 - Train Iteration 6480: loss: 0.2243, d_k_M range: [0.0026, 0.1616], d_k_M_hat range: [0.5291, 0.9807]
2025-03-11 20:37:11 - Train Iteration 6481: loss: 0.5890, d_k_M range: [0.0105, 0.7672], d_k_M_hat range: [0.6339, 0.9997]
2025-03-11 20:37:11 - Train Iteration 6482: loss: 0.3288, d_k_M range: [0.0002, 0.4380], d_k_M_hat range: [0.4268, 0.9979]
2025-03-11 20:37:12 - Train Iteration 6483: loss: 0.2842, d_k_M range: [0.0457, 0.4179], d_k_M_hat range: [0.8848, 0.9675]
2025-03-11 20:37:12 - Train Iteration 6484: loss: 0.2795, d_k_M range: [0.0019, 0.4966], d_k_M_hat range: [0.6124, 0.9696]
2025-03-11 20:37:13 - Train Iteration 6485: loss: 0.2759, d_k_M range: [0.0001, 0.1885], d_k_M_hat range: [0.4748, 0.9498]
2025-03-11 20:37:13 - Train Iteration 6486: loss: 0.6769, d_k_M range: [0.0002, 0.5900], d_k_M_hat range: [0.1774, 0.9972]
2025-03-11 20:37:13 - Train Iteration 6487: loss: 0.2978, d_k_M range: [0.0006, 0.3539], d_k_M_hat range: [0.4549, 0.9828]
2025-03-11 20:37:14 - Train Iteration 6488: loss: 0.3283, d_k_M range: [0.0239, 0.5705], d_k_M_hat range: [0.6350, 0.9976]
2025-03-11 20:37:14 - Train Iteration 6489: loss: 0.3702, d_k_M range: [0.0002, 0.3752], d_k_M_hat range: [0.4008, 0.9867]
2025-03-11 20:37:15 - Train Iteration 6490: loss: 0.2997, d_k_M range: [0.0102, 0.5413], d_k_M_hat range: [0.7373, 0.9965]
2025-03-11 20:37:15 - Train Iteration 6491: loss: 0.2849, d_k_M range: [0.0000, 0.5082], d_k_M_hat range: [0.4686, 0.9927]
2025-03-11 20:37:16 - Train Iteration 6492: loss: 0.4047, d_k_M range: [0.0030, 0.4038], d_k_M_hat range: [0.6057, 0.9680]
2025-03-11 20:37:16 - Train Iteration 6493: loss: 0.1885, d_k_M range: [0.0126, 0.4258], d_k_M_hat range: [0.6064, 0.9915]
2025-03-11 20:37:17 - Train Iteration 6494: loss: 0.2268, d_k_M range: [0.0023, 0.4670], d_k_M_hat range: [0.5867, 0.9908]
2025-03-11 20:37:17 - Train Iteration 6495: loss: 0.2440, d_k_M range: [0.0011, 0.3418], d_k_M_hat range: [0.5072, 0.9756]
2025-03-11 20:37:17 - Train Iteration 6496: loss: 0.3095, d_k_M range: [0.0005, 0.1992], d_k_M_hat range: [0.4444, 0.8798]
2025-03-11 20:37:18 - Train Iteration 6497: loss: 0.1882, d_k_M range: [0.0004, 0.2693], d_k_M_hat range: [0.5671, 0.9197]
2025-03-11 20:37:18 - Train Iteration 6498: loss: 0.2068, d_k_M range: [0.0011, 0.1585], d_k_M_hat range: [0.5616, 0.9608]
2025-03-11 20:37:19 - Train Iteration 6499: loss: 0.2989, d_k_M range: [0.0186, 0.5454], d_k_M_hat range: [0.8050, 0.9987]
2025-03-11 20:37:19 - Train Iteration 6500: loss: 0.2341, d_k_M range: [0.0059, 0.4794], d_k_M_hat range: [0.6434, 0.9956]
2025-03-11 20:37:20 - Train Iteration 6501: loss: 0.2726, d_k_M range: [0.0005, 0.1503], d_k_M_hat range: [0.4785, 0.9680]
2025-03-11 20:37:20 - Train Iteration 6502: loss: 0.1608, d_k_M range: [0.0161, 0.3415], d_k_M_hat range: [0.8692, 0.9909]
2025-03-11 20:37:21 - Train Iteration 6503: loss: 0.7280, d_k_M range: [0.0062, 0.8516], d_k_M_hat range: [0.6150, 0.9986]
2025-03-11 20:37:21 - Train Iteration 6504: loss: 0.3187, d_k_M range: [0.0003, 0.3893], d_k_M_hat range: [0.4358, 0.9994]
2025-03-11 20:37:22 - Train Iteration 6505: loss: 0.4197, d_k_M range: [0.0372, 0.6464], d_k_M_hat range: [0.7803, 0.9986]
2025-03-11 20:37:22 - Train Iteration 6506: loss: 0.2454, d_k_M range: [0.0006, 0.1536], d_k_M_hat range: [0.5052, 0.8570]
2025-03-11 20:37:23 - Train Iteration 6507: loss: 0.2759, d_k_M range: [0.0081, 0.5212], d_k_M_hat range: [0.7105, 0.9990]
2025-03-11 20:37:23 - Train Iteration 6508: loss: 0.2115, d_k_M range: [0.0002, 0.0257], d_k_M_hat range: [0.5533, 0.7321]
2025-03-11 20:37:23 - Train Iteration 6509: loss: 0.1041, d_k_M range: [0.0005, 0.1537], d_k_M_hat range: [0.6779, 0.9675]
2025-03-11 20:37:24 - Train Iteration 6510: loss: 0.2263, d_k_M range: [0.0038, 0.4584], d_k_M_hat range: [0.6107, 0.9827]
2025-03-11 20:37:24 - Train Iteration 6511: loss: 0.2230, d_k_M range: [0.0001, 0.3279], d_k_M_hat range: [0.5278, 0.9684]
2025-03-11 20:37:25 - Train Iteration 6512: loss: 0.2014, d_k_M range: [0.0002, 0.4410], d_k_M_hat range: [0.5813, 0.9922]
2025-03-11 20:37:25 - Train Iteration 6513: loss: 0.2999, d_k_M range: [0.0000, 0.0922], d_k_M_hat range: [0.4523, 0.8513]
2025-03-11 20:37:26 - Train Iteration 6514: loss: 0.3456, d_k_M range: [0.0149, 0.5868], d_k_M_hat range: [0.8130, 0.9989]
2025-03-11 20:37:26 - Train Iteration 6515: loss: 0.2240, d_k_M range: [0.0019, 0.4090], d_k_M_hat range: [0.5440, 0.9669]
2025-03-11 20:37:26 - Train Iteration 6516: loss: 0.5284, d_k_M range: [0.0017, 0.3221], d_k_M_hat range: [0.2749, 0.9352]
2025-03-11 20:37:27 - Train Iteration 6517: loss: 0.3510, d_k_M range: [0.0057, 0.5919], d_k_M_hat range: [0.6815, 0.9994]
2025-03-11 20:37:27 - Train Iteration 6518: loss: 0.1847, d_k_M range: [0.0063, 0.2006], d_k_M_hat range: [0.5765, 0.9903]
2025-03-11 20:37:28 - Train Iteration 6519: loss: 0.2100, d_k_M range: [0.0051, 0.4329], d_k_M_hat range: [0.6298, 0.9923]
2025-03-11 20:37:28 - Train Iteration 6520: loss: 0.2312, d_k_M range: [0.0058, 0.4703], d_k_M_hat range: [0.6410, 0.9894]
2025-03-11 20:37:29 - Train Iteration 6521: loss: 0.3079, d_k_M range: [0.0010, 0.4667], d_k_M_hat range: [0.4462, 0.9823]
2025-03-11 20:37:29 - Train Iteration 6522: loss: 0.1007, d_k_M range: [0.0128, 0.2959], d_k_M_hat range: [0.8020, 0.9785]
2025-03-11 20:37:29 - Train Iteration 6523: loss: 0.2922, d_k_M range: [0.0022, 0.5396], d_k_M_hat range: [0.5028, 0.9991]
2025-03-11 20:37:30 - Train Iteration 6524: loss: 0.2281, d_k_M range: [0.0121, 0.4738], d_k_M_hat range: [0.7708, 0.9961]
2025-03-11 20:37:30 - Train Iteration 6525: loss: 0.1748, d_k_M range: [0.0050, 0.3818], d_k_M_hat range: [0.6106, 0.9991]
2025-03-11 20:37:31 - Train Iteration 6526: loss: 0.2645, d_k_M range: [0.0016, 0.3813], d_k_M_hat range: [0.4899, 0.9652]
2025-03-11 20:37:31 - Train Iteration 6527: loss: 0.2632, d_k_M range: [0.0021, 0.4911], d_k_M_hat range: [0.7097, 0.9878]
2025-03-11 20:37:32 - Train Iteration 6528: loss: 0.3349, d_k_M range: [0.0002, 0.5343], d_k_M_hat range: [0.4221, 0.9996]
2025-03-11 20:37:32 - Train Iteration 6529: loss: 0.2316, d_k_M range: [0.0040, 0.4547], d_k_M_hat range: [0.5737, 0.9917]
2025-03-11 20:37:33 - Train Iteration 6530: loss: 0.2923, d_k_M range: [0.0012, 0.5317], d_k_M_hat range: [0.5806, 0.9996]
2025-03-11 20:37:33 - Train Iteration 6531: loss: 0.1933, d_k_M range: [0.0011, 0.3673], d_k_M_hat range: [0.6326, 0.9790]
2025-03-11 20:37:33 - Train Iteration 6532: loss: 0.2312, d_k_M range: [0.0084, 0.4528], d_k_M_hat range: [0.5533, 0.9843]
2025-03-11 20:37:34 - Train Iteration 6533: loss: 0.2783, d_k_M range: [0.0044, 0.4813], d_k_M_hat range: [0.6833, 0.9917]
2025-03-11 20:37:34 - Train Iteration 6534: loss: 0.2659, d_k_M range: [0.0001, 0.2609], d_k_M_hat range: [0.4844, 0.9560]
2025-03-11 20:37:35 - Train Iteration 6535: loss: 0.7006, d_k_M range: [0.0025, 0.8368], d_k_M_hat range: [0.5943, 0.9998]
2025-03-11 20:37:35 - Train Iteration 6536: loss: 0.2793, d_k_M range: [0.0004, 0.0544], d_k_M_hat range: [0.4800, 0.8608]
2025-03-11 20:37:36 - Train Iteration 6537: loss: 0.3408, d_k_M range: [0.0128, 0.5828], d_k_M_hat range: [0.6987, 0.9990]
2025-03-11 20:37:36 - Train Iteration 6538: loss: 0.5839, d_k_M range: [0.0005, 0.2123], d_k_M_hat range: [0.2364, 0.9558]
2025-03-11 20:37:37 - Train Iteration 6539: loss: 0.4679, d_k_M range: [0.0019, 0.6830], d_k_M_hat range: [0.7594, 0.9990]
2025-03-11 20:37:37 - Train Iteration 6540: loss: 0.2331, d_k_M range: [0.0007, 0.4785], d_k_M_hat range: [0.5646, 0.9957]
2025-03-11 20:37:37 - Train Iteration 6541: loss: 0.2211, d_k_M range: [0.0054, 0.4676], d_k_M_hat range: [0.5770, 0.9974]
2025-03-11 20:37:38 - Train Iteration 6542: loss: 0.1021, d_k_M range: [0.0009, 0.1958], d_k_M_hat range: [0.6814, 0.9605]
2025-03-11 20:37:38 - Train Iteration 6543: loss: 0.1184, d_k_M range: [0.0039, 0.2634], d_k_M_hat range: [0.7138, 0.9601]
2025-03-11 20:37:39 - Train Iteration 6544: loss: 0.1928, d_k_M range: [0.0007, 0.1600], d_k_M_hat range: [0.5619, 0.8705]
2025-03-11 20:37:39 - Train Iteration 6545: loss: 0.2600, d_k_M range: [0.0184, 0.4786], d_k_M_hat range: [0.7116, 0.9929]
2025-03-11 20:37:40 - Train Iteration 6546: loss: 0.1959, d_k_M range: [0.0042, 0.4325], d_k_M_hat range: [0.5763, 0.9898]
2025-03-11 20:37:40 - Train Iteration 6547: loss: 0.2654, d_k_M range: [0.0015, 0.4674], d_k_M_hat range: [0.4863, 0.9867]
2025-03-11 20:37:40 - Train Iteration 6548: loss: 0.3673, d_k_M range: [0.0165, 0.6058], d_k_M_hat range: [0.9139, 0.9998]
2025-03-11 20:37:41 - Train Iteration 6549: loss: 0.1304, d_k_M range: [0.0021, 0.2538], d_k_M_hat range: [0.6571, 0.9628]
2025-03-11 20:37:41 - Train Iteration 6550: loss: 0.2074, d_k_M range: [0.0003, 0.4196], d_k_M_hat range: [0.5449, 0.9932]
2025-03-11 20:37:42 - Train Iteration 6551: loss: 0.0540, d_k_M range: [0.0057, 0.1793], d_k_M_hat range: [0.8267, 0.9849]
2025-03-11 20:37:42 - Train Iteration 6552: loss: 0.2278, d_k_M range: [0.0008, 0.4230], d_k_M_hat range: [0.5235, 0.9778]
2025-03-11 20:37:43 - Train Iteration 6553: loss: 0.2109, d_k_M range: [0.0051, 0.4504], d_k_M_hat range: [0.7543, 0.9972]
2025-03-11 20:37:43 - Train Iteration 6554: loss: 0.3118, d_k_M range: [0.0003, 0.3986], d_k_M_hat range: [0.4419, 0.9462]
2025-03-11 20:37:43 - Train Iteration 6555: loss: 0.2511, d_k_M range: [0.0008, 0.4868], d_k_M_hat range: [0.5692, 0.9874]
2025-03-11 20:37:44 - Train Iteration 6556: loss: 0.1728, d_k_M range: [0.0183, 0.4133], d_k_M_hat range: [0.7628, 0.9976]
2025-03-11 20:37:44 - Train Iteration 6557: loss: 0.3418, d_k_M range: [0.0005, 0.1823], d_k_M_hat range: [0.4158, 0.9454]
2025-03-11 20:37:45 - Train Iteration 6558: loss: 0.2352, d_k_M range: [0.0104, 0.4726], d_k_M_hat range: [0.8321, 0.9879]
2025-03-11 20:37:45 - Train Iteration 6559: loss: 0.2037, d_k_M range: [0.0017, 0.2282], d_k_M_hat range: [0.5542, 0.9883]
2025-03-11 20:37:46 - Train Iteration 6560: loss: 0.2524, d_k_M range: [0.0019, 0.2043], d_k_M_hat range: [0.4996, 0.9195]
2025-03-11 20:37:46 - Train Iteration 6561: loss: 0.2099, d_k_M range: [0.0017, 0.2291], d_k_M_hat range: [0.5438, 0.9651]
2025-03-11 20:37:46 - Train Iteration 6562: loss: 0.1776, d_k_M range: [0.0042, 0.3950], d_k_M_hat range: [0.7091, 0.9736]
2025-03-11 20:37:47 - Train Iteration 6563: loss: 0.6495, d_k_M range: [0.0002, 0.0351], d_k_M_hat range: [0.1947, 0.6200]
2025-03-11 20:37:47 - Train Iteration 6564: loss: 0.2173, d_k_M range: [0.0035, 0.3724], d_k_M_hat range: [0.5373, 0.9810]
2025-03-11 20:37:48 - Train Iteration 6565: loss: 0.2427, d_k_M range: [0.0119, 0.4840], d_k_M_hat range: [0.8544, 0.9947]
2025-03-11 20:37:48 - Train Iteration 6566: loss: 0.2898, d_k_M range: [0.0260, 0.5351], d_k_M_hat range: [0.7785, 0.9968]
2025-03-11 20:37:49 - Train Iteration 6567: loss: 0.3371, d_k_M range: [0.0001, 0.3271], d_k_M_hat range: [0.4195, 0.9910]
2025-03-11 20:37:49 - Train Iteration 6568: loss: 0.1520, d_k_M range: [0.0021, 0.2894], d_k_M_hat range: [0.6123, 0.9930]
2025-03-11 20:37:49 - Train Iteration 6569: loss: 0.2924, d_k_M range: [0.0002, 0.1332], d_k_M_hat range: [0.4595, 0.9584]
2025-03-11 20:37:50 - Train Iteration 6570: loss: 0.3132, d_k_M range: [0.0004, 0.4243], d_k_M_hat range: [0.4407, 0.9808]
2025-03-11 20:37:50 - Train Iteration 6571: loss: 0.2648, d_k_M range: [0.0004, 0.5067], d_k_M_hat range: [0.5431, 0.9954]
2025-03-11 20:37:51 - Train Iteration 6572: loss: 0.2799, d_k_M range: [0.0150, 0.5285], d_k_M_hat range: [0.9440, 0.9994]
2025-03-11 20:37:51 - Train Iteration 6573: loss: 0.3654, d_k_M range: [0.0001, 0.2733], d_k_M_hat range: [0.3956, 0.9332]
2025-03-11 20:37:52 - Train Iteration 6574: loss: 0.2387, d_k_M range: [0.0098, 0.4828], d_k_M_hat range: [0.6012, 0.9943]
2025-03-11 20:37:52 - Train Iteration 6575: loss: 0.3639, d_k_M range: [0.0100, 0.5930], d_k_M_hat range: [0.6742, 0.9897]
2025-03-11 20:37:53 - Train Iteration 6576: loss: 0.3709, d_k_M range: [0.0002, 0.0785], d_k_M_hat range: [0.3912, 0.9377]
2025-03-11 20:37:53 - Train Iteration 6577: loss: 0.2819, d_k_M range: [0.0023, 0.2932], d_k_M_hat range: [0.4729, 0.9727]
2025-03-11 20:37:53 - Train Iteration 6578: loss: 0.2748, d_k_M range: [0.0039, 0.3197], d_k_M_hat range: [0.6387, 0.9947]
2025-03-11 20:37:54 - Train Iteration 6579: loss: 0.2478, d_k_M range: [0.0016, 0.4418], d_k_M_hat range: [0.5038, 0.9960]
2025-03-11 20:37:54 - Train Iteration 6580: loss: 0.2993, d_k_M range: [0.0009, 0.5459], d_k_M_hat range: [0.5985, 0.9988]
2025-03-11 20:37:55 - Train Iteration 6581: loss: 0.3293, d_k_M range: [0.0011, 0.2687], d_k_M_hat range: [0.4273, 0.9806]
2025-03-11 20:37:55 - Train Iteration 6582: loss: 0.2480, d_k_M range: [0.0117, 0.4898], d_k_M_hat range: [0.7213, 0.9918]
2025-03-11 20:37:56 - Train Iteration 6583: loss: 0.2083, d_k_M range: [0.0007, 0.4471], d_k_M_hat range: [0.6815, 0.9908]
2025-03-11 20:37:56 - Train Iteration 6584: loss: 0.3844, d_k_M range: [0.0018, 0.6155], d_k_M_hat range: [0.6831, 0.9961]
2025-03-11 20:37:56 - Train Iteration 6585: loss: 0.2479, d_k_M range: [0.0006, 0.4906], d_k_M_hat range: [0.6499, 0.9954]
2025-03-11 20:37:57 - Train Iteration 6586: loss: 0.1913, d_k_M range: [0.0005, 0.4116], d_k_M_hat range: [0.5631, 0.9959]
2025-03-11 20:37:57 - Train Iteration 6587: loss: 0.5645, d_k_M range: [0.0200, 0.7487], d_k_M_hat range: [0.9197, 0.9999]
2025-03-11 20:37:58 - Train Iteration 6588: loss: 0.9648, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.0178, 0.6994]
2025-03-11 20:37:58 - Train Iteration 6589: loss: 0.3015, d_k_M range: [0.0082, 0.5483], d_k_M_hat range: [0.7471, 0.9992]
2025-03-11 20:37:59 - Train Iteration 6590: loss: 0.2203, d_k_M range: [0.0017, 0.4218], d_k_M_hat range: [0.5445, 0.9835]
2025-03-11 20:37:59 - Train Iteration 6591: loss: 0.2663, d_k_M range: [0.0014, 0.2346], d_k_M_hat range: [0.4867, 0.9716]
2025-03-11 20:37:59 - Train Iteration 6592: loss: 0.1995, d_k_M range: [0.0000, 0.3064], d_k_M_hat range: [0.5533, 0.9060]
2025-03-11 20:38:00 - Train Iteration 6593: loss: 0.2741, d_k_M range: [0.0003, 0.5116], d_k_M_hat range: [0.6440, 0.9880]
2025-03-11 20:38:00 - Train Iteration 6594: loss: 0.2007, d_k_M range: [0.0074, 0.4168], d_k_M_hat range: [0.7399, 0.9923]
2025-03-11 20:38:01 - Train Iteration 6595: loss: 0.2690, d_k_M range: [0.0020, 0.2857], d_k_M_hat range: [0.4834, 0.9807]
2025-03-11 20:38:01 - Train Iteration 6596: loss: 0.1583, d_k_M range: [0.0020, 0.0684], d_k_M_hat range: [0.6049, 0.8945]
2025-03-11 20:38:02 - Train Iteration 6597: loss: 0.4917, d_k_M range: [0.0004, 0.6965], d_k_M_hat range: [0.6272, 0.9953]
2025-03-11 20:38:02 - Train Iteration 6598: loss: 0.2202, d_k_M range: [0.0007, 0.4399], d_k_M_hat range: [0.6003, 0.9829]
2025-03-11 20:38:02 - Train Iteration 6599: loss: 0.1776, d_k_M range: [0.0007, 0.0881], d_k_M_hat range: [0.5793, 0.9840]
2025-03-11 20:38:03 - Train Iteration 6600: loss: 0.2279, d_k_M range: [0.0027, 0.4757], d_k_M_hat range: [0.7863, 0.9983]
2025-03-11 20:38:03 - Train Iteration 6601: loss: 0.2305, d_k_M range: [0.0003, 0.4243], d_k_M_hat range: [0.5202, 0.9799]
2025-03-11 20:38:04 - Train Iteration 6602: loss: 0.7313, d_k_M range: [0.0005, 0.1920], d_k_M_hat range: [0.1453, 0.8850]
2025-03-11 20:38:04 - Train Iteration 6603: loss: 0.5276, d_k_M range: [0.0348, 0.7225], d_k_M_hat range: [0.8052, 0.9993]
2025-03-11 20:38:05 - Train Iteration 6604: loss: 0.2420, d_k_M range: [0.0006, 0.3150], d_k_M_hat range: [0.5089, 0.9464]
2025-03-11 20:38:05 - Train Iteration 6605: loss: 0.3282, d_k_M range: [0.0055, 0.4982], d_k_M_hat range: [0.6458, 0.9925]
2025-03-11 20:38:05 - Train Iteration 6606: loss: 0.3106, d_k_M range: [0.0001, 0.5547], d_k_M_hat range: [0.5906, 0.9977]
2025-03-11 20:38:06 - Train Iteration 6607: loss: 0.2278, d_k_M range: [0.0007, 0.3903], d_k_M_hat range: [0.5250, 0.9585]
2025-03-11 20:38:06 - Train Iteration 6608: loss: 0.2666, d_k_M range: [0.0061, 0.5150], d_k_M_hat range: [0.7044, 0.9986]
2025-03-11 20:38:07 - Train Iteration 6609: loss: 0.2457, d_k_M range: [0.0023, 0.3129], d_k_M_hat range: [0.5603, 0.9792]
2025-03-11 20:38:07 - Train Iteration 6610: loss: 0.2124, d_k_M range: [0.0004, 0.4254], d_k_M_hat range: [0.5555, 0.9955]
2025-03-11 20:38:07 - Train Iteration 6611: loss: 0.1756, d_k_M range: [0.0007, 0.3202], d_k_M_hat range: [0.5830, 0.9735]
2025-03-11 20:38:08 - Train Iteration 6612: loss: 0.3770, d_k_M range: [0.0010, 0.6116], d_k_M_hat range: [0.7832, 0.9976]
2025-03-11 20:38:08 - Train Iteration 6613: loss: 0.3875, d_k_M range: [0.0002, 0.2599], d_k_M_hat range: [0.3778, 0.9642]
2025-03-11 20:38:09 - Train Iteration 6614: loss: 0.2456, d_k_M range: [0.0004, 0.4536], d_k_M_hat range: [0.6564, 0.9978]
2025-03-11 20:38:09 - Train Iteration 6615: loss: 0.1796, d_k_M range: [0.0062, 0.4089], d_k_M_hat range: [0.6378, 0.9877]
2025-03-11 20:38:10 - Train Iteration 6616: loss: 0.1899, d_k_M range: [0.0070, 0.4093], d_k_M_hat range: [0.5712, 0.9900]
2025-03-11 20:38:10 - Train Iteration 6617: loss: 0.3039, d_k_M range: [0.0009, 0.5357], d_k_M_hat range: [0.4781, 0.9911]
2025-03-11 20:38:10 - Train Iteration 6618: loss: 0.2120, d_k_M range: [0.0003, 0.3845], d_k_M_hat range: [0.5399, 0.9947]
2025-03-11 20:38:11 - Train Iteration 6619: loss: 0.2672, d_k_M range: [0.0005, 0.1285], d_k_M_hat range: [0.4835, 0.9624]
2025-03-11 20:38:11 - Train Iteration 6620: loss: 0.3022, d_k_M range: [0.0013, 0.1593], d_k_M_hat range: [0.4522, 0.8977]
2025-03-11 20:38:12 - Train Iteration 6621: loss: 0.1606, d_k_M range: [0.0045, 0.3943], d_k_M_hat range: [0.6080, 0.9936]
2025-03-11 20:38:12 - Train Iteration 6622: loss: 0.2430, d_k_M range: [0.0111, 0.4833], d_k_M_hat range: [0.5709, 0.9903]
2025-03-11 20:38:13 - Train Iteration 6623: loss: 0.2413, d_k_M range: [0.0024, 0.2380], d_k_M_hat range: [0.5452, 0.8834]
2025-03-11 20:38:13 - Train Iteration 6624: loss: 0.2287, d_k_M range: [0.0137, 0.4762], d_k_M_hat range: [0.7191, 0.9980]
2025-03-11 20:38:14 - Train Iteration 6625: loss: 0.1555, d_k_M range: [0.0003, 0.1863], d_k_M_hat range: [0.6060, 0.8829]
2025-03-11 20:38:14 - Train Iteration 6626: loss: 0.3668, d_k_M range: [0.1104, 0.5961], d_k_M_hat range: [0.8843, 0.9987]
2025-03-11 20:38:14 - Train Iteration 6627: loss: 0.3058, d_k_M range: [0.0049, 0.3467], d_k_M_hat range: [0.4568, 0.9886]
2025-03-11 20:38:15 - Train Iteration 6628: loss: 0.1276, d_k_M range: [0.0224, 0.3082], d_k_M_hat range: [0.8169, 0.9677]
2025-03-11 20:38:15 - Train Iteration 6629: loss: 0.2148, d_k_M range: [0.0008, 0.1605], d_k_M_hat range: [0.5771, 0.9492]
2025-03-11 20:38:16 - Train Iteration 6630: loss: 0.2133, d_k_M range: [0.0030, 0.4106], d_k_M_hat range: [0.5477, 0.9795]
2025-03-11 20:38:16 - Train Iteration 6631: loss: 0.2579, d_k_M range: [0.0017, 0.5074], d_k_M_hat range: [0.6948, 0.9996]
2025-03-11 20:38:16 - Train Iteration 6632: loss: 0.1741, d_k_M range: [0.0029, 0.3583], d_k_M_hat range: [0.5857, 0.9924]
2025-03-11 20:38:17 - Train Iteration 6633: loss: 0.2051, d_k_M range: [0.0010, 0.2949], d_k_M_hat range: [0.5494, 0.9749]
2025-03-11 20:38:17 - Train Iteration 6634: loss: 0.2905, d_k_M range: [0.0009, 0.5293], d_k_M_hat range: [0.6128, 0.9903]
2025-03-11 20:38:18 - Train Iteration 6635: loss: 0.2259, d_k_M range: [0.0015, 0.3977], d_k_M_hat range: [0.6225, 0.9972]
2025-03-11 20:38:18 - Train Iteration 6636: loss: 0.1973, d_k_M range: [0.0061, 0.2548], d_k_M_hat range: [0.5804, 0.9606]
2025-03-11 20:38:19 - Train Iteration 6637: loss: 0.2637, d_k_M range: [0.0397, 0.5131], d_k_M_hat range: [0.7633, 0.9996]
2025-03-11 20:38:19 - Train Iteration 6638: loss: 0.3088, d_k_M range: [0.0003, 0.0454], d_k_M_hat range: [0.4447, 0.9228]
2025-03-11 20:38:19 - Train Iteration 6639: loss: 0.1613, d_k_M range: [0.0019, 0.3996], d_k_M_hat range: [0.6665, 0.9980]
2025-03-11 20:38:20 - Train Iteration 6640: loss: 0.0945, d_k_M range: [0.0190, 0.2968], d_k_M_hat range: [0.7373, 0.9893]
2025-03-11 20:38:20 - Train Iteration 6641: loss: 0.1345, d_k_M range: [0.0001, 0.2490], d_k_M_hat range: [0.6492, 0.9764]
2025-03-11 20:38:21 - Train Iteration 6642: loss: 0.2063, d_k_M range: [0.0008, 0.4276], d_k_M_hat range: [0.5884, 0.9734]
2025-03-11 20:38:21 - Train Iteration 6643: loss: 0.2673, d_k_M range: [0.0001, 0.5122], d_k_M_hat range: [0.6645, 0.9952]
2025-03-11 20:38:22 - Train Iteration 6644: loss: 0.2097, d_k_M range: [0.0006, 0.3873], d_k_M_hat range: [0.5469, 0.9857]
2025-03-11 20:38:22 - Train Iteration 6645: loss: 0.2312, d_k_M range: [0.0007, 0.2928], d_k_M_hat range: [0.5205, 0.9510]
2025-03-11 20:38:22 - Train Iteration 6646: loss: 0.2085, d_k_M range: [0.0395, 0.4542], d_k_M_hat range: [0.7363, 0.9976]
2025-03-11 20:38:23 - Train Iteration 6647: loss: 0.1979, d_k_M range: [0.0049, 0.3640], d_k_M_hat range: [0.5600, 0.9928]
2025-03-11 20:38:23 - Train Iteration 6648: loss: 0.3730, d_k_M range: [0.0000, 0.1987], d_k_M_hat range: [0.3903, 0.9774]
2025-03-11 20:38:24 - Train Iteration 6649: loss: 0.7036, d_k_M range: [0.0126, 0.8382], d_k_M_hat range: [0.7159, 0.9994]
2025-03-11 20:38:24 - Train Iteration 6650: loss: 0.2086, d_k_M range: [0.0017, 0.1714], d_k_M_hat range: [0.5477, 0.9369]
2025-03-11 20:38:25 - Train Iteration 6651: loss: 0.2367, d_k_M range: [0.0040, 0.4523], d_k_M_hat range: [0.5177, 0.9959]
2025-03-11 20:38:25 - Train Iteration 6652: loss: 0.2189, d_k_M range: [0.0004, 0.4317], d_k_M_hat range: [0.5325, 0.9972]
2025-03-11 20:38:25 - Train Iteration 6653: loss: 0.3092, d_k_M range: [0.0029, 0.5330], d_k_M_hat range: [0.6596, 0.9996]
2025-03-11 20:38:26 - Train Iteration 6654: loss: 0.2925, d_k_M range: [0.0004, 0.5359], d_k_M_hat range: [0.5519, 0.9951]
2025-03-11 20:38:26 - Train Iteration 6655: loss: 0.6711, d_k_M range: [0.0034, 0.8154], d_k_M_hat range: [0.5113, 0.9962]
2025-03-11 20:38:27 - Train Iteration 6656: loss: 0.2980, d_k_M range: [0.0003, 0.4345], d_k_M_hat range: [0.4566, 0.9956]
2025-03-11 20:38:27 - Train Iteration 6657: loss: 0.3093, d_k_M range: [0.0013, 0.5539], d_k_M_hat range: [0.5091, 0.9978]
2025-03-11 20:38:28 - Train Iteration 6658: loss: 0.3287, d_k_M range: [0.0002, 0.2514], d_k_M_hat range: [0.4268, 0.9807]
2025-03-11 20:38:28 - Train Iteration 6659: loss: 0.1935, d_k_M range: [0.0016, 0.4390], d_k_M_hat range: [0.5690, 0.9991]
2025-03-11 20:38:29 - Train Iteration 6660: loss: 0.2355, d_k_M range: [0.0014, 0.4291], d_k_M_hat range: [0.5161, 0.9843]
2025-03-11 20:38:29 - Train Iteration 6661: loss: 0.5047, d_k_M range: [0.0010, 0.7080], d_k_M_hat range: [0.4693, 0.9996]
2025-03-11 20:38:29 - Train Iteration 6662: loss: 0.2127, d_k_M range: [0.0008, 0.3608], d_k_M_hat range: [0.5396, 0.9637]
2025-03-11 20:38:30 - Train Iteration 6663: loss: 0.2970, d_k_M range: [0.0009, 0.5443], d_k_M_hat range: [0.6628, 0.9993]
2025-03-11 20:38:30 - Train Iteration 6664: loss: 0.1719, d_k_M range: [0.0008, 0.2762], d_k_M_hat range: [0.5862, 0.9823]
2025-03-11 20:38:31 - Train Iteration 6665: loss: 0.1859, d_k_M range: [0.0019, 0.4092], d_k_M_hat range: [0.5735, 0.9780]
2025-03-11 20:38:31 - Train Iteration 6666: loss: 0.2605, d_k_M range: [0.0003, 0.5060], d_k_M_hat range: [0.5344, 0.9956]
2025-03-11 20:38:32 - Train Iteration 6667: loss: 0.1819, d_k_M range: [0.0008, 0.2838], d_k_M_hat range: [0.5789, 0.9552]
2025-03-11 20:38:32 - Train Iteration 6668: loss: 0.5740, d_k_M range: [0.0242, 0.7559], d_k_M_hat range: [0.6586, 0.9997]
2025-03-11 20:38:32 - Train Iteration 6669: loss: 0.2316, d_k_M range: [0.0008, 0.1725], d_k_M_hat range: [0.5195, 0.9464]
2025-03-11 20:38:33 - Train Iteration 6670: loss: 0.3522, d_k_M range: [0.0032, 0.4970], d_k_M_hat range: [0.5912, 0.9750]
2025-03-11 20:38:33 - Train Iteration 6671: loss: 0.1642, d_k_M range: [0.0056, 0.3050], d_k_M_hat range: [0.6032, 0.9924]
2025-03-11 20:38:34 - Train Iteration 6672: loss: 0.2191, d_k_M range: [0.0015, 0.4616], d_k_M_hat range: [0.5671, 0.9936]
2025-03-11 20:38:34 - Train Iteration 6673: loss: 0.1969, d_k_M range: [0.0028, 0.4060], d_k_M_hat range: [0.6007, 0.9738]
2025-03-11 20:38:35 - Train Iteration 6674: loss: 0.2238, d_k_M range: [0.0005, 0.1871], d_k_M_hat range: [0.5309, 0.9860]
2025-03-11 20:38:35 - Train Iteration 6675: loss: 0.1558, d_k_M range: [0.0007, 0.3229], d_k_M_hat range: [0.6059, 0.9954]
2025-03-11 20:38:36 - Train Iteration 6676: loss: 0.1416, d_k_M range: [0.0008, 0.3639], d_k_M_hat range: [0.6420, 0.9878]
2025-03-11 20:38:36 - Train Iteration 6677: loss: 0.2772, d_k_M range: [0.0017, 0.3047], d_k_M_hat range: [0.4781, 0.9878]
2025-03-11 20:38:37 - Train Iteration 6678: loss: 0.2913, d_k_M range: [0.0020, 0.5255], d_k_M_hat range: [0.7215, 0.9936]
2025-03-11 20:38:37 - Train Iteration 6679: loss: 0.1720, d_k_M range: [0.0001, 0.0621], d_k_M_hat range: [0.5854, 0.8786]
2025-03-11 20:38:37 - Train Iteration 6680: loss: 0.1559, d_k_M range: [0.0002, 0.3550], d_k_M_hat range: [0.6054, 0.9946]
2025-03-11 20:38:38 - Train Iteration 6681: loss: 0.2078, d_k_M range: [0.0056, 0.4519], d_k_M_hat range: [0.6291, 0.9961]
2025-03-11 20:38:38 - Train Iteration 6682: loss: 0.2397, d_k_M range: [0.0004, 0.3137], d_k_M_hat range: [0.5112, 0.9474]
2025-03-11 20:38:39 - Train Iteration 6683: loss: 0.1463, d_k_M range: [0.0022, 0.3345], d_k_M_hat range: [0.7588, 0.9918]
2025-03-11 20:38:39 - Train Iteration 6684: loss: 0.2594, d_k_M range: [0.0002, 0.3764], d_k_M_hat range: [0.4911, 0.9968]
2025-03-11 20:38:39 - Train Iteration 6685: loss: 0.2836, d_k_M range: [0.0041, 0.2233], d_k_M_hat range: [0.4715, 0.9414]
2025-03-11 20:38:40 - Train Iteration 6686: loss: 0.4896, d_k_M range: [0.0098, 0.2481], d_k_M_hat range: [0.3449, 0.9900]
2025-03-11 20:38:40 - Train Iteration 6687: loss: 0.1897, d_k_M range: [0.0002, 0.2619], d_k_M_hat range: [0.5646, 0.9499]
2025-03-11 20:38:41 - Train Iteration 6688: loss: 0.2634, d_k_M range: [0.0003, 0.5122], d_k_M_hat range: [0.6219, 0.9990]
2025-03-11 20:38:41 - Train Iteration 6689: loss: 0.3016, d_k_M range: [0.0234, 0.5483], d_k_M_hat range: [0.7714, 0.9991]
2025-03-11 20:38:42 - Train Iteration 6690: loss: 0.1813, d_k_M range: [0.0025, 0.4146], d_k_M_hat range: [0.6378, 0.9921]
2025-03-11 20:38:42 - Train Iteration 6691: loss: 0.1566, d_k_M range: [0.0005, 0.3851], d_k_M_hat range: [0.6257, 0.9894]
2025-03-11 20:38:42 - Train Iteration 6692: loss: 0.3136, d_k_M range: [0.0005, 0.1631], d_k_M_hat range: [0.4405, 0.9691]
2025-03-11 20:38:43 - Train Iteration 6693: loss: 0.3172, d_k_M range: [0.0047, 0.5622], d_k_M_hat range: [0.5359, 0.9990]
2025-03-11 20:38:43 - Train Iteration 6694: loss: 0.2868, d_k_M range: [0.0000, 0.2901], d_k_M_hat range: [0.4645, 0.9783]
2025-03-11 20:38:44 - Train Iteration 6695: loss: 0.1584, d_k_M range: [0.0076, 0.3686], d_k_M_hat range: [0.7894, 0.9768]
2025-03-11 20:38:44 - Train Iteration 6696: loss: 0.2010, d_k_M range: [0.0005, 0.2313], d_k_M_hat range: [0.5540, 0.9727]
2025-03-11 20:38:45 - Train Iteration 6697: loss: 0.3767, d_k_M range: [0.0015, 0.6110], d_k_M_hat range: [0.5816, 0.9973]
2025-03-11 20:38:45 - Train Iteration 6698: loss: 0.3189, d_k_M range: [0.0025, 0.5639], d_k_M_hat range: [0.5907, 0.9994]
2025-03-11 20:38:45 - Train Iteration 6699: loss: 0.2338, d_k_M range: [0.0000, 0.0607], d_k_M_hat range: [0.5169, 0.9473]
2025-03-11 20:38:46 - Train Iteration 6700: loss: 0.1673, d_k_M range: [0.0056, 0.4018], d_k_M_hat range: [0.6603, 0.9969]
2025-03-11 20:38:46 - Train Iteration 6701: loss: 0.1633, d_k_M range: [0.0050, 0.2429], d_k_M_hat range: [0.6011, 0.9656]
2025-03-11 20:38:47 - Train Iteration 6702: loss: 0.2072, d_k_M range: [0.0014, 0.4517], d_k_M_hat range: [0.5959, 0.9966]
2025-03-11 20:38:47 - Train Iteration 6703: loss: 0.2580, d_k_M range: [0.0010, 0.4919], d_k_M_hat range: [0.6794, 0.9840]
2025-03-11 20:38:48 - Train Iteration 6704: loss: 0.1354, d_k_M range: [0.0034, 0.3388], d_k_M_hat range: [0.8097, 0.9977]
2025-03-11 20:38:48 - Train Iteration 6705: loss: 0.3331, d_k_M range: [0.0057, 0.5603], d_k_M_hat range: [0.6514, 0.9837]
2025-03-11 20:38:48 - Train Iteration 6706: loss: 0.2127, d_k_M range: [0.0002, 0.4271], d_k_M_hat range: [0.6994, 0.9914]
2025-03-11 20:38:49 - Train Iteration 6707: loss: 0.3386, d_k_M range: [0.0001, 0.1946], d_k_M_hat range: [0.4184, 0.9843]
2025-03-11 20:38:49 - Train Iteration 6708: loss: 0.2759, d_k_M range: [0.0083, 0.5249], d_k_M_hat range: [0.8172, 0.9996]
2025-03-11 20:38:50 - Train Iteration 6709: loss: 0.2144, d_k_M range: [0.0004, 0.4540], d_k_M_hat range: [0.5931, 0.9910]
2025-03-11 20:38:50 - Train Iteration 6710: loss: 0.1404, d_k_M range: [0.0163, 0.3064], d_k_M_hat range: [0.6594, 0.9954]
2025-03-11 20:38:50 - Train Iteration 6711: loss: 0.1594, d_k_M range: [0.0101, 0.3972], d_k_M_hat range: [0.8980, 0.9980]
2025-03-11 20:38:51 - Train Iteration 6712: loss: 0.2306, d_k_M range: [0.0011, 0.3300], d_k_M_hat range: [0.5209, 0.9825]
2025-03-11 20:38:51 - Train Iteration 6713: loss: 0.2510, d_k_M range: [0.0024, 0.4998], d_k_M_hat range: [0.7186, 0.9989]
2025-03-11 20:38:52 - Train Iteration 6714: loss: 0.6662, d_k_M range: [0.0001, 0.3912], d_k_M_hat range: [0.1839, 0.9796]
2025-03-11 20:38:52 - Train Iteration 6715: loss: 0.3902, d_k_M range: [0.0095, 0.6152], d_k_M_hat range: [0.6188, 0.9906]
2025-03-11 20:38:52 - Train Iteration 6716: loss: 0.2351, d_k_M range: [0.0000, 0.1057], d_k_M_hat range: [0.5151, 0.8656]
2025-03-11 20:38:53 - Train Iteration 6717: loss: 0.2673, d_k_M range: [0.0521, 0.5167], d_k_M_hat range: [0.9265, 0.9997]
2025-03-11 20:38:53 - Train Iteration 6718: loss: 0.2342, d_k_M range: [0.0153, 0.4813], d_k_M_hat range: [0.6145, 0.9974]
2025-03-11 20:38:54 - Train Iteration 6719: loss: 0.3046, d_k_M range: [0.0002, 0.5515], d_k_M_hat range: [0.6331, 0.9996]
2025-03-11 20:38:54 - Train Iteration 6720: loss: 0.4001, d_k_M range: [0.0000, 0.3271], d_k_M_hat range: [0.3675, 0.9732]
2025-03-11 20:38:55 - Train Iteration 6721: loss: 0.2421, d_k_M range: [0.0002, 0.4398], d_k_M_hat range: [0.5082, 0.9923]
2025-03-11 20:38:55 - Train Iteration 6722: loss: 0.3468, d_k_M range: [0.0005, 0.5223], d_k_M_hat range: [0.4116, 0.9948]
2025-03-11 20:38:55 - Train Iteration 6723: loss: 0.2552, d_k_M range: [0.0006, 0.4981], d_k_M_hat range: [0.7717, 0.9958]
2025-03-11 20:38:56 - Train Iteration 6724: loss: 0.2327, d_k_M range: [0.0001, 0.4617], d_k_M_hat range: [0.5292, 0.9813]
2025-03-11 20:38:56 - Train Iteration 6725: loss: 0.2011, d_k_M range: [0.0047, 0.2596], d_k_M_hat range: [0.5562, 0.9976]
2025-03-11 20:38:57 - Train Iteration 6726: loss: 0.2735, d_k_M range: [0.0009, 0.4288], d_k_M_hat range: [0.4792, 0.9787]
2025-03-11 20:38:57 - Train Iteration 6727: loss: 0.3000, d_k_M range: [0.0006, 0.5360], d_k_M_hat range: [0.5688, 0.9986]
2025-03-11 20:38:58 - Train Iteration 6728: loss: 0.2870, d_k_M range: [0.0004, 0.2970], d_k_M_hat range: [0.4647, 0.9667]
2025-03-11 20:38:58 - Train Iteration 6729: loss: 0.2002, d_k_M range: [0.0009, 0.3420], d_k_M_hat range: [0.5534, 0.9838]
2025-03-11 20:38:59 - Train Iteration 6730: loss: 0.2172, d_k_M range: [0.0015, 0.4252], d_k_M_hat range: [0.7532, 0.9861]
2025-03-11 20:38:59 - Train Iteration 6731: loss: 0.1816, d_k_M range: [0.0001, 0.4217], d_k_M_hat range: [0.6290, 0.9955]
2025-03-11 20:38:59 - Train Iteration 6732: loss: 0.5173, d_k_M range: [0.0003, 0.4310], d_k_M_hat range: [0.2811, 0.9931]
2025-03-11 20:39:00 - Train Iteration 6733: loss: 0.2945, d_k_M range: [0.0024, 0.5103], d_k_M_hat range: [0.8697, 0.9970]
2025-03-11 20:39:00 - Train Iteration 6734: loss: 0.2892, d_k_M range: [0.0006, 0.4943], d_k_M_hat range: [0.4628, 0.9956]
2025-03-11 20:39:01 - Train Iteration 6735: loss: 0.1531, d_k_M range: [0.0026, 0.2564], d_k_M_hat range: [0.6113, 0.9807]
2025-03-11 20:39:01 - Train Iteration 6736: loss: 0.2825, d_k_M range: [0.0006, 0.1959], d_k_M_hat range: [0.4691, 0.9640]
2025-03-11 20:39:02 - Train Iteration 6737: loss: 0.7467, d_k_M range: [0.0015, 0.8641], d_k_M_hat range: [0.7788, 1.0000]
2025-03-11 20:39:02 - Train Iteration 6738: loss: 0.6472, d_k_M range: [0.0010, 0.3404], d_k_M_hat range: [0.1970, 0.9786]
2025-03-11 20:39:03 - Train Iteration 6739: loss: 0.1819, d_k_M range: [0.0016, 0.4236], d_k_M_hat range: [0.5977, 0.9972]
2025-03-11 20:39:03 - Train Iteration 6740: loss: 0.2257, d_k_M range: [0.0001, 0.3604], d_k_M_hat range: [0.5251, 0.9909]
2025-03-11 20:39:04 - Train Iteration 6741: loss: 0.3160, d_k_M range: [0.0048, 0.5611], d_k_M_hat range: [0.7938, 0.9994]
2025-03-11 20:39:04 - Train Iteration 6742: loss: 0.1839, d_k_M range: [0.0113, 0.3924], d_k_M_hat range: [0.7646, 0.9719]
2025-03-11 20:39:05 - Train Iteration 6743: loss: 0.3747, d_k_M range: [0.0002, 0.6100], d_k_M_hat range: [0.5052, 0.9979]
2025-03-11 20:39:05 - Train Iteration 6744: loss: 0.2243, d_k_M range: [0.0001, 0.0703], d_k_M_hat range: [0.5265, 0.8690]
2025-03-11 20:39:06 - Train Iteration 6745: loss: 0.2382, d_k_M range: [0.0022, 0.4572], d_k_M_hat range: [0.6571, 0.9873]
2025-03-11 20:39:06 - Train Iteration 6746: loss: 0.2920, d_k_M range: [0.0014, 0.0326], d_k_M_hat range: [0.4653, 0.8097]
2025-03-11 20:39:06 - Train Iteration 6747: loss: 0.2446, d_k_M range: [0.0004, 0.1967], d_k_M_hat range: [0.5058, 0.9738]
2025-03-11 20:39:07 - Train Iteration 6748: loss: 0.2890, d_k_M range: [0.0004, 0.5193], d_k_M_hat range: [0.6085, 0.9950]
2025-03-11 20:39:07 - Train Iteration 6749: loss: 0.2703, d_k_M range: [0.0005, 0.3759], d_k_M_hat range: [0.4806, 0.9851]
2025-03-11 20:39:08 - Train Iteration 6750: loss: 0.4892, d_k_M range: [0.0000, 0.2110], d_k_M_hat range: [0.3006, 0.9739]
2025-03-11 20:39:08 - Train Iteration 6751: loss: 0.1849, d_k_M range: [0.0002, 0.4016], d_k_M_hat range: [0.5952, 0.9716]
2025-03-11 20:39:09 - Train Iteration 6752: loss: 0.4711, d_k_M range: [0.0001, 0.2081], d_k_M_hat range: [0.3137, 0.9757]
2025-03-11 20:39:09 - Train Iteration 6753: loss: 0.2523, d_k_M range: [0.0169, 0.4892], d_k_M_hat range: [0.7850, 0.9921]
2025-03-11 20:39:10 - Train Iteration 6754: loss: 0.3420, d_k_M range: [0.0017, 0.5544], d_k_M_hat range: [0.5525, 0.9974]
2025-03-11 20:39:10 - Train Iteration 6755: loss: 0.9402, d_k_M range: [0.0001, 0.2770], d_k_M_hat range: [0.0304, 0.9378]
2025-03-11 20:39:11 - Train Iteration 6756: loss: 0.1480, d_k_M range: [0.0033, 0.3428], d_k_M_hat range: [0.6186, 0.9856]
2025-03-11 20:39:11 - Train Iteration 6757: loss: 0.5233, d_k_M range: [0.0009, 0.7227], d_k_M_hat range: [0.6124, 0.9993]
2025-03-11 20:39:11 - Train Iteration 6758: loss: 0.2315, d_k_M range: [0.0002, 0.3326], d_k_M_hat range: [0.5190, 0.9632]
2025-03-11 20:39:12 - Train Iteration 6759: loss: 0.3035, d_k_M range: [0.0002, 0.5483], d_k_M_hat range: [0.5227, 0.9974]
2025-03-11 20:39:12 - Train Iteration 6760: loss: 0.4093, d_k_M range: [0.0002, 0.6325], d_k_M_hat range: [0.5245, 0.9927]
2025-03-11 20:39:13 - Train Iteration 6761: loss: 0.2445, d_k_M range: [0.0005, 0.0948], d_k_M_hat range: [0.5222, 0.8388]
2025-03-11 20:39:13 - Train Iteration 6762: loss: 0.1901, d_k_M range: [0.0011, 0.3829], d_k_M_hat range: [0.5807, 0.9948]
2025-03-11 20:39:14 - Train Iteration 6763: loss: 0.2016, d_k_M range: [0.0001, 0.4455], d_k_M_hat range: [0.5747, 0.9965]
2025-03-11 20:39:14 - Train Iteration 6764: loss: 0.1717, d_k_M range: [0.0000, 0.4073], d_k_M_hat range: [0.6023, 0.9929]
2025-03-11 20:39:15 - Train Iteration 6765: loss: 0.2014, d_k_M range: [0.0013, 0.2913], d_k_M_hat range: [0.5525, 0.9860]
2025-03-11 20:39:15 - Train Iteration 6766: loss: 0.2813, d_k_M range: [0.0006, 0.4327], d_k_M_hat range: [0.5992, 0.9865]
2025-03-11 20:39:15 - Train Iteration 6767: loss: 0.2528, d_k_M range: [0.0013, 0.4996], d_k_M_hat range: [0.6582, 0.9967]
2025-03-11 20:39:16 - Train Iteration 6768: loss: 0.3146, d_k_M range: [0.0005, 0.5571], d_k_M_hat range: [0.6677, 0.9961]
2025-03-11 20:39:16 - Train Iteration 6769: loss: 0.2549, d_k_M range: [0.0001, 0.0237], d_k_M_hat range: [0.4980, 0.9242]
2025-03-11 20:39:17 - Train Iteration 6770: loss: 0.2252, d_k_M range: [0.0100, 0.4207], d_k_M_hat range: [0.6112, 0.9871]
2025-03-11 20:39:17 - Train Iteration 6771: loss: 0.3489, d_k_M range: [0.0012, 0.5853], d_k_M_hat range: [0.5100, 0.9946]
2025-03-11 20:39:18 - Train Iteration 6772: loss: 0.2439, d_k_M range: [0.0007, 0.4650], d_k_M_hat range: [0.6004, 0.9712]
2025-03-11 20:39:18 - Train Iteration 6773: loss: 0.3089, d_k_M range: [0.0001, 0.2114], d_k_M_hat range: [0.4462, 0.9132]
2025-03-11 20:39:18 - Train Iteration 6774: loss: 0.2453, d_k_M range: [0.0008, 0.3087], d_k_M_hat range: [0.5056, 0.9591]
2025-03-11 20:39:19 - Train Iteration 6775: loss: 0.4031, d_k_M range: [0.0881, 0.6339], d_k_M_hat range: [0.9099, 0.9990]
2025-03-11 20:39:19 - Train Iteration 6776: loss: 0.2059, d_k_M range: [0.0096, 0.3474], d_k_M_hat range: [0.6963, 0.9852]
2025-03-11 20:39:20 - Train Iteration 6777: loss: 0.3265, d_k_M range: [0.0002, 0.3875], d_k_M_hat range: [0.6009, 0.9969]
2025-03-11 20:39:20 - Train Iteration 6778: loss: 0.2453, d_k_M range: [0.0214, 0.4897], d_k_M_hat range: [0.5690, 0.9944]
2025-03-11 20:39:21 - Train Iteration 6779: loss: 0.2277, d_k_M range: [0.0028, 0.4647], d_k_M_hat range: [0.5817, 0.9875]
2025-03-11 20:39:21 - Train Iteration 6780: loss: 0.5194, d_k_M range: [0.0073, 0.7207], d_k_M_hat range: [0.6560, 1.0000]
2025-03-11 20:39:21 - Train Iteration 6781: loss: 0.1572, d_k_M range: [0.0004, 0.3188], d_k_M_hat range: [0.6039, 0.9598]
2025-03-11 20:39:22 - Train Iteration 6782: loss: 0.5506, d_k_M range: [0.0001, 0.2741], d_k_M_hat range: [0.2597, 0.9744]
2025-03-11 20:39:22 - Train Iteration 6783: loss: 0.1941, d_k_M range: [0.0014, 0.4272], d_k_M_hat range: [0.5659, 0.9866]
2025-03-11 20:39:23 - Train Iteration 6784: loss: 0.3841, d_k_M range: [0.0006, 0.5408], d_k_M_hat range: [0.3873, 0.9969]
2025-03-11 20:39:23 - Train Iteration 6785: loss: 0.3393, d_k_M range: [0.0157, 0.3686], d_k_M_hat range: [0.6902, 0.9893]
2025-03-11 20:39:24 - Train Iteration 6786: loss: 0.3515, d_k_M range: [0.0030, 0.3858], d_k_M_hat range: [0.4282, 0.9964]
2025-03-11 20:39:24 - Train Iteration 6787: loss: 0.2087, d_k_M range: [0.0022, 0.3047], d_k_M_hat range: [0.5463, 0.9628]
2025-03-11 20:39:24 - Train Iteration 6788: loss: 0.1650, d_k_M range: [0.0140, 0.3878], d_k_M_hat range: [0.7439, 0.9816]
2025-03-11 20:39:25 - Train Iteration 6789: loss: 0.4358, d_k_M range: [0.0001, 0.5127], d_k_M_hat range: [0.3400, 0.9949]
2025-03-11 20:39:25 - Train Iteration 6790: loss: 0.2684, d_k_M range: [0.0238, 0.5156], d_k_M_hat range: [0.7347, 0.9975]
2025-03-11 20:39:26 - Train Iteration 6791: loss: 0.3264, d_k_M range: [0.0001, 0.4556], d_k_M_hat range: [0.4288, 0.9898]
2025-03-11 20:39:26 - Train Iteration 6792: loss: 0.3099, d_k_M range: [0.0263, 0.5529], d_k_M_hat range: [0.5768, 0.9962]
2025-03-11 20:39:27 - Train Iteration 6793: loss: 0.2314, d_k_M range: [0.0004, 0.2957], d_k_M_hat range: [0.5199, 0.9801]
2025-03-11 20:39:27 - Train Iteration 6794: loss: 0.2338, d_k_M range: [0.0166, 0.4647], d_k_M_hat range: [0.6893, 0.9949]
2025-03-11 20:39:28 - Train Iteration 6795: loss: 0.2833, d_k_M range: [0.0018, 0.5294], d_k_M_hat range: [0.6710, 0.9971]
2025-03-11 20:39:28 - Train Iteration 6796: loss: 0.1313, d_k_M range: [0.0025, 0.2569], d_k_M_hat range: [0.6813, 0.9768]
2025-03-11 20:39:28 - Train Iteration 6797: loss: 0.3578, d_k_M range: [0.0013, 0.4866], d_k_M_hat range: [0.4032, 0.9992]
2025-03-11 20:39:29 - Train Iteration 6798: loss: 0.2363, d_k_M range: [0.0174, 0.4718], d_k_M_hat range: [0.7124, 0.9959]
2025-03-11 20:39:29 - Train Iteration 6799: loss: 0.2559, d_k_M range: [0.0000, 0.4228], d_k_M_hat range: [0.4942, 0.9774]
2025-03-11 20:39:30 - Train Iteration 6800: loss: 0.3177, d_k_M range: [0.0017, 0.5484], d_k_M_hat range: [0.4398, 0.9979]
2025-03-11 20:39:30 - Train Iteration 6801: loss: 0.3991, d_k_M range: [0.0024, 0.6315], d_k_M_hat range: [0.6116, 0.9998]
2025-03-11 20:39:31 - Train Iteration 6802: loss: 0.1718, d_k_M range: [0.0044, 0.3014], d_k_M_hat range: [0.6040, 0.9868]
2025-03-11 20:39:31 - Train Iteration 6803: loss: 0.1735, d_k_M range: [0.0015, 0.3169], d_k_M_hat range: [0.5849, 0.9915]
2025-03-11 20:39:32 - Train Iteration 6804: loss: 0.2536, d_k_M range: [0.0057, 0.4930], d_k_M_hat range: [0.6762, 0.9894]
2025-03-11 20:39:32 - Train Iteration 6805: loss: 0.1903, d_k_M range: [0.0009, 0.3295], d_k_M_hat range: [0.5677, 0.9727]
2025-03-11 20:39:32 - Train Iteration 6806: loss: 0.4374, d_k_M range: [0.0003, 0.2779], d_k_M_hat range: [0.3389, 0.9442]
2025-03-11 20:39:33 - Train Iteration 6807: loss: 0.3562, d_k_M range: [0.0162, 0.5963], d_k_M_hat range: [0.8208, 0.9995]
2025-03-11 20:39:33 - Train Iteration 6808: loss: 0.2283, d_k_M range: [0.0001, 0.0474], d_k_M_hat range: [0.5246, 0.7692]
2025-03-11 20:39:34 - Train Iteration 6809: loss: 0.2123, d_k_M range: [0.0018, 0.4536], d_k_M_hat range: [0.6859, 0.9929]
2025-03-11 20:39:34 - Train Iteration 6810: loss: 0.3321, d_k_M range: [0.0046, 0.5745], d_k_M_hat range: [0.6766, 0.9982]
2025-03-11 20:39:35 - Train Iteration 6811: loss: 0.2193, d_k_M range: [0.1338, 0.4617], d_k_M_hat range: [0.8841, 0.9933]
2025-03-11 20:39:35 - Train Iteration 6812: loss: 0.2113, d_k_M range: [0.0013, 0.2453], d_k_M_hat range: [0.5416, 0.9370]
2025-03-11 20:39:35 - Train Iteration 6813: loss: 0.2543, d_k_M range: [0.0025, 0.5017], d_k_M_hat range: [0.5681, 0.9975]
2025-03-11 20:39:36 - Train Iteration 6814: loss: 0.2454, d_k_M range: [0.0001, 0.1943], d_k_M_hat range: [0.5079, 0.9854]
2025-03-11 20:39:36 - Train Iteration 6815: loss: 0.1679, d_k_M range: [0.0037, 0.3373], d_k_M_hat range: [0.5954, 0.9913]
2025-03-11 20:39:37 - Train Iteration 6816: loss: 0.1711, d_k_M range: [0.0001, 0.1638], d_k_M_hat range: [0.5876, 0.9385]
2025-03-11 20:39:37 - Train Iteration 6817: loss: 0.2019, d_k_M range: [0.0056, 0.3687], d_k_M_hat range: [0.6363, 0.9945]
2025-03-11 20:39:38 - Train Iteration 6818: loss: 0.2301, d_k_M range: [0.0005, 0.3010], d_k_M_hat range: [0.5225, 0.9743]
2025-03-11 20:39:38 - Train Iteration 6819: loss: 0.2456, d_k_M range: [0.0148, 0.4870], d_k_M_hat range: [0.8172, 0.9914]
2025-03-11 20:39:39 - Train Iteration 6820: loss: 0.2633, d_k_M range: [0.0003, 0.0502], d_k_M_hat range: [0.4872, 0.7701]
2025-03-11 20:39:39 - Train Iteration 6821: loss: 0.1989, d_k_M range: [0.0038, 0.4434], d_k_M_hat range: [0.6183, 0.9974]
2025-03-11 20:39:40 - Train Iteration 6822: loss: 0.2584, d_k_M range: [0.0006, 0.0253], d_k_M_hat range: [0.4951, 0.7619]
2025-03-11 20:39:40 - Train Iteration 6823: loss: 0.1879, d_k_M range: [0.0004, 0.4294], d_k_M_hat range: [0.5898, 0.9960]
2025-03-11 20:39:40 - Train Iteration 6824: loss: 0.1650, d_k_M range: [0.0003, 0.3991], d_k_M_hat range: [0.6194, 0.9929]
2025-03-11 20:39:41 - Train Iteration 6825: loss: 0.2377, d_k_M range: [0.0005, 0.4026], d_k_M_hat range: [0.5138, 0.9947]
2025-03-11 20:39:41 - Train Iteration 6826: loss: 0.2551, d_k_M range: [0.0004, 0.4933], d_k_M_hat range: [0.5253, 0.9882]
2025-03-11 20:39:42 - Train Iteration 6827: loss: 0.2824, d_k_M range: [0.0020, 0.4170], d_k_M_hat range: [0.4714, 0.9924]
2025-03-11 20:39:42 - Train Iteration 6828: loss: 0.2099, d_k_M range: [0.0254, 0.4462], d_k_M_hat range: [0.7875, 0.9880]
2025-03-11 20:39:43 - Train Iteration 6829: loss: 0.1966, d_k_M range: [0.0003, 0.1081], d_k_M_hat range: [0.5597, 0.9493]
2025-03-11 20:39:43 - Train Iteration 6830: loss: 0.3141, d_k_M range: [0.0379, 0.5571], d_k_M_hat range: [0.7617, 0.9966]
2025-03-11 20:39:44 - Train Iteration 6831: loss: 0.1796, d_k_M range: [0.0014, 0.3189], d_k_M_hat range: [0.6440, 0.9819]
2025-03-11 20:39:44 - Train Iteration 6832: loss: 0.2214, d_k_M range: [0.0006, 0.4644], d_k_M_hat range: [0.5541, 0.9938]
2025-03-11 20:39:44 - Train Iteration 6833: loss: 0.2855, d_k_M range: [0.0017, 0.5321], d_k_M_hat range: [0.6452, 0.9978]
2025-03-11 20:39:45 - Train Iteration 6834: loss: 0.2193, d_k_M range: [0.0000, 0.1426], d_k_M_hat range: [0.5317, 0.8177]
2025-03-11 20:39:45 - Train Iteration 6835: loss: 0.1671, d_k_M range: [0.0068, 0.3657], d_k_M_hat range: [0.6842, 0.9569]
2025-03-11 20:39:46 - Train Iteration 6836: loss: 0.5332, d_k_M range: [0.0000, 0.3955], d_k_M_hat range: [0.2698, 0.9807]
2025-03-11 20:39:46 - Train Iteration 6837: loss: 0.0974, d_k_M range: [0.0058, 0.2995], d_k_M_hat range: [0.7771, 0.9940]
2025-03-11 20:39:47 - Train Iteration 6838: loss: 0.3757, d_k_M range: [0.0112, 0.5151], d_k_M_hat range: [0.6157, 0.9966]
2025-03-11 20:39:47 - Train Iteration 6839: loss: 0.2916, d_k_M range: [0.0005, 0.3131], d_k_M_hat range: [0.4604, 0.9972]
2025-03-11 20:39:47 - Train Iteration 6840: loss: 0.2848, d_k_M range: [0.0331, 0.5293], d_k_M_hat range: [0.6312, 0.9958]
2025-03-11 20:39:48 - Train Iteration 6841: loss: 0.1629, d_k_M range: [0.0001, 0.3054], d_k_M_hat range: [0.6025, 0.9777]
2025-03-11 20:39:48 - Train Iteration 6842: loss: 0.3290, d_k_M range: [0.0012, 0.5288], d_k_M_hat range: [0.5963, 0.9891]
2025-03-11 20:39:49 - Train Iteration 6843: loss: 0.2245, d_k_M range: [0.0104, 0.4670], d_k_M_hat range: [0.7520, 0.9932]
2025-03-11 20:39:49 - Train Iteration 6844: loss: 0.1720, d_k_M range: [0.0029, 0.1829], d_k_M_hat range: [0.5882, 0.9785]
2025-03-11 20:39:50 - Train Iteration 6845: loss: 0.2695, d_k_M range: [0.0015, 0.5151], d_k_M_hat range: [0.6182, 0.9959]
2025-03-11 20:39:50 - Train Iteration 6846: loss: 0.1905, d_k_M range: [0.0008, 0.1684], d_k_M_hat range: [0.5644, 0.9714]
2025-03-11 20:39:50 - Train Iteration 6847: loss: 0.2160, d_k_M range: [0.0034, 0.4622], d_k_M_hat range: [0.5857, 0.9974]
2025-03-11 20:39:51 - Train Iteration 6848: loss: 0.3084, d_k_M range: [0.0023, 0.4509], d_k_M_hat range: [0.5272, 0.9897]
2025-03-11 20:39:51 - Train Iteration 6849: loss: 0.2976, d_k_M range: [0.0027, 0.5274], d_k_M_hat range: [0.6555, 0.9970]
2025-03-11 20:39:52 - Train Iteration 6850: loss: 0.2421, d_k_M range: [0.0004, 0.4895], d_k_M_hat range: [0.5123, 0.9975]
2025-03-11 20:39:52 - Train Iteration 6851: loss: 0.1398, d_k_M range: [0.0011, 0.2202], d_k_M_hat range: [0.6272, 0.9718]
2025-03-11 20:39:53 - Train Iteration 6852: loss: 0.1615, d_k_M range: [0.0013, 0.1145], d_k_M_hat range: [0.6024, 0.8685]
2025-03-11 20:39:53 - Train Iteration 6853: loss: 0.2829, d_k_M range: [0.0005, 0.1382], d_k_M_hat range: [0.4699, 0.8315]
2025-03-11 20:39:53 - Train Iteration 6854: loss: 0.3985, d_k_M range: [0.0014, 0.6311], d_k_M_hat range: [0.7673, 0.9999]
2025-03-11 20:39:54 - Train Iteration 6855: loss: 0.1980, d_k_M range: [0.0004, 0.3123], d_k_M_hat range: [0.5555, 0.9630]
2025-03-11 20:39:54 - Train Iteration 6856: loss: 0.2969, d_k_M range: [0.0006, 0.5442], d_k_M_hat range: [0.5182, 0.9993]
2025-03-11 20:39:55 - Train Iteration 6857: loss: 0.2148, d_k_M range: [0.0017, 0.4361], d_k_M_hat range: [0.5384, 0.9951]
2025-03-11 20:39:55 - Train Iteration 6858: loss: 0.2892, d_k_M range: [0.0091, 0.5295], d_k_M_hat range: [0.6552, 0.9981]
2025-03-11 20:39:56 - Train Iteration 6859: loss: 0.2603, d_k_M range: [0.0007, 0.5025], d_k_M_hat range: [0.5198, 0.9922]
2025-03-11 20:39:56 - Train Iteration 6860: loss: 0.2313, d_k_M range: [0.0002, 0.0138], d_k_M_hat range: [0.5192, 0.6957]
2025-03-11 20:39:56 - Train Iteration 6861: loss: 0.4124, d_k_M range: [0.0002, 0.1961], d_k_M_hat range: [0.3613, 0.9501]
2025-03-11 20:39:57 - Train Iteration 6862: loss: 0.5770, d_k_M range: [0.0001, 0.7573], d_k_M_hat range: [0.6680, 0.9977]
2025-03-11 20:39:57 - Train Iteration 6863: loss: 0.2162, d_k_M range: [0.0014, 0.4316], d_k_M_hat range: [0.5779, 0.9666]
2025-03-11 20:39:58 - Train Iteration 6864: loss: 0.2101, d_k_M range: [0.0002, 0.1876], d_k_M_hat range: [0.5452, 0.9403]
2025-03-11 20:39:58 - Train Iteration 6865: loss: 0.2171, d_k_M range: [0.0098, 0.4397], d_k_M_hat range: [0.6181, 0.9891]
2025-03-11 20:39:59 - Train Iteration 6866: loss: 0.4229, d_k_M range: [0.0185, 0.6500], d_k_M_hat range: [0.6342, 0.9997]
2025-03-11 20:39:59 - Train Iteration 6867: loss: 0.1969, d_k_M range: [0.0014, 0.3137], d_k_M_hat range: [0.5675, 0.9728]
2025-03-11 20:40:00 - Train Iteration 6868: loss: 0.3086, d_k_M range: [0.2015, 0.5552], d_k_M_hat range: [0.9325, 0.9997]
2025-03-11 20:40:00 - Train Iteration 6869: loss: 0.3084, d_k_M range: [0.0063, 0.5458], d_k_M_hat range: [0.6418, 0.9954]
2025-03-11 20:40:01 - Train Iteration 6870: loss: 0.2825, d_k_M range: [0.0009, 0.4258], d_k_M_hat range: [0.4694, 0.9951]
2025-03-11 20:40:01 - Train Iteration 6871: loss: 0.2215, d_k_M range: [0.0881, 0.4672], d_k_M_hat range: [0.8717, 0.9965]
2025-03-11 20:40:01 - Train Iteration 6872: loss: 0.1349, d_k_M range: [0.0017, 0.3045], d_k_M_hat range: [0.6357, 0.9602]
2025-03-11 20:40:02 - Train Iteration 6873: loss: 0.2508, d_k_M range: [0.0049, 0.4383], d_k_M_hat range: [0.5538, 0.9938]
2025-03-11 20:40:02 - Train Iteration 6874: loss: 0.1843, d_k_M range: [0.0001, 0.4015], d_k_M_hat range: [0.5957, 0.9755]
2025-03-11 20:40:03 - Train Iteration 6875: loss: 0.3307, d_k_M range: [0.0008, 0.5733], d_k_M_hat range: [0.5553, 0.9982]
2025-03-11 20:40:03 - Train Iteration 6876: loss: 0.3480, d_k_M range: [0.0066, 0.5894], d_k_M_hat range: [0.7439, 0.9995]
2025-03-11 20:40:04 - Train Iteration 6877: loss: 0.2141, d_k_M range: [0.0001, 0.2950], d_k_M_hat range: [0.5395, 0.9465]
2025-03-11 20:40:04 - Train Iteration 6878: loss: 0.2618, d_k_M range: [0.0002, 0.5074], d_k_M_hat range: [0.6421, 0.9957]
2025-03-11 20:40:04 - Train Iteration 6879: loss: 0.1862, d_k_M range: [0.0002, 0.3259], d_k_M_hat range: [0.5688, 0.9906]
2025-03-11 20:40:05 - Train Iteration 6880: loss: 0.3113, d_k_M range: [0.0015, 0.5457], d_k_M_hat range: [0.6088, 0.9877]
2025-03-11 20:40:05 - Train Iteration 6881: loss: 0.3089, d_k_M range: [0.0000, 0.4031], d_k_M_hat range: [0.4442, 0.9556]
2025-03-11 20:40:06 - Train Iteration 6882: loss: 0.3075, d_k_M range: [0.0120, 0.5454], d_k_M_hat range: [0.5883, 0.9909]
2025-03-11 20:40:06 - Train Iteration 6883: loss: 0.4967, d_k_M range: [0.0000, 0.3704], d_k_M_hat range: [0.2953, 0.9607]
2025-03-11 20:40:06 - Train Iteration 6884: loss: 0.1855, d_k_M range: [0.0212, 0.4211], d_k_M_hat range: [0.7829, 0.9968]
2025-03-11 20:40:07 - Train Iteration 6885: loss: 0.3731, d_k_M range: [0.0141, 0.6102], d_k_M_hat range: [0.7183, 0.9994]
2025-03-11 20:40:07 - Train Iteration 6886: loss: 0.1394, d_k_M range: [0.0049, 0.2468], d_k_M_hat range: [0.6316, 0.9674]
2025-03-11 20:40:08 - Train Iteration 6887: loss: 0.3273, d_k_M range: [0.0116, 0.5712], d_k_M_hat range: [0.7423, 0.9991]
2025-03-11 20:40:08 - Train Iteration 6888: loss: 0.2900, d_k_M range: [0.0000, 0.1120], d_k_M_hat range: [0.4615, 0.9009]
2025-03-11 20:40:09 - Train Iteration 6889: loss: 0.4701, d_k_M range: [0.0096, 0.6856], d_k_M_hat range: [0.6934, 1.0000]
2025-03-11 20:40:09 - Train Iteration 6890: loss: 0.2499, d_k_M range: [0.0003, 0.3865], d_k_M_hat range: [0.5019, 0.9522]
2025-03-11 20:40:10 - Train Iteration 6891: loss: 0.1512, d_k_M range: [0.0032, 0.3308], d_k_M_hat range: [0.6143, 0.9723]
2025-03-11 20:40:10 - Train Iteration 6892: loss: 0.1532, d_k_M range: [0.0044, 0.3404], d_k_M_hat range: [0.6235, 0.9783]
2025-03-11 20:40:11 - Train Iteration 6893: loss: 0.2866, d_k_M range: [0.0004, 0.5330], d_k_M_hat range: [0.5774, 0.9976]
2025-03-11 20:40:11 - Train Iteration 6894: loss: 0.2813, d_k_M range: [0.0005, 0.0397], d_k_M_hat range: [0.4710, 0.8238]
2025-03-11 20:40:11 - Train Iteration 6895: loss: 0.1968, d_k_M range: [0.0046, 0.4093], d_k_M_hat range: [0.6536, 0.9940]
2025-03-11 20:40:12 - Train Iteration 6896: loss: 0.1901, d_k_M range: [0.0015, 0.3410], d_k_M_hat range: [0.5692, 0.9613]
2025-03-11 20:40:12 - Train Iteration 6897: loss: 0.2839, d_k_M range: [0.0115, 0.5326], d_k_M_hat range: [0.8140, 0.9998]
2025-03-11 20:40:13 - Train Iteration 6898: loss: 0.1882, d_k_M range: [0.0001, 0.1005], d_k_M_hat range: [0.5688, 0.9460]
2025-03-11 20:40:13 - Train Iteration 6899: loss: 0.3001, d_k_M range: [0.0001, 0.4566], d_k_M_hat range: [0.4523, 0.9963]
2025-03-11 20:40:14 - Train Iteration 6900: loss: 0.2584, d_k_M range: [0.0004, 0.4380], d_k_M_hat range: [0.5884, 0.9919]
2025-03-11 20:40:14 - Train Iteration 6901: loss: 0.2343, d_k_M range: [0.0011, 0.4797], d_k_M_hat range: [0.6022, 0.9982]
2025-03-11 20:40:15 - Train Iteration 6902: loss: 0.2942, d_k_M range: [0.0047, 0.5186], d_k_M_hat range: [0.6189, 0.9915]
2025-03-11 20:40:15 - Train Iteration 6903: loss: 0.3214, d_k_M range: [0.0007, 0.4053], d_k_M_hat range: [0.4342, 0.9935]
2025-03-11 20:40:15 - Train Iteration 6904: loss: 0.2092, d_k_M range: [0.0017, 0.4487], d_k_M_hat range: [0.7138, 0.9913]
2025-03-11 20:40:16 - Train Iteration 6905: loss: 0.1707, d_k_M range: [0.0014, 0.1232], d_k_M_hat range: [0.5883, 0.9582]
2025-03-11 20:40:16 - Train Iteration 6906: loss: 0.2883, d_k_M range: [0.0176, 0.5225], d_k_M_hat range: [0.7139, 0.9986]
2025-03-11 20:40:17 - Train Iteration 6907: loss: 0.1606, d_k_M range: [0.0003, 0.3305], d_k_M_hat range: [0.6152, 0.9919]
2025-03-11 20:40:17 - Train Iteration 6908: loss: 0.2187, d_k_M range: [0.0122, 0.4591], d_k_M_hat range: [0.6612, 0.9914]
2025-03-11 20:40:18 - Train Iteration 6909: loss: 0.2298, d_k_M range: [0.0002, 0.4778], d_k_M_hat range: [0.6027, 0.9984]
2025-03-11 20:40:18 - Train Iteration 6910: loss: 0.1161, d_k_M range: [0.0014, 0.3234], d_k_M_hat range: [0.7359, 0.9827]
2025-03-11 20:40:19 - Train Iteration 6911: loss: 0.1598, d_k_M range: [0.0001, 0.1078], d_k_M_hat range: [0.6006, 0.9100]
2025-03-11 20:40:19 - Train Iteration 6912: loss: 0.1332, d_k_M range: [0.0031, 0.3579], d_k_M_hat range: [0.6970, 0.9980]
2025-03-11 20:40:19 - Train Iteration 6913: loss: 0.2009, d_k_M range: [0.0013, 0.2107], d_k_M_hat range: [0.5621, 0.9988]
2025-03-11 20:40:20 - Train Iteration 6914: loss: 0.1804, d_k_M range: [0.0032, 0.3996], d_k_M_hat range: [0.6361, 0.9830]
2025-03-11 20:40:20 - Train Iteration 6915: loss: 0.1905, d_k_M range: [0.0013, 0.3074], d_k_M_hat range: [0.5732, 0.9948]
2025-03-11 20:40:21 - Train Iteration 6916: loss: 0.2746, d_k_M range: [0.0036, 0.5194], d_k_M_hat range: [0.7137, 0.9954]
2025-03-11 20:40:21 - Train Iteration 6917: loss: 0.2287, d_k_M range: [0.0000, 0.2682], d_k_M_hat range: [0.5218, 0.9777]
2025-03-11 20:40:22 - Train Iteration 6918: loss: 0.1913, d_k_M range: [0.0026, 0.4252], d_k_M_hat range: [0.6098, 0.9878]
2025-03-11 20:40:22 - Train Iteration 6919: loss: 0.2521, d_k_M range: [0.0011, 0.1821], d_k_M_hat range: [0.5030, 0.9583]
2025-03-11 20:40:23 - Train Iteration 6920: loss: 0.1600, d_k_M range: [0.0030, 0.3952], d_k_M_hat range: [0.7853, 0.9986]
2025-03-11 20:40:23 - Train Iteration 6921: loss: 0.0731, d_k_M range: [0.0012, 0.2168], d_k_M_hat range: [0.7308, 0.9761]
2025-03-11 20:40:24 - Train Iteration 6922: loss: 0.2708, d_k_M range: [0.0012, 0.3727], d_k_M_hat range: [0.4808, 0.9922]
2025-03-11 20:40:24 - Train Iteration 6923: loss: 0.0817, d_k_M range: [0.0017, 0.1968], d_k_M_hat range: [0.7613, 0.9766]
2025-03-11 20:40:24 - Train Iteration 6924: loss: 0.1962, d_k_M range: [0.0003, 0.2328], d_k_M_hat range: [0.6149, 0.9792]
2025-03-11 20:40:25 - Train Iteration 6925: loss: 0.3255, d_k_M range: [0.0003, 0.4024], d_k_M_hat range: [0.4299, 0.9856]
2025-03-11 20:40:25 - Train Iteration 6926: loss: 0.2572, d_k_M range: [0.0002, 0.0723], d_k_M_hat range: [0.4931, 0.9373]
2025-03-11 20:40:26 - Train Iteration 6927: loss: 0.1852, d_k_M range: [0.0072, 0.4254], d_k_M_hat range: [0.8742, 0.9982]
2025-03-11 20:40:26 - Train Iteration 6928: loss: 0.2562, d_k_M range: [0.0002, 0.0552], d_k_M_hat range: [0.4940, 0.9627]
2025-03-11 20:40:27 - Train Iteration 6929: loss: 0.1393, d_k_M range: [0.0019, 0.3632], d_k_M_hat range: [0.6540, 0.9899]
2025-03-11 20:40:27 - Train Iteration 6930: loss: 0.1186, d_k_M range: [0.0039, 0.3292], d_k_M_hat range: [0.7243, 0.9848]
2025-03-11 20:40:27 - Train Iteration 6931: loss: 0.2397, d_k_M range: [0.0016, 0.4703], d_k_M_hat range: [0.6190, 0.9807]
2025-03-11 20:40:28 - Train Iteration 6932: loss: 0.2139, d_k_M range: [0.0005, 0.3442], d_k_M_hat range: [0.6316, 0.9839]
2025-03-11 20:40:28 - Train Iteration 6933: loss: 0.2175, d_k_M range: [0.0000, 0.2799], d_k_M_hat range: [0.5338, 0.9784]
2025-03-11 20:40:29 - Train Iteration 6934: loss: 0.2652, d_k_M range: [0.0202, 0.5102], d_k_M_hat range: [0.7319, 0.9991]
2025-03-11 20:40:29 - Train Iteration 6935: loss: 0.4560, d_k_M range: [0.0000, 0.2340], d_k_M_hat range: [0.3251, 0.9801]
2025-03-11 20:40:30 - Train Iteration 6936: loss: 0.3035, d_k_M range: [0.0857, 0.5422], d_k_M_hat range: [0.9306, 0.9990]
2025-03-11 20:40:30 - Train Iteration 6937: loss: 0.2343, d_k_M range: [0.0000, 0.4611], d_k_M_hat range: [0.5181, 0.9958]
2025-03-11 20:40:31 - Train Iteration 6938: loss: 0.2610, d_k_M range: [0.0003, 0.5101], d_k_M_hat range: [0.6407, 0.9993]
2025-03-11 20:40:31 - Train Iteration 6939: loss: 0.2215, d_k_M range: [0.0012, 0.3643], d_k_M_hat range: [0.5325, 0.9873]
2025-03-11 20:40:32 - Train Iteration 6940: loss: 0.3362, d_k_M range: [0.0000, 0.3192], d_k_M_hat range: [0.4202, 0.9715]
2025-03-11 20:40:32 - Train Iteration 6941: loss: 0.3024, d_k_M range: [0.0164, 0.5487], d_k_M_hat range: [0.8596, 0.9988]
2025-03-11 20:40:33 - Train Iteration 6942: loss: 0.2389, d_k_M range: [0.0019, 0.2508], d_k_M_hat range: [0.5999, 0.9674]
2025-03-11 20:40:33 - Train Iteration 6943: loss: 0.2706, d_k_M range: [0.0001, 0.4561], d_k_M_hat range: [0.4835, 0.9779]
2025-03-11 20:40:34 - Train Iteration 6944: loss: 0.2781, d_k_M range: [0.0095, 0.5229], d_k_M_hat range: [0.8286, 0.9992]
2025-03-11 20:40:34 - Train Iteration 6945: loss: 0.2344, d_k_M range: [0.0000, 0.4619], d_k_M_hat range: [0.5665, 0.9778]
2025-03-11 20:40:34 - Train Iteration 6946: loss: 0.2801, d_k_M range: [0.0043, 0.5292], d_k_M_hat range: [0.7852, 0.9999]
2025-03-11 20:40:35 - Train Iteration 6947: loss: 0.2662, d_k_M range: [0.0000, 0.5152], d_k_M_hat range: [0.5718, 0.9993]
2025-03-11 20:40:35 - Train Iteration 6948: loss: 0.1567, d_k_M range: [0.0070, 0.3455], d_k_M_hat range: [0.6113, 0.9707]
2025-03-11 20:40:36 - Train Iteration 6949: loss: 0.2204, d_k_M range: [0.0039, 0.4075], d_k_M_hat range: [0.5362, 0.9975]
2025-03-11 20:40:36 - Train Iteration 6950: loss: 0.2526, d_k_M range: [0.0000, 0.3770], d_k_M_hat range: [0.4974, 0.9941]
2025-03-11 20:40:37 - Train Iteration 6951: loss: 0.3131, d_k_M range: [0.0164, 0.5588], d_k_M_hat range: [0.7788, 0.9993]
2025-03-11 20:40:37 - Train Iteration 6952: loss: 0.2288, d_k_M range: [0.0027, 0.2766], d_k_M_hat range: [0.5244, 0.9461]
2025-03-11 20:40:37 - Train Iteration 6953: loss: 0.1717, d_k_M range: [0.0067, 0.4109], d_k_M_hat range: [0.8088, 0.9966]
2025-03-11 20:40:38 - Train Iteration 6954: loss: 0.1396, d_k_M range: [0.0006, 0.3684], d_k_M_hat range: [0.6907, 0.9947]
2025-03-11 20:40:38 - Train Iteration 6955: loss: 0.4268, d_k_M range: [0.0000, 0.1149], d_k_M_hat range: [0.3467, 0.9878]
2025-03-11 20:40:39 - Train Iteration 6956: loss: 0.5116, d_k_M range: [0.0027, 0.7152], d_k_M_hat range: [0.6255, 0.9999]
2025-03-11 20:40:39 - Train Iteration 6957: loss: 0.2224, d_k_M range: [0.0000, 0.1703], d_k_M_hat range: [0.5284, 0.9747]
2025-03-11 20:40:40 - Train Iteration 6958: loss: 0.2067, d_k_M range: [0.0011, 0.0977], d_k_M_hat range: [0.5480, 0.9298]
2025-03-11 20:40:40 - Train Iteration 6959: loss: 0.2749, d_k_M range: [0.0015, 0.5235], d_k_M_hat range: [0.8185, 0.9992]
2025-03-11 20:40:41 - Train Iteration 6960: loss: 0.2304, d_k_M range: [0.0012, 0.4654], d_k_M_hat range: [0.5540, 0.9952]
2025-03-11 20:40:41 - Train Iteration 6961: loss: 0.2662, d_k_M range: [0.0000, 0.0536], d_k_M_hat range: [0.4841, 0.9197]
2025-03-11 20:40:41 - Train Iteration 6962: loss: 0.1974, d_k_M range: [0.0006, 0.1190], d_k_M_hat range: [0.5577, 0.9476]
2025-03-11 20:40:42 - Train Iteration 6963: loss: 0.1508, d_k_M range: [0.0093, 0.3843], d_k_M_hat range: [0.8015, 0.9960]
2025-03-11 20:40:42 - Train Iteration 6964: loss: 0.4709, d_k_M range: [0.0014, 0.6841], d_k_M_hat range: [0.6281, 0.9979]
2025-03-11 20:40:43 - Train Iteration 6965: loss: 0.3422, d_k_M range: [0.0013, 0.5833], d_k_M_hat range: [0.6123, 0.9983]
2025-03-11 20:40:43 - Train Iteration 6966: loss: 0.2217, d_k_M range: [0.0003, 0.1754], d_k_M_hat range: [0.5302, 0.9552]
2025-03-11 20:40:44 - Train Iteration 6967: loss: 0.4297, d_k_M range: [0.0006, 0.6551], d_k_M_hat range: [0.5348, 0.9996]
2025-03-11 20:40:44 - Train Iteration 6968: loss: 0.1953, d_k_M range: [0.0001, 0.2071], d_k_M_hat range: [0.5582, 0.9756]
2025-03-11 20:40:45 - Train Iteration 6969: loss: 0.2869, d_k_M range: [0.0004, 0.5303], d_k_M_hat range: [0.5423, 0.9947]
2025-03-11 20:40:45 - Train Iteration 6970: loss: 0.3225, d_k_M range: [0.0000, 0.5643], d_k_M_hat range: [0.6334, 0.9964]
2025-03-11 20:40:45 - Train Iteration 6971: loss: 0.2014, d_k_M range: [0.0027, 0.4419], d_k_M_hat range: [0.6262, 0.9931]
2025-03-11 20:40:46 - Train Iteration 6972: loss: 0.0658, d_k_M range: [0.0011, 0.2381], d_k_M_hat range: [0.7654, 0.9898]
2025-03-11 20:40:46 - Train Iteration 6973: loss: 0.1290, d_k_M range: [0.0008, 0.2457], d_k_M_hat range: [0.6416, 0.9808]
2025-03-11 20:40:47 - Train Iteration 6974: loss: 0.1430, d_k_M range: [0.0008, 0.1760], d_k_M_hat range: [0.6226, 0.9650]
2025-03-11 20:40:47 - Train Iteration 6975: loss: 0.2040, d_k_M range: [0.0015, 0.3144], d_k_M_hat range: [0.5511, 0.9906]
2025-03-11 20:40:48 - Train Iteration 6976: loss: 0.2225, d_k_M range: [0.0002, 0.4658], d_k_M_hat range: [0.5956, 0.9941]
2025-03-11 20:40:48 - Train Iteration 6977: loss: 0.1500, d_k_M range: [0.0423, 0.3833], d_k_M_hat range: [0.8776, 0.9960]
2025-03-11 20:40:49 - Train Iteration 6978: loss: 0.2722, d_k_M range: [0.0001, 0.1925], d_k_M_hat range: [0.4787, 0.9112]
2025-03-11 20:40:49 - Train Iteration 6979: loss: 0.3405, d_k_M range: [0.0016, 0.5830], d_k_M_hat range: [0.6622, 0.9995]
2025-03-11 20:40:49 - Train Iteration 6980: loss: 0.2134, d_k_M range: [0.0014, 0.2388], d_k_M_hat range: [0.5403, 0.9686]
2025-03-11 20:40:50 - Train Iteration 6981: loss: 0.2557, d_k_M range: [0.0024, 0.5042], d_k_M_hat range: [0.7890, 0.9986]
2025-03-11 20:40:50 - Train Iteration 6982: loss: 0.1692, d_k_M range: [0.0012, 0.4058], d_k_M_hat range: [0.6737, 0.9944]
2025-03-11 20:40:51 - Train Iteration 6983: loss: 0.2712, d_k_M range: [0.0000, 0.2390], d_k_M_hat range: [0.4797, 0.9643]
2025-03-11 20:40:51 - Train Iteration 6984: loss: 0.7274, d_k_M range: [0.0000, 0.1331], d_k_M_hat range: [0.1472, 0.9119]
2025-03-11 20:40:52 - Train Iteration 6985: loss: 0.1811, d_k_M range: [0.0003, 0.1634], d_k_M_hat range: [0.5748, 0.9836]
2025-03-11 20:40:52 - Train Iteration 6986: loss: 0.2357, d_k_M range: [0.0000, 0.3755], d_k_M_hat range: [0.5145, 0.9812]
2025-03-11 20:40:53 - Train Iteration 6987: loss: 0.2016, d_k_M range: [0.0006, 0.4380], d_k_M_hat range: [0.6294, 0.9893]
2025-03-11 20:40:53 - Train Iteration 6988: loss: 0.7316, d_k_M range: [0.0002, 0.7360], d_k_M_hat range: [0.1448, 0.9968]
2025-03-11 20:40:53 - Train Iteration 6989: loss: 0.2891, d_k_M range: [0.0015, 0.5362], d_k_M_hat range: [0.6673, 0.9985]
2025-03-11 20:40:54 - Train Iteration 6990: loss: 0.1811, d_k_M range: [0.0030, 0.4148], d_k_M_hat range: [0.5774, 0.9916]
2025-03-11 20:40:54 - Train Iteration 6991: loss: 0.3028, d_k_M range: [0.0013, 0.4674], d_k_M_hat range: [0.4525, 0.9960]
2025-03-11 20:40:54 - Train Iteration 6992: loss: 0.4209, d_k_M range: [0.0006, 0.3967], d_k_M_hat range: [0.4866, 0.9324]
2025-03-11 20:40:55 - Train Iteration 6993: loss: 0.1616, d_k_M range: [0.0005, 0.3970], d_k_M_hat range: [0.6633, 0.9950]
2025-03-11 20:40:55 - Train Iteration 6994: loss: 0.1596, d_k_M range: [0.0004, 0.3608], d_k_M_hat range: [0.6876, 0.9612]
2025-03-11 20:40:56 - Train Iteration 6995: loss: 0.1971, d_k_M range: [0.0032, 0.3251], d_k_M_hat range: [0.5618, 0.9918]
2025-03-11 20:40:56 - Train Iteration 6996: loss: 0.2355, d_k_M range: [0.0053, 0.4519], d_k_M_hat range: [0.7888, 0.9939]
2025-03-11 20:40:56 - Train Iteration 6997: loss: 0.3942, d_k_M range: [0.0014, 0.6258], d_k_M_hat range: [0.6668, 0.9980]
2025-03-11 20:40:57 - Train Iteration 6998: loss: 0.3962, d_k_M range: [0.0004, 0.6261], d_k_M_hat range: [0.5053, 0.9983]
2025-03-11 20:40:57 - Train Iteration 6999: loss: 0.2386, d_k_M range: [0.0178, 0.4857], d_k_M_hat range: [0.8901, 0.9975]
2025-03-11 20:40:58 - Train Iteration 7000: loss: 0.1798, d_k_M range: [0.0003, 0.3663], d_k_M_hat range: [0.5903, 0.9567]
2025-03-11 20:40:58 - Train Iteration 7001: loss: 0.6034, d_k_M range: [0.0135, 0.7762], d_k_M_hat range: [0.7287, 0.9994]
2025-03-11 20:40:59 - Train Iteration 7002: loss: 0.0567, d_k_M range: [0.0086, 0.1611], d_k_M_hat range: [0.7832, 0.9685]
2025-03-11 20:40:59 - Train Iteration 7003: loss: 0.3394, d_k_M range: [0.0004, 0.5824], d_k_M_hat range: [0.6386, 0.9998]
2025-03-11 20:40:59 - Train Iteration 7004: loss: 0.2260, d_k_M range: [0.0000, 0.0811], d_k_M_hat range: [0.5250, 0.9434]
2025-03-11 20:41:00 - Train Iteration 7005: loss: 0.2381, d_k_M range: [0.0001, 0.4866], d_k_M_hat range: [0.5763, 0.9986]
2025-03-11 20:41:00 - Train Iteration 7006: loss: 0.3124, d_k_M range: [0.0012, 0.5587], d_k_M_hat range: [0.6364, 0.9997]
2025-03-11 20:41:00 - Train Iteration 7007: loss: 0.4040, d_k_M range: [0.0025, 0.6356], d_k_M_hat range: [0.8310, 1.0000]
2025-03-11 20:41:01 - Train Iteration 7008: loss: 0.2309, d_k_M range: [0.0152, 0.4693], d_k_M_hat range: [0.6332, 0.9888]
2025-03-11 20:41:01 - Train Iteration 7009: loss: 0.1645, d_k_M range: [0.0002, 0.1580], d_k_M_hat range: [0.5952, 0.8989]
2025-03-11 20:41:02 - Train Iteration 7010: loss: 0.1167, d_k_M range: [0.0005, 0.3285], d_k_M_hat range: [0.6971, 0.9973]
2025-03-11 20:41:02 - Train Iteration 7011: loss: 0.2791, d_k_M range: [0.0002, 0.5056], d_k_M_hat range: [0.4736, 0.9960]
2025-03-11 20:41:03 - Train Iteration 7012: loss: 0.1840, d_k_M range: [0.0011, 0.3310], d_k_M_hat range: [0.5721, 0.9939]
2025-03-11 20:41:03 - Train Iteration 7013: loss: 0.0683, d_k_M range: [0.0048, 0.2418], d_k_M_hat range: [0.7946, 0.9921]
2025-03-11 20:41:03 - Train Iteration 7014: loss: 0.2669, d_k_M range: [0.0001, 0.2164], d_k_M_hat range: [0.4852, 0.9767]
2025-03-11 20:41:04 - Train Iteration 7015: loss: 0.1606, d_k_M range: [0.0036, 0.3923], d_k_M_hat range: [0.6758, 0.9915]
2025-03-11 20:41:04 - Train Iteration 7016: loss: 0.1913, d_k_M range: [0.0003, 0.1430], d_k_M_hat range: [0.5660, 0.9014]
2025-03-11 20:41:05 - Train Iteration 7017: loss: 0.3246, d_k_M range: [0.0004, 0.1347], d_k_M_hat range: [0.4373, 0.9017]
2025-03-11 20:41:05 - Train Iteration 7018: loss: 0.4081, d_k_M range: [0.0035, 0.6358], d_k_M_hat range: [0.6303, 0.9970]
2025-03-11 20:41:06 - Train Iteration 7019: loss: 0.4598, d_k_M range: [0.0092, 0.6767], d_k_M_hat range: [0.6181, 0.9996]
2025-03-11 20:41:06 - Train Iteration 7020: loss: 0.1490, d_k_M range: [0.0003, 0.0410], d_k_M_hat range: [0.6175, 0.9541]
2025-03-11 20:41:06 - Train Iteration 7021: loss: 0.2684, d_k_M range: [0.0361, 0.5177], d_k_M_hat range: [0.9466, 0.9997]
2025-03-11 20:41:07 - Train Iteration 7022: loss: 0.1902, d_k_M range: [0.0003, 0.4089], d_k_M_hat range: [0.6176, 0.9728]
2025-03-11 20:41:07 - Train Iteration 7023: loss: 0.0871, d_k_M range: [0.0015, 0.2469], d_k_M_hat range: [0.7277, 0.9968]
2025-03-11 20:41:08 - Train Iteration 7024: loss: 0.2162, d_k_M range: [0.0001, 0.2939], d_k_M_hat range: [0.5369, 0.9875]
2025-03-11 20:41:08 - Train Iteration 7025: loss: 0.2158, d_k_M range: [0.0061, 0.4352], d_k_M_hat range: [0.7599, 0.9888]
2025-03-11 20:41:08 - Train Iteration 7026: loss: 0.1584, d_k_M range: [0.0002, 0.3358], d_k_M_hat range: [0.6093, 0.9892]
2025-03-11 20:41:09 - Train Iteration 7027: loss: 0.1485, d_k_M range: [0.0005, 0.3816], d_k_M_hat range: [0.7701, 0.9963]
2025-03-11 20:41:09 - Train Iteration 7028: loss: 0.2264, d_k_M range: [0.0007, 0.4706], d_k_M_hat range: [0.6546, 0.9948]
2025-03-11 20:41:10 - Train Iteration 7029: loss: 0.2543, d_k_M range: [0.0000, 0.2449], d_k_M_hat range: [0.4958, 0.9926]
2025-03-11 20:41:10 - Train Iteration 7030: loss: 0.2661, d_k_M range: [0.0002, 0.2107], d_k_M_hat range: [0.4843, 0.9792]
2025-03-11 20:41:10 - Train Iteration 7031: loss: 0.1841, d_k_M range: [0.0002, 0.4048], d_k_M_hat range: [0.5737, 0.9868]
2025-03-11 20:41:11 - Train Iteration 7032: loss: 0.4139, d_k_M range: [0.0003, 0.6432], d_k_M_hat range: [0.5000, 0.9999]
2025-03-11 20:41:11 - Train Iteration 7033: loss: 0.2359, d_k_M range: [0.0003, 0.2619], d_k_M_hat range: [0.5147, 0.9763]
2025-03-11 20:41:12 - Train Iteration 7034: loss: 0.1808, d_k_M range: [0.0020, 0.3217], d_k_M_hat range: [0.7662, 0.9863]
2025-03-11 20:41:12 - Train Iteration 7035: loss: 0.3177, d_k_M range: [0.0032, 0.5636], d_k_M_hat range: [0.7197, 0.9999]
2025-03-11 20:41:12 - Train Iteration 7036: loss: 0.2370, d_k_M range: [0.0000, 0.3567], d_k_M_hat range: [0.5132, 0.9506]
2025-03-11 20:41:13 - Train Iteration 7037: loss: 0.1199, d_k_M range: [0.0001, 0.2483], d_k_M_hat range: [0.6540, 0.9716]
2025-03-11 20:41:13 - Train Iteration 7038: loss: 0.2102, d_k_M range: [0.0001, 0.1322], d_k_M_hat range: [0.5417, 0.8116]
2025-03-11 20:41:14 - Train Iteration 7039: loss: 0.1306, d_k_M range: [0.0005, 0.3538], d_k_M_hat range: [0.6756, 0.9925]
2025-03-11 20:41:14 - Train Iteration 7040: loss: 0.1312, d_k_M range: [0.0001, 0.2791], d_k_M_hat range: [0.6378, 0.9729]
2025-03-11 20:41:14 - Train Iteration 7041: loss: 0.2069, d_k_M range: [0.0014, 0.4232], d_k_M_hat range: [0.5533, 0.9915]
2025-03-11 20:41:15 - Train Iteration 7042: loss: 0.3796, d_k_M range: [0.0007, 0.1224], d_k_M_hat range: [0.3857, 0.9920]
2025-03-11 20:41:15 - Train Iteration 7043: loss: 0.1748, d_k_M range: [0.0449, 0.4118], d_k_M_hat range: [0.8239, 0.9937]
2025-03-11 20:41:16 - Train Iteration 7044: loss: 0.4160, d_k_M range: [0.0001, 0.4712], d_k_M_hat range: [0.3551, 0.9966]
2025-03-11 20:41:16 - Train Iteration 7045: loss: 0.1300, d_k_M range: [0.0012, 0.3595], d_k_M_hat range: [0.6643, 0.9990]
2025-03-11 20:41:16 - Train Iteration 7046: loss: 0.2164, d_k_M range: [0.0020, 0.4534], d_k_M_hat range: [0.7452, 0.9921]
2025-03-11 20:41:17 - Train Iteration 7047: loss: 0.1354, d_k_M range: [0.0001, 0.2658], d_k_M_hat range: [0.6321, 0.9710]
2025-03-11 20:41:17 - Train Iteration 7048: loss: 0.0963, d_k_M range: [0.0031, 0.2902], d_k_M_hat range: [0.7212, 0.9811]
2025-03-11 20:41:18 - Train Iteration 7049: loss: 0.2665, d_k_M range: [0.0018, 0.1617], d_k_M_hat range: [0.4858, 0.9913]
2025-03-11 20:41:18 - Train Iteration 7050: loss: 0.1551, d_k_M range: [0.0130, 0.3918], d_k_M_hat range: [0.7438, 0.9980]
2025-03-11 20:41:19 - Train Iteration 7051: loss: 0.1562, d_k_M range: [0.0018, 0.3088], d_k_M_hat range: [0.6149, 0.9806]
2025-03-11 20:41:19 - Train Iteration 7052: loss: 0.1976, d_k_M range: [0.0005, 0.1865], d_k_M_hat range: [0.5560, 0.9957]
2025-03-11 20:41:19 - Train Iteration 7053: loss: 0.2508, d_k_M range: [0.0006, 0.3791], d_k_M_hat range: [0.4998, 0.9994]
2025-03-11 20:41:20 - Train Iteration 7054: loss: 0.2505, d_k_M range: [0.0012, 0.4664], d_k_M_hat range: [0.5050, 0.9902]
2025-03-11 20:41:20 - Train Iteration 7055: loss: 0.1312, d_k_M range: [0.0008, 0.1966], d_k_M_hat range: [0.6386, 0.9188]
2025-03-11 20:41:21 - Train Iteration 7056: loss: 0.1971, d_k_M range: [0.0008, 0.3733], d_k_M_hat range: [0.5724, 0.9870]
2025-03-11 20:41:21 - Train Iteration 7057: loss: 0.3629, d_k_M range: [0.0652, 0.6020], d_k_M_hat range: [0.9397, 0.9996]
2025-03-11 20:41:21 - Train Iteration 7058: loss: 0.2537, d_k_M range: [0.0004, 0.1771], d_k_M_hat range: [0.4966, 0.9810]
2025-03-11 20:41:22 - Train Iteration 7059: loss: 0.3473, d_k_M range: [0.0420, 0.5889], d_k_M_hat range: [0.8210, 0.9996]
2025-03-11 20:41:22 - Train Iteration 7060: loss: 0.2164, d_k_M range: [0.0010, 0.4585], d_k_M_hat range: [0.6454, 0.9966]
2025-03-11 20:41:23 - Train Iteration 7061: loss: 0.3068, d_k_M range: [0.0002, 0.0500], d_k_M_hat range: [0.4961, 0.9571]
2025-03-11 20:41:23 - Train Iteration 7062: loss: 0.2434, d_k_M range: [0.0023, 0.4673], d_k_M_hat range: [0.7771, 0.9955]
2025-03-11 20:41:23 - Train Iteration 7063: loss: 0.1052, d_k_M range: [0.0008, 0.2144], d_k_M_hat range: [0.6764, 0.9675]
2025-03-11 20:41:24 - Train Iteration 7064: loss: 0.3191, d_k_M range: [0.0001, 0.4317], d_k_M_hat range: [0.4352, 0.9975]
2025-03-11 20:41:24 - Train Iteration 7065: loss: 0.1450, d_k_M range: [0.0010, 0.1574], d_k_M_hat range: [0.6203, 0.9893]
2025-03-11 20:41:25 - Train Iteration 7066: loss: 0.1117, d_k_M range: [0.0001, 0.0539], d_k_M_hat range: [0.6660, 0.9176]
2025-03-11 20:41:25 - Train Iteration 7067: loss: 0.2426, d_k_M range: [0.0067, 0.4922], d_k_M_hat range: [0.9176, 0.9997]
2025-03-11 20:41:26 - Train Iteration 7068: loss: 0.1962, d_k_M range: [0.0001, 0.1414], d_k_M_hat range: [0.5600, 0.9736]
2025-03-11 20:41:26 - Train Iteration 7069: loss: 0.1925, d_k_M range: [0.0044, 0.2512], d_k_M_hat range: [0.5657, 0.9582]
2025-03-11 20:41:26 - Train Iteration 7070: loss: 0.1304, d_k_M range: [0.0051, 0.3565], d_k_M_hat range: [0.6765, 0.9954]
2025-03-11 20:41:27 - Train Iteration 7071: loss: 0.1915, d_k_M range: [0.0004, 0.1079], d_k_M_hat range: [0.5681, 0.9900]
2025-03-11 20:41:27 - Train Iteration 7072: loss: 0.4602, d_k_M range: [0.0025, 0.6757], d_k_M_hat range: [0.5742, 0.9994]
2025-03-11 20:41:28 - Train Iteration 7073: loss: 0.1886, d_k_M range: [0.0002, 0.4124], d_k_M_hat range: [0.5737, 0.9932]
2025-03-11 20:41:28 - Train Iteration 7074: loss: 0.2410, d_k_M range: [0.0003, 0.0737], d_k_M_hat range: [0.5094, 0.8622]
2025-03-11 20:41:28 - Train Iteration 7075: loss: 0.2060, d_k_M range: [0.0004, 0.4510], d_k_M_hat range: [0.6873, 0.9971]
2025-03-11 20:41:29 - Train Iteration 7076: loss: 0.2192, d_k_M range: [0.0000, 0.2414], d_k_M_hat range: [0.5322, 0.9632]
2025-03-11 20:41:29 - Train Iteration 7077: loss: 0.2050, d_k_M range: [0.0012, 0.3250], d_k_M_hat range: [0.5577, 0.9958]
2025-03-11 20:41:30 - Train Iteration 7078: loss: 0.1880, d_k_M range: [0.0002, 0.1328], d_k_M_hat range: [0.5666, 0.9705]
2025-03-11 20:41:30 - Train Iteration 7079: loss: 0.1517, d_k_M range: [0.0093, 0.3507], d_k_M_hat range: [0.7215, 0.9978]
2025-03-11 20:41:30 - Train Iteration 7080: loss: 0.2294, d_k_M range: [0.0007, 0.4733], d_k_M_hat range: [0.5658, 0.9943]
2025-03-11 20:41:31 - Train Iteration 7081: loss: 0.1313, d_k_M range: [0.0180, 0.3458], d_k_M_hat range: [0.8738, 0.9908]
2025-03-11 20:41:31 - Train Iteration 7082: loss: 0.1916, d_k_M range: [0.0002, 0.2340], d_k_M_hat range: [0.5624, 0.9853]
2025-03-11 20:41:32 - Train Iteration 7083: loss: 0.5286, d_k_M range: [0.0049, 0.7218], d_k_M_hat range: [0.8190, 0.9948]
2025-03-11 20:41:32 - Train Iteration 7084: loss: 0.1898, d_k_M range: [0.0000, 0.1146], d_k_M_hat range: [0.5644, 0.9384]
2025-03-11 20:41:32 - Train Iteration 7085: loss: 0.5155, d_k_M range: [0.0026, 0.7180], d_k_M_hat range: [0.7214, 1.0000]
2025-03-11 20:41:33 - Train Iteration 7086: loss: 0.6340, d_k_M range: [0.0022, 0.7962], d_k_M_hat range: [0.5214, 1.0000]
2025-03-11 20:41:33 - Train Iteration 7087: loss: 0.5142, d_k_M range: [0.0013, 0.1571], d_k_M_hat range: [0.2843, 0.9917]
2025-03-11 20:41:34 - Train Iteration 7088: loss: 0.5325, d_k_M range: [0.0411, 0.7294], d_k_M_hat range: [0.7759, 0.9998]
2025-03-11 20:41:34 - Train Iteration 7089: loss: 0.1460, d_k_M range: [0.0107, 0.3592], d_k_M_hat range: [0.6868, 0.9825]
2025-03-11 20:41:34 - Train Iteration 7090: loss: 0.1277, d_k_M range: [0.0008, 0.2633], d_k_M_hat range: [0.6435, 0.9748]
2025-03-11 20:41:35 - Train Iteration 7091: loss: 0.1110, d_k_M range: [0.0183, 0.1757], d_k_M_hat range: [0.7060, 0.9782]
2025-03-11 20:41:35 - Train Iteration 7092: loss: 0.1875, d_k_M range: [0.0004, 0.1064], d_k_M_hat range: [0.5733, 0.8948]
2025-03-11 20:41:35 - Train Iteration 7093: loss: 0.5334, d_k_M range: [0.0246, 0.7244], d_k_M_hat range: [0.8726, 0.9985]
2025-03-11 20:41:36 - Train Iteration 7094: loss: 0.2040, d_k_M range: [0.0003, 0.1610], d_k_M_hat range: [0.5533, 0.9581]
2025-03-11 20:41:36 - Train Iteration 7095: loss: 0.2711, d_k_M range: [0.0085, 0.4534], d_k_M_hat range: [0.4934, 0.9921]
2025-03-11 20:41:37 - Train Iteration 7096: loss: 0.2609, d_k_M range: [0.0097, 0.5072], d_k_M_hat range: [0.7112, 0.9990]
2025-03-11 20:41:37 - Train Iteration 7097: loss: 0.2097, d_k_M range: [0.0020, 0.4528], d_k_M_hat range: [0.6235, 0.9950]
2025-03-11 20:41:37 - Train Iteration 7098: loss: 0.2290, d_k_M range: [0.0001, 0.4765], d_k_M_hat range: [0.5840, 0.9979]
2025-03-11 20:41:38 - Train Iteration 7099: loss: 0.0935, d_k_M range: [0.0033, 0.2041], d_k_M_hat range: [0.7905, 0.9951]
2025-03-11 20:41:38 - Train Iteration 7100: loss: 0.2236, d_k_M range: [0.0001, 0.1012], d_k_M_hat range: [0.5274, 0.9377]
2025-03-11 20:41:38 - Train Iteration 7101: loss: 0.4070, d_k_M range: [0.0589, 0.6379], d_k_M_hat range: [0.9758, 1.0000]
2025-03-11 20:41:39 - Train Iteration 7102: loss: 0.1590, d_k_M range: [0.0009, 0.2374], d_k_M_hat range: [0.6028, 0.9706]
2025-03-11 20:41:39 - Train Iteration 7103: loss: 0.2209, d_k_M range: [0.0040, 0.4679], d_k_M_hat range: [0.6423, 0.9979]
2025-03-11 20:41:40 - Train Iteration 7104: loss: 0.1869, d_k_M range: [0.0004, 0.0511], d_k_M_hat range: [0.5733, 0.9853]
2025-03-11 20:41:40 - Train Iteration 7105: loss: 0.7201, d_k_M range: [0.0060, 0.8400], d_k_M_hat range: [0.7308, 0.9985]
2025-03-11 20:41:41 - Train Iteration 7106: loss: 0.3718, d_k_M range: [0.0001, 0.3436], d_k_M_hat range: [0.3903, 0.9853]
2025-03-11 20:41:41 - Train Iteration 7107: loss: 0.3517, d_k_M range: [0.0080, 0.5927], d_k_M_hat range: [0.6966, 0.9997]
2025-03-11 20:41:42 - Train Iteration 7108: loss: 0.1240, d_k_M range: [0.0016, 0.2796], d_k_M_hat range: [0.6497, 0.9946]
2025-03-11 20:41:42 - Train Iteration 7109: loss: 0.6213, d_k_M range: [0.0048, 0.7880], d_k_M_hat range: [0.9142, 0.9998]
2025-03-11 20:41:42 - Train Iteration 7110: loss: 0.3221, d_k_M range: [0.0003, 0.1504], d_k_M_hat range: [0.4327, 0.9373]
2025-03-11 20:41:43 - Train Iteration 7111: loss: 0.1522, d_k_M range: [0.0002, 0.3542], d_k_M_hat range: [0.6100, 0.9995]
2025-03-11 20:41:43 - Train Iteration 7112: loss: 0.1968, d_k_M range: [0.0004, 0.0627], d_k_M_hat range: [0.5575, 0.8484]
2025-03-11 20:41:44 - Train Iteration 7113: loss: 0.2182, d_k_M range: [0.0003, 0.4154], d_k_M_hat range: [0.5397, 0.9711]
2025-03-11 20:41:44 - Train Iteration 7114: loss: 0.2049, d_k_M range: [0.0011, 0.0769], d_k_M_hat range: [0.5485, 0.9236]
2025-03-11 20:41:44 - Train Iteration 7115: loss: 0.4534, d_k_M range: [0.0006, 0.6731], d_k_M_hat range: [0.6917, 0.9998]
2025-03-11 20:41:45 - Train Iteration 7116: loss: 0.2116, d_k_M range: [0.0005, 0.2479], d_k_M_hat range: [0.5426, 0.9924]
2025-03-11 20:41:45 - Train Iteration 7117: loss: 0.3216, d_k_M range: [0.0017, 0.5557], d_k_M_hat range: [0.7934, 0.9886]
2025-03-11 20:41:46 - Train Iteration 7118: loss: 0.1812, d_k_M range: [0.0000, 0.4051], d_k_M_hat range: [0.5744, 0.9823]
2025-03-11 20:41:46 - Train Iteration 7119: loss: 0.2894, d_k_M range: [0.0009, 0.5075], d_k_M_hat range: [0.6803, 0.9744]
2025-03-11 20:41:46 - Train Iteration 7120: loss: 0.2999, d_k_M range: [0.0000, 0.5460], d_k_M_hat range: [0.5338, 0.9983]
2025-03-11 20:41:47 - Train Iteration 7121: loss: 0.3427, d_k_M range: [0.0004, 0.2326], d_k_M_hat range: [0.4150, 0.9742]
2025-03-11 20:41:47 - Train Iteration 7122: loss: 0.1429, d_k_M range: [0.0011, 0.3046], d_k_M_hat range: [0.6240, 0.9973]
2025-03-11 20:41:48 - Train Iteration 7123: loss: 0.1459, d_k_M range: [0.0038, 0.3710], d_k_M_hat range: [0.7179, 0.9891]
2025-03-11 20:41:48 - Train Iteration 7124: loss: 0.1411, d_k_M range: [0.0007, 0.3035], d_k_M_hat range: [0.6390, 0.9886]
2025-03-11 20:41:49 - Train Iteration 7125: loss: 0.2512, d_k_M range: [0.0003, 0.2798], d_k_M_hat range: [0.5023, 0.9374]
2025-03-11 20:41:49 - Train Iteration 7126: loss: 0.2898, d_k_M range: [0.0010, 0.2214], d_k_M_hat range: [0.4626, 0.9638]
2025-03-11 20:41:49 - Train Iteration 7127: loss: 0.2302, d_k_M range: [0.0058, 0.4413], d_k_M_hat range: [0.6567, 0.9844]
2025-03-11 20:41:50 - Train Iteration 7128: loss: 0.3265, d_k_M range: [0.0000, 0.5677], d_k_M_hat range: [0.6454, 0.9963]
2025-03-11 20:41:50 - Train Iteration 7129: loss: 0.1159, d_k_M range: [0.0002, 0.3003], d_k_M_hat range: [0.6603, 0.9981]
2025-03-11 20:41:51 - Train Iteration 7130: loss: 0.3123, d_k_M range: [0.0026, 0.5535], d_k_M_hat range: [0.5846, 0.9990]
2025-03-11 20:41:51 - Train Iteration 7131: loss: 0.2523, d_k_M range: [0.0000, 0.3154], d_k_M_hat range: [0.4978, 0.9871]
2025-03-11 20:41:51 - Train Iteration 7132: loss: 0.2767, d_k_M range: [0.0476, 0.5231], d_k_M_hat range: [0.8125, 0.9998]
2025-03-11 20:41:52 - Train Iteration 7133: loss: 0.3530, d_k_M range: [0.0004, 0.5889], d_k_M_hat range: [0.5332, 0.9948]
2025-03-11 20:41:52 - Train Iteration 7134: loss: 0.2205, d_k_M range: [0.0002, 0.4648], d_k_M_hat range: [0.5847, 0.9953]
2025-03-11 20:41:53 - Train Iteration 7135: loss: 0.4455, d_k_M range: [0.0000, 0.0094], d_k_M_hat range: [0.3325, 0.9622]
2025-03-11 20:41:53 - Train Iteration 7136: loss: 0.1997, d_k_M range: [0.0039, 0.4328], d_k_M_hat range: [0.6768, 0.9891]
2025-03-11 20:41:53 - Train Iteration 7137: loss: 0.5835, d_k_M range: [0.0028, 0.6328], d_k_M_hat range: [0.2452, 0.9996]
2025-03-11 20:41:54 - Train Iteration 7138: loss: 0.2625, d_k_M range: [0.0009, 0.5097], d_k_M_hat range: [0.8192, 0.9973]
2025-03-11 20:41:54 - Train Iteration 7139: loss: 0.1632, d_k_M range: [0.0006, 0.0765], d_k_M_hat range: [0.5966, 0.8302]
2025-03-11 20:41:55 - Train Iteration 7140: loss: 0.1513, d_k_M range: [0.0004, 0.3505], d_k_M_hat range: [0.6235, 0.9890]
2025-03-11 20:41:55 - Train Iteration 7141: loss: 0.5751, d_k_M range: [0.0305, 0.7573], d_k_M_hat range: [0.9035, 0.9989]
2025-03-11 20:41:55 - Train Iteration 7142: loss: 0.2602, d_k_M range: [0.0000, 0.0557], d_k_M_hat range: [0.5047, 0.8925]
2025-03-11 20:41:56 - Train Iteration 7143: loss: 0.2570, d_k_M range: [0.0001, 0.1490], d_k_M_hat range: [0.4939, 0.9598]
2025-03-11 20:41:56 - Train Iteration 7144: loss: 0.2599, d_k_M range: [0.0001, 0.4713], d_k_M_hat range: [0.4903, 0.9927]
2025-03-11 20:41:57 - Train Iteration 7145: loss: 0.2351, d_k_M range: [0.0002, 0.4842], d_k_M_hat range: [0.6951, 0.9994]
2025-03-11 20:41:57 - Train Iteration 7146: loss: 0.6949, d_k_M range: [0.0001, 0.2622], d_k_M_hat range: [0.1665, 0.9867]
2025-03-11 20:41:57 - Train Iteration 7147: loss: 0.3475, d_k_M range: [0.1686, 0.5812], d_k_M_hat range: [0.9696, 0.9997]
2025-03-11 20:41:58 - Train Iteration 7148: loss: 0.2821, d_k_M range: [0.0180, 0.5105], d_k_M_hat range: [0.7839, 0.9944]
2025-03-11 20:41:58 - Train Iteration 7149: loss: 0.4382, d_k_M range: [0.0004, 0.2346], d_k_M_hat range: [0.3412, 0.9558]
2025-03-11 20:41:59 - Train Iteration 7150: loss: 0.1732, d_k_M range: [0.0015, 0.1754], d_k_M_hat range: [0.5852, 0.9500]
2025-03-11 20:41:59 - Train Iteration 7151: loss: 0.1108, d_k_M range: [0.0002, 0.1938], d_k_M_hat range: [0.6674, 0.9859]
2025-03-11 20:41:59 - Train Iteration 7152: loss: 0.1619, d_k_M range: [0.0007, 0.3893], d_k_M_hat range: [0.6111, 0.9869]
2025-03-11 20:42:00 - Train Iteration 7153: loss: 0.3087, d_k_M range: [0.0017, 0.5282], d_k_M_hat range: [0.5637, 0.9949]
2025-03-11 20:42:00 - Train Iteration 7154: loss: 0.3812, d_k_M range: [0.0001, 0.3230], d_k_M_hat range: [0.3827, 0.9770]
2025-03-11 20:42:01 - Train Iteration 7155: loss: 0.1738, d_k_M range: [0.0212, 0.4133], d_k_M_hat range: [0.6469, 0.9964]
2025-03-11 20:42:01 - Train Iteration 7156: loss: 0.3567, d_k_M range: [0.0001, 0.3856], d_k_M_hat range: [0.4029, 0.9957]
2025-03-11 20:42:02 - Train Iteration 7157: loss: 0.6345, d_k_M range: [0.0022, 0.7962], d_k_M_hat range: [0.6154, 0.9996]
2025-03-11 20:42:02 - Train Iteration 7158: loss: 0.1736, d_k_M range: [0.0003, 0.4031], d_k_M_hat range: [0.6174, 0.9865]
2025-03-11 20:42:02 - Train Iteration 7159: loss: 0.2089, d_k_M range: [0.0002, 0.0614], d_k_M_hat range: [0.5503, 0.9478]
2025-03-11 20:42:03 - Train Iteration 7160: loss: 0.2940, d_k_M range: [0.0000, 0.5325], d_k_M_hat range: [0.5421, 0.9969]
2025-03-11 20:42:03 - Train Iteration 7161: loss: 0.1938, d_k_M range: [0.0004, 0.0579], d_k_M_hat range: [0.5678, 0.8630]
2025-03-11 20:42:04 - Train Iteration 7162: loss: 0.2269, d_k_M range: [0.0364, 0.4713], d_k_M_hat range: [0.8417, 0.9950]
2025-03-11 20:42:04 - Train Iteration 7163: loss: 0.3794, d_k_M range: [0.0132, 0.6144], d_k_M_hat range: [0.7699, 0.9985]
2025-03-11 20:42:04 - Train Iteration 7164: loss: 0.2404, d_k_M range: [0.0008, 0.4859], d_k_M_hat range: [0.5790, 0.9956]
2025-03-11 20:42:05 - Train Iteration 7165: loss: 0.2663, d_k_M range: [0.0017, 0.5044], d_k_M_hat range: [0.6457, 0.9951]
2025-03-11 20:42:05 - Train Iteration 7166: loss: 0.2907, d_k_M range: [0.0004, 0.5347], d_k_M_hat range: [0.5059, 0.9954]
2025-03-11 20:42:05 - Train Iteration 7167: loss: 0.3574, d_k_M range: [0.0009, 0.5809], d_k_M_hat range: [0.4365, 0.9830]
2025-03-11 20:42:06 - Train Iteration 7168: loss: 0.1887, d_k_M range: [0.0003, 0.1291], d_k_M_hat range: [0.5666, 0.9586]
2025-03-11 20:42:06 - Train Iteration 7169: loss: 0.3126, d_k_M range: [0.0003, 0.4870], d_k_M_hat range: [0.4412, 0.9981]
2025-03-11 20:42:06 - Train Iteration 7170: loss: 0.2846, d_k_M range: [0.0013, 0.4246], d_k_M_hat range: [0.4678, 0.9974]
2025-03-11 20:42:07 - Train Iteration 7171: loss: 0.2043, d_k_M range: [0.0030, 0.4349], d_k_M_hat range: [0.8845, 0.9991]
2025-03-11 20:42:07 - Train Iteration 7172: loss: 0.3702, d_k_M range: [0.0001, 0.1407], d_k_M_hat range: [0.3916, 0.9872]
2025-03-11 20:42:08 - Train Iteration 7173: loss: 0.1797, d_k_M range: [0.0041, 0.4194], d_k_M_hat range: [0.7136, 0.9955]
2025-03-11 20:42:08 - Train Iteration 7174: loss: 0.3468, d_k_M range: [0.0062, 0.5888], d_k_M_hat range: [0.7381, 0.9999]
2025-03-11 20:42:08 - Train Iteration 7175: loss: 0.0976, d_k_M range: [0.0082, 0.2964], d_k_M_hat range: [0.8089, 0.9840]
2025-03-11 20:42:09 - Train Iteration 7176: loss: 0.4729, d_k_M range: [0.0000, 0.1196], d_k_M_hat range: [0.3123, 0.9132]
2025-03-11 20:42:09 - Train Iteration 7177: loss: 0.3077, d_k_M range: [0.0058, 0.5539], d_k_M_hat range: [0.9346, 0.9992]
2025-03-11 20:42:10 - Train Iteration 7178: loss: 0.1714, d_k_M range: [0.0002, 0.0722], d_k_M_hat range: [0.5867, 0.8812]
2025-03-11 20:42:10 - Train Iteration 7179: loss: 0.0893, d_k_M range: [0.0010, 0.2225], d_k_M_hat range: [0.7021, 0.9958]
2025-03-11 20:42:11 - Train Iteration 7180: loss: 0.2194, d_k_M range: [0.0071, 0.4677], d_k_M_hat range: [0.6430, 0.9993]
2025-03-11 20:42:11 - Train Iteration 7181: loss: 0.1921, d_k_M range: [0.0002, 0.3540], d_k_M_hat range: [0.5619, 0.9839]
2025-03-11 20:42:11 - Train Iteration 7182: loss: 0.2192, d_k_M range: [0.0027, 0.4668], d_k_M_hat range: [0.5351, 0.9986]
2025-03-11 20:42:12 - Train Iteration 7183: loss: 0.1988, d_k_M range: [0.0010, 0.4452], d_k_M_hat range: [0.6992, 0.9994]
2025-03-11 20:42:12 - Train Iteration 7184: loss: 0.1917, d_k_M range: [0.0106, 0.4086], d_k_M_hat range: [0.5918, 0.9707]
2025-03-11 20:42:13 - Train Iteration 7185: loss: 0.3263, d_k_M range: [0.0008, 0.4131], d_k_M_hat range: [0.4296, 0.9867]
2025-03-11 20:42:13 - Train Iteration 7186: loss: 0.0998, d_k_M range: [0.0211, 0.2946], d_k_M_hat range: [0.7231, 0.9947]
2025-03-11 20:42:13 - Train Iteration 7187: loss: 0.2429, d_k_M range: [0.0004, 0.1678], d_k_M_hat range: [0.5075, 0.9259]
2025-03-11 20:42:14 - Train Iteration 7188: loss: 0.1966, d_k_M range: [0.0003, 0.4273], d_k_M_hat range: [0.6459, 0.9980]
2025-03-11 20:42:14 - Train Iteration 7189: loss: 0.1806, d_k_M range: [0.0002, 0.1203], d_k_M_hat range: [0.5814, 0.9643]
2025-03-11 20:42:15 - Train Iteration 7190: loss: 0.2624, d_k_M range: [0.0012, 0.5091], d_k_M_hat range: [0.6363, 0.9969]
2025-03-11 20:42:15 - Train Iteration 7191: loss: 0.2264, d_k_M range: [0.0017, 0.4681], d_k_M_hat range: [0.5584, 0.9984]
2025-03-11 20:42:16 - Train Iteration 7192: loss: 0.1204, d_k_M range: [0.0005, 0.0362], d_k_M_hat range: [0.6535, 0.9706]
2025-03-11 20:42:16 - Train Iteration 7193: loss: 0.2477, d_k_M range: [0.0006, 0.0368], d_k_M_hat range: [0.5031, 0.9389]
2025-03-11 20:42:16 - Train Iteration 7194: loss: 0.1246, d_k_M range: [0.0015, 0.3303], d_k_M_hat range: [0.6485, 0.9975]
2025-03-11 20:42:17 - Train Iteration 7195: loss: 0.2637, d_k_M range: [0.0001, 0.0578], d_k_M_hat range: [0.5443, 0.9303]
2025-03-11 20:42:17 - Train Iteration 7196: loss: 0.3270, d_k_M range: [0.0018, 0.5704], d_k_M_hat range: [0.8421, 0.9988]
2025-03-11 20:42:17 - Train Iteration 7197: loss: 0.1717, d_k_M range: [0.0167, 0.4120], d_k_M_hat range: [0.8921, 0.9990]
2025-03-11 20:42:18 - Train Iteration 7198: loss: 0.1879, d_k_M range: [0.0001, 0.3322], d_k_M_hat range: [0.5673, 0.9752]
2025-03-11 20:42:18 - Train Iteration 7199: loss: 0.1857, d_k_M range: [0.0001, 0.3650], d_k_M_hat range: [0.5732, 0.9850]
2025-03-11 20:42:19 - Train Iteration 7200: loss: 0.3729, d_k_M range: [0.0103, 0.6098], d_k_M_hat range: [0.7025, 0.9992]
2025-03-11 20:42:19 - Train Iteration 7201: loss: 0.2148, d_k_M range: [0.0005, 0.1854], d_k_M_hat range: [0.5371, 0.9831]
2025-03-11 20:42:19 - Train Iteration 7202: loss: 0.3248, d_k_M range: [0.0002, 0.5669], d_k_M_hat range: [0.6836, 0.9970]
2025-03-11 20:42:20 - Train Iteration 7203: loss: 0.2398, d_k_M range: [0.0010, 0.4757], d_k_M_hat range: [0.8055, 0.9860]
2025-03-11 20:42:20 - Train Iteration 7204: loss: 0.3026, d_k_M range: [0.0000, 0.5442], d_k_M_hat range: [0.4693, 0.9942]
2025-03-11 20:42:21 - Train Iteration 7205: loss: 0.1426, d_k_M range: [0.0024, 0.3205], d_k_M_hat range: [0.6248, 0.9640]
2025-03-11 20:42:21 - Train Iteration 7206: loss: 0.1669, d_k_M range: [0.0008, 0.2594], d_k_M_hat range: [0.5926, 0.9525]
2025-03-11 20:42:22 - Train Iteration 7207: loss: 0.2212, d_k_M range: [0.0058, 0.4642], d_k_M_hat range: [0.6590, 0.9939]
2025-03-11 20:42:22 - Train Iteration 7208: loss: 0.1742, d_k_M range: [0.0033, 0.3970], d_k_M_hat range: [0.7960, 0.9932]
2025-03-11 20:42:22 - Train Iteration 7209: loss: 0.1629, d_k_M range: [0.0012, 0.2022], d_k_M_hat range: [0.5976, 0.8997]
2025-03-11 20:42:23 - Train Iteration 7210: loss: 0.5503, d_k_M range: [0.0166, 0.7417], d_k_M_hat range: [0.5894, 0.9999]
2025-03-11 20:42:23 - Train Iteration 7211: loss: 0.2146, d_k_M range: [0.0007, 0.4272], d_k_M_hat range: [0.5394, 0.9641]
2025-03-11 20:42:24 - Train Iteration 7212: loss: 0.1610, d_k_M range: [0.0012, 0.3276], d_k_M_hat range: [0.6584, 0.9895]
2025-03-11 20:42:24 - Train Iteration 7213: loss: 0.1195, d_k_M range: [0.0010, 0.0300], d_k_M_hat range: [0.6553, 0.9754]
2025-03-11 20:42:25 - Train Iteration 7214: loss: 0.2463, d_k_M range: [0.0034, 0.4900], d_k_M_hat range: [0.8436, 0.9965]
2025-03-11 20:42:25 - Train Iteration 7215: loss: 0.2713, d_k_M range: [0.0000, 0.1491], d_k_M_hat range: [0.4792, 0.9573]
2025-03-11 20:42:25 - Train Iteration 7216: loss: 0.2078, d_k_M range: [0.0031, 0.3803], d_k_M_hat range: [0.5781, 0.9922]
2025-03-11 20:42:26 - Train Iteration 7217: loss: 0.7067, d_k_M range: [0.0016, 0.8405], d_k_M_hat range: [0.7035, 0.9999]
2025-03-11 20:42:26 - Train Iteration 7218: loss: 0.2929, d_k_M range: [0.0000, 0.5405], d_k_M_hat range: [0.4887, 0.9992]
2025-03-11 20:42:27 - Train Iteration 7219: loss: 0.3022, d_k_M range: [0.0004, 0.0928], d_k_M_hat range: [0.4507, 0.9093]
2025-03-11 20:42:27 - Train Iteration 7220: loss: 0.1643, d_k_M range: [0.0005, 0.4001], d_k_M_hat range: [0.6199, 0.9948]
2025-03-11 20:42:27 - Train Iteration 7221: loss: 0.2328, d_k_M range: [0.0010, 0.2232], d_k_M_hat range: [0.5186, 0.9972]
2025-03-11 20:42:28 - Train Iteration 7222: loss: 0.1496, d_k_M range: [0.0006, 0.3862], d_k_M_hat range: [0.7728, 0.9995]
2025-03-11 20:42:28 - Train Iteration 7223: loss: 0.2244, d_k_M range: [0.0001, 0.3960], d_k_M_hat range: [0.5264, 0.9692]
2025-03-11 20:42:28 - Train Iteration 7224: loss: 0.3551, d_k_M range: [0.0008, 0.5946], d_k_M_hat range: [0.6874, 0.9987]
2025-03-11 20:42:29 - Train Iteration 7225: loss: 0.1224, d_k_M range: [0.0001, 0.0696], d_k_M_hat range: [0.6502, 0.9725]
2025-03-11 20:42:29 - Train Iteration 7226: loss: 0.1360, d_k_M range: [0.0001, 0.3156], d_k_M_hat range: [0.6313, 0.9941]
2025-03-11 20:42:30 - Train Iteration 7227: loss: 0.3940, d_k_M range: [0.0031, 0.6263], d_k_M_hat range: [0.6369, 1.0000]
2025-03-11 20:42:30 - Train Iteration 7228: loss: 0.2034, d_k_M range: [0.0007, 0.3735], d_k_M_hat range: [0.5497, 0.9928]
2025-03-11 20:42:30 - Train Iteration 7229: loss: 0.3719, d_k_M range: [0.0013, 0.6086], d_k_M_hat range: [0.5548, 0.9987]
2025-03-11 20:42:31 - Train Iteration 7230: loss: 0.3119, d_k_M range: [0.0001, 0.5550], d_k_M_hat range: [0.5982, 0.9965]
2025-03-11 20:42:31 - Train Iteration 7231: loss: 0.2123, d_k_M range: [0.0002, 0.4539], d_k_M_hat range: [0.6966, 0.9983]
2025-03-11 20:42:32 - Train Iteration 7232: loss: 0.3235, d_k_M range: [0.0000, 0.3601], d_k_M_hat range: [0.4312, 0.9941]
2025-03-11 20:42:32 - Train Iteration 7233: loss: 0.1305, d_k_M range: [0.0001, 0.2991], d_k_M_hat range: [0.6388, 0.9870]
2025-03-11 20:42:32 - Train Iteration 7234: loss: 0.2898, d_k_M range: [0.0003, 0.4694], d_k_M_hat range: [0.6337, 0.9885]
2025-03-11 20:42:33 - Train Iteration 7235: loss: 0.2669, d_k_M range: [0.0003, 0.2472], d_k_M_hat range: [0.4850, 0.9866]
2025-03-11 20:42:33 - Train Iteration 7236: loss: 0.2416, d_k_M range: [0.0000, 0.4908], d_k_M_hat range: [0.6837, 0.9992]
2025-03-11 20:42:34 - Train Iteration 7237: loss: 0.5412, d_k_M range: [0.0001, 0.3123], d_k_M_hat range: [0.2644, 0.9782]
2025-03-11 20:42:34 - Train Iteration 7238: loss: 0.3283, d_k_M range: [0.0176, 0.5728], d_k_M_hat range: [0.8648, 0.9999]
2025-03-11 20:42:35 - Train Iteration 7239: loss: 0.1194, d_k_M range: [0.0002, 0.3096], d_k_M_hat range: [0.7318, 0.9767]
2025-03-11 20:42:35 - Train Iteration 7240: loss: 0.1473, d_k_M range: [0.0023, 0.3800], d_k_M_hat range: [0.7500, 0.9962]
2025-03-11 20:42:35 - Train Iteration 7241: loss: 0.2032, d_k_M range: [0.0003, 0.4489], d_k_M_hat range: [0.6980, 0.9981]
2025-03-11 20:42:36 - Train Iteration 7242: loss: 0.2987, d_k_M range: [0.0139, 0.5446], d_k_M_hat range: [0.7447, 0.9981]
2025-03-11 20:42:36 - Train Iteration 7243: loss: 0.1170, d_k_M range: [0.0015, 0.3292], d_k_M_hat range: [0.6742, 0.9974]
2025-03-11 20:42:37 - Train Iteration 7244: loss: 0.7317, d_k_M range: [0.0038, 0.8544], d_k_M_hat range: [0.6242, 0.9993]
2025-03-11 20:42:37 - Train Iteration 7245: loss: 0.1612, d_k_M range: [0.0023, 0.3628], d_k_M_hat range: [0.7230, 0.9752]
2025-03-11 20:42:37 - Train Iteration 7246: loss: 0.3205, d_k_M range: [0.0002, 0.3236], d_k_M_hat range: [0.4341, 0.9947]
2025-03-11 20:42:38 - Train Iteration 7247: loss: 0.2104, d_k_M range: [0.0001, 0.2393], d_k_M_hat range: [0.5415, 0.9658]
2025-03-11 20:42:38 - Train Iteration 7248: loss: 0.2027, d_k_M range: [0.0000, 0.3817], d_k_M_hat range: [0.5498, 0.9974]
2025-03-11 20:42:39 - Train Iteration 7249: loss: 0.4288, d_k_M range: [0.0133, 0.6538], d_k_M_hat range: [0.6907, 0.9998]
2025-03-11 20:42:39 - Train Iteration 7250: loss: 0.3970, d_k_M range: [0.0002, 0.1909], d_k_M_hat range: [0.3701, 0.9612]
2025-03-11 20:42:39 - Train Iteration 7251: loss: 0.2319, d_k_M range: [0.0151, 0.4786], d_k_M_hat range: [0.7932, 0.9970]
2025-03-11 20:42:40 - Train Iteration 7252: loss: 0.3718, d_k_M range: [0.0005, 0.2973], d_k_M_hat range: [0.3908, 0.9974]
2025-03-11 20:42:40 - Train Iteration 7253: loss: 0.2046, d_k_M range: [0.0086, 0.4504], d_k_M_hat range: [0.5877, 0.9981]
2025-03-11 20:42:41 - Train Iteration 7254: loss: 0.2562, d_k_M range: [0.0001, 0.4665], d_k_M_hat range: [0.4940, 0.9980]
2025-03-11 20:42:41 - Train Iteration 7255: loss: 0.2330, d_k_M range: [0.0187, 0.4742], d_k_M_hat range: [0.8210, 0.9954]
2025-03-11 20:42:41 - Train Iteration 7256: loss: 0.1487, d_k_M range: [0.0008, 0.1663], d_k_M_hat range: [0.6160, 0.9878]
2025-03-11 20:42:42 - Train Iteration 7257: loss: 0.3431, d_k_M range: [0.0053, 0.5857], d_k_M_hat range: [0.7757, 0.9999]
2025-03-11 20:42:42 - Train Iteration 7258: loss: 0.2859, d_k_M range: [0.0013, 0.2527], d_k_M_hat range: [0.5269, 0.9825]
2025-03-11 20:42:43 - Train Iteration 7259: loss: 0.1665, d_k_M range: [0.0000, 0.2512], d_k_M_hat range: [0.5923, 0.9989]
2025-03-11 20:42:43 - Train Iteration 7260: loss: 0.1709, d_k_M range: [0.0081, 0.4037], d_k_M_hat range: [0.7122, 0.9961]
2025-03-11 20:42:43 - Train Iteration 7261: loss: 0.1946, d_k_M range: [0.0000, 0.4051], d_k_M_hat range: [0.5978, 0.9668]
2025-03-11 20:42:44 - Train Iteration 7262: loss: 0.1943, d_k_M range: [0.0005, 0.1867], d_k_M_hat range: [0.5597, 0.9735]
2025-03-11 20:42:44 - Train Iteration 7263: loss: 0.2679, d_k_M range: [0.0029, 0.5085], d_k_M_hat range: [0.7008, 0.9969]
2025-03-11 20:42:45 - Train Iteration 7264: loss: 0.1780, d_k_M range: [0.0003, 0.4021], d_k_M_hat range: [0.7499, 0.9802]
2025-03-11 20:42:45 - Train Iteration 7265: loss: 0.2987, d_k_M range: [0.0000, 0.0411], d_k_M_hat range: [0.4537, 0.9576]
2025-03-11 20:42:45 - Train Iteration 7266: loss: 0.1173, d_k_M range: [0.0006, 0.3173], d_k_M_hat range: [0.6616, 0.9935]
2025-03-11 20:42:46 - Train Iteration 7267: loss: 0.0652, d_k_M range: [0.0026, 0.2225], d_k_M_hat range: [0.8105, 0.9858]
2025-03-11 20:42:46 - Train Iteration 7268: loss: 0.2352, d_k_M range: [0.0000, 0.1827], d_k_M_hat range: [0.5154, 0.9814]
2025-03-11 20:42:47 - Train Iteration 7269: loss: 0.2907, d_k_M range: [0.0013, 0.5371], d_k_M_hat range: [0.6242, 0.9980]
2025-03-11 20:42:47 - Train Iteration 7270: loss: 0.1744, d_k_M range: [0.0002, 0.1889], d_k_M_hat range: [0.5825, 0.9982]
2025-03-11 20:42:48 - Train Iteration 7271: loss: 0.1214, d_k_M range: [0.0008, 0.2904], d_k_M_hat range: [0.6523, 0.9936]
2025-03-11 20:42:48 - Train Iteration 7272: loss: 0.5478, d_k_M range: [0.0040, 0.7398], d_k_M_hat range: [0.5867, 1.0000]
2025-03-11 20:42:48 - Train Iteration 7273: loss: 0.1152, d_k_M range: [0.0018, 0.0750], d_k_M_hat range: [0.6635, 0.9261]
2025-03-11 20:42:49 - Train Iteration 7274: loss: 0.2386, d_k_M range: [0.0088, 0.4877], d_k_M_hat range: [0.8271, 0.9992]
2025-03-11 20:42:49 - Train Iteration 7275: loss: 0.2621, d_k_M range: [0.0000, 0.3004], d_k_M_hat range: [0.4881, 0.9684]
2025-03-11 20:42:50 - Train Iteration 7276: loss: 0.2354, d_k_M range: [0.0012, 0.2325], d_k_M_hat range: [0.5633, 0.9858]
2025-03-11 20:42:50 - Train Iteration 7277: loss: 0.1834, d_k_M range: [0.0001, 0.4251], d_k_M_hat range: [0.7029, 0.9968]
2025-03-11 20:42:50 - Train Iteration 7278: loss: 0.2338, d_k_M range: [0.0002, 0.4763], d_k_M_hat range: [0.6543, 0.9927]
2025-03-11 20:42:51 - Train Iteration 7279: loss: 0.3407, d_k_M range: [0.0001, 0.1817], d_k_M_hat range: [0.4166, 0.9250]
2025-03-11 20:42:51 - Train Iteration 7280: loss: 0.3526, d_k_M range: [0.0099, 0.5934], d_k_M_hat range: [0.8737, 0.9995]
2025-03-11 20:42:52 - Train Iteration 7281: loss: 0.2146, d_k_M range: [0.0025, 0.4453], d_k_M_hat range: [0.6961, 0.9945]
2025-03-11 20:42:52 - Train Iteration 7282: loss: 0.3100, d_k_M range: [0.0000, 0.2124], d_k_M_hat range: [0.4432, 0.9222]
2025-03-11 20:42:52 - Train Iteration 7283: loss: 0.0784, d_k_M range: [0.0002, 0.2757], d_k_M_hat range: [0.7300, 0.9956]
2025-03-11 20:42:53 - Train Iteration 7284: loss: 0.2640, d_k_M range: [0.0003, 0.2048], d_k_M_hat range: [0.4866, 0.9864]
2025-03-11 20:42:53 - Train Iteration 7285: loss: 0.2730, d_k_M range: [0.0047, 0.5204], d_k_M_hat range: [0.8217, 0.9979]
2025-03-11 20:42:53 - Train Iteration 7286: loss: 0.1898, d_k_M range: [0.0001, 0.4200], d_k_M_hat range: [0.5649, 0.9897]
2025-03-11 20:42:54 - Train Iteration 7287: loss: 0.1938, d_k_M range: [0.0001, 0.3203], d_k_M_hat range: [0.6429, 0.9956]
2025-03-11 20:42:54 - Train Iteration 7288: loss: 0.2309, d_k_M range: [0.0013, 0.4726], d_k_M_hat range: [0.5918, 0.9920]
2025-03-11 20:42:55 - Train Iteration 7289: loss: 0.2219, d_k_M range: [0.0004, 0.3217], d_k_M_hat range: [0.5295, 0.9979]
2025-03-11 20:42:55 - Train Iteration 7290: loss: 0.3647, d_k_M range: [0.0000, 0.0150], d_k_M_hat range: [0.3961, 0.9332]
2025-03-11 20:42:55 - Train Iteration 7291: loss: 0.4368, d_k_M range: [0.0024, 0.6607], d_k_M_hat range: [0.9729, 0.9998]
2025-03-11 20:42:56 - Train Iteration 7292: loss: 0.3283, d_k_M range: [0.0029, 0.5702], d_k_M_hat range: [0.7701, 0.9991]
2025-03-11 20:42:56 - Train Iteration 7293: loss: 0.2389, d_k_M range: [0.0010, 0.4857], d_k_M_hat range: [0.5713, 0.9969]
2025-03-11 20:42:57 - Train Iteration 7294: loss: 0.1494, d_k_M range: [0.0003, 0.3638], d_k_M_hat range: [0.6139, 0.9949]
2025-03-11 20:42:57 - Train Iteration 7295: loss: 0.1937, d_k_M range: [0.0004, 0.0957], d_k_M_hat range: [0.5624, 0.9015]
2025-03-11 20:42:57 - Train Iteration 7296: loss: 0.2545, d_k_M range: [0.0045, 0.5031], d_k_M_hat range: [0.6708, 0.9986]
2025-03-11 20:42:58 - Train Iteration 7297: loss: 0.1807, d_k_M range: [0.0000, 0.1263], d_k_M_hat range: [0.5750, 0.9851]
2025-03-11 20:42:58 - Train Iteration 7298: loss: 0.1531, d_k_M range: [0.0024, 0.2415], d_k_M_hat range: [0.6151, 0.9948]
2025-03-11 20:42:59 - Train Iteration 7299: loss: 0.1201, d_k_M range: [0.0032, 0.1546], d_k_M_hat range: [0.6567, 0.9912]
2025-03-11 20:42:59 - Train Iteration 7300: loss: 0.3563, d_k_M range: [0.0020, 0.5941], d_k_M_hat range: [0.6321, 0.9971]
2025-03-11 20:43:00 - Train Iteration 7301: loss: 0.1607, d_k_M range: [0.0004, 0.0924], d_k_M_hat range: [0.5996, 0.9692]
2025-03-11 20:43:00 - Train Iteration 7302: loss: 0.2557, d_k_M range: [0.0051, 0.4923], d_k_M_hat range: [0.8999, 0.9970]
2025-03-11 20:43:00 - Train Iteration 7303: loss: 0.3691, d_k_M range: [0.0001, 0.0264], d_k_M_hat range: [0.3925, 0.7599]
2025-03-11 20:43:01 - Train Iteration 7304: loss: 0.1967, d_k_M range: [0.0018, 0.4394], d_k_M_hat range: [0.9165, 0.9973]
2025-03-11 20:43:01 - Train Iteration 7305: loss: 0.2085, d_k_M range: [0.0003, 0.0359], d_k_M_hat range: [0.5437, 0.9229]
2025-03-11 20:43:01 - Train Iteration 7306: loss: 0.4946, d_k_M range: [0.0064, 0.7000], d_k_M_hat range: [0.6879, 0.9967]
2025-03-11 20:43:02 - Train Iteration 7307: loss: 0.2105, d_k_M range: [0.0001, 0.1909], d_k_M_hat range: [0.5413, 0.9788]
2025-03-11 20:43:02 - Train Iteration 7308: loss: 0.1267, d_k_M range: [0.0002, 0.3347], d_k_M_hat range: [0.6496, 0.9946]
2025-03-11 20:43:03 - Train Iteration 7309: loss: 0.0830, d_k_M range: [0.0012, 0.2773], d_k_M_hat range: [0.7163, 0.9968]
2025-03-11 20:43:03 - Train Iteration 7310: loss: 0.2328, d_k_M range: [0.0000, 0.1677], d_k_M_hat range: [0.5195, 0.9663]
2025-03-11 20:43:03 - Train Iteration 7311: loss: 0.2581, d_k_M range: [0.0012, 0.5069], d_k_M_hat range: [0.8526, 0.9988]
2025-03-11 20:43:04 - Train Iteration 7312: loss: 0.3903, d_k_M range: [0.0001, 0.2429], d_k_M_hat range: [0.3754, 0.9726]
2025-03-11 20:43:04 - Train Iteration 7313: loss: 0.2074, d_k_M range: [0.0010, 0.4536], d_k_M_hat range: [0.7212, 0.9982]
2025-03-11 20:43:05 - Train Iteration 7314: loss: 0.2743, d_k_M range: [0.0004, 0.4165], d_k_M_hat range: [0.4766, 0.9913]
2025-03-11 20:43:05 - Train Iteration 7315: loss: 0.4555, d_k_M range: [0.0002, 0.6737], d_k_M_hat range: [0.5578, 0.9988]
2025-03-11 20:43:06 - Train Iteration 7316: loss: 0.2832, d_k_M range: [0.0043, 0.5003], d_k_M_hat range: [0.6917, 0.9681]
2025-03-11 20:43:06 - Train Iteration 7317: loss: 0.1105, d_k_M range: [0.0016, 0.2951], d_k_M_hat range: [0.6691, 0.9811]
2025-03-11 20:43:06 - Train Iteration 7318: loss: 0.1914, d_k_M range: [0.0000, 0.1545], d_k_M_hat range: [0.5707, 0.9074]
2025-03-11 20:43:07 - Train Iteration 7319: loss: 0.1548, d_k_M range: [0.0000, 0.1988], d_k_M_hat range: [0.6066, 0.9936]
2025-03-11 20:43:07 - Train Iteration 7320: loss: 0.1101, d_k_M range: [0.0003, 0.3052], d_k_M_hat range: [0.6916, 0.9902]
2025-03-11 20:43:08 - Train Iteration 7321: loss: 0.2476, d_k_M range: [0.0002, 0.0082], d_k_M_hat range: [0.5026, 0.8138]
2025-03-11 20:43:08 - Train Iteration 7322: loss: 0.2835, d_k_M range: [0.0001, 0.5264], d_k_M_hat range: [0.5070, 0.9939]
2025-03-11 20:43:09 - Train Iteration 7323: loss: 0.1394, d_k_M range: [0.0018, 0.3692], d_k_M_hat range: [0.7025, 0.9958]
2025-03-11 20:43:09 - Train Iteration 7324: loss: 0.2286, d_k_M range: [0.0019, 0.4662], d_k_M_hat range: [0.7342, 0.9880]
2025-03-11 20:43:09 - Train Iteration 7325: loss: 0.2640, d_k_M range: [0.0002, 0.0906], d_k_M_hat range: [0.4865, 0.9578]
2025-03-11 20:43:10 - Train Iteration 7326: loss: 0.1092, d_k_M range: [0.0065, 0.1985], d_k_M_hat range: [0.6760, 0.9703]
2025-03-11 20:43:10 - Train Iteration 7327: loss: 0.1716, d_k_M range: [0.0005, 0.4120], d_k_M_hat range: [0.7143, 0.9977]
2025-03-11 20:43:11 - Train Iteration 7328: loss: 0.2095, d_k_M range: [0.0013, 0.4534], d_k_M_hat range: [0.6455, 0.9956]
2025-03-11 20:43:11 - Train Iteration 7329: loss: 0.2799, d_k_M range: [0.0000, 0.2725], d_k_M_hat range: [0.4709, 0.9935]
2025-03-11 20:43:11 - Train Iteration 7330: loss: 0.1657, d_k_M range: [0.0202, 0.4005], d_k_M_hat range: [0.8564, 0.9935]
2025-03-11 20:43:12 - Train Iteration 7331: loss: 0.1363, d_k_M range: [0.0005, 0.3632], d_k_M_hat range: [0.6963, 0.9940]
2025-03-11 20:43:12 - Train Iteration 7332: loss: 0.2514, d_k_M range: [0.0005, 0.4818], d_k_M_hat range: [0.6654, 0.9945]
2025-03-11 20:43:12 - Train Iteration 7333: loss: 0.2050, d_k_M range: [0.0000, 0.3554], d_k_M_hat range: [0.5474, 0.9734]
2025-03-11 20:43:13 - Train Iteration 7334: loss: 0.3787, d_k_M range: [0.0000, 0.2233], d_k_M_hat range: [0.3847, 0.9963]
2025-03-11 20:43:13 - Train Iteration 7335: loss: 0.3578, d_k_M range: [0.0036, 0.5944], d_k_M_hat range: [0.9184, 0.9990]
2025-03-11 20:43:14 - Train Iteration 7336: loss: 0.2901, d_k_M range: [0.0000, 0.2879], d_k_M_hat range: [0.4615, 0.9806]
2025-03-11 20:43:14 - Train Iteration 7337: loss: 0.5561, d_k_M range: [0.0058, 0.7453], d_k_M_hat range: [0.8522, 0.9996]
2025-03-11 20:43:14 - Train Iteration 7338: loss: 0.6146, d_k_M range: [0.0017, 0.3726], d_k_M_hat range: [0.2178, 0.9765]
2025-03-11 20:43:15 - Train Iteration 7339: loss: 0.4821, d_k_M range: [0.0000, 0.2376], d_k_M_hat range: [0.3057, 0.9964]
2025-03-11 20:43:15 - Train Iteration 7340: loss: 0.3160, d_k_M range: [0.0003, 0.5565], d_k_M_hat range: [0.8365, 0.9968]
2025-03-11 20:43:16 - Train Iteration 7341: loss: 0.2350, d_k_M range: [0.0025, 0.4762], d_k_M_hat range: [0.5731, 0.9973]
2025-03-11 20:43:16 - Train Iteration 7342: loss: 0.1524, d_k_M range: [0.0001, 0.0865], d_k_M_hat range: [0.6106, 0.9078]
2025-03-11 20:43:16 - Train Iteration 7343: loss: 0.1987, d_k_M range: [0.0014, 0.4385], d_k_M_hat range: [0.6463, 0.9966]
2025-03-11 20:43:17 - Train Iteration 7344: loss: 0.2109, d_k_M range: [0.0001, 0.0365], d_k_M_hat range: [0.5428, 0.9903]
2025-03-11 20:43:17 - Train Iteration 7345: loss: 0.1690, d_k_M range: [0.0006, 0.2566], d_k_M_hat range: [0.8421, 0.9679]
2025-03-11 20:43:18 - Train Iteration 7346: loss: 0.3499, d_k_M range: [0.0001, 0.0892], d_k_M_hat range: [0.4086, 0.9860]
2025-03-11 20:43:18 - Train Iteration 7347: loss: 0.5653, d_k_M range: [0.0025, 0.7513], d_k_M_hat range: [0.7534, 0.9994]
2025-03-11 20:43:18 - Train Iteration 7348: loss: 0.5169, d_k_M range: [0.0000, 0.0157], d_k_M_hat range: [0.2810, 0.9291]
2025-03-11 20:43:19 - Train Iteration 7349: loss: 0.1457, d_k_M range: [0.0047, 0.2530], d_k_M_hat range: [0.6230, 0.9838]
2025-03-11 20:43:19 - Train Iteration 7350: loss: 0.1483, d_k_M range: [0.0018, 0.3283], d_k_M_hat range: [0.6639, 0.9835]
2025-03-11 20:43:20 - Train Iteration 7351: loss: 0.3610, d_k_M range: [0.0270, 0.6005], d_k_M_hat range: [0.8572, 0.9997]
2025-03-11 20:43:20 - Train Iteration 7352: loss: 0.2520, d_k_M range: [0.0037, 0.4994], d_k_M_hat range: [0.6397, 0.9974]
2025-03-11 20:43:20 - Train Iteration 7353: loss: 0.2498, d_k_M range: [0.0020, 0.4961], d_k_M_hat range: [0.8114, 0.9962]
2025-03-11 20:43:21 - Train Iteration 7354: loss: 0.2072, d_k_M range: [0.0005, 0.4525], d_k_M_hat range: [0.5821, 0.9973]
2025-03-11 20:43:21 - Train Iteration 7355: loss: 0.2061, d_k_M range: [0.0028, 0.4501], d_k_M_hat range: [0.6997, 0.9961]
2025-03-11 20:43:22 - Train Iteration 7356: loss: 0.3577, d_k_M range: [0.0000, 0.4504], d_k_M_hat range: [0.4020, 0.9964]
2025-03-11 20:43:22 - Train Iteration 7357: loss: 0.2613, d_k_M range: [0.0005, 0.5097], d_k_M_hat range: [0.5736, 0.9985]
2025-03-11 20:43:22 - Train Iteration 7358: loss: 0.4977, d_k_M range: [0.0019, 0.7054], d_k_M_hat range: [0.6075, 0.9999]
2025-03-11 20:43:23 - Train Iteration 7359: loss: 0.1483, d_k_M range: [0.0008, 0.2704], d_k_M_hat range: [0.6570, 0.9925]
2025-03-11 20:43:23 - Train Iteration 7360: loss: 0.4611, d_k_M range: [0.0001, 0.5651], d_k_M_hat range: [0.3211, 0.9999]
2025-03-11 20:43:24 - Train Iteration 7361: loss: 0.2068, d_k_M range: [0.0003, 0.3734], d_k_M_hat range: [0.5534, 0.9938]
2025-03-11 20:43:24 - Train Iteration 7362: loss: 0.2284, d_k_M range: [0.0012, 0.4662], d_k_M_hat range: [0.5509, 0.9983]
2025-03-11 20:43:24 - Train Iteration 7363: loss: 0.1627, d_k_M range: [0.0040, 0.3893], d_k_M_hat range: [0.8968, 0.9914]
2025-03-11 20:43:25 - Train Iteration 7364: loss: 0.1633, d_k_M range: [0.0007, 0.3285], d_k_M_hat range: [0.7142, 0.9419]
2025-03-11 20:43:25 - Train Iteration 7365: loss: 0.2862, d_k_M range: [0.0001, 0.0293], d_k_M_hat range: [0.4652, 0.9277]
2025-03-11 20:43:25 - Train Iteration 7366: loss: 0.2006, d_k_M range: [0.0000, 0.2648], d_k_M_hat range: [0.5523, 0.9303]
2025-03-11 20:43:26 - Train Iteration 7367: loss: 0.3121, d_k_M range: [0.0001, 0.5324], d_k_M_hat range: [0.4522, 0.9842]
2025-03-11 20:43:26 - Train Iteration 7368: loss: 0.0890, d_k_M range: [0.0009, 0.2978], d_k_M_hat range: [0.8113, 0.9996]
2025-03-11 20:43:27 - Train Iteration 7369: loss: 0.1886, d_k_M range: [0.0008, 0.1209], d_k_M_hat range: [0.5916, 0.9954]
2025-03-11 20:43:27 - Train Iteration 7370: loss: 0.4738, d_k_M range: [0.0000, 0.6883], d_k_M_hat range: [0.6272, 1.0000]
2025-03-11 20:43:27 - Train Iteration 7371: loss: 0.2453, d_k_M range: [0.0007, 0.3147], d_k_M_hat range: [0.5054, 0.9765]
2025-03-11 20:43:28 - Train Iteration 7372: loss: 0.1125, d_k_M range: [0.0004, 0.2738], d_k_M_hat range: [0.6659, 0.9741]
2025-03-11 20:43:28 - Train Iteration 7373: loss: 0.3142, d_k_M range: [0.0001, 0.5560], d_k_M_hat range: [0.7104, 0.9994]
2025-03-11 20:43:29 - Train Iteration 7374: loss: 0.0887, d_k_M range: [0.0001, 0.1799], d_k_M_hat range: [0.7034, 0.9754]
2025-03-11 20:43:29 - Train Iteration 7375: loss: 0.3750, d_k_M range: [0.0013, 0.6114], d_k_M_hat range: [0.8465, 0.9990]
2025-03-11 20:43:29 - Train Iteration 7376: loss: 0.1471, d_k_M range: [0.0014, 0.0279], d_k_M_hat range: [0.6226, 0.9232]
2025-03-11 20:43:30 - Train Iteration 7377: loss: 0.2759, d_k_M range: [0.0025, 0.5243], d_k_M_hat range: [0.6530, 0.9991]
2025-03-11 20:43:30 - Train Iteration 7378: loss: 0.1561, d_k_M range: [0.0002, 0.3791], d_k_M_hat range: [0.6206, 0.9840]
2025-03-11 20:43:31 - Train Iteration 7379: loss: 0.2385, d_k_M range: [0.0003, 0.3475], d_k_M_hat range: [0.5120, 0.9905]
2025-03-11 20:43:31 - Train Iteration 7380: loss: 0.6018, d_k_M range: [0.0027, 0.7752], d_k_M_hat range: [0.7220, 0.9995]
2025-03-11 20:43:32 - Train Iteration 7381: loss: 0.2595, d_k_M range: [0.0000, 0.0171], d_k_M_hat range: [0.4909, 0.7673]
2025-03-11 20:43:32 - Train Iteration 7382: loss: 0.1945, d_k_M range: [0.0101, 0.4145], d_k_M_hat range: [0.7382, 0.9734]
2025-03-11 20:43:32 - Train Iteration 7383: loss: 0.0969, d_k_M range: [0.0007, 0.0828], d_k_M_hat range: [0.6900, 0.9701]
2025-03-11 20:43:33 - Train Iteration 7384: loss: 0.0590, d_k_M range: [0.0016, 0.1801], d_k_M_hat range: [0.7989, 0.9911]
2025-03-11 20:43:33 - Train Iteration 7385: loss: 0.1939, d_k_M range: [0.0016, 0.4268], d_k_M_hat range: [0.8474, 0.9981]
2025-03-11 20:43:33 - Train Iteration 7386: loss: 0.1981, d_k_M range: [0.0010, 0.4428], d_k_M_hat range: [0.5656, 0.9977]
2025-03-11 20:43:34 - Train Iteration 7387: loss: 0.2731, d_k_M range: [0.0023, 0.3310], d_k_M_hat range: [0.4798, 0.9947]
2025-03-11 20:43:34 - Train Iteration 7388: loss: 0.4876, d_k_M range: [0.0011, 0.6958], d_k_M_hat range: [0.6570, 0.9975]
2025-03-11 20:43:35 - Train Iteration 7389: loss: 0.3444, d_k_M range: [0.0002, 0.0397], d_k_M_hat range: [0.4133, 0.8096]
2025-03-11 20:43:35 - Train Iteration 7390: loss: 0.1041, d_k_M range: [0.0004, 0.2590], d_k_M_hat range: [0.6822, 0.9857]
2025-03-11 20:43:35 - Train Iteration 7391: loss: 0.1567, d_k_M range: [0.0000, 0.3599], d_k_M_hat range: [0.6220, 0.9830]
2025-03-11 20:43:36 - Train Iteration 7392: loss: 0.1996, d_k_M range: [0.0001, 0.4361], d_k_M_hat range: [0.5712, 0.9893]
2025-03-11 20:43:36 - Train Iteration 7393: loss: 0.3994, d_k_M range: [0.0000, 0.0168], d_k_M_hat range: [0.3681, 0.9238]
2025-03-11 20:43:37 - Train Iteration 7394: loss: 0.2363, d_k_M range: [0.0000, 0.4120], d_k_M_hat range: [0.5185, 0.9953]
2025-03-11 20:43:37 - Train Iteration 7395: loss: 0.1181, d_k_M range: [0.0002, 0.3377], d_k_M_hat range: [0.6618, 0.9941]
2025-03-11 20:43:37 - Train Iteration 7396: loss: 0.0799, d_k_M range: [0.0004, 0.1964], d_k_M_hat range: [0.7213, 0.9879]
2025-03-11 20:43:38 - Train Iteration 7397: loss: 0.1886, d_k_M range: [0.0031, 0.4320], d_k_M_hat range: [0.6080, 0.9986]
2025-03-11 20:43:38 - Train Iteration 7398: loss: 0.1956, d_k_M range: [0.0001, 0.1405], d_k_M_hat range: [0.5578, 0.9783]
2025-03-11 20:43:39 - Train Iteration 7399: loss: 0.3091, d_k_M range: [0.0134, 0.5503], d_k_M_hat range: [0.9392, 0.9999]
2025-03-11 20:43:39 - Train Iteration 7400: loss: 0.1521, d_k_M range: [0.0000, 0.2744], d_k_M_hat range: [0.6101, 0.9814]
2025-03-11 20:43:39 - Train Iteration 7401: loss: 0.1699, d_k_M range: [0.0005, 0.0180], d_k_M_hat range: [0.6058, 0.9754]
2025-03-11 20:43:40 - Train Iteration 7402: loss: 0.2050, d_k_M range: [0.0006, 0.4523], d_k_M_hat range: [0.8719, 0.9996]
2025-03-11 20:43:40 - Train Iteration 7403: loss: 0.2032, d_k_M range: [0.0001, 0.4505], d_k_M_hat range: [0.5632, 0.9997]
2025-03-11 20:43:41 - Train Iteration 7404: loss: 0.8557, d_k_M range: [0.0000, 0.4153], d_k_M_hat range: [0.0750, 0.9977]
2025-03-11 20:43:41 - Train Iteration 7405: loss: 0.2032, d_k_M range: [0.0026, 0.4489], d_k_M_hat range: [0.6724, 0.9982]
2025-03-11 20:43:41 - Train Iteration 7406: loss: 0.1462, d_k_M range: [0.0001, 0.2214], d_k_M_hat range: [0.6294, 0.9884]
2025-03-11 20:43:42 - Train Iteration 7407: loss: 0.3200, d_k_M range: [0.0032, 0.5642], d_k_M_hat range: [0.9628, 0.9991]
2025-03-11 20:43:42 - Train Iteration 7408: loss: 0.0829, d_k_M range: [0.0009, 0.1073], d_k_M_hat range: [0.7131, 0.9960]
2025-03-11 20:43:43 - Train Iteration 7409: loss: 0.4284, d_k_M range: [0.0000, 0.0236], d_k_M_hat range: [0.3459, 0.9735]
2025-03-11 20:43:43 - Train Iteration 7410: loss: 0.2927, d_k_M range: [0.0007, 0.0323], d_k_M_hat range: [0.4632, 0.9733]
2025-03-11 20:43:44 - Train Iteration 7411: loss: 0.1533, d_k_M range: [0.0001, 0.3776], d_k_M_hat range: [0.6100, 0.9860]
2025-03-11 20:43:44 - Train Iteration 7412: loss: 0.2660, d_k_M range: [0.0002, 0.0827], d_k_M_hat range: [0.4845, 0.9184]
2025-03-11 20:43:44 - Train Iteration 7413: loss: 0.1277, d_k_M range: [0.0001, 0.0627], d_k_M_hat range: [0.6427, 0.9861]
2025-03-11 20:43:45 - Train Iteration 7414: loss: 0.1507, d_k_M range: [0.0005, 0.3161], d_k_M_hat range: [0.6122, 0.9961]
2025-03-11 20:43:45 - Train Iteration 7415: loss: 0.1577, d_k_M range: [0.0005, 0.3790], d_k_M_hat range: [0.6038, 0.9902]
2025-03-11 20:43:45 - Train Iteration 7416: loss: 0.0711, d_k_M range: [0.0008, 0.1265], d_k_M_hat range: [0.7426, 0.9960]
2025-03-11 20:43:46 - Train Iteration 7417: loss: 0.2723, d_k_M range: [0.0015, 0.5217], d_k_M_hat range: [0.5261, 0.9999]
2025-03-11 20:43:46 - Train Iteration 7418: loss: 0.1174, d_k_M range: [0.0001, 0.0916], d_k_M_hat range: [0.6575, 0.9757]
2025-03-11 20:43:47 - Train Iteration 7419: loss: 0.4853, d_k_M range: [0.0005, 0.6963], d_k_M_hat range: [0.8830, 0.9997]
2025-03-11 20:43:47 - Train Iteration 7420: loss: 0.1823, d_k_M range: [0.0002, 0.1971], d_k_M_hat range: [0.5732, 0.9651]
2025-03-11 20:43:47 - Train Iteration 7421: loss: 0.6392, d_k_M range: [0.0287, 0.7988], d_k_M_hat range: [0.9581, 0.9993]
2025-03-11 20:43:48 - Train Iteration 7422: loss: 0.1175, d_k_M range: [0.0003, 0.3105], d_k_M_hat range: [0.8040, 0.9833]
2025-03-11 20:43:48 - Train Iteration 7423: loss: 0.1373, d_k_M range: [0.0012, 0.1387], d_k_M_hat range: [0.6563, 0.9723]
2025-03-11 20:43:49 - Train Iteration 7424: loss: 0.1694, d_k_M range: [0.0001, 0.2653], d_k_M_hat range: [0.5886, 0.9839]
2025-03-11 20:43:49 - Train Iteration 7425: loss: 0.1800, d_k_M range: [0.0001, 0.1081], d_k_M_hat range: [0.5758, 0.9568]
2025-03-11 20:43:49 - Train Iteration 7426: loss: 0.0819, d_k_M range: [0.0018, 0.2193], d_k_M_hat range: [0.7288, 0.9931]
2025-03-11 20:43:50 - Train Iteration 7427: loss: 0.3373, d_k_M range: [0.0005, 0.3813], d_k_M_hat range: [0.4197, 0.9977]
2025-03-11 20:43:50 - Train Iteration 7428: loss: 0.1207, d_k_M range: [0.0186, 0.2799], d_k_M_hat range: [0.8565, 0.9980]
2025-03-11 20:43:51 - Train Iteration 7429: loss: 0.2145, d_k_M range: [0.0000, 0.2021], d_k_M_hat range: [0.5370, 0.9900]
2025-03-11 20:43:51 - Train Iteration 7430: loss: 0.2180, d_k_M range: [0.0064, 0.4621], d_k_M_hat range: [0.8719, 0.9952]
2025-03-11 20:43:51 - Train Iteration 7431: loss: 0.1138, d_k_M range: [0.0004, 0.3174], d_k_M_hat range: [0.6681, 0.9973]
2025-03-11 20:43:52 - Train Iteration 7432: loss: 0.1780, d_k_M range: [0.0001, 0.2699], d_k_M_hat range: [0.5846, 0.9972]
2025-03-11 20:43:52 - Train Iteration 7433: loss: 0.1140, d_k_M range: [0.0043, 0.3323], d_k_M_hat range: [0.9111, 0.9980]
2025-03-11 20:43:53 - Train Iteration 7434: loss: 0.5095, d_k_M range: [0.0004, 0.1176], d_k_M_hat range: [0.2866, 0.9386]
2025-03-11 20:43:53 - Train Iteration 7435: loss: 0.2796, d_k_M range: [0.0210, 0.5268], d_k_M_hat range: [0.7492, 0.9988]
2025-03-11 20:43:54 - Train Iteration 7436: loss: 0.8705, d_k_M range: [0.0001, 0.1185], d_k_M_hat range: [0.0671, 0.9755]
2025-03-11 20:43:54 - Train Iteration 7437: loss: 0.1980, d_k_M range: [0.0007, 0.4311], d_k_M_hat range: [0.5967, 0.9965]
2025-03-11 20:43:54 - Train Iteration 7438: loss: 0.3605, d_k_M range: [0.0001, 0.2829], d_k_M_hat range: [0.4005, 0.9835]
2025-03-11 20:43:55 - Train Iteration 7439: loss: 0.1052, d_k_M range: [0.0014, 0.1223], d_k_M_hat range: [0.6822, 0.9906]
2025-03-11 20:43:55 - Train Iteration 7440: loss: 0.1814, d_k_M range: [0.0078, 0.4205], d_k_M_hat range: [0.9449, 0.9991]
2025-03-11 20:43:56 - Train Iteration 7441: loss: 0.3057, d_k_M range: [0.0000, 0.0115], d_k_M_hat range: [0.4516, 0.8865]
2025-03-11 20:43:56 - Train Iteration 7442: loss: 0.2164, d_k_M range: [0.0000, 0.0769], d_k_M_hat range: [0.5349, 0.9138]
2025-03-11 20:43:56 - Train Iteration 7443: loss: 0.1891, d_k_M range: [0.0000, 0.0538], d_k_M_hat range: [0.5652, 0.9593]
2025-03-11 20:43:57 - Train Iteration 7444: loss: 0.2652, d_k_M range: [0.0000, 0.4102], d_k_M_hat range: [0.4850, 0.9982]
2025-03-11 20:43:57 - Train Iteration 7445: loss: 0.2310, d_k_M range: [0.0096, 0.4012], d_k_M_hat range: [0.5310, 0.9938]
2025-03-11 20:43:57 - Train Iteration 7446: loss: 0.1969, d_k_M range: [0.0126, 0.4429], d_k_M_hat range: [0.9215, 0.9992]
2025-03-11 20:43:58 - Train Iteration 7447: loss: 0.2430, d_k_M range: [0.0000, 0.0746], d_k_M_hat range: [0.5076, 0.9593]
2025-03-11 20:43:58 - Train Iteration 7448: loss: 0.2424, d_k_M range: [0.0019, 0.4855], d_k_M_hat range: [0.9050, 0.9980]
2025-03-11 20:43:59 - Train Iteration 7449: loss: 0.1914, d_k_M range: [0.0022, 0.4285], d_k_M_hat range: [0.6348, 0.9936]
2025-03-11 20:43:59 - Train Iteration 7450: loss: 0.2212, d_k_M range: [0.0007, 0.4459], d_k_M_hat range: [0.5303, 0.9926]
2025-03-11 20:43:59 - Train Iteration 7451: loss: 0.7632, d_k_M range: [0.0001, 0.0373], d_k_M_hat range: [0.1265, 0.9624]
2025-03-11 20:44:00 - Train Iteration 7452: loss: 0.1777, d_k_M range: [0.0006, 0.4155], d_k_M_hat range: [0.6390, 0.9978]
2025-03-11 20:44:00 - Train Iteration 7453: loss: 0.1933, d_k_M range: [0.0000, 0.1577], d_k_M_hat range: [0.5640, 0.9697]
2025-03-11 20:44:01 - Train Iteration 7454: loss: 0.2873, d_k_M range: [0.0163, 0.5352], d_k_M_hat range: [0.8578, 0.9992]
2025-03-11 20:44:01 - Train Iteration 7455: loss: 0.1653, d_k_M range: [0.0000, 0.1986], d_k_M_hat range: [0.5934, 0.9845]
2025-03-11 20:44:01 - Train Iteration 7456: loss: 0.4735, d_k_M range: [0.0089, 0.6858], d_k_M_hat range: [0.7964, 0.9990]
2025-03-11 20:44:02 - Train Iteration 7457: loss: 0.0738, d_k_M range: [0.0000, 0.0626], d_k_M_hat range: [0.7284, 0.9950]
2025-03-11 20:44:02 - Train Iteration 7458: loss: 0.4477, d_k_M range: [0.0011, 0.6687], d_k_M_hat range: [0.5178, 0.9996]
2025-03-11 20:44:03 - Train Iteration 7459: loss: 0.1328, d_k_M range: [0.0001, 0.3564], d_k_M_hat range: [0.6723, 0.9919]
2025-03-11 20:44:03 - Train Iteration 7460: loss: 0.1351, d_k_M range: [0.0031, 0.3572], d_k_M_hat range: [0.7529, 0.9896]
2025-03-11 20:44:04 - Train Iteration 7461: loss: 0.5357, d_k_M range: [0.0000, 0.2209], d_k_M_hat range: [0.2686, 0.9826]
2025-03-11 20:44:04 - Train Iteration 7462: loss: 0.1050, d_k_M range: [0.0011, 0.2553], d_k_M_hat range: [0.6772, 0.9967]
2025-03-11 20:44:04 - Train Iteration 7463: loss: 0.1223, d_k_M range: [0.0003, 0.2527], d_k_M_hat range: [0.6605, 0.9466]
2025-03-11 20:44:05 - Train Iteration 7464: loss: 0.3211, d_k_M range: [0.0003, 0.5640], d_k_M_hat range: [0.7804, 0.9973]
2025-03-11 20:44:05 - Train Iteration 7465: loss: 0.5875, d_k_M range: [0.0000, 0.1881], d_k_M_hat range: [0.2335, 0.9794]
2025-03-11 20:44:05 - Train Iteration 7466: loss: 0.2570, d_k_M range: [0.0164, 0.4974], d_k_M_hat range: [0.9459, 0.9998]
2025-03-11 20:44:06 - Train Iteration 7467: loss: 0.2713, d_k_M range: [0.0001, 0.0421], d_k_M_hat range: [0.4800, 0.9260]
2025-03-11 20:44:06 - Train Iteration 7468: loss: 0.1216, d_k_M range: [0.0002, 0.3235], d_k_M_hat range: [0.6565, 0.9793]
2025-03-11 20:44:07 - Train Iteration 7469: loss: 0.1700, d_k_M range: [0.0004, 0.0554], d_k_M_hat range: [0.5881, 0.9107]
2025-03-11 20:44:07 - Train Iteration 7470: loss: 0.1931, d_k_M range: [0.0016, 0.4314], d_k_M_hat range: [0.7007, 0.9919]
2025-03-11 20:44:07 - Train Iteration 7471: loss: 0.2942, d_k_M range: [0.0001, 0.1596], d_k_M_hat range: [0.4577, 0.9893]
2025-03-11 20:44:08 - Train Iteration 7472: loss: 0.3750, d_k_M range: [0.0006, 0.6118], d_k_M_hat range: [0.6790, 0.9994]
2025-03-11 20:44:08 - Train Iteration 7473: loss: 0.3160, d_k_M range: [0.0001, 0.2849], d_k_M_hat range: [0.4380, 0.9977]
2025-03-11 20:44:09 - Train Iteration 7474: loss: 0.2955, d_k_M range: [0.0187, 0.5341], d_k_M_hat range: [0.9013, 0.9969]
2025-03-11 20:44:09 - Train Iteration 7475: loss: 0.0853, d_k_M range: [0.0002, 0.2261], d_k_M_hat range: [0.7483, 0.9862]
2025-03-11 20:44:09 - Train Iteration 7476: loss: 0.3292, d_k_M range: [0.0029, 0.5734], d_k_M_hat range: [0.6394, 0.9996]
2025-03-11 20:44:10 - Train Iteration 7477: loss: 0.2988, d_k_M range: [0.0000, 0.0495], d_k_M_hat range: [0.4632, 0.9348]
2025-03-11 20:44:10 - Train Iteration 7478: loss: 0.2571, d_k_M range: [0.0022, 0.5032], d_k_M_hat range: [0.6502, 0.9961]
2025-03-11 20:44:11 - Train Iteration 7479: loss: 0.2397, d_k_M range: [0.0006, 0.4882], d_k_M_hat range: [0.8197, 0.9995]
2025-03-11 20:44:11 - Train Iteration 7480: loss: 0.2665, d_k_M range: [0.0001, 0.1306], d_k_M_hat range: [0.4856, 0.8630]
2025-03-11 20:44:12 - Train Iteration 7481: loss: 0.2471, d_k_M range: [0.0066, 0.4888], d_k_M_hat range: [0.8771, 0.9917]
2025-03-11 20:44:12 - Train Iteration 7482: loss: 0.1806, d_k_M range: [0.0001, 0.1941], d_k_M_hat range: [0.5768, 0.9682]
2025-03-11 20:44:12 - Train Iteration 7483: loss: 0.1357, d_k_M range: [0.0000, 0.1258], d_k_M_hat range: [0.6319, 0.9889]
2025-03-11 20:44:13 - Train Iteration 7484: loss: 0.4169, d_k_M range: [0.0149, 0.6383], d_k_M_hat range: [0.7432, 0.9937]
2025-03-11 20:44:13 - Train Iteration 7485: loss: 0.1775, d_k_M range: [0.0001, 0.3998], d_k_M_hat range: [0.5901, 0.9784]
2025-03-11 20:44:14 - Train Iteration 7486: loss: 0.2305, d_k_M range: [0.0125, 0.4751], d_k_M_hat range: [0.8603, 0.9980]
2025-03-11 20:44:14 - Train Iteration 7487: loss: 0.3407, d_k_M range: [0.0005, 0.0734], d_k_M_hat range: [0.4170, 0.9960]
2025-03-11 20:44:14 - Train Iteration 7488: loss: 0.2018, d_k_M range: [0.0009, 0.4333], d_k_M_hat range: [0.6865, 0.9971]
2025-03-11 20:44:15 - Train Iteration 7489: loss: 0.0901, d_k_M range: [0.0003, 0.1623], d_k_M_hat range: [0.7025, 0.9664]
2025-03-11 20:44:15 - Train Iteration 7490: loss: 0.3037, d_k_M range: [0.0493, 0.5387], d_k_M_hat range: [0.9180, 0.9906]
2025-03-11 20:44:16 - Train Iteration 7491: loss: 0.1875, d_k_M range: [0.0001, 0.3242], d_k_M_hat range: [0.5673, 0.9927]
2025-03-11 20:44:16 - Train Iteration 7492: loss: 0.3608, d_k_M range: [0.0005, 0.6003], d_k_M_hat range: [0.5035, 0.9996]
2025-03-11 20:44:16 - Train Iteration 7493: loss: 0.1066, d_k_M range: [0.0072, 0.3211], d_k_M_hat range: [0.7021, 0.9946]
2025-03-11 20:44:17 - Train Iteration 7494: loss: 0.0640, d_k_M range: [0.0066, 0.2381], d_k_M_hat range: [0.7629, 0.9851]
2025-03-11 20:44:17 - Train Iteration 7495: loss: 0.1704, d_k_M range: [0.0041, 0.2848], d_k_M_hat range: [0.5913, 0.9975]
2025-03-11 20:44:17 - Train Iteration 7496: loss: 0.1496, d_k_M range: [0.0003, 0.3535], d_k_M_hat range: [0.6408, 0.9742]
2025-03-11 20:44:18 - Train Iteration 7497: loss: 0.2061, d_k_M range: [0.0002, 0.2807], d_k_M_hat range: [0.5462, 0.9882]
2025-03-11 20:44:18 - Train Iteration 7498: loss: 0.2655, d_k_M range: [0.0200, 0.5100], d_k_M_hat range: [0.8678, 0.9975]
2025-03-11 20:44:19 - Train Iteration 7499: loss: 0.3682, d_k_M range: [0.0004, 0.0532], d_k_M_hat range: [0.3958, 0.9392]
2025-03-11 20:44:19 - Train Iteration 7500: loss: 0.2457, d_k_M range: [0.0002, 0.4931], d_k_M_hat range: [0.6406, 0.9974]
2025-03-11 20:44:19 - Train Iteration 7501: loss: 0.2410, d_k_M range: [0.0018, 0.2590], d_k_M_hat range: [0.5114, 0.9919]
2025-03-11 20:44:20 - Train Iteration 7502: loss: 0.8091, d_k_M range: [0.0009, 0.8993], d_k_M_hat range: [0.7620, 0.9998]
2025-03-11 20:44:20 - Train Iteration 7503: loss: 0.3211, d_k_M range: [0.0000, 0.0272], d_k_M_hat range: [0.4333, 0.7634]
2025-03-11 20:44:20 - Train Iteration 7504: loss: 0.1882, d_k_M range: [0.0057, 0.4193], d_k_M_hat range: [0.6895, 0.9933]
2025-03-11 20:44:21 - Train Iteration 7505: loss: 0.2721, d_k_M range: [0.0003, 0.1187], d_k_M_hat range: [0.4805, 0.8739]
2025-03-11 20:44:21 - Train Iteration 7506: loss: 0.2060, d_k_M range: [0.0003, 0.4257], d_k_M_hat range: [0.5751, 0.9975]
2025-03-11 20:44:22 - Train Iteration 7507: loss: 0.2304, d_k_M range: [0.0111, 0.4758], d_k_M_hat range: [0.5847, 0.9959]
2025-03-11 20:44:22 - Train Iteration 7508: loss: 0.3034, d_k_M range: [0.0001, 0.5500], d_k_M_hat range: [0.5691, 0.9992]
2025-03-11 20:44:23 - Train Iteration 7509: loss: 0.1862, d_k_M range: [0.0000, 0.1547], d_k_M_hat range: [0.5685, 0.9771]
2025-03-11 20:44:23 - Train Iteration 7510: loss: 0.4490, d_k_M range: [0.0015, 0.5113], d_k_M_hat range: [0.3321, 0.9972]
2025-03-11 20:44:23 - Train Iteration 7511: loss: 0.1541, d_k_M range: [0.0010, 0.3913], d_k_M_hat range: [0.8998, 0.9986]
2025-03-11 20:44:24 - Train Iteration 7512: loss: 0.6401, d_k_M range: [0.0000, 0.1751], d_k_M_hat range: [0.2000, 0.9113]
2025-03-11 20:44:24 - Train Iteration 7513: loss: 0.4169, d_k_M range: [0.0203, 0.6441], d_k_M_hat range: [0.8044, 0.9988]
2025-03-11 20:44:25 - Train Iteration 7514: loss: 0.8655, d_k_M range: [0.0000, 0.1217], d_k_M_hat range: [0.0697, 0.9619]
2025-03-11 20:44:25 - Train Iteration 7515: loss: 0.4168, d_k_M range: [0.0075, 0.6456], d_k_M_hat range: [0.7963, 1.0000]
2025-03-11 20:44:25 - Train Iteration 7516: loss: 0.1719, d_k_M range: [0.0001, 0.2830], d_k_M_hat range: [0.5856, 0.9797]
2025-03-11 20:44:26 - Train Iteration 7517: loss: 0.4888, d_k_M range: [0.0084, 0.6990], d_k_M_hat range: [0.8208, 0.9999]
2025-03-11 20:44:26 - Train Iteration 7518: loss: 0.1941, d_k_M range: [0.0001, 0.3934], d_k_M_hat range: [0.5609, 0.9964]
2025-03-11 20:44:27 - Train Iteration 7519: loss: 0.1736, d_k_M range: [0.0006, 0.4141], d_k_M_hat range: [0.6106, 0.9975]
2025-03-11 20:44:27 - Train Iteration 7520: loss: 0.3808, d_k_M range: [0.0069, 0.5869], d_k_M_hat range: [0.8115, 0.9699]
2025-03-11 20:44:28 - Train Iteration 7521: loss: 0.2718, d_k_M range: [0.0024, 0.5197], d_k_M_hat range: [0.6677, 0.9983]
2025-03-11 20:44:28 - Train Iteration 7522: loss: 0.1975, d_k_M range: [0.0004, 0.3458], d_k_M_hat range: [0.5563, 0.9803]
2025-03-11 20:44:28 - Train Iteration 7523: loss: 0.1806, d_k_M range: [0.0002, 0.2522], d_k_M_hat range: [0.5758, 0.9839]
2025-03-11 20:44:29 - Train Iteration 7524: loss: 0.1987, d_k_M range: [0.0006, 0.4176], d_k_M_hat range: [0.5548, 0.9949]
2025-03-11 20:44:29 - Train Iteration 7525: loss: 0.3375, d_k_M range: [0.0004, 0.5248], d_k_M_hat range: [0.4195, 0.9888]
2025-03-11 20:44:30 - Train Iteration 7526: loss: 0.1648, d_k_M range: [0.0007, 0.3726], d_k_M_hat range: [0.8377, 0.9872]
2025-03-11 20:44:30 - Train Iteration 7527: loss: 0.1202, d_k_M range: [0.0090, 0.1601], d_k_M_hat range: [0.6662, 0.9469]
2025-03-11 20:44:30 - Train Iteration 7528: loss: 0.1665, d_k_M range: [0.0008, 0.4027], d_k_M_hat range: [0.6246, 0.9946]
2025-03-11 20:44:31 - Train Iteration 7529: loss: 0.0916, d_k_M range: [0.0002, 0.2294], d_k_M_hat range: [0.6976, 0.9824]
2025-03-11 20:44:31 - Train Iteration 7530: loss: 0.1254, d_k_M range: [0.0133, 0.3516], d_k_M_hat range: [0.7854, 0.9974]
2025-03-11 20:44:31 - Train Iteration 7531: loss: 0.3453, d_k_M range: [0.0001, 0.5769], d_k_M_hat range: [0.5710, 0.9959]
2025-03-11 20:44:32 - Train Iteration 7532: loss: 0.4196, d_k_M range: [0.0002, 0.0151], d_k_M_hat range: [0.3541, 0.7985]
2025-03-11 20:44:32 - Train Iteration 7533: loss: 0.1319, d_k_M range: [0.0036, 0.3618], d_k_M_hat range: [0.6803, 0.9986]
2025-03-11 20:44:33 - Train Iteration 7534: loss: 0.4874, d_k_M range: [0.0000, 0.5523], d_k_M_hat range: [0.3019, 0.9847]
2025-03-11 20:44:33 - Train Iteration 7535: loss: 0.2336, d_k_M range: [0.0077, 0.4806], d_k_M_hat range: [0.7464, 0.9973]
2025-03-11 20:44:34 - Train Iteration 7536: loss: 0.3106, d_k_M range: [0.0002, 0.1108], d_k_M_hat range: [0.4438, 0.9860]
2025-03-11 20:44:34 - Train Iteration 7537: loss: 0.3015, d_k_M range: [0.0019, 0.5481], d_k_M_hat range: [0.6843, 0.9990]
2025-03-11 20:44:35 - Train Iteration 7538: loss: 0.1107, d_k_M range: [0.0006, 0.3271], d_k_M_hat range: [0.6842, 0.9944]
2025-03-11 20:44:35 - Train Iteration 7539: loss: 0.2167, d_k_M range: [0.0000, 0.1045], d_k_M_hat range: [0.5345, 0.9888]
2025-03-11 20:44:35 - Train Iteration 7540: loss: 0.1788, d_k_M range: [0.0003, 0.4176], d_k_M_hat range: [0.7087, 0.9947]
2025-03-11 20:44:36 - Train Iteration 7541: loss: 0.1490, d_k_M range: [0.0271, 0.3793], d_k_M_hat range: [0.8587, 0.9934]
2025-03-11 20:44:36 - Train Iteration 7542: loss: 0.1054, d_k_M range: [0.0004, 0.1989], d_k_M_hat range: [0.6814, 0.9881]
2025-03-11 20:44:37 - Train Iteration 7543: loss: 0.1270, d_k_M range: [0.0008, 0.3452], d_k_M_hat range: [0.6444, 0.9956]
2025-03-11 20:44:37 - Train Iteration 7544: loss: 0.4184, d_k_M range: [0.0086, 0.6468], d_k_M_hat range: [0.5872, 1.0000]
2025-03-11 20:44:38 - Train Iteration 7545: loss: 0.3903, d_k_M range: [0.0000, 0.2091], d_k_M_hat range: [0.3753, 0.9893]
2025-03-11 20:44:38 - Train Iteration 7546: loss: 0.1755, d_k_M range: [0.0004, 0.2524], d_k_M_hat range: [0.5856, 0.9835]
2025-03-11 20:44:38 - Train Iteration 7547: loss: 0.1554, d_k_M range: [0.0001, 0.1118], d_k_M_hat range: [0.6059, 0.9848]
2025-03-11 20:44:39 - Train Iteration 7548: loss: 0.1438, d_k_M range: [0.0008, 0.2640], d_k_M_hat range: [0.6216, 0.9824]
2025-03-11 20:44:39 - Train Iteration 7549: loss: 0.2862, d_k_M range: [0.0000, 0.5316], d_k_M_hat range: [0.4815, 0.9967]
2025-03-11 20:44:39 - Train Iteration 7550: loss: 0.0959, d_k_M range: [0.0051, 0.2557], d_k_M_hat range: [0.7336, 0.9691]
2025-03-11 20:44:40 - Train Iteration 7551: loss: 0.3634, d_k_M range: [0.0000, 0.1138], d_k_M_hat range: [0.4228, 0.8833]
2025-03-11 20:44:40 - Train Iteration 7552: loss: 0.4746, d_k_M range: [0.1322, 0.6871], d_k_M_hat range: [0.9847, 0.9997]
2025-03-11 20:44:41 - Train Iteration 7553: loss: 0.1925, d_k_M range: [0.0000, 0.1309], d_k_M_hat range: [0.5612, 0.9326]
2025-03-11 20:44:41 - Train Iteration 7554: loss: 0.1117, d_k_M range: [0.0001, 0.2836], d_k_M_hat range: [0.6659, 0.9904]
2025-03-11 20:44:41 - Train Iteration 7555: loss: 0.0814, d_k_M range: [0.0007, 0.2366], d_k_M_hat range: [0.7175, 0.9759]
2025-03-11 20:44:42 - Train Iteration 7556: loss: 0.2422, d_k_M range: [0.0006, 0.3506], d_k_M_hat range: [0.5085, 0.9952]
2025-03-11 20:44:42 - Train Iteration 7557: loss: 0.1616, d_k_M range: [0.0653, 0.4004], d_k_M_hat range: [0.7892, 0.9984]
2025-03-11 20:44:43 - Train Iteration 7558: loss: 0.2947, d_k_M range: [0.0001, 0.5389], d_k_M_hat range: [0.4992, 0.9960]
2025-03-11 20:44:43 - Train Iteration 7559: loss: 0.1720, d_k_M range: [0.0027, 0.4131], d_k_M_hat range: [0.7466, 0.9984]
2025-03-11 20:44:43 - Train Iteration 7560: loss: 0.4653, d_k_M range: [0.0000, 0.4849], d_k_M_hat range: [0.3179, 0.9990]
2025-03-11 20:44:44 - Train Iteration 7561: loss: 0.6545, d_k_M range: [0.0104, 0.8088], d_k_M_hat range: [0.7558, 0.9998]
2025-03-11 20:44:44 - Train Iteration 7562: loss: 0.2304, d_k_M range: [0.0004, 0.0630], d_k_M_hat range: [0.5205, 0.9792]
2025-03-11 20:44:45 - Train Iteration 7563: loss: 0.1726, d_k_M range: [0.0016, 0.4081], d_k_M_hat range: [0.6581, 0.9944]
2025-03-11 20:44:45 - Train Iteration 7564: loss: 0.2348, d_k_M range: [0.0003, 0.2038], d_k_M_hat range: [0.5157, 0.9906]
2025-03-11 20:44:45 - Train Iteration 7565: loss: 0.2698, d_k_M range: [0.0007, 0.5156], d_k_M_hat range: [0.8626, 0.9961]
2025-03-11 20:44:46 - Train Iteration 7566: loss: 0.2297, d_k_M range: [0.0011, 0.4746], d_k_M_hat range: [0.5788, 0.9953]
2025-03-11 20:44:46 - Train Iteration 7567: loss: 0.1700, d_k_M range: [0.0001, 0.0975], d_k_M_hat range: [0.5904, 0.9711]
2025-03-11 20:44:47 - Train Iteration 7568: loss: 0.5311, d_k_M range: [0.0011, 0.7288], d_k_M_hat range: [0.6522, 1.0000]
2025-03-11 20:44:47 - Train Iteration 7569: loss: 0.2622, d_k_M range: [0.0002, 0.0155], d_k_M_hat range: [0.4890, 0.8926]
2025-03-11 20:44:48 - Train Iteration 7570: loss: 0.2270, d_k_M range: [0.0015, 0.2203], d_k_M_hat range: [0.5250, 0.9941]
2025-03-11 20:44:48 - Train Iteration 7571: loss: 0.1255, d_k_M range: [0.0001, 0.0218], d_k_M_hat range: [0.6595, 0.9811]
2025-03-11 20:44:48 - Train Iteration 7572: loss: 0.2014, d_k_M range: [0.0001, 0.0202], d_k_M_hat range: [0.5513, 0.9212]
2025-03-11 20:44:49 - Train Iteration 7573: loss: 0.1599, d_k_M range: [0.0010, 0.3971], d_k_M_hat range: [0.7241, 0.9973]
2025-03-11 20:44:49 - Train Iteration 7574: loss: 0.3248, d_k_M range: [0.0008, 0.3589], d_k_M_hat range: [0.4343, 0.9752]
2025-03-11 20:44:50 - Train Iteration 7575: loss: 0.4109, d_k_M range: [0.0405, 0.6393], d_k_M_hat range: [0.8900, 0.9990]
2025-03-11 20:44:50 - Train Iteration 7576: loss: 0.2569, d_k_M range: [0.0002, 0.2139], d_k_M_hat range: [0.5165, 0.9501]
2025-03-11 20:44:51 - Train Iteration 7577: loss: 0.1734, d_k_M range: [0.0019, 0.2516], d_k_M_hat range: [0.5865, 0.9878]
2025-03-11 20:44:51 - Train Iteration 7578: loss: 0.3816, d_k_M range: [0.0236, 0.6174], d_k_M_hat range: [0.9425, 0.9997]
2025-03-11 20:44:51 - Train Iteration 7579: loss: 0.1424, d_k_M range: [0.0000, 0.3739], d_k_M_hat range: [0.6544, 0.9966]
2025-03-11 20:44:52 - Train Iteration 7580: loss: 0.1365, d_k_M range: [0.0004, 0.3537], d_k_M_hat range: [0.8730, 0.9961]
2025-03-11 20:44:52 - Train Iteration 7581: loss: 0.1574, d_k_M range: [0.0002, 0.3545], d_k_M_hat range: [0.6034, 0.9879]
2025-03-11 20:44:53 - Train Iteration 7582: loss: 0.2567, d_k_M range: [0.0013, 0.3352], d_k_M_hat range: [0.4947, 0.9892]
2025-03-11 20:44:53 - Train Iteration 7583: loss: 0.3144, d_k_M range: [0.0001, 0.3204], d_k_M_hat range: [0.4393, 0.9902]
2025-03-11 20:44:53 - Train Iteration 7584: loss: 0.4502, d_k_M range: [0.0002, 0.6708], d_k_M_hat range: [0.7049, 0.9998]
2025-03-11 20:44:54 - Train Iteration 7585: loss: 0.2192, d_k_M range: [0.0000, 0.3795], d_k_M_hat range: [0.5319, 0.9803]
2025-03-11 20:44:54 - Train Iteration 7586: loss: 0.2148, d_k_M range: [0.0024, 0.4577], d_k_M_hat range: [0.8091, 0.9942]
2025-03-11 20:44:54 - Train Iteration 7587: loss: 0.0756, d_k_M range: [0.0056, 0.2728], d_k_M_hat range: [0.7897, 0.9978]
2025-03-11 20:44:55 - Train Iteration 7588: loss: 0.8091, d_k_M range: [0.0000, 0.0383], d_k_M_hat range: [0.1006, 0.9526]
2025-03-11 20:44:55 - Train Iteration 7589: loss: 0.1861, d_k_M range: [0.0001, 0.3012], d_k_M_hat range: [0.5687, 0.9810]
2025-03-11 20:44:56 - Train Iteration 7590: loss: 0.1868, d_k_M range: [0.0009, 0.2386], d_k_M_hat range: [0.5763, 0.9877]
2025-03-11 20:44:56 - Train Iteration 7591: loss: 0.2649, d_k_M range: [0.0032, 0.5122], d_k_M_hat range: [0.6880, 0.9978]
2025-03-11 20:44:57 - Train Iteration 7592: loss: 0.8371, d_k_M range: [0.0000, 0.0432], d_k_M_hat range: [0.0851, 0.8152]
2025-03-11 20:44:57 - Train Iteration 7593: loss: 0.3106, d_k_M range: [0.0006, 0.2247], d_k_M_hat range: [0.4433, 0.9708]
2025-03-11 20:44:58 - Train Iteration 7594: loss: 0.2582, d_k_M range: [0.0067, 0.5043], d_k_M_hat range: [0.6558, 0.9971]
2025-03-11 20:44:58 - Train Iteration 7595: loss: 0.1891, d_k_M range: [0.0002, 0.4214], d_k_M_hat range: [0.5745, 0.9982]
2025-03-11 20:44:58 - Train Iteration 7596: loss: 0.2243, d_k_M range: [0.0002, 0.2889], d_k_M_hat range: [0.5266, 0.9978]
2025-03-11 20:44:59 - Train Iteration 7597: loss: 0.1740, d_k_M range: [0.0000, 0.3927], d_k_M_hat range: [0.6732, 0.9756]
2025-03-11 20:44:59 - Train Iteration 7598: loss: 0.4163, d_k_M range: [0.0000, 0.6444], d_k_M_hat range: [0.6215, 0.9992]
2025-03-11 20:45:00 - Train Iteration 7599: loss: 0.3274, d_k_M range: [0.0000, 0.3637], d_k_M_hat range: [0.4278, 0.9923]
2025-03-11 20:45:00 - Train Iteration 7600: loss: 0.1904, d_k_M range: [0.0007, 0.4333], d_k_M_hat range: [0.6945, 0.9969]
2025-03-11 20:45:00 - Train Iteration 7601: loss: 0.4032, d_k_M range: [0.0042, 0.6338], d_k_M_hat range: [0.6721, 0.9996]
2025-03-11 20:45:01 - Train Iteration 7602: loss: 0.1838, d_k_M range: [0.0001, 0.3909], d_k_M_hat range: [0.5732, 0.9973]
2025-03-11 20:45:01 - Train Iteration 7603: loss: 0.3259, d_k_M range: [0.0000, 0.0303], d_k_M_hat range: [0.4292, 0.8290]
2025-03-11 20:45:02 - Train Iteration 7604: loss: 0.1739, d_k_M range: [0.0003, 0.3905], d_k_M_hat range: [0.6797, 0.9929]
2025-03-11 20:45:02 - Train Iteration 7605: loss: 0.1703, d_k_M range: [0.0000, 0.1068], d_k_M_hat range: [0.5893, 0.9416]
2025-03-11 20:45:02 - Train Iteration 7606: loss: 0.2083, d_k_M range: [0.0006, 0.1997], d_k_M_hat range: [0.5446, 0.9798]
2025-03-11 20:45:03 - Train Iteration 7607: loss: 0.3248, d_k_M range: [0.0137, 0.5695], d_k_M_hat range: [0.8643, 0.9997]
2025-03-11 20:45:03 - Train Iteration 7608: loss: 0.0881, d_k_M range: [0.0014, 0.2132], d_k_M_hat range: [0.7142, 0.9969]
2025-03-11 20:45:03 - Train Iteration 7609: loss: 0.1671, d_k_M range: [0.0054, 0.4025], d_k_M_hat range: [0.6554, 0.9938]
2025-03-11 20:45:04 - Train Iteration 7610: loss: 0.2715, d_k_M range: [0.0035, 0.5123], d_k_M_hat range: [0.6482, 0.9912]
2025-03-11 20:45:04 - Train Iteration 7611: loss: 0.2580, d_k_M range: [0.0007, 0.2995], d_k_M_hat range: [0.4955, 0.9601]
2025-03-11 20:45:05 - Train Iteration 7612: loss: 0.2341, d_k_M range: [0.0057, 0.4832], d_k_M_hat range: [0.6899, 0.9993]
2025-03-11 20:45:05 - Train Iteration 7613: loss: 0.3054, d_k_M range: [0.0001, 0.4045], d_k_M_hat range: [0.4479, 0.9827]
2025-03-11 20:45:05 - Train Iteration 7614: loss: 0.3438, d_k_M range: [0.0001, 0.5846], d_k_M_hat range: [0.5774, 0.9982]
2025-03-11 20:45:06 - Train Iteration 7615: loss: 0.1445, d_k_M range: [0.0009, 0.1457], d_k_M_hat range: [0.6250, 0.9843]
2025-03-11 20:45:06 - Train Iteration 7616: loss: 0.3868, d_k_M range: [0.0003, 0.6163], d_k_M_hat range: [0.5415, 0.9991]
2025-03-11 20:45:07 - Train Iteration 7617: loss: 0.1414, d_k_M range: [0.0048, 0.3096], d_k_M_hat range: [0.6315, 0.9889]
2025-03-11 20:45:07 - Train Iteration 7618: loss: 0.3835, d_k_M range: [0.0000, 0.3718], d_k_M_hat range: [0.3808, 0.9966]
2025-03-11 20:45:07 - Train Iteration 7619: loss: 0.1612, d_k_M range: [0.0003, 0.3961], d_k_M_hat range: [0.6226, 0.9946]
2025-03-11 20:45:08 - Train Iteration 7620: loss: 0.5230, d_k_M range: [0.0002, 0.7200], d_k_M_hat range: [0.6445, 0.9969]
2025-03-11 20:45:08 - Train Iteration 7621: loss: 0.3652, d_k_M range: [0.0001, 0.3331], d_k_M_hat range: [0.4060, 0.9983]
2025-03-11 20:45:09 - Train Iteration 7622: loss: 0.2040, d_k_M range: [0.0001, 0.4475], d_k_M_hat range: [0.5747, 0.9985]
2025-03-11 20:45:09 - Train Iteration 7623: loss: 0.2391, d_k_M range: [0.0020, 0.4800], d_k_M_hat range: [0.6713, 0.9940]
2025-03-11 20:45:09 - Train Iteration 7624: loss: 0.3794, d_k_M range: [0.0027, 0.6148], d_k_M_hat range: [0.7739, 0.9988]
2025-03-11 20:45:10 - Train Iteration 7625: loss: 0.4193, d_k_M range: [0.0006, 0.1211], d_k_M_hat range: [0.3543, 0.9886]
2025-03-11 20:45:10 - Train Iteration 7626: loss: 0.4554, d_k_M range: [0.0010, 0.6684], d_k_M_hat range: [0.5859, 0.9936]
2025-03-11 20:45:10 - Train Iteration 7627: loss: 0.6219, d_k_M range: [0.0001, 0.7882], d_k_M_hat range: [0.6303, 0.9996]
2025-03-11 20:45:11 - Train Iteration 7628: loss: 0.1404, d_k_M range: [0.0025, 0.1489], d_k_M_hat range: [0.6278, 0.9846]
2025-03-11 20:45:11 - Train Iteration 7629: loss: 0.1695, d_k_M range: [0.0019, 0.0763], d_k_M_hat range: [0.5907, 0.9815]
2025-03-11 20:45:12 - Train Iteration 7630: loss: 0.3490, d_k_M range: [0.0001, 0.2101], d_k_M_hat range: [0.4093, 0.9894]
2025-03-11 20:45:12 - Train Iteration 7631: loss: 0.2271, d_k_M range: [0.0002, 0.3953], d_k_M_hat range: [0.6194, 0.9948]
2025-03-11 20:45:12 - Train Iteration 7632: loss: 0.2337, d_k_M range: [0.0003, 0.3880], d_k_M_hat range: [0.5174, 0.9962]
2025-03-11 20:45:13 - Train Iteration 7633: loss: 0.1892, d_k_M range: [0.0011, 0.4285], d_k_M_hat range: [0.8625, 0.9936]
2025-03-11 20:45:13 - Train Iteration 7634: loss: 0.1027, d_k_M range: [0.0003, 0.2004], d_k_M_hat range: [0.6798, 0.9965]
2025-03-11 20:45:14 - Train Iteration 7635: loss: 0.2513, d_k_M range: [0.0095, 0.4996], d_k_M_hat range: [0.6679, 0.9983]
2025-03-11 20:45:14 - Train Iteration 7636: loss: 0.0963, d_k_M range: [0.0010, 0.3048], d_k_M_hat range: [0.7107, 0.9945]
2025-03-11 20:45:14 - Train Iteration 7637: loss: 0.3210, d_k_M range: [0.0000, 0.0153], d_k_M_hat range: [0.4338, 0.8985]
2025-03-11 20:45:15 - Train Iteration 7638: loss: 0.2503, d_k_M range: [0.0016, 0.3455], d_k_M_hat range: [0.7851, 0.9958]
2025-03-11 20:45:15 - Train Iteration 7639: loss: 0.1514, d_k_M range: [0.0002, 0.1071], d_k_M_hat range: [0.6118, 0.9127]
2025-03-11 20:45:15 - Train Iteration 7640: loss: 0.3301, d_k_M range: [0.0029, 0.5728], d_k_M_hat range: [0.8995, 0.9983]
2025-03-11 20:45:16 - Train Iteration 7641: loss: 0.2076, d_k_M range: [0.0003, 0.0750], d_k_M_hat range: [0.5464, 0.9637]
2025-03-11 20:45:16 - Train Iteration 7642: loss: 0.2367, d_k_M range: [0.0007, 0.4840], d_k_M_hat range: [0.7463, 0.9984]
2025-03-11 20:45:17 - Train Iteration 7643: loss: 0.0535, d_k_M range: [0.0023, 0.2149], d_k_M_hat range: [0.7738, 0.9847]
2025-03-11 20:45:17 - Train Iteration 7644: loss: 0.6726, d_k_M range: [0.0005, 0.8196], d_k_M_hat range: [0.3785, 0.9995]
2025-03-11 20:45:17 - Train Iteration 7645: loss: 0.3058, d_k_M range: [0.0001, 0.0445], d_k_M_hat range: [0.4473, 0.8881]
2025-03-11 20:45:18 - Train Iteration 7646: loss: 0.4389, d_k_M range: [0.0013, 0.6624], d_k_M_hat range: [0.8180, 0.9999]
2025-03-11 20:45:18 - Train Iteration 7647: loss: 0.2190, d_k_M range: [0.0006, 0.4668], d_k_M_hat range: [0.6961, 0.9988]
2025-03-11 20:45:19 - Train Iteration 7648: loss: 0.1574, d_k_M range: [0.0006, 0.3698], d_k_M_hat range: [0.6039, 0.9997]
2025-03-11 20:45:19 - Train Iteration 7649: loss: 0.2508, d_k_M range: [0.0001, 0.0786], d_k_M_hat range: [0.4994, 0.9837]
2025-03-11 20:45:20 - Train Iteration 7650: loss: 0.1338, d_k_M range: [0.0014, 0.3635], d_k_M_hat range: [0.6962, 0.9977]
2025-03-11 20:45:20 - Train Iteration 7651: loss: 0.1632, d_k_M range: [0.0002, 0.2052], d_k_M_hat range: [0.5963, 0.9776]
2025-03-11 20:45:20 - Train Iteration 7652: loss: 0.3282, d_k_M range: [0.0324, 0.5711], d_k_M_hat range: [0.9866, 0.9986]
2025-03-11 20:45:21 - Train Iteration 7653: loss: 0.2951, d_k_M range: [0.0025, 0.5407], d_k_M_hat range: [0.7323, 0.9975]
2025-03-11 20:45:21 - Train Iteration 7654: loss: 0.2388, d_k_M range: [0.0017, 0.4329], d_k_M_hat range: [0.5502, 0.9944]
2025-03-11 20:45:22 - Train Iteration 7655: loss: 0.1835, d_k_M range: [0.0012, 0.4264], d_k_M_hat range: [0.7891, 0.9980]
2025-03-11 20:45:22 - Train Iteration 7656: loss: 0.0921, d_k_M range: [0.0009, 0.2914], d_k_M_hat range: [0.7244, 0.9981]
2025-03-11 20:45:22 - Train Iteration 7657: loss: 0.5523, d_k_M range: [0.0054, 0.7431], d_k_M_hat range: [0.8405, 0.9999]
2025-03-11 20:45:23 - Train Iteration 7658: loss: 0.2511, d_k_M range: [0.0001, 0.0204], d_k_M_hat range: [0.5094, 0.9120]
2025-03-11 20:45:23 - Train Iteration 7659: loss: 0.1642, d_k_M range: [0.0007, 0.3024], d_k_M_hat range: [0.5972, 0.9910]
2025-03-11 20:45:23 - Train Iteration 7660: loss: 0.4103, d_k_M range: [0.0022, 0.6380], d_k_M_hat range: [0.9267, 0.9998]
2025-03-11 20:45:24 - Train Iteration 7661: loss: 0.7240, d_k_M range: [0.0000, 0.1236], d_k_M_hat range: [0.1492, 0.9717]
2025-03-11 20:45:24 - Train Iteration 7662: loss: 0.2281, d_k_M range: [0.0123, 0.4767], d_k_M_hat range: [0.5973, 0.9991]
2025-03-11 20:45:25 - Train Iteration 7663: loss: 0.1885, d_k_M range: [0.0000, 0.0431], d_k_M_hat range: [0.5665, 0.9181]
2025-03-11 20:45:25 - Train Iteration 7664: loss: 0.2602, d_k_M range: [0.0054, 0.5009], d_k_M_hat range: [0.6107, 0.9978]
2025-03-11 20:45:25 - Train Iteration 7665: loss: 0.1698, d_k_M range: [0.0011, 0.3953], d_k_M_hat range: [0.5906, 0.9941]
2025-03-11 20:45:26 - Train Iteration 7666: loss: 0.2411, d_k_M range: [0.0869, 0.4861], d_k_M_hat range: [0.9553, 0.9989]
2025-03-11 20:45:26 - Train Iteration 7667: loss: 0.1824, d_k_M range: [0.0019, 0.2888], d_k_M_hat range: [0.6301, 0.9878]
2025-03-11 20:45:27 - Train Iteration 7668: loss: 0.1296, d_k_M range: [0.0001, 0.3575], d_k_M_hat range: [0.7740, 0.9975]
2025-03-11 20:45:27 - Train Iteration 7669: loss: 0.2240, d_k_M range: [0.0004, 0.0553], d_k_M_hat range: [0.5278, 0.9904]
2025-03-11 20:45:27 - Train Iteration 7670: loss: 0.1344, d_k_M range: [0.0005, 0.3639], d_k_M_hat range: [0.6946, 0.9973]
2025-03-11 20:45:28 - Train Iteration 7671: loss: 0.2209, d_k_M range: [0.0003, 0.3182], d_k_M_hat range: [0.5333, 0.9901]
2025-03-11 20:45:28 - Train Iteration 7672: loss: 0.1111, d_k_M range: [0.0001, 0.3199], d_k_M_hat range: [0.8000, 0.9865]
2025-03-11 20:45:29 - Train Iteration 7673: loss: 0.1714, d_k_M range: [0.0002, 0.3846], d_k_M_hat range: [0.6253, 0.9887]
2025-03-11 20:45:29 - Train Iteration 7674: loss: 0.2338, d_k_M range: [0.0000, 0.2046], d_k_M_hat range: [0.5165, 0.9832]
2025-03-11 20:45:29 - Train Iteration 7675: loss: 0.3556, d_k_M range: [0.0038, 0.5953], d_k_M_hat range: [0.6909, 0.9994]
2025-03-11 20:45:30 - Train Iteration 7676: loss: 0.1743, d_k_M range: [0.0002, 0.1427], d_k_M_hat range: [0.5827, 0.9743]
2025-03-11 20:45:30 - Train Iteration 7677: loss: 0.1921, d_k_M range: [0.0000, 0.0149], d_k_M_hat range: [0.5617, 0.8548]
2025-03-11 20:45:31 - Train Iteration 7678: loss: 0.1307, d_k_M range: [0.0059, 0.3395], d_k_M_hat range: [0.8801, 0.9951]
2025-03-11 20:45:31 - Train Iteration 7679: loss: 0.2932, d_k_M range: [0.0001, 0.3294], d_k_M_hat range: [0.4592, 0.9857]
2025-03-11 20:45:31 - Train Iteration 7680: loss: 0.0257, d_k_M range: [0.0026, 0.1099], d_k_M_hat range: [0.8639, 0.9884]
2025-03-11 20:45:32 - Train Iteration 7681: loss: 0.3082, d_k_M range: [0.0002, 0.5534], d_k_M_hat range: [0.7427, 0.9982]
2025-03-11 20:45:32 - Train Iteration 7682: loss: 0.1771, d_k_M range: [0.0002, 0.4164], d_k_M_hat range: [0.7851, 0.9969]
2025-03-11 20:45:32 - Train Iteration 7683: loss: 0.1411, d_k_M range: [0.0012, 0.1701], d_k_M_hat range: [0.6279, 0.9497]
2025-03-11 20:45:33 - Train Iteration 7684: loss: 0.1900, d_k_M range: [0.0150, 0.4350], d_k_M_hat range: [0.9476, 0.9996]
2025-03-11 20:45:33 - Train Iteration 7685: loss: 0.3547, d_k_M range: [0.0000, 0.1601], d_k_M_hat range: [0.4044, 0.9796]
2025-03-11 20:45:34 - Train Iteration 7686: loss: 0.3810, d_k_M range: [0.1207, 0.6153], d_k_M_hat range: [0.9897, 0.9980]
2025-03-11 20:45:34 - Train Iteration 7687: loss: 0.3375, d_k_M range: [0.0000, 0.0714], d_k_M_hat range: [0.4196, 0.8598]
2025-03-11 20:45:35 - Train Iteration 7688: loss: 0.2634, d_k_M range: [0.0047, 0.5123], d_k_M_hat range: [0.8442, 0.9990]
2025-03-11 20:45:35 - Train Iteration 7689: loss: 0.4802, d_k_M range: [0.0000, 0.3896], d_k_M_hat range: [0.3070, 0.9768]
2025-03-11 20:45:35 - Train Iteration 7690: loss: 0.2502, d_k_M range: [0.0043, 0.5001], d_k_M_hat range: [0.8193, 1.0000]
2025-03-11 20:45:36 - Train Iteration 7691: loss: 0.1525, d_k_M range: [0.0013, 0.3577], d_k_M_hat range: [0.6312, 0.9948]
2025-03-11 20:45:36 - Train Iteration 7692: loss: 0.2949, d_k_M range: [0.0000, 0.0221], d_k_M_hat range: [0.4569, 0.9195]
2025-03-11 20:45:36 - Train Iteration 7693: loss: 0.4019, d_k_M range: [0.0005, 0.6318], d_k_M_hat range: [0.6673, 0.9993]
2025-03-11 20:45:37 - Train Iteration 7694: loss: 0.2045, d_k_M range: [0.0002, 0.4443], d_k_M_hat range: [0.6724, 0.9921]
2025-03-11 20:45:37 - Train Iteration 7695: loss: 0.0631, d_k_M range: [0.0017, 0.2110], d_k_M_hat range: [0.7505, 0.9884]
2025-03-11 20:45:38 - Train Iteration 7696: loss: 0.2124, d_k_M range: [0.0012, 0.4515], d_k_M_hat range: [0.8355, 0.9951]
2025-03-11 20:45:38 - Train Iteration 7697: loss: 0.2299, d_k_M range: [0.0001, 0.0674], d_k_M_hat range: [0.5206, 0.8731]
2025-03-11 20:45:38 - Train Iteration 7698: loss: 0.7586, d_k_M range: [0.0006, 0.4452], d_k_M_hat range: [0.1296, 0.9981]
2025-03-11 20:45:39 - Train Iteration 7699: loss: 0.1891, d_k_M range: [0.0071, 0.4325], d_k_M_hat range: [0.8147, 0.9977]
2025-03-11 20:45:39 - Train Iteration 7700: loss: 0.2035, d_k_M range: [0.0000, 0.0406], d_k_M_hat range: [0.5567, 0.9328]
2025-03-11 20:45:40 - Train Iteration 7701: loss: 0.3314, d_k_M range: [0.0000, 0.4837], d_k_M_hat range: [0.4243, 0.9994]
2025-03-11 20:45:40 - Train Iteration 7702: loss: 0.1376, d_k_M range: [0.0048, 0.3677], d_k_M_hat range: [0.7100, 0.9967]
2025-03-11 20:45:40 - Train Iteration 7703: loss: 0.3494, d_k_M range: [0.0003, 0.5909], d_k_M_hat range: [0.5955, 0.9998]
2025-03-11 20:45:41 - Train Iteration 7704: loss: 0.5131, d_k_M range: [0.0000, 0.0204], d_k_M_hat range: [0.2837, 0.8849]
2025-03-11 20:45:41 - Train Iteration 7705: loss: 0.1694, d_k_M range: [0.0001, 0.2704], d_k_M_hat range: [0.5885, 0.9729]
2025-03-11 20:45:42 - Train Iteration 7706: loss: 0.1423, d_k_M range: [0.0013, 0.3432], d_k_M_hat range: [0.6283, 0.9877]
2025-03-11 20:45:42 - Train Iteration 7707: loss: 0.2927, d_k_M range: [0.0009, 0.5406], d_k_M_hat range: [0.9153, 0.9995]
2025-03-11 20:45:42 - Train Iteration 7708: loss: 0.3697, d_k_M range: [0.0017, 0.4668], d_k_M_hat range: [0.3937, 0.9990]
2025-03-11 20:45:43 - Train Iteration 7709: loss: 0.2105, d_k_M range: [0.0001, 0.1583], d_k_M_hat range: [0.5413, 0.9564]
2025-03-11 20:45:43 - Train Iteration 7710: loss: 0.1170, d_k_M range: [0.0002, 0.2180], d_k_M_hat range: [0.6581, 0.9908]
2025-03-11 20:45:44 - Train Iteration 7711: loss: 0.1429, d_k_M range: [0.0025, 0.3748], d_k_M_hat range: [0.7271, 0.9968]
2025-03-11 20:45:44 - Train Iteration 7712: loss: 0.1012, d_k_M range: [0.0016, 0.0774], d_k_M_hat range: [0.6846, 0.9747]
2025-03-11 20:45:44 - Train Iteration 7713: loss: 0.1500, d_k_M range: [0.0003, 0.2171], d_k_M_hat range: [0.6143, 0.9683]
2025-03-11 20:45:45 - Train Iteration 7714: loss: 0.1296, d_k_M range: [0.0011, 0.3526], d_k_M_hat range: [0.6411, 0.9970]
2025-03-11 20:45:45 - Train Iteration 7715: loss: 0.2214, d_k_M range: [0.0012, 0.4682], d_k_M_hat range: [0.5811, 0.9977]
2025-03-11 20:45:46 - Train Iteration 7716: loss: 0.3668, d_k_M range: [0.0001, 0.1638], d_k_M_hat range: [0.3945, 0.9731]
2025-03-11 20:45:46 - Train Iteration 7717: loss: 0.3482, d_k_M range: [0.0021, 0.5884], d_k_M_hat range: [0.7896, 0.9983]
2025-03-11 20:45:46 - Train Iteration 7718: loss: 0.1320, d_k_M range: [0.0008, 0.2342], d_k_M_hat range: [0.6375, 0.9893]
2025-03-11 20:45:47 - Train Iteration 7719: loss: 0.0726, d_k_M range: [0.0011, 0.2246], d_k_M_hat range: [0.7582, 0.9933]
2025-03-11 20:45:47 - Train Iteration 7720: loss: 0.1928, d_k_M range: [0.0026, 0.4373], d_k_M_hat range: [0.6905, 0.9982]
2025-03-11 20:45:47 - Train Iteration 7721: loss: 0.2355, d_k_M range: [0.0003, 0.4696], d_k_M_hat range: [0.6512, 0.9843]
2025-03-11 20:45:48 - Train Iteration 7722: loss: 0.4057, d_k_M range: [0.0002, 0.1327], d_k_M_hat range: [0.3632, 0.9813]
2025-03-11 20:45:48 - Train Iteration 7723: loss: 0.0659, d_k_M range: [0.0021, 0.2541], d_k_M_hat range: [0.9616, 0.9974]
2025-03-11 20:45:49 - Train Iteration 7724: loss: 0.3194, d_k_M range: [0.0000, 0.5601], d_k_M_hat range: [0.5151, 0.9949]
2025-03-11 20:45:49 - Train Iteration 7725: loss: 0.1307, d_k_M range: [0.0000, 0.1886], d_k_M_hat range: [0.6406, 0.9626]
2025-03-11 20:45:50 - Train Iteration 7726: loss: 0.1901, d_k_M range: [0.0000, 0.0509], d_k_M_hat range: [0.5641, 0.9971]
2025-03-11 20:45:50 - Train Iteration 7727: loss: 0.1807, d_k_M range: [0.0001, 0.2923], d_k_M_hat range: [0.5768, 0.9828]
2025-03-11 20:45:50 - Train Iteration 7728: loss: 0.2722, d_k_M range: [0.0095, 0.5202], d_k_M_hat range: [0.8428, 0.9985]
2025-03-11 20:45:51 - Train Iteration 7729: loss: 0.3442, d_k_M range: [0.0003, 0.5606], d_k_M_hat range: [0.4899, 0.9739]
2025-03-11 20:45:51 - Train Iteration 7730: loss: 0.2780, d_k_M range: [0.0068, 0.5223], d_k_M_hat range: [0.7832, 0.9995]
2025-03-11 20:45:51 - Train Iteration 7731: loss: 0.2994, d_k_M range: [0.0036, 0.5467], d_k_M_hat range: [0.8545, 0.9995]
2025-03-11 20:45:52 - Train Iteration 7732: loss: 0.1849, d_k_M range: [0.0012, 0.2804], d_k_M_hat range: [0.5716, 0.9819]
2025-03-11 20:45:52 - Train Iteration 7733: loss: 0.3770, d_k_M range: [0.0020, 0.6118], d_k_M_hat range: [0.9080, 0.9979]
2025-03-11 20:45:52 - Train Iteration 7734: loss: 0.1449, d_k_M range: [0.0005, 0.0336], d_k_M_hat range: [0.6213, 0.9502]
2025-03-11 20:45:53 - Train Iteration 7735: loss: 0.2040, d_k_M range: [0.0008, 0.4376], d_k_M_hat range: [0.6627, 0.9942]
2025-03-11 20:45:53 - Train Iteration 7736: loss: 0.1364, d_k_M range: [0.0044, 0.3606], d_k_M_hat range: [0.7333, 0.9912]
2025-03-11 20:45:54 - Train Iteration 7737: loss: 0.7244, d_k_M range: [0.0000, 0.3567], d_k_M_hat range: [0.1489, 0.9956]
2025-03-11 20:45:54 - Train Iteration 7738: loss: 0.6484, d_k_M range: [0.0328, 0.8052], d_k_M_hat range: [0.9119, 1.0000]
2025-03-11 20:45:55 - Train Iteration 7739: loss: 0.1592, d_k_M range: [0.0000, 0.3915], d_k_M_hat range: [0.6028, 0.9960]
2025-03-11 20:45:55 - Train Iteration 7740: loss: 0.1563, d_k_M range: [0.0008, 0.3947], d_k_M_hat range: [0.7935, 0.9993]
2025-03-11 20:45:55 - Train Iteration 7741: loss: 0.1617, d_k_M range: [0.0000, 0.2143], d_k_M_hat range: [0.5979, 0.9951]
2025-03-11 20:45:56 - Train Iteration 7742: loss: 0.2431, d_k_M range: [0.0002, 0.4874], d_k_M_hat range: [0.8124, 0.9970]
2025-03-11 20:45:56 - Train Iteration 7743: loss: 0.2645, d_k_M range: [0.0002, 0.5110], d_k_M_hat range: [0.7566, 0.9967]
2025-03-11 20:45:57 - Train Iteration 7744: loss: 0.1980, d_k_M range: [0.0073, 0.4417], d_k_M_hat range: [0.7911, 0.9994]
2025-03-11 20:45:57 - Train Iteration 7745: loss: 0.1121, d_k_M range: [0.0002, 0.3159], d_k_M_hat range: [0.6756, 0.9989]
2025-03-11 20:45:57 - Train Iteration 7746: loss: 0.1885, d_k_M range: [0.0003, 0.4271], d_k_M_hat range: [0.8337, 0.9930]
2025-03-11 20:45:58 - Train Iteration 7747: loss: 0.3052, d_k_M range: [0.0000, 0.3590], d_k_M_hat range: [0.4476, 0.9930]
2025-03-11 20:45:58 - Train Iteration 7748: loss: 0.2079, d_k_M range: [0.0035, 0.4539], d_k_M_hat range: [0.7145, 0.9989]
2025-03-11 20:45:59 - Train Iteration 7749: loss: 0.1315, d_k_M range: [0.0007, 0.3617], d_k_M_hat range: [0.6842, 0.9991]
2025-03-11 20:45:59 - Train Iteration 7750: loss: 0.2635, d_k_M range: [0.0001, 0.0614], d_k_M_hat range: [0.4868, 0.9351]
2025-03-11 20:45:59 - Train Iteration 7751: loss: 0.4157, d_k_M range: [0.0003, 0.6404], d_k_M_hat range: [0.8024, 0.9970]
2025-03-11 20:46:00 - Train Iteration 7752: loss: 0.3608, d_k_M range: [0.0001, 0.0061], d_k_M_hat range: [0.4002, 0.7947]
2025-03-11 20:46:00 - Train Iteration 7753: loss: 0.0922, d_k_M range: [0.0005, 0.2746], d_k_M_hat range: [0.7281, 0.9852]
2025-03-11 20:46:01 - Train Iteration 7754: loss: 0.1057, d_k_M range: [0.0045, 0.3147], d_k_M_hat range: [0.7480, 0.9896]
2025-03-11 20:46:01 - Train Iteration 7755: loss: 0.6301, d_k_M range: [0.0000, 0.2750], d_k_M_hat range: [0.2083, 0.9588]
2025-03-11 20:46:01 - Train Iteration 7756: loss: 0.7105, d_k_M range: [0.0032, 0.8429], d_k_M_hat range: [0.6494, 1.0000]
2025-03-11 20:46:02 - Train Iteration 7757: loss: 0.4039, d_k_M range: [0.0001, 0.1134], d_k_M_hat range: [0.3646, 0.9125]
2025-03-11 20:46:02 - Train Iteration 7758: loss: 0.2191, d_k_M range: [0.1037, 0.4371], d_k_M_hat range: [0.9043, 0.9930]
2025-03-11 20:46:03 - Train Iteration 7759: loss: 0.2112, d_k_M range: [0.0001, 0.0362], d_k_M_hat range: [0.5405, 0.7887]
2025-03-11 20:46:03 - Train Iteration 7760: loss: 0.2040, d_k_M range: [0.0036, 0.4506], d_k_M_hat range: [0.6758, 0.9989]
2025-03-11 20:46:03 - Train Iteration 7761: loss: 0.1306, d_k_M range: [0.0000, 0.3556], d_k_M_hat range: [0.6915, 0.9942]
2025-03-11 20:46:04 - Train Iteration 7762: loss: 0.2062, d_k_M range: [0.0016, 0.3215], d_k_M_hat range: [0.5481, 0.9955]
2025-03-11 20:46:04 - Train Iteration 7763: loss: 0.1128, d_k_M range: [0.0001, 0.1436], d_k_M_hat range: [0.6884, 0.9943]
2025-03-11 20:46:05 - Train Iteration 7764: loss: 0.3742, d_k_M range: [0.0009, 0.6103], d_k_M_hat range: [0.6041, 0.9985]
2025-03-11 20:46:05 - Train Iteration 7765: loss: 0.5633, d_k_M range: [0.0000, 0.3904], d_k_M_hat range: [0.2500, 0.9950]
2025-03-11 20:46:05 - Train Iteration 7766: loss: 0.2429, d_k_M range: [0.0018, 0.4873], d_k_M_hat range: [0.7089, 0.9945]
2025-03-11 20:46:06 - Train Iteration 7767: loss: 0.1870, d_k_M range: [0.0001, 0.2272], d_k_M_hat range: [0.5790, 0.9594]
2025-03-11 20:46:06 - Train Iteration 7768: loss: 0.1238, d_k_M range: [0.0001, 0.3018], d_k_M_hat range: [0.6483, 0.9943]
2025-03-11 20:46:06 - Train Iteration 7769: loss: 0.3196, d_k_M range: [0.0000, 0.0627], d_k_M_hat range: [0.4347, 0.9739]
2025-03-11 20:46:07 - Train Iteration 7770: loss: 0.4209, d_k_M range: [0.0004, 0.6485], d_k_M_hat range: [0.7981, 0.9997]
2025-03-11 20:46:07 - Train Iteration 7771: loss: 0.2265, d_k_M range: [0.0000, 0.2478], d_k_M_hat range: [0.5243, 0.9747]
2025-03-11 20:46:08 - Train Iteration 7772: loss: 0.2466, d_k_M range: [0.2171, 0.4921], d_k_M_hat range: [0.9849, 0.9979]
2025-03-11 20:46:08 - Train Iteration 7773: loss: 0.1964, d_k_M range: [0.0016, 0.4091], d_k_M_hat range: [0.7172, 0.9988]
2025-03-11 20:46:08 - Train Iteration 7774: loss: 0.2288, d_k_M range: [0.0010, 0.0897], d_k_M_hat range: [0.5238, 0.9934]
2025-03-11 20:46:09 - Train Iteration 7775: loss: 0.1440, d_k_M range: [0.0021, 0.3624], d_k_M_hat range: [0.7143, 0.9938]
2025-03-11 20:46:09 - Train Iteration 7776: loss: 0.2037, d_k_M range: [0.0007, 0.2584], d_k_M_hat range: [0.5512, 0.9903]
2025-03-11 20:46:09 - Train Iteration 7777: loss: 0.1119, d_k_M range: [0.0046, 0.3163], d_k_M_hat range: [0.6812, 0.9855]
2025-03-11 20:46:10 - Train Iteration 7778: loss: 0.1540, d_k_M range: [0.0005, 0.3663], d_k_M_hat range: [0.6081, 0.9971]
2025-03-11 20:46:10 - Train Iteration 7779: loss: 0.3411, d_k_M range: [0.0177, 0.5779], d_k_M_hat range: [0.7920, 0.9995]
2025-03-11 20:46:11 - Train Iteration 7780: loss: 0.1426, d_k_M range: [0.0005, 0.3698], d_k_M_hat range: [0.6641, 0.9921]
2025-03-11 20:46:11 - Train Iteration 7781: loss: 0.1073, d_k_M range: [0.0008, 0.3231], d_k_M_hat range: [0.6921, 0.9955]
2025-03-11 20:46:11 - Train Iteration 7782: loss: 0.3633, d_k_M range: [0.0007, 0.6016], d_k_M_hat range: [0.7926, 0.9988]
2025-03-11 20:46:12 - Train Iteration 7783: loss: 0.4182, d_k_M range: [0.0006, 0.0226], d_k_M_hat range: [0.3540, 0.9130]
2025-03-11 20:46:12 - Train Iteration 7784: loss: 0.2103, d_k_M range: [0.0069, 0.4401], d_k_M_hat range: [0.8038, 0.9961]
2025-03-11 20:46:13 - Train Iteration 7785: loss: 0.3193, d_k_M range: [0.0005, 0.5477], d_k_M_hat range: [0.6441, 0.9826]
2025-03-11 20:46:13 - Train Iteration 7786: loss: 0.1277, d_k_M range: [0.0010, 0.3556], d_k_M_hat range: [0.7010, 0.9982]
2025-03-11 20:46:13 - Train Iteration 7787: loss: 0.1216, d_k_M range: [0.0021, 0.0998], d_k_M_hat range: [0.6593, 0.9535]
2025-03-11 20:46:14 - Train Iteration 7788: loss: 0.1519, d_k_M range: [0.0005, 0.0885], d_k_M_hat range: [0.6118, 0.9910]
2025-03-11 20:46:14 - Train Iteration 7789: loss: 0.1673, d_k_M range: [0.0033, 0.4086], d_k_M_hat range: [0.6358, 0.9996]
2025-03-11 20:46:15 - Train Iteration 7790: loss: 0.1636, d_k_M range: [0.0002, 0.0139], d_k_M_hat range: [0.6019, 0.9752]
2025-03-11 20:46:15 - Train Iteration 7791: loss: 0.1182, d_k_M range: [0.0001, 0.3376], d_k_M_hat range: [0.6564, 0.9968]
2025-03-11 20:46:15 - Train Iteration 7792: loss: 0.2306, d_k_M range: [0.0004, 0.4756], d_k_M_hat range: [0.6780, 0.9967]
2025-03-11 20:46:16 - Train Iteration 7793: loss: 0.2221, d_k_M range: [0.0003, 0.2802], d_k_M_hat range: [0.5293, 0.9873]
2025-03-11 20:46:16 - Train Iteration 7794: loss: 0.4113, d_k_M range: [0.0099, 0.6380], d_k_M_hat range: [0.9800, 0.9987]
2025-03-11 20:46:17 - Train Iteration 7795: loss: 0.4079, d_k_M range: [0.0000, 0.2461], d_k_M_hat range: [0.3616, 0.9923]
2025-03-11 20:46:17 - Train Iteration 7796: loss: 0.3568, d_k_M range: [0.0118, 0.5973], d_k_M_hat range: [0.9447, 0.9999]
2025-03-11 20:46:17 - Train Iteration 7797: loss: 0.2599, d_k_M range: [0.0001, 0.1560], d_k_M_hat range: [0.4903, 0.9925]
2025-03-11 20:46:18 - Train Iteration 7798: loss: 0.0985, d_k_M range: [0.0023, 0.1913], d_k_M_hat range: [0.7027, 0.9361]
2025-03-11 20:46:18 - Train Iteration 7799: loss: 0.2355, d_k_M range: [0.0033, 0.4840], d_k_M_hat range: [0.7420, 0.9987]
2025-03-11 20:46:19 - Train Iteration 7800: loss: 0.1650, d_k_M range: [0.0004, 0.2524], d_k_M_hat range: [0.6097, 0.9886]
2025-03-11 20:46:19 - Train Iteration 7801: loss: 0.1925, d_k_M range: [0.0000, 0.4375], d_k_M_hat range: [0.7468, 0.9987]
2025-03-11 20:46:20 - Train Iteration 7802: loss: 0.1380, d_k_M range: [0.0001, 0.2760], d_k_M_hat range: [0.6310, 0.9143]
2025-03-11 20:46:20 - Train Iteration 7803: loss: 0.0482, d_k_M range: [0.0016, 0.1302], d_k_M_hat range: [0.7820, 0.9785]
2025-03-11 20:46:20 - Train Iteration 7804: loss: 0.1948, d_k_M range: [0.0004, 0.4395], d_k_M_hat range: [0.6639, 0.9981]
2025-03-11 20:46:21 - Train Iteration 7805: loss: 0.2453, d_k_M range: [0.0001, 0.2446], d_k_M_hat range: [0.5048, 0.9685]
2025-03-11 20:46:21 - Train Iteration 7806: loss: 0.2210, d_k_M range: [0.0179, 0.4619], d_k_M_hat range: [0.8131, 0.9918]
2025-03-11 20:46:22 - Train Iteration 7807: loss: 0.2438, d_k_M range: [0.0001, 0.3027], d_k_M_hat range: [0.5063, 0.9758]
2025-03-11 20:46:22 - Train Iteration 7808: loss: 0.2832, d_k_M range: [0.0004, 0.3872], d_k_M_hat range: [0.4682, 0.9975]
2025-03-11 20:46:22 - Train Iteration 7809: loss: 0.1827, d_k_M range: [0.0057, 0.4225], d_k_M_hat range: [0.7450, 0.9982]
2025-03-11 20:46:23 - Train Iteration 7810: loss: 0.2112, d_k_M range: [0.0001, 0.1057], d_k_M_hat range: [0.5408, 0.9539]
2025-03-11 20:46:23 - Train Iteration 7811: loss: 0.3428, d_k_M range: [0.0207, 0.5852], d_k_M_hat range: [0.9687, 0.9997]
2025-03-11 20:46:24 - Train Iteration 7812: loss: 0.1039, d_k_M range: [0.0221, 0.2925], d_k_M_hat range: [0.7462, 0.9911]
2025-03-11 20:46:24 - Train Iteration 7813: loss: 0.1938, d_k_M range: [0.0004, 0.0883], d_k_M_hat range: [0.5606, 0.9947]
2025-03-11 20:46:25 - Train Iteration 7814: loss: 0.0714, d_k_M range: [0.0050, 0.2589], d_k_M_hat range: [0.8758, 0.9916]
2025-03-11 20:46:25 - Train Iteration 7815: loss: 0.3139, d_k_M range: [0.0085, 0.5595], d_k_M_hat range: [0.7956, 0.9993]
2025-03-11 20:46:25 - Train Iteration 7816: loss: 0.3692, d_k_M range: [0.0001, 0.2562], d_k_M_hat range: [0.3925, 0.9933]
2025-03-11 20:46:26 - Train Iteration 7817: loss: 0.1790, d_k_M range: [0.0072, 0.4030], d_k_M_hat range: [0.8631, 0.9950]
2025-03-11 20:46:26 - Train Iteration 7818: loss: 0.1453, d_k_M range: [0.0011, 0.3788], d_k_M_hat range: [0.6226, 0.9976]
2025-03-11 20:46:26 - Train Iteration 7819: loss: 0.3157, d_k_M range: [0.0007, 0.2911], d_k_M_hat range: [0.4389, 0.9939]
2025-03-11 20:46:27 - Train Iteration 7820: loss: 0.2479, d_k_M range: [0.0716, 0.4966], d_k_M_hat range: [0.9444, 0.9987]
2025-03-11 20:46:27 - Train Iteration 7821: loss: 0.2583, d_k_M range: [0.0002, 0.4972], d_k_M_hat range: [0.6352, 0.9957]
2025-03-11 20:46:28 - Train Iteration 7822: loss: 0.2513, d_k_M range: [0.0000, 0.1189], d_k_M_hat range: [0.4988, 0.9931]
2025-03-11 20:46:28 - Train Iteration 7823: loss: 0.2074, d_k_M range: [0.0018, 0.3920], d_k_M_hat range: [0.5465, 0.9996]
2025-03-11 20:46:28 - Train Iteration 7824: loss: 0.3036, d_k_M range: [0.0142, 0.5486], d_k_M_hat range: [0.9446, 0.9976]
2025-03-11 20:46:29 - Train Iteration 7825: loss: 0.6761, d_k_M range: [0.0000, 0.0328], d_k_M_hat range: [0.1778, 0.9444]
2025-03-11 20:46:29 - Train Iteration 7826: loss: 0.2124, d_k_M range: [0.0285, 0.4561], d_k_M_hat range: [0.9464, 0.9993]
2025-03-11 20:46:30 - Train Iteration 7827: loss: 0.1090, d_k_M range: [0.0001, 0.1591], d_k_M_hat range: [0.6699, 0.9811]
2025-03-11 20:46:30 - Train Iteration 7828: loss: 0.3090, d_k_M range: [0.0002, 0.5555], d_k_M_hat range: [0.5762, 0.9996]
2025-03-11 20:46:30 - Train Iteration 7829: loss: 0.3154, d_k_M range: [0.0000, 0.1885], d_k_M_hat range: [0.4386, 0.9250]
2025-03-11 20:46:31 - Train Iteration 7830: loss: 0.2071, d_k_M range: [0.0066, 0.4531], d_k_M_hat range: [0.9251, 0.9993]
2025-03-11 20:46:31 - Train Iteration 7831: loss: 0.1900, d_k_M range: [0.0001, 0.2686], d_k_M_hat range: [0.5688, 0.9971]
2025-03-11 20:46:31 - Train Iteration 7832: loss: 0.0859, d_k_M range: [0.0102, 0.2863], d_k_M_hat range: [0.8709, 0.9996]
2025-03-11 20:46:32 - Train Iteration 7833: loss: 0.2003, d_k_M range: [0.0001, 0.0957], d_k_M_hat range: [0.5533, 0.9670]
2025-03-11 20:46:32 - Train Iteration 7834: loss: 0.3014, d_k_M range: [0.0102, 0.5486], d_k_M_hat range: [0.9354, 0.9996]
2025-03-11 20:46:33 - Train Iteration 7835: loss: 0.2194, d_k_M range: [0.0000, 0.1348], d_k_M_hat range: [0.5320, 0.9617]
2025-03-11 20:46:33 - Train Iteration 7836: loss: 0.3810, d_k_M range: [0.0191, 0.6171], d_k_M_hat range: [0.9619, 0.9999]
2025-03-11 20:46:33 - Train Iteration 7837: loss: 0.2320, d_k_M range: [0.0001, 0.0767], d_k_M_hat range: [0.5184, 0.9963]
2025-03-11 20:46:34 - Train Iteration 7838: loss: 0.1437, d_k_M range: [0.0006, 0.3694], d_k_M_hat range: [0.8445, 0.9943]
2025-03-11 20:46:34 - Train Iteration 7839: loss: 0.3325, d_k_M range: [0.0004, 0.1464], d_k_M_hat range: [0.4238, 0.9896]
2025-03-11 20:46:35 - Train Iteration 7840: loss: 0.1948, d_k_M range: [0.0025, 0.4393], d_k_M_hat range: [0.8232, 0.9979]
2025-03-11 20:46:35 - Train Iteration 7841: loss: 0.3584, d_k_M range: [0.0000, 0.2996], d_k_M_hat range: [0.4015, 0.9946]
2025-03-11 20:46:35 - Train Iteration 7842: loss: 0.2201, d_k_M range: [0.0005, 0.4687], d_k_M_hat range: [0.7253, 0.9996]
2025-03-11 20:46:36 - Train Iteration 7843: loss: 0.4705, d_k_M range: [0.0003, 0.0255], d_k_M_hat range: [0.3144, 0.9756]
2025-03-11 20:46:36 - Train Iteration 7844: loss: 0.5982, d_k_M range: [0.0040, 0.7724], d_k_M_hat range: [0.7758, 0.9996]
2025-03-11 20:46:37 - Train Iteration 7845: loss: 0.4197, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.3522, 0.8814]
2025-03-11 20:46:37 - Train Iteration 7846: loss: 0.1355, d_k_M range: [0.0026, 0.3673], d_k_M_hat range: [0.8489, 0.9992]
2025-03-11 20:46:37 - Train Iteration 7847: loss: 0.4569, d_k_M range: [0.0001, 0.3885], d_k_M_hat range: [0.3318, 0.9975]
2025-03-11 20:46:38 - Train Iteration 7848: loss: 0.4539, d_k_M range: [0.0790, 0.6732], d_k_M_hat range: [0.9873, 0.9997]
2025-03-11 20:46:38 - Train Iteration 7849: loss: 0.1870, d_k_M range: [0.0048, 0.3902], d_k_M_hat range: [0.5723, 0.9872]
2025-03-11 20:46:39 - Train Iteration 7850: loss: 0.0925, d_k_M range: [0.0001, 0.0881], d_k_M_hat range: [0.6962, 0.9803]
2025-03-11 20:46:39 - Train Iteration 7851: loss: 0.1885, d_k_M range: [0.0007, 0.4312], d_k_M_hat range: [0.7371, 0.9971]
2025-03-11 20:46:39 - Train Iteration 7852: loss: 0.1472, d_k_M range: [0.0007, 0.3556], d_k_M_hat range: [0.8318, 0.9961]
2025-03-11 20:46:40 - Train Iteration 7853: loss: 0.1093, d_k_M range: [0.0017, 0.2588], d_k_M_hat range: [0.6711, 0.9884]
2025-03-11 20:46:40 - Train Iteration 7854: loss: 0.1758, d_k_M range: [0.0668, 0.4190], d_k_M_hat range: [0.9334, 0.9998]
2025-03-11 20:46:40 - Train Iteration 7855: loss: 0.3394, d_k_M range: [0.0048, 0.5433], d_k_M_hat range: [0.8985, 0.9992]
2025-03-11 20:46:41 - Train Iteration 7856: loss: 0.1612, d_k_M range: [0.0124, 0.3934], d_k_M_hat range: [0.6969, 0.9919]
2025-03-11 20:46:41 - Train Iteration 7857: loss: 0.1332, d_k_M range: [0.0001, 0.1363], d_k_M_hat range: [0.6351, 0.9796]
2025-03-11 20:46:42 - Train Iteration 7858: loss: 0.2658, d_k_M range: [0.0040, 0.5148], d_k_M_hat range: [0.6489, 0.9993]
2025-03-11 20:46:42 - Train Iteration 7859: loss: 0.1062, d_k_M range: [0.0015, 0.0430], d_k_M_hat range: [0.6791, 0.9654]
2025-03-11 20:46:42 - Train Iteration 7860: loss: 0.3467, d_k_M range: [0.0008, 0.5886], d_k_M_hat range: [0.6502, 0.9998]
2025-03-11 20:46:43 - Train Iteration 7861: loss: 0.3615, d_k_M range: [0.0031, 0.5987], d_k_M_hat range: [0.8712, 0.9977]
2025-03-11 20:46:43 - Train Iteration 7862: loss: 0.4123, d_k_M range: [0.0002, 0.4687], d_k_M_hat range: [0.3581, 0.9898]
2025-03-11 20:46:44 - Train Iteration 7863: loss: 0.1745, d_k_M range: [0.0047, 0.4154], d_k_M_hat range: [0.7939, 0.9977]
2025-03-11 20:46:44 - Train Iteration 7864: loss: 0.2639, d_k_M range: [0.0013, 0.5086], d_k_M_hat range: [0.8234, 0.9971]
2025-03-11 20:46:45 - Train Iteration 7865: loss: 0.0743, d_k_M range: [0.0001, 0.1232], d_k_M_hat range: [0.7275, 0.9858]
2025-03-11 20:46:45 - Train Iteration 7866: loss: 0.5584, d_k_M range: [0.0008, 0.7472], d_k_M_hat range: [0.5559, 0.9999]
2025-03-11 20:46:45 - Train Iteration 7867: loss: 0.0768, d_k_M range: [0.0090, 0.2700], d_k_M_hat range: [0.7732, 0.9944]
2025-03-11 20:46:46 - Train Iteration 7868: loss: 0.2926, d_k_M range: [0.0001, 0.5390], d_k_M_hat range: [0.5929, 0.9981]
2025-03-11 20:46:46 - Train Iteration 7869: loss: 0.1873, d_k_M range: [0.0000, 0.0692], d_k_M_hat range: [0.5675, 0.9807]
2025-03-11 20:46:47 - Train Iteration 7870: loss: 0.3161, d_k_M range: [0.0013, 0.5622], d_k_M_hat range: [0.4706, 0.9999]
2025-03-11 20:46:47 - Train Iteration 7871: loss: 0.0552, d_k_M range: [0.0018, 0.2271], d_k_M_hat range: [0.7825, 0.9922]
2025-03-11 20:46:47 - Train Iteration 7872: loss: 0.0616, d_k_M range: [0.0062, 0.2430], d_k_M_hat range: [0.8472, 0.9956]
2025-03-11 20:46:48 - Train Iteration 7873: loss: 0.2151, d_k_M range: [0.0029, 0.4542], d_k_M_hat range: [0.9090, 0.9904]
2025-03-11 20:46:48 - Train Iteration 7874: loss: 0.2628, d_k_M range: [0.0016, 0.5117], d_k_M_hat range: [0.8873, 0.9990]
2025-03-11 20:46:49 - Train Iteration 7875: loss: 0.1596, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.6028, 0.8959]
2025-03-11 20:46:49 - Train Iteration 7876: loss: 0.1189, d_k_M range: [0.0031, 0.3326], d_k_M_hat range: [0.8206, 0.9992]
2025-03-11 20:46:49 - Train Iteration 7877: loss: 0.2526, d_k_M range: [0.0011, 0.5016], d_k_M_hat range: [0.6243, 0.9991]
2025-03-11 20:46:50 - Train Iteration 7878: loss: 0.3023, d_k_M range: [0.0001, 0.3161], d_k_M_hat range: [0.4510, 0.9904]
2025-03-11 20:46:50 - Train Iteration 7879: loss: 0.2360, d_k_M range: [0.0192, 0.4791], d_k_M_hat range: [0.9842, 0.9972]
2025-03-11 20:46:50 - Train Iteration 7880: loss: 0.4762, d_k_M range: [0.0006, 0.0329], d_k_M_hat range: [0.3131, 0.9309]
2025-03-11 20:46:51 - Train Iteration 7881: loss: 0.6665, d_k_M range: [0.0028, 0.8161], d_k_M_hat range: [0.7458, 0.9998]
2025-03-11 20:46:51 - Train Iteration 7882: loss: 0.2004, d_k_M range: [0.0009, 0.4409], d_k_M_hat range: [0.6531, 0.9933]
2025-03-11 20:46:52 - Train Iteration 7883: loss: 0.1770, d_k_M range: [0.0342, 0.4105], d_k_M_hat range: [0.9565, 0.9975]
2025-03-11 20:46:52 - Train Iteration 7884: loss: 0.0980, d_k_M range: [0.0001, 0.1531], d_k_M_hat range: [0.6902, 0.9789]
2025-03-11 20:46:52 - Train Iteration 7885: loss: 0.1985, d_k_M range: [0.0003, 0.4403], d_k_M_hat range: [0.8262, 0.9986]
2025-03-11 20:46:53 - Train Iteration 7886: loss: 0.1813, d_k_M range: [0.0005, 0.4182], d_k_M_hat range: [0.6139, 0.9924]
2025-03-11 20:46:53 - Train Iteration 7887: loss: 0.1464, d_k_M range: [0.0000, 0.0482], d_k_M_hat range: [0.6174, 0.9879]
2025-03-11 20:46:54 - Train Iteration 7888: loss: 0.2293, d_k_M range: [0.0143, 0.4787], d_k_M_hat range: [0.9525, 1.0000]
2025-03-11 20:46:54 - Train Iteration 7889: loss: 0.1013, d_k_M range: [0.0008, 0.3124], d_k_M_hat range: [0.7450, 0.9940]
2025-03-11 20:46:55 - Train Iteration 7890: loss: 0.4082, d_k_M range: [0.0026, 0.6335], d_k_M_hat range: [0.5758, 0.9947]
2025-03-11 20:46:55 - Train Iteration 7891: loss: 0.1414, d_k_M range: [0.0000, 0.0073], d_k_M_hat range: [0.6240, 0.9179]
2025-03-11 20:46:55 - Train Iteration 7892: loss: 0.0372, d_k_M range: [0.0003, 0.1633], d_k_M_hat range: [0.8075, 0.9882]
2025-03-11 20:46:56 - Train Iteration 7893: loss: 0.3138, d_k_M range: [0.0002, 0.0591], d_k_M_hat range: [0.4420, 0.9906]
2025-03-11 20:46:56 - Train Iteration 7894: loss: 0.2433, d_k_M range: [0.0000, 0.0643], d_k_M_hat range: [0.5069, 0.9395]
2025-03-11 20:46:56 - Train Iteration 7895: loss: 0.8150, d_k_M range: [0.0327, 0.9020], d_k_M_hat range: [0.9027, 0.9995]
2025-03-11 20:46:57 - Train Iteration 7896: loss: 0.0882, d_k_M range: [0.0486, 0.2938], d_k_M_hat range: [0.8720, 0.9984]
2025-03-11 20:46:57 - Train Iteration 7897: loss: 0.2090, d_k_M range: [0.0004, 0.0252], d_k_M_hat range: [0.5440, 0.9788]
2025-03-11 20:46:58 - Train Iteration 7898: loss: 0.2379, d_k_M range: [0.0001, 0.1580], d_k_M_hat range: [0.5123, 0.9886]
2025-03-11 20:46:58 - Train Iteration 7899: loss: 0.2736, d_k_M range: [0.0057, 0.5078], d_k_M_hat range: [0.8302, 0.9959]
2025-03-11 20:46:58 - Train Iteration 7900: loss: 0.2976, d_k_M range: [0.0001, 0.1393], d_k_M_hat range: [0.4548, 0.9975]
2025-03-11 20:46:59 - Train Iteration 7901: loss: 0.2288, d_k_M range: [0.0028, 0.4768], d_k_M_hat range: [0.7990, 0.9995]
2025-03-11 20:46:59 - Train Iteration 7902: loss: 0.4597, d_k_M range: [0.0002, 0.4175], d_k_M_hat range: [0.3223, 0.9951]
2025-03-11 20:47:00 - Train Iteration 7903: loss: 0.2547, d_k_M range: [0.0078, 0.5040], d_k_M_hat range: [0.9107, 0.9993]
2025-03-11 20:47:00 - Train Iteration 7904: loss: 0.2747, d_k_M range: [0.0001, 0.0936], d_k_M_hat range: [0.4759, 0.9849]
2025-03-11 20:47:00 - Train Iteration 7905: loss: 0.1657, d_k_M range: [0.0117, 0.4051], d_k_M_hat range: [0.9412, 0.9992]
2025-03-11 20:47:01 - Train Iteration 7906: loss: 0.3649, d_k_M range: [0.0011, 0.1661], d_k_M_hat range: [0.4141, 0.9921]
2025-03-11 20:47:01 - Train Iteration 7907: loss: 0.2215, d_k_M range: [0.0033, 0.4691], d_k_M_hat range: [0.7607, 0.9985]
2025-03-11 20:47:01 - Train Iteration 7908: loss: 0.1361, d_k_M range: [0.0003, 0.1364], d_k_M_hat range: [0.6314, 0.9728]
2025-03-11 20:47:02 - Train Iteration 7909: loss: 0.3278, d_k_M range: [0.0001, 0.5712], d_k_M_hat range: [0.5827, 0.9991]
2025-03-11 20:47:02 - Train Iteration 7910: loss: 0.1419, d_k_M range: [0.0004, 0.1679], d_k_M_hat range: [0.6238, 0.9972]
2025-03-11 20:47:03 - Train Iteration 7911: loss: 0.1577, d_k_M range: [0.0031, 0.3962], d_k_M_hat range: [0.6086, 0.9993]
2025-03-11 20:47:03 - Train Iteration 7912: loss: 0.1877, d_k_M range: [0.0001, 0.4311], d_k_M_hat range: [0.5724, 0.9979]
2025-03-11 20:47:03 - Train Iteration 7913: loss: 0.3065, d_k_M range: [0.0007, 0.5535], d_k_M_hat range: [0.6021, 0.9999]
2025-03-11 20:47:04 - Train Iteration 7914: loss: 0.2273, d_k_M range: [0.0008, 0.1373], d_k_M_hat range: [0.5280, 0.9893]
2025-03-11 20:47:04 - Train Iteration 7915: loss: 0.1368, d_k_M range: [0.0055, 0.1342], d_k_M_hat range: [0.6422, 0.9878]
2025-03-11 20:47:05 - Train Iteration 7916: loss: 0.2068, d_k_M range: [0.0043, 0.4538], d_k_M_hat range: [0.7477, 0.9994]
2025-03-11 20:47:05 - Train Iteration 7917: loss: 0.0793, d_k_M range: [0.0012, 0.1023], d_k_M_hat range: [0.7208, 0.9741]
2025-03-11 20:47:05 - Train Iteration 7918: loss: 0.3361, d_k_M range: [0.0016, 0.5794], d_k_M_hat range: [0.7669, 0.9997]
2025-03-11 20:47:06 - Train Iteration 7919: loss: 0.2562, d_k_M range: [0.0000, 0.2010], d_k_M_hat range: [0.4939, 0.9633]
2025-03-11 20:47:06 - Train Iteration 7920: loss: 0.2105, d_k_M range: [0.0033, 0.3708], d_k_M_hat range: [0.5529, 0.9992]
2025-03-11 20:47:07 - Train Iteration 7921: loss: 0.2351, d_k_M range: [0.0009, 0.4463], d_k_M_hat range: [0.7889, 0.9864]
2025-03-11 20:47:07 - Train Iteration 7922: loss: 0.2125, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.5391, 0.8924]
2025-03-11 20:47:07 - Train Iteration 7923: loss: 0.1173, d_k_M range: [0.0005, 0.3385], d_k_M_hat range: [0.8682, 0.9998]
2025-03-11 20:47:08 - Train Iteration 7924: loss: 0.1825, d_k_M range: [0.0006, 0.2510], d_k_M_hat range: [0.5734, 0.9927]
2025-03-11 20:47:08 - Train Iteration 7925: loss: 0.1641, d_k_M range: [0.0003, 0.4033], d_k_M_hat range: [0.8951, 0.9982]
2025-03-11 20:47:09 - Train Iteration 7926: loss: 0.2010, d_k_M range: [0.0000, 0.4071], d_k_M_hat range: [0.5535, 0.9993]
2025-03-11 20:47:09 - Train Iteration 7927: loss: 0.5278, d_k_M range: [0.0013, 0.7261], d_k_M_hat range: [0.8893, 0.9999]
2025-03-11 20:47:09 - Train Iteration 7928: loss: 0.2724, d_k_M range: [0.0001, 0.0193], d_k_M_hat range: [0.4782, 0.9241]
2025-03-11 20:47:10 - Train Iteration 7929: loss: 0.1219, d_k_M range: [0.0020, 0.3230], d_k_M_hat range: [0.9286, 0.9957]
2025-03-11 20:47:10 - Train Iteration 7930: loss: 0.2260, d_k_M range: [0.0026, 0.4737], d_k_M_hat range: [0.6019, 0.9989]
2025-03-11 20:47:11 - Train Iteration 7931: loss: 0.1370, d_k_M range: [0.0000, 0.1363], d_k_M_hat range: [0.6304, 0.9798]
2025-03-11 20:47:11 - Train Iteration 7932: loss: 0.7245, d_k_M range: [0.0002, 0.8508], d_k_M_hat range: [0.7576, 0.9996]
2025-03-11 20:47:11 - Train Iteration 7933: loss: 0.2720, d_k_M range: [0.0000, 0.0276], d_k_M_hat range: [0.4787, 0.9689]
2025-03-11 20:47:12 - Train Iteration 7934: loss: 0.2039, d_k_M range: [0.0008, 0.3240], d_k_M_hat range: [0.5493, 0.9891]
2025-03-11 20:47:12 - Train Iteration 7935: loss: 0.1575, d_k_M range: [0.0166, 0.3900], d_k_M_hat range: [0.9900, 0.9983]
2025-03-11 20:47:13 - Train Iteration 7936: loss: 0.1290, d_k_M range: [0.0001, 0.0559], d_k_M_hat range: [0.6581, 0.9844]
2025-03-11 20:47:13 - Train Iteration 7937: loss: 0.1578, d_k_M range: [0.0231, 0.3951], d_k_M_hat range: [0.8293, 0.9996]
2025-03-11 20:47:13 - Train Iteration 7938: loss: 0.0439, d_k_M range: [0.0003, 0.0196], d_k_M_hat range: [0.7919, 0.9679]
2025-03-11 20:47:14 - Train Iteration 7939: loss: 0.5112, d_k_M range: [0.0058, 0.4696], d_k_M_hat range: [0.2908, 0.9926]
2025-03-11 20:47:14 - Train Iteration 7940: loss: 0.1462, d_k_M range: [0.0001, 0.3427], d_k_M_hat range: [0.6177, 0.9878]
2025-03-11 20:47:14 - Train Iteration 7941: loss: 0.1061, d_k_M range: [0.0037, 0.1865], d_k_M_hat range: [0.7485, 0.9935]
2025-03-11 20:47:15 - Train Iteration 7942: loss: 0.2843, d_k_M range: [0.0000, 0.1434], d_k_M_hat range: [0.4669, 0.9777]
2025-03-11 20:47:15 - Train Iteration 7943: loss: 0.2003, d_k_M range: [0.0000, 0.4454], d_k_M_hat range: [0.7218, 0.9979]
2025-03-11 20:47:16 - Train Iteration 7944: loss: 0.1930, d_k_M range: [0.0000, 0.1267], d_k_M_hat range: [0.5623, 0.9968]
2025-03-11 20:47:16 - Train Iteration 7945: loss: 0.1258, d_k_M range: [0.0184, 0.3534], d_k_M_hat range: [0.9141, 0.9987]
2025-03-11 20:47:17 - Train Iteration 7946: loss: 0.1612, d_k_M range: [0.0001, 0.1806], d_k_M_hat range: [0.5993, 0.9940]
2025-03-11 20:47:17 - Train Iteration 7947: loss: 0.2733, d_k_M range: [0.0012, 0.5226], d_k_M_hat range: [0.7835, 0.9998]
2025-03-11 20:47:17 - Train Iteration 7948: loss: 0.4841, d_k_M range: [0.0000, 0.3820], d_k_M_hat range: [0.3043, 0.9858]
2025-03-11 20:47:18 - Train Iteration 7949: loss: 0.3641, d_k_M range: [0.0048, 0.6012], d_k_M_hat range: [0.9521, 1.0000]
2025-03-11 20:47:18 - Train Iteration 7950: loss: 0.4108, d_k_M range: [0.0002, 0.1048], d_k_M_hat range: [0.3592, 0.9873]
2025-03-11 20:47:19 - Train Iteration 7951: loss: 0.1688, d_k_M range: [0.0098, 0.4106], d_k_M_hat range: [0.9353, 0.9997]
2025-03-11 20:47:19 - Train Iteration 7952: loss: 0.2851, d_k_M range: [0.0006, 0.2734], d_k_M_hat range: [0.4669, 0.9881]
2025-03-11 20:47:20 - Train Iteration 7953: loss: 0.2486, d_k_M range: [0.0008, 0.4813], d_k_M_hat range: [0.7441, 0.9918]
2025-03-11 20:47:20 - Train Iteration 7954: loss: 0.2990, d_k_M range: [0.0000, 0.0676], d_k_M_hat range: [0.4533, 0.9972]
2025-03-11 20:47:20 - Train Iteration 7955: loss: 0.3021, d_k_M range: [0.0031, 0.5490], d_k_M_hat range: [0.7972, 0.9994]
2025-03-11 20:47:21 - Train Iteration 7956: loss: 0.1489, d_k_M range: [0.0000, 0.1615], d_k_M_hat range: [0.6179, 0.9944]
2025-03-11 20:47:21 - Train Iteration 7957: loss: 0.2327, d_k_M range: [0.0045, 0.4821], d_k_M_hat range: [0.7965, 0.9997]
2025-03-11 20:47:22 - Train Iteration 7958: loss: 0.2545, d_k_M range: [0.0000, 0.4070], d_k_M_hat range: [0.4955, 0.9982]
2025-03-11 20:47:22 - Train Iteration 7959: loss: 0.1052, d_k_M range: [0.0012, 0.3239], d_k_M_hat range: [0.6913, 0.9996]
2025-03-11 20:47:23 - Train Iteration 7960: loss: 0.1417, d_k_M range: [0.0000, 0.0388], d_k_M_hat range: [0.6237, 0.9064]
2025-03-11 20:47:23 - Train Iteration 7961: loss: 0.3233, d_k_M range: [0.0002, 0.0176], d_k_M_hat range: [0.4316, 0.8831]
2025-03-11 20:47:23 - Train Iteration 7962: loss: 0.2486, d_k_M range: [0.0068, 0.4962], d_k_M_hat range: [0.8536, 0.9997]
2025-03-11 20:47:24 - Train Iteration 7963: loss: 0.1300, d_k_M range: [0.0000, 0.3422], d_k_M_hat range: [0.6670, 0.9909]
2025-03-11 20:47:24 - Train Iteration 7964: loss: 0.2651, d_k_M range: [0.0021, 0.5020], d_k_M_hat range: [0.6133, 0.9958]
2025-03-11 20:47:25 - Train Iteration 7965: loss: 0.2189, d_k_M range: [0.0001, 0.4479], d_k_M_hat range: [0.6623, 0.9979]
2025-03-11 20:47:25 - Train Iteration 7966: loss: 0.2137, d_k_M range: [0.0001, 0.1012], d_k_M_hat range: [0.5378, 0.9901]
2025-03-11 20:47:26 - Train Iteration 7967: loss: 0.4179, d_k_M range: [0.0006, 0.6464], d_k_M_hat range: [0.5993, 0.9999]
2025-03-11 20:47:26 - Train Iteration 7968: loss: 0.6877, d_k_M range: [0.0000, 0.2298], d_k_M_hat range: [0.1707, 0.9797]
2025-03-11 20:47:27 - Train Iteration 7969: loss: 0.3470, d_k_M range: [0.0041, 0.5879], d_k_M_hat range: [0.8196, 0.9997]
2025-03-11 20:47:27 - Train Iteration 7970: loss: 0.1986, d_k_M range: [0.0001, 0.4265], d_k_M_hat range: [0.5548, 0.9964]
2025-03-11 20:47:27 - Train Iteration 7971: loss: 0.0863, d_k_M range: [0.0040, 0.2650], d_k_M_hat range: [0.8218, 0.9930]
2025-03-11 20:47:28 - Train Iteration 7972: loss: 0.0716, d_k_M range: [0.0006, 0.1663], d_k_M_hat range: [0.7500, 0.9941]
2025-03-11 20:47:28 - Train Iteration 7973: loss: 0.1690, d_k_M range: [0.0016, 0.2220], d_k_M_hat range: [0.6048, 0.9988]
2025-03-11 20:47:29 - Train Iteration 7974: loss: 0.2194, d_k_M range: [0.0004, 0.4676], d_k_M_hat range: [0.5846, 0.9996]
2025-03-11 20:47:29 - Train Iteration 7975: loss: 0.1585, d_k_M range: [0.0017, 0.1912], d_k_M_hat range: [0.6054, 0.9878]
2025-03-11 20:47:30 - Train Iteration 7976: loss: 0.3382, d_k_M range: [0.0007, 0.5813], d_k_M_hat range: [0.8907, 0.9998]
2025-03-11 20:47:30 - Train Iteration 7977: loss: 0.3766, d_k_M range: [0.0014, 0.3955], d_k_M_hat range: [0.3885, 0.9965]
2025-03-11 20:47:30 - Train Iteration 7978: loss: 0.1054, d_k_M range: [0.0007, 0.2535], d_k_M_hat range: [0.6952, 0.9983]
2025-03-11 20:47:31 - Train Iteration 7979: loss: 0.0933, d_k_M range: [0.0042, 0.3013], d_k_M_hat range: [0.7916, 0.9959]
2025-03-11 20:47:31 - Train Iteration 7980: loss: 0.2222, d_k_M range: [0.0000, 0.3296], d_k_M_hat range: [0.5289, 0.9912]
2025-03-11 20:47:32 - Train Iteration 7981: loss: 0.2294, d_k_M range: [0.0069, 0.4777], d_k_M_hat range: [0.7062, 0.9988]
2025-03-11 20:47:32 - Train Iteration 7982: loss: 0.2156, d_k_M range: [0.0013, 0.4629], d_k_M_hat range: [0.6941, 0.9986]
2025-03-11 20:47:33 - Train Iteration 7983: loss: 0.2256, d_k_M range: [0.0000, 0.2244], d_k_M_hat range: [0.5268, 0.9776]
2025-03-11 20:47:33 - Train Iteration 7984: loss: 0.0448, d_k_M range: [0.0006, 0.2067], d_k_M_hat range: [0.8013, 0.9951]
2025-03-11 20:47:34 - Train Iteration 7985: loss: 0.1604, d_k_M range: [0.0019, 0.2836], d_k_M_hat range: [0.8831, 0.9998]
2025-03-11 20:47:34 - Train Iteration 7986: loss: 0.1819, d_k_M range: [0.0003, 0.4249], d_k_M_hat range: [0.6331, 0.9983]
2025-03-11 20:47:35 - Train Iteration 7987: loss: 0.3337, d_k_M range: [0.0000, 0.0100], d_k_M_hat range: [0.4226, 0.7498]
2025-03-11 20:47:35 - Train Iteration 7988: loss: 0.1300, d_k_M range: [0.0003, 0.1343], d_k_M_hat range: [0.6415, 0.9988]
2025-03-11 20:47:36 - Train Iteration 7989: loss: 0.2894, d_k_M range: [0.0014, 0.5375], d_k_M_hat range: [0.7353, 0.9997]
2025-03-11 20:47:36 - Train Iteration 7990: loss: 0.0984, d_k_M range: [0.0005, 0.2957], d_k_M_hat range: [0.7535, 0.9888]
2025-03-11 20:47:36 - Train Iteration 7991: loss: 0.1095, d_k_M range: [0.0018, 0.3218], d_k_M_hat range: [0.8151, 0.9950]
2025-03-11 20:47:37 - Train Iteration 7992: loss: 0.1209, d_k_M range: [0.0005, 0.1402], d_k_M_hat range: [0.6536, 0.9874]
2025-03-11 20:47:37 - Train Iteration 7993: loss: 0.1541, d_k_M range: [0.0020, 0.3816], d_k_M_hat range: [0.6094, 0.9982]
2025-03-11 20:47:38 - Train Iteration 7994: loss: 0.1941, d_k_M range: [0.0268, 0.4380], d_k_M_hat range: [0.8779, 0.9974]
2025-03-11 20:47:38 - Train Iteration 7995: loss: 0.4975, d_k_M range: [0.0009, 0.4717], d_k_M_hat range: [0.2961, 0.9953]
2025-03-11 20:47:39 - Train Iteration 7996: loss: 0.2641, d_k_M range: [0.0013, 0.5083], d_k_M_hat range: [0.9561, 0.9974]
2025-03-11 20:47:39 - Train Iteration 7997: loss: 0.2090, d_k_M range: [0.0003, 0.0439], d_k_M_hat range: [0.5605, 0.9629]
2025-03-11 20:47:40 - Train Iteration 7998: loss: 0.1808, d_k_M range: [0.0000, 0.3248], d_k_M_hat range: [0.5748, 0.9992]
2025-03-11 20:47:40 - Train Iteration 7999: loss: 0.5535, d_k_M range: [0.0003, 0.7407], d_k_M_hat range: [0.7006, 0.9968]
2025-03-11 20:47:41 - Train Iteration 8000: loss: 0.4781, d_k_M range: [0.0001, 0.0112], d_k_M_hat range: [0.3087, 0.7613]
2025-03-11 20:47:41 - Train Iteration 8001: loss: 0.2792, d_k_M range: [0.0010, 0.4823], d_k_M_hat range: [0.6104, 0.9961]
2025-03-11 20:47:42 - Train Iteration 8002: loss: 0.2151, d_k_M range: [0.0001, 0.1447], d_k_M_hat range: [0.5366, 0.9727]
2025-03-11 20:47:42 - Train Iteration 8003: loss: 0.2435, d_k_M range: [0.0007, 0.3017], d_k_M_hat range: [0.5484, 0.9993]
2025-03-11 20:47:43 - Train Iteration 8004: loss: 0.1681, d_k_M range: [0.0002, 0.1774], d_k_M_hat range: [0.5908, 0.9793]
2025-03-11 20:47:43 - Train Iteration 8005: loss: 0.3540, d_k_M range: [0.0264, 0.5948], d_k_M_hat range: [0.9436, 0.9998]
2025-03-11 20:47:44 - Train Iteration 8006: loss: 0.3550, d_k_M range: [0.0003, 0.3328], d_k_M_hat range: [0.4047, 0.9949]
2025-03-11 20:47:44 - Train Iteration 8007: loss: 0.0730, d_k_M range: [0.0014, 0.2332], d_k_M_hat range: [0.8777, 0.9907]
2025-03-11 20:47:45 - Train Iteration 8008: loss: 0.1280, d_k_M range: [0.0001, 0.3445], d_k_M_hat range: [0.6915, 0.9973]
2025-03-11 20:47:45 - Train Iteration 8009: loss: 0.1547, d_k_M range: [0.0001, 0.3193], d_k_M_hat range: [0.6070, 0.9899]
2025-03-11 20:47:45 - Train Iteration 8010: loss: 0.4139, d_k_M range: [0.0000, 0.2733], d_k_M_hat range: [0.3567, 0.9945]
2025-03-11 20:47:46 - Train Iteration 8011: loss: 0.0934, d_k_M range: [0.0004, 0.3027], d_k_M_hat range: [0.7968, 0.9971]
2025-03-11 20:47:46 - Train Iteration 8012: loss: 0.0648, d_k_M range: [0.0017, 0.2215], d_k_M_hat range: [0.7530, 0.9975]
2025-03-11 20:47:47 - Train Iteration 8013: loss: 0.2483, d_k_M range: [0.0029, 0.4943], d_k_M_hat range: [0.8358, 0.9979]
2025-03-11 20:47:47 - Train Iteration 8014: loss: 0.1038, d_k_M range: [0.0023, 0.3189], d_k_M_hat range: [0.8824, 0.9968]
2025-03-11 20:47:48 - Train Iteration 8015: loss: 0.0589, d_k_M range: [0.0002, 0.0423], d_k_M_hat range: [0.7597, 0.9926]
2025-03-11 20:47:48 - Train Iteration 8016: loss: 0.2314, d_k_M range: [0.0010, 0.4800], d_k_M_hat range: [0.7256, 0.9989]
2025-03-11 20:47:48 - Train Iteration 8017: loss: 0.1854, d_k_M range: [0.0012, 0.0798], d_k_M_hat range: [0.5709, 0.9675]
2025-03-11 20:47:49 - Train Iteration 8018: loss: 0.1551, d_k_M range: [0.0088, 0.3854], d_k_M_hat range: [0.8757, 0.9997]
2025-03-11 20:47:49 - Train Iteration 8019: loss: 0.2219, d_k_M range: [0.0025, 0.4655], d_k_M_hat range: [0.9319, 0.9989]
2025-03-11 20:47:50 - Train Iteration 8020: loss: 0.6601, d_k_M range: [0.0004, 0.8052], d_k_M_hat range: [0.8422, 0.9928]
2025-03-11 20:47:50 - Train Iteration 8021: loss: 0.0767, d_k_M range: [0.0075, 0.1833], d_k_M_hat range: [0.7928, 0.9845]
2025-03-11 20:47:51 - Train Iteration 8022: loss: 0.6703, d_k_M range: [0.0000, 0.4432], d_k_M_hat range: [0.1813, 0.9994]
2025-03-11 20:47:51 - Train Iteration 8023: loss: 0.4940, d_k_M range: [0.0389, 0.7016], d_k_M_hat range: [0.9921, 0.9998]
2025-03-11 20:47:51 - Train Iteration 8024: loss: 0.6868, d_k_M range: [0.0000, 0.1169], d_k_M_hat range: [0.1713, 0.9985]
2025-03-11 20:47:52 - Train Iteration 8025: loss: 0.1522, d_k_M range: [0.0018, 0.1421], d_k_M_hat range: [0.6116, 0.9965]
2025-03-11 20:47:52 - Train Iteration 8026: loss: 0.1280, d_k_M range: [0.0051, 0.3507], d_k_M_hat range: [0.8670, 0.9963]
2025-03-11 20:47:53 - Train Iteration 8027: loss: 0.2090, d_k_M range: [0.0003, 0.0615], d_k_M_hat range: [0.5477, 0.9900]
2025-03-11 20:47:53 - Train Iteration 8028: loss: 0.2386, d_k_M range: [0.0022, 0.4876], d_k_M_hat range: [0.5696, 0.9991]
2025-03-11 20:47:53 - Train Iteration 8029: loss: 0.1166, d_k_M range: [0.0000, 0.2373], d_k_M_hat range: [0.6610, 0.9709]
2025-03-11 20:47:54 - Train Iteration 8030: loss: 0.2700, d_k_M range: [0.0003, 0.5119], d_k_M_hat range: [0.7317, 0.9956]
2025-03-11 20:47:54 - Train Iteration 8031: loss: 0.5967, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.2275, 0.7915]
2025-03-11 20:47:55 - Train Iteration 8032: loss: 0.1253, d_k_M range: [0.0173, 0.3416], d_k_M_hat range: [0.8844, 0.9978]
2025-03-11 20:47:55 - Train Iteration 8033: loss: 0.5944, d_k_M range: [0.0001, 0.7709], d_k_M_hat range: [0.6191, 1.0000]
2025-03-11 20:47:56 - Train Iteration 8034: loss: 0.1576, d_k_M range: [0.0008, 0.1014], d_k_M_hat range: [0.6069, 0.9910]
2025-03-11 20:47:56 - Train Iteration 8035: loss: 0.0363, d_k_M range: [0.0054, 0.1841], d_k_M_hat range: [0.9037, 0.9996]
2025-03-11 20:47:57 - Train Iteration 8036: loss: 0.3862, d_k_M range: [0.0001, 0.6213], d_k_M_hat range: [0.5621, 0.9998]
2025-03-11 20:47:57 - Train Iteration 8037: loss: 0.0856, d_k_M range: [0.0005, 0.2901], d_k_M_hat range: [0.7739, 0.9976]
2025-03-11 20:47:58 - Train Iteration 8038: loss: 0.1401, d_k_M range: [0.0009, 0.3441], d_k_M_hat range: [0.6268, 0.9984]
2025-03-11 20:47:58 - Train Iteration 8039: loss: 0.2075, d_k_M range: [0.0032, 0.2879], d_k_M_hat range: [0.5506, 0.9978]
2025-03-11 20:47:58 - Train Iteration 8040: loss: 0.3834, d_k_M range: [0.0002, 0.1287], d_k_M_hat range: [0.3810, 0.9894]
2025-03-11 20:47:59 - Train Iteration 8041: loss: 0.1534, d_k_M range: [0.0001, 0.3241], d_k_M_hat range: [0.6085, 0.9996]
2025-03-11 20:47:59 - Train Iteration 8042: loss: 0.2725, d_k_M range: [0.0013, 0.5216], d_k_M_hat range: [0.7485, 0.9997]
2025-03-11 20:48:00 - Train Iteration 8043: loss: 0.2600, d_k_M range: [0.0002, 0.5088], d_k_M_hat range: [0.6781, 0.9990]
2025-03-11 20:48:00 - Train Iteration 8044: loss: 0.2142, d_k_M range: [0.0003, 0.4624], d_k_M_hat range: [0.6709, 0.9996]
2025-03-11 20:48:01 - Train Iteration 8045: loss: 0.1160, d_k_M range: [0.0001, 0.0389], d_k_M_hat range: [0.6596, 0.9820]
2025-03-11 20:48:01 - Train Iteration 8046: loss: 0.2516, d_k_M range: [0.0002, 0.4895], d_k_M_hat range: [0.4985, 0.9984]
2025-03-11 20:48:02 - Train Iteration 8047: loss: 0.3722, d_k_M range: [0.0014, 0.6082], d_k_M_hat range: [0.9688, 0.9981]
2025-03-11 20:48:02 - Train Iteration 8048: loss: 0.1209, d_k_M range: [0.0001, 0.2846], d_k_M_hat range: [0.6523, 0.9935]
2025-03-11 20:48:02 - Train Iteration 8049: loss: 0.1706, d_k_M range: [0.0014, 0.3355], d_k_M_hat range: [0.5889, 0.9946]
2025-03-11 20:48:03 - Train Iteration 8050: loss: 0.2923, d_k_M range: [0.0026, 0.5405], d_k_M_hat range: [0.8140, 0.9998]
2025-03-11 20:48:03 - Train Iteration 8051: loss: 0.0306, d_k_M range: [0.0002, 0.0481], d_k_M_hat range: [0.8254, 0.9946]
2025-03-11 20:48:04 - Train Iteration 8052: loss: 0.1433, d_k_M range: [0.0078, 0.3743], d_k_M_hat range: [0.9221, 0.9996]
2025-03-11 20:48:04 - Train Iteration 8053: loss: 0.0928, d_k_M range: [0.0000, 0.1674], d_k_M_hat range: [0.6954, 0.9978]
2025-03-11 20:48:05 - Train Iteration 8054: loss: 0.1320, d_k_M range: [0.0000, 0.1820], d_k_M_hat range: [0.8138, 0.9915]
2025-03-11 20:48:05 - Train Iteration 8055: loss: 0.1379, d_k_M range: [0.0056, 0.3680], d_k_M_hat range: [0.8707, 0.9970]
2025-03-11 20:48:05 - Train Iteration 8056: loss: 0.1022, d_k_M range: [0.0005, 0.3034], d_k_M_hat range: [0.6808, 0.9996]
2025-03-11 20:48:06 - Train Iteration 8057: loss: 0.1697, d_k_M range: [0.0009, 0.4118], d_k_M_hat range: [0.6594, 0.9999]
2025-03-11 20:48:06 - Train Iteration 8058: loss: 0.2574, d_k_M range: [0.0012, 0.5071], d_k_M_hat range: [0.8635, 0.9997]
2025-03-11 20:48:07 - Train Iteration 8059: loss: 0.1920, d_k_M range: [0.0025, 0.4329], d_k_M_hat range: [0.8842, 0.9994]
2025-03-11 20:48:07 - Train Iteration 8060: loss: 0.1045, d_k_M range: [0.0000, 0.1653], d_k_M_hat range: [0.6770, 0.9980]
2025-03-11 20:48:08 - Train Iteration 8061: loss: 0.2132, d_k_M range: [0.0034, 0.2864], d_k_M_hat range: [0.5529, 0.9987]
2025-03-11 20:48:08 - Train Iteration 8062: loss: 0.2622, d_k_M range: [0.0003, 0.0568], d_k_M_hat range: [0.4915, 0.9437]
2025-03-11 20:48:09 - Train Iteration 8063: loss: 0.2223, d_k_M range: [0.0092, 0.4691], d_k_M_hat range: [0.9744, 0.9977]
2025-03-11 20:48:09 - Train Iteration 8064: loss: 0.4314, d_k_M range: [0.0001, 0.0937], d_k_M_hat range: [0.3434, 0.9893]
2025-03-11 20:48:09 - Train Iteration 8065: loss: 0.4081, d_k_M range: [0.0015, 0.6387], d_k_M_hat range: [0.8617, 0.9999]
2025-03-11 20:48:10 - Train Iteration 8066: loss: 0.2881, d_k_M range: [0.0001, 0.1047], d_k_M_hat range: [0.4636, 0.9736]
2025-03-11 20:48:10 - Train Iteration 8067: loss: 0.1776, d_k_M range: [0.0009, 0.4202], d_k_M_hat range: [0.9212, 0.9987]
2025-03-11 20:48:11 - Train Iteration 8068: loss: 0.2280, d_k_M range: [0.0001, 0.1264], d_k_M_hat range: [0.5226, 0.9977]
2025-03-11 20:48:11 - Train Iteration 8069: loss: 0.1436, d_k_M range: [0.0011, 0.3766], d_k_M_hat range: [0.7919, 0.9990]
2025-03-11 20:48:12 - Train Iteration 8070: loss: 0.1334, d_k_M range: [0.0001, 0.1853], d_k_M_hat range: [0.6481, 0.9958]
2025-03-11 20:48:12 - Train Iteration 8071: loss: 0.2255, d_k_M range: [0.0108, 0.4735], d_k_M_hat range: [0.9629, 0.9999]
2025-03-11 20:48:13 - Train Iteration 8072: loss: 0.3041, d_k_M range: [0.0000, 0.1588], d_k_M_hat range: [0.4486, 0.9841]
2025-03-11 20:48:13 - Train Iteration 8073: loss: 0.2802, d_k_M range: [0.0004, 0.5290], d_k_M_hat range: [0.5992, 0.9997]
2025-03-11 20:48:13 - Train Iteration 8074: loss: 0.1771, d_k_M range: [0.0001, 0.0342], d_k_M_hat range: [0.5804, 0.9561]
2025-03-11 20:48:14 - Train Iteration 8075: loss: 0.1139, d_k_M range: [0.0384, 0.3343], d_k_M_hat range: [0.8722, 0.9995]
2025-03-11 20:48:14 - Train Iteration 8076: loss: 0.2652, d_k_M range: [0.0010, 0.4449], d_k_M_hat range: [0.4860, 0.9995]
2025-03-11 20:48:15 - Train Iteration 8077: loss: 0.5818, d_k_M range: [0.0002, 0.3331], d_k_M_hat range: [0.2374, 0.9987]
2025-03-11 20:48:15 - Train Iteration 8078: loss: 0.3756, d_k_M range: [0.0000, 0.6076], d_k_M_hat range: [0.7882, 0.9948]
2025-03-11 20:48:16 - Train Iteration 8079: loss: 0.0833, d_k_M range: [0.0000, 0.1831], d_k_M_hat range: [0.7114, 0.9873]
2025-03-11 20:48:16 - Train Iteration 8080: loss: 0.1262, d_k_M range: [0.0001, 0.3467], d_k_M_hat range: [0.6761, 0.9999]
2025-03-11 20:48:16 - Train Iteration 8081: loss: 0.1377, d_k_M range: [0.0001, 0.1886], d_k_M_hat range: [0.6305, 0.9918]
2025-03-11 20:48:17 - Train Iteration 8082: loss: 0.6348, d_k_M range: [0.0006, 0.7962], d_k_M_hat range: [0.9231, 0.9998]
2025-03-11 20:48:17 - Train Iteration 8083: loss: 0.2030, d_k_M range: [0.0031, 0.3036], d_k_M_hat range: [0.5527, 0.9856]
2025-03-11 20:48:18 - Train Iteration 8084: loss: 0.4197, d_k_M range: [0.0003, 0.6476], d_k_M_hat range: [0.5102, 0.9998]
2025-03-11 20:48:18 - Train Iteration 8085: loss: 0.3038, d_k_M range: [0.0003, 0.0803], d_k_M_hat range: [0.4491, 0.9539]
2025-03-11 20:48:18 - Train Iteration 8086: loss: 0.3702, d_k_M range: [0.0027, 0.6039], d_k_M_hat range: [0.7319, 0.9997]
2025-03-11 20:48:19 - Train Iteration 8087: loss: 0.8860, d_k_M range: [0.0007, 0.3387], d_k_M_hat range: [0.0595, 0.9985]
2025-03-11 20:48:19 - Train Iteration 8088: loss: 0.5587, d_k_M range: [0.0227, 0.7474], d_k_M_hat range: [0.9755, 1.0000]
2025-03-11 20:48:20 - Train Iteration 8089: loss: 0.1721, d_k_M range: [0.0006, 0.2469], d_k_M_hat range: [0.5864, 0.9807]
2025-03-11 20:48:20 - Train Iteration 8090: loss: 0.3629, d_k_M range: [0.0036, 0.6016], d_k_M_hat range: [0.9686, 0.9992]
2025-03-11 20:48:21 - Train Iteration 8091: loss: 0.2609, d_k_M range: [0.0000, 0.5102], d_k_M_hat range: [0.5929, 0.9994]
2025-03-11 20:48:21 - Train Iteration 8092: loss: 0.1757, d_k_M range: [0.0003, 0.0995], d_k_M_hat range: [0.6524, 0.9691]
2025-03-11 20:48:21 - Train Iteration 8093: loss: 0.1704, d_k_M range: [0.0024, 0.2449], d_k_M_hat range: [0.5896, 0.9946]
2025-03-11 20:48:22 - Train Iteration 8094: loss: 0.3324, d_k_M range: [0.0098, 0.5764], d_k_M_hat range: [0.9180, 0.9999]
2025-03-11 20:48:22 - Train Iteration 8095: loss: 0.2236, d_k_M range: [0.0005, 0.4564], d_k_M_hat range: [0.5276, 0.9999]
2025-03-11 20:48:23 - Train Iteration 8096: loss: 0.1471, d_k_M range: [0.0029, 0.3833], d_k_M_hat range: [0.8980, 0.9999]
2025-03-11 20:48:23 - Train Iteration 8097: loss: 0.4722, d_k_M range: [0.0000, 0.0342], d_k_M_hat range: [0.3247, 0.9889]
2025-03-11 20:48:24 - Train Iteration 8098: loss: 0.2033, d_k_M range: [0.0049, 0.4501], d_k_M_hat range: [0.9710, 0.9999]
2025-03-11 20:48:24 - Train Iteration 8099: loss: 0.2226, d_k_M range: [0.0002, 0.4669], d_k_M_hat range: [0.6646, 0.9951]
2025-03-11 20:48:25 - Train Iteration 8100: loss: 0.1304, d_k_M range: [0.0001, 0.1748], d_k_M_hat range: [0.6723, 0.9985]
2025-03-11 20:48:25 - Train Iteration 8101: loss: 0.3564, d_k_M range: [0.0011, 0.5968], d_k_M_hat range: [0.8381, 0.9997]
2025-03-11 20:48:25 - Train Iteration 8102: loss: 0.3462, d_k_M range: [0.0003, 0.3906], d_k_M_hat range: [0.4143, 0.9948]
2025-03-11 20:48:26 - Train Iteration 8103: loss: 0.5116, d_k_M range: [0.0093, 0.7150], d_k_M_hat range: [0.9705, 0.9997]
2025-03-11 20:48:26 - Train Iteration 8104: loss: 0.1103, d_k_M range: [0.0024, 0.3167], d_k_M_hat range: [0.9175, 0.9847]
2025-03-11 20:48:27 - Train Iteration 8105: loss: 0.1015, d_k_M range: [0.0000, 0.0117], d_k_M_hat range: [0.6814, 0.9644]
2025-03-11 20:48:27 - Train Iteration 8106: loss: 0.4436, d_k_M range: [0.0004, 0.6584], d_k_M_hat range: [0.4650, 0.9996]
2025-03-11 20:48:28 - Train Iteration 8107: loss: 0.2715, d_k_M range: [0.0029, 0.5193], d_k_M_hat range: [0.8942, 0.9983]
2025-03-11 20:48:28 - Train Iteration 8108: loss: 0.2042, d_k_M range: [0.0000, 0.0771], d_k_M_hat range: [0.5481, 0.9957]
2025-03-11 20:48:28 - Train Iteration 8109: loss: 0.4392, d_k_M range: [0.0039, 0.6626], d_k_M_hat range: [0.8324, 0.9999]
2025-03-11 20:48:29 - Train Iteration 8110: loss: 0.1948, d_k_M range: [0.0000, 0.1344], d_k_M_hat range: [0.5587, 0.9749]
2025-03-11 20:48:29 - Train Iteration 8111: loss: 0.2560, d_k_M range: [0.0112, 0.5046], d_k_M_hat range: [0.8543, 0.9989]
2025-03-11 20:48:30 - Train Iteration 8112: loss: 0.1914, d_k_M range: [0.0001, 0.4366], d_k_M_hat range: [0.6803, 0.9991]
2025-03-11 20:48:30 - Train Iteration 8113: loss: 0.0326, d_k_M range: [0.0007, 0.1750], d_k_M_hat range: [0.8577, 0.9946]
2025-03-11 20:48:31 - Train Iteration 8114: loss: 0.0622, d_k_M range: [0.0042, 0.2432], d_k_M_hat range: [0.9428, 0.9979]
2025-03-11 20:48:31 - Train Iteration 8115: loss: 0.2973, d_k_M range: [0.0000, 0.2435], d_k_M_hat range: [0.4549, 0.9810]
2025-03-11 20:48:32 - Train Iteration 8116: loss: 0.1454, d_k_M range: [0.0001, 0.2052], d_k_M_hat range: [0.6196, 0.9989]
2025-03-11 20:48:32 - Train Iteration 8117: loss: 0.1853, d_k_M range: [0.0003, 0.1479], d_k_M_hat range: [0.5711, 0.9929]
2025-03-11 20:48:33 - Train Iteration 8118: loss: 0.2590, d_k_M range: [0.0027, 0.5043], d_k_M_hat range: [0.7495, 0.9984]
2025-03-11 20:48:33 - Train Iteration 8119: loss: 0.0543, d_k_M range: [0.0004, 0.0289], d_k_M_hat range: [0.7675, 0.9839]
2025-03-11 20:48:34 - Train Iteration 8120: loss: 0.2961, d_k_M range: [0.0012, 0.5437], d_k_M_hat range: [0.8256, 0.9997]
2025-03-11 20:48:34 - Train Iteration 8121: loss: 0.1249, d_k_M range: [0.0014, 0.3438], d_k_M_hat range: [0.6480, 0.9946]
2025-03-11 20:48:34 - Train Iteration 8122: loss: 0.1403, d_k_M range: [0.0171, 0.3666], d_k_M_hat range: [0.9151, 0.9920]
2025-03-11 20:48:35 - Train Iteration 8123: loss: 0.2352, d_k_M range: [0.0004, 0.0174], d_k_M_hat range: [0.5157, 0.9568]
2025-03-11 20:48:35 - Train Iteration 8124: loss: 0.2392, d_k_M range: [0.0039, 0.4882], d_k_M_hat range: [0.8170, 0.9995]
2025-03-11 20:48:36 - Train Iteration 8125: loss: 0.1922, d_k_M range: [0.0005, 0.2581], d_k_M_hat range: [0.5720, 0.9978]
2025-03-11 20:48:36 - Train Iteration 8126: loss: 0.2474, d_k_M range: [0.0121, 0.4957], d_k_M_hat range: [0.9546, 0.9999]
2025-03-11 20:48:37 - Train Iteration 8127: loss: 0.1926, d_k_M range: [0.0001, 0.0288], d_k_M_hat range: [0.5618, 0.9893]
2025-03-11 20:48:37 - Train Iteration 8128: loss: 0.3212, d_k_M range: [0.0004, 0.4547], d_k_M_hat range: [0.4341, 0.9996]
2025-03-11 20:48:37 - Train Iteration 8129: loss: 0.0479, d_k_M range: [0.0001, 0.1743], d_k_M_hat range: [0.7984, 0.9992]
2025-03-11 20:48:38 - Train Iteration 8130: loss: 0.1790, d_k_M range: [0.0001, 0.0695], d_k_M_hat range: [0.5772, 0.9974]
2025-03-11 20:48:38 - Train Iteration 8131: loss: 0.0484, d_k_M range: [0.0024, 0.2178], d_k_M_hat range: [0.9000, 0.9979]
2025-03-11 20:48:39 - Train Iteration 8132: loss: 0.1311, d_k_M range: [0.0005, 0.3613], d_k_M_hat range: [0.6606, 0.9993]
2025-03-11 20:48:39 - Train Iteration 8133: loss: 0.0507, d_k_M range: [0.0032, 0.1952], d_k_M_hat range: [0.7816, 0.9987]
2025-03-11 20:48:40 - Train Iteration 8134: loss: 0.1394, d_k_M range: [0.0005, 0.3682], d_k_M_hat range: [0.6935, 0.9948]
2025-03-11 20:48:40 - Train Iteration 8135: loss: 0.3236, d_k_M range: [0.0000, 0.3096], d_k_M_hat range: [0.4329, 0.9955]
2025-03-11 20:48:41 - Train Iteration 8136: loss: 0.3469, d_k_M range: [0.0010, 0.5834], d_k_M_hat range: [0.7180, 0.9997]
2025-03-11 20:48:41 - Train Iteration 8137: loss: 0.2621, d_k_M range: [0.0002, 0.1152], d_k_M_hat range: [0.4897, 0.9933]
2025-03-11 20:48:41 - Train Iteration 8138: loss: 0.1912, d_k_M range: [0.1162, 0.4331], d_k_M_hat range: [0.9923, 0.9998]
2025-03-11 20:48:42 - Train Iteration 8139: loss: 0.0604, d_k_M range: [0.0000, 0.0493], d_k_M_hat range: [0.7544, 0.9899]
2025-03-11 20:48:42 - Train Iteration 8140: loss: 0.5373, d_k_M range: [0.0003, 0.7299], d_k_M_hat range: [0.8709, 0.9991]
2025-03-11 20:48:43 - Train Iteration 8141: loss: 0.1699, d_k_M range: [0.0001, 0.1291], d_k_M_hat range: [0.5879, 0.9943]
2025-03-11 20:48:43 - Train Iteration 8142: loss: 0.2648, d_k_M range: [0.0002, 0.5145], d_k_M_hat range: [0.9620, 0.9999]
2025-03-11 20:48:44 - Train Iteration 8143: loss: 0.2208, d_k_M range: [0.0000, 0.1881], d_k_M_hat range: [0.5301, 0.9863]
2025-03-11 20:48:44 - Train Iteration 8144: loss: 0.3256, d_k_M range: [0.0050, 0.5701], d_k_M_hat range: [0.7271, 0.9997]
2025-03-11 20:48:45 - Train Iteration 8145: loss: 0.1686, d_k_M range: [0.0001, 0.3108], d_k_M_hat range: [0.5895, 0.9901]
2025-03-11 20:48:45 - Train Iteration 8146: loss: 0.1256, d_k_M range: [0.0013, 0.2938], d_k_M_hat range: [0.6472, 0.9995]
2025-03-11 20:48:45 - Train Iteration 8147: loss: 0.0544, d_k_M range: [0.0004, 0.2194], d_k_M_hat range: [0.9819, 0.9990]
2025-03-11 20:48:46 - Train Iteration 8148: loss: 0.1370, d_k_M range: [0.0001, 0.2921], d_k_M_hat range: [0.6299, 0.9991]
2025-03-11 20:48:46 - Train Iteration 8149: loss: 0.1115, d_k_M range: [0.0017, 0.3329], d_k_M_hat range: [0.9528, 0.9997]
2025-03-11 20:48:47 - Train Iteration 8150: loss: 0.2509, d_k_M range: [0.0001, 0.4995], d_k_M_hat range: [0.7204, 0.9996]
2025-03-11 20:48:47 - Train Iteration 8151: loss: 0.1008, d_k_M range: [0.0000, 0.0771], d_k_M_hat range: [0.6825, 0.9880]
2025-03-11 20:48:48 - Train Iteration 8152: loss: 0.2405, d_k_M range: [0.0005, 0.4886], d_k_M_hat range: [0.8878, 0.9996]
2025-03-11 20:48:48 - Train Iteration 8153: loss: 0.2471, d_k_M range: [0.0001, 0.0104], d_k_M_hat range: [0.5046, 0.9759]
2025-03-11 20:48:48 - Train Iteration 8154: loss: 0.1283, d_k_M range: [0.0002, 0.3509], d_k_M_hat range: [0.8317, 0.9990]
2025-03-11 20:48:49 - Train Iteration 8155: loss: 0.2432, d_k_M range: [0.0001, 0.0471], d_k_M_hat range: [0.5069, 0.9824]
2025-03-11 20:48:49 - Train Iteration 8156: loss: 0.2464, d_k_M range: [0.0175, 0.4963], d_k_M_hat range: [0.9307, 1.0000]
2025-03-11 20:48:50 - Train Iteration 8157: loss: 0.4623, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.3202, 0.9859]
2025-03-11 20:48:50 - Train Iteration 8158: loss: 0.1741, d_k_M range: [0.0001, 0.3798], d_k_M_hat range: [0.5848, 0.9999]
2025-03-11 20:48:51 - Train Iteration 8159: loss: 0.1982, d_k_M range: [0.0004, 0.4431], d_k_M_hat range: [0.7830, 0.9978]
2025-03-11 20:48:51 - Train Iteration 8160: loss: 0.1844, d_k_M range: [0.0012, 0.4157], d_k_M_hat range: [0.8138, 0.9978]
2025-03-11 20:48:51 - Train Iteration 8161: loss: 0.2375, d_k_M range: [0.0008, 0.4865], d_k_M_hat range: [0.9365, 0.9991]
2025-03-11 20:48:52 - Train Iteration 8162: loss: 0.4519, d_k_M range: [0.0001, 0.6024], d_k_M_hat range: [0.3289, 0.9970]
2025-03-11 20:48:52 - Train Iteration 8163: loss: 0.1022, d_k_M range: [0.0012, 0.3138], d_k_M_hat range: [0.8832, 0.9940]
2025-03-11 20:48:53 - Train Iteration 8164: loss: 0.6057, d_k_M range: [0.0004, 0.7782], d_k_M_hat range: [0.6037, 1.0000]
2025-03-11 20:48:53 - Train Iteration 8165: loss: 0.1926, d_k_M range: [0.0003, 0.0095], d_k_M_hat range: [0.5614, 0.9812]
2025-03-11 20:48:54 - Train Iteration 8166: loss: 0.2291, d_k_M range: [0.0015, 0.4713], d_k_M_hat range: [0.9737, 0.9974]
2025-03-11 20:48:54 - Train Iteration 8167: loss: 0.1716, d_k_M range: [0.0002, 0.0761], d_k_M_hat range: [0.5869, 0.9641]
2025-03-11 20:48:55 - Train Iteration 8168: loss: 0.2096, d_k_M range: [0.0027, 0.4572], d_k_M_hat range: [0.8017, 0.9996]
2025-03-11 20:48:55 - Train Iteration 8169: loss: 0.0932, d_k_M range: [0.0000, 0.2204], d_k_M_hat range: [0.6948, 0.9969]
2025-03-11 20:48:56 - Train Iteration 8170: loss: 0.3579, d_k_M range: [0.0027, 0.5976], d_k_M_hat range: [0.9733, 0.9994]
2025-03-11 20:48:56 - Train Iteration 8171: loss: 0.2670, d_k_M range: [0.0002, 0.0750], d_k_M_hat range: [0.4976, 0.9826]
2025-03-11 20:48:57 - Train Iteration 8172: loss: 0.2084, d_k_M range: [0.0016, 0.2231], d_k_M_hat range: [0.5455, 0.9925]
2025-03-11 20:48:57 - Train Iteration 8173: loss: 0.8156, d_k_M range: [0.0000, 0.2678], d_k_M_hat range: [0.0969, 0.9992]
2025-03-11 20:48:57 - Train Iteration 8174: loss: 0.6324, d_k_M range: [0.2645, 0.7952], d_k_M_hat range: [0.9779, 0.9999]
2025-03-11 20:48:58 - Train Iteration 8175: loss: 0.1756, d_k_M range: [0.0002, 0.2562], d_k_M_hat range: [0.6018, 0.9997]
2025-03-11 20:48:58 - Train Iteration 8176: loss: 0.3687, d_k_M range: [0.0145, 0.6058], d_k_M_hat range: [0.9609, 0.9997]
2025-03-11 20:48:59 - Train Iteration 8177: loss: 0.1347, d_k_M range: [0.0000, 0.0235], d_k_M_hat range: [0.6330, 0.9847]
2025-03-11 20:48:59 - Train Iteration 8178: loss: 0.1451, d_k_M range: [0.0001, 0.2277], d_k_M_hat range: [0.6202, 0.9963]
2025-03-11 20:49:00 - Train Iteration 8179: loss: 0.1658, d_k_M range: [0.0096, 0.4069], d_k_M_hat range: [0.9240, 0.9997]
2025-03-11 20:49:00 - Train Iteration 8180: loss: 0.0416, d_k_M range: [0.0003, 0.0488], d_k_M_hat range: [0.7968, 0.9848]
2025-03-11 20:49:01 - Train Iteration 8181: loss: 0.2803, d_k_M range: [0.0002, 0.0971], d_k_M_hat range: [0.4707, 0.9778]
2025-03-11 20:49:01 - Train Iteration 8182: loss: 0.9318, d_k_M range: [0.0002, 0.9650], d_k_M_hat range: [0.7796, 0.9998]
2025-03-11 20:49:01 - Train Iteration 8183: loss: 0.1994, d_k_M range: [0.0013, 0.4436], d_k_M_hat range: [0.8846, 0.9995]
2025-03-11 20:49:02 - Train Iteration 8184: loss: 0.6551, d_k_M range: [0.0001, 0.0051], d_k_M_hat range: [0.1909, 0.9361]
2025-03-11 20:49:02 - Train Iteration 8185: loss: 0.1218, d_k_M range: [0.0004, 0.3400], d_k_M_hat range: [0.8331, 0.9910]
2025-03-11 20:49:03 - Train Iteration 8186: loss: 0.1572, d_k_M range: [0.0007, 0.0335], d_k_M_hat range: [0.6042, 0.9981]
2025-03-11 20:49:03 - Train Iteration 8187: loss: 0.3363, d_k_M range: [0.0064, 0.5797], d_k_M_hat range: [0.9082, 0.9998]
2025-03-11 20:49:04 - Train Iteration 8188: loss: 0.1852, d_k_M range: [0.0000, 0.0595], d_k_M_hat range: [0.5697, 0.9910]
2025-03-11 20:49:04 - Train Iteration 8189: loss: 0.3398, d_k_M range: [0.0014, 0.5778], d_k_M_hat range: [0.8640, 0.9997]
2025-03-11 20:49:04 - Train Iteration 8190: loss: 0.1309, d_k_M range: [0.0001, 0.3486], d_k_M_hat range: [0.6385, 0.9963]
2025-03-11 20:49:05 - Train Iteration 8191: loss: 0.1966, d_k_M range: [0.0001, 0.4428], d_k_M_hat range: [0.7956, 0.9994]
2025-03-11 20:49:05 - Train Iteration 8192: loss: 0.9182, d_k_M range: [0.0000, 0.0823], d_k_M_hat range: [0.0418, 0.9900]
2025-03-11 20:49:06 - Train Iteration 8193: loss: 0.0783, d_k_M range: [0.0013, 0.2765], d_k_M_hat range: [0.8941, 0.9991]
2025-03-11 20:49:06 - Train Iteration 8194: loss: 0.0859, d_k_M range: [0.0001, 0.0489], d_k_M_hat range: [0.7559, 0.9873]
2025-03-11 20:49:07 - Train Iteration 8195: loss: 0.8954, d_k_M range: [0.0005, 0.9462], d_k_M_hat range: [0.9439, 1.0000]
2025-03-11 20:49:07 - Train Iteration 8196: loss: 0.1049, d_k_M range: [0.0000, 0.2379], d_k_M_hat range: [0.6808, 0.9932]
2025-03-11 20:49:08 - Train Iteration 8197: loss: 0.0826, d_k_M range: [0.0017, 0.2641], d_k_M_hat range: [0.9543, 0.9994]
2025-03-11 20:49:08 - Train Iteration 8198: loss: 0.2102, d_k_M range: [0.0001, 0.0449], d_k_M_hat range: [0.5417, 0.9502]
2025-03-11 20:49:09 - Train Iteration 8199: loss: 0.2093, d_k_M range: [0.0076, 0.4568], d_k_M_hat range: [0.9234, 0.9997]
2025-03-11 20:49:09 - Train Iteration 8200: loss: 0.1249, d_k_M range: [0.0001, 0.0984], d_k_M_hat range: [0.6486, 0.9775]
2025-03-11 20:49:09 - Train Iteration 8201: loss: 0.5233, d_k_M range: [0.0111, 0.7226], d_k_M_hat range: [0.9455, 0.9998]
2025-03-11 20:49:10 - Train Iteration 8202: loss: 0.0474, d_k_M range: [0.0004, 0.2101], d_k_M_hat range: [0.8833, 0.9924]
2025-03-11 20:49:10 - Train Iteration 8203: loss: 0.3160, d_k_M range: [0.0001, 0.0550], d_k_M_hat range: [0.4379, 0.9531]
2025-03-11 20:49:11 - Train Iteration 8204: loss: 0.0729, d_k_M range: [0.0029, 0.2673], d_k_M_hat range: [0.8466, 0.9996]
2025-03-11 20:49:11 - Train Iteration 8205: loss: 0.0789, d_k_M range: [0.0006, 0.2121], d_k_M_hat range: [0.7220, 0.9870]
2025-03-11 20:49:11 - Train Iteration 8206: loss: 0.1111, d_k_M range: [0.0049, 0.3040], d_k_M_hat range: [0.6836, 0.9997]
2025-03-11 20:49:12 - Train Iteration 8207: loss: 0.0828, d_k_M range: [0.0065, 0.2795], d_k_M_hat range: [0.8714, 0.9959]
2025-03-11 20:49:12 - Train Iteration 8208: loss: 0.8400, d_k_M range: [0.0000, 0.0438], d_k_M_hat range: [0.0835, 0.9693]
2025-03-11 20:49:13 - Train Iteration 8209: loss: 0.1320, d_k_M range: [0.0014, 0.3624], d_k_M_hat range: [0.8534, 0.9990]
2025-03-11 20:49:13 - Train Iteration 8210: loss: 0.1949, d_k_M range: [0.0001, 0.2013], d_k_M_hat range: [0.5589, 0.9836]
2025-03-11 20:49:14 - Train Iteration 8211: loss: 0.1145, d_k_M range: [0.0012, 0.3355], d_k_M_hat range: [0.8778, 0.9993]
2025-03-11 20:49:14 - Train Iteration 8212: loss: 0.2657, d_k_M range: [0.0001, 0.1883], d_k_M_hat range: [0.4848, 0.9948]
2025-03-11 20:49:15 - Train Iteration 8213: loss: 0.1233, d_k_M range: [0.0114, 0.3506], d_k_M_hat range: [0.8126, 0.9994]
2025-03-11 20:49:15 - Train Iteration 8214: loss: 0.5117, d_k_M range: [0.0027, 0.7150], d_k_M_hat range: [0.8125, 0.9996]
2025-03-11 20:49:16 - Train Iteration 8215: loss: 0.1042, d_k_M range: [0.0000, 0.1670], d_k_M_hat range: [0.6777, 0.9924]
2025-03-11 20:49:16 - Train Iteration 8216: loss: 0.0520, d_k_M range: [0.0002, 0.1998], d_k_M_hat range: [0.8830, 0.9974]
2025-03-11 20:49:16 - Train Iteration 8217: loss: 0.2111, d_k_M range: [0.0082, 0.4559], d_k_M_hat range: [0.9362, 0.9991]
2025-03-11 20:49:17 - Train Iteration 8218: loss: 0.1351, d_k_M range: [0.0004, 0.2655], d_k_M_hat range: [0.6329, 0.9984]
2025-03-11 20:49:17 - Train Iteration 8219: loss: 0.0544, d_k_M range: [0.0024, 0.2328], d_k_M_hat range: [0.8585, 0.9996]
2025-03-11 20:49:18 - Train Iteration 8220: loss: 0.1934, d_k_M range: [0.0001, 0.0791], d_k_M_hat range: [0.5606, 0.8493]
2025-03-11 20:49:18 - Train Iteration 8221: loss: 0.0997, d_k_M range: [0.0011, 0.3154], d_k_M_hat range: [0.7453, 0.9999]
2025-03-11 20:49:19 - Train Iteration 8222: loss: 0.2120, d_k_M range: [0.0002, 0.0869], d_k_M_hat range: [0.5541, 0.9761]
2025-03-11 20:49:19 - Train Iteration 8223: loss: 0.1526, d_k_M range: [0.0073, 0.3881], d_k_M_hat range: [0.7238, 0.9984]
2025-03-11 20:49:19 - Train Iteration 8224: loss: 0.2902, d_k_M range: [0.0005, 0.5383], d_k_M_hat range: [0.6022, 0.9996]
2025-03-11 20:49:20 - Train Iteration 8225: loss: 0.2144, d_k_M range: [0.0002, 0.4548], d_k_M_hat range: [0.5928, 0.9918]
2025-03-11 20:49:20 - Train Iteration 8226: loss: 0.3091, d_k_M range: [0.0003, 0.1058], d_k_M_hat range: [0.4505, 0.9949]
2025-03-11 20:49:21 - Train Iteration 8227: loss: 0.3650, d_k_M range: [0.0056, 0.6038], d_k_M_hat range: [0.9461, 0.9997]
2025-03-11 20:49:21 - Train Iteration 8228: loss: 0.0619, d_k_M range: [0.0002, 0.2298], d_k_M_hat range: [0.7590, 0.9983]
2025-03-11 20:49:22 - Train Iteration 8229: loss: 0.2588, d_k_M range: [0.0003, 0.0514], d_k_M_hat range: [0.4988, 0.9702]
2025-03-11 20:49:22 - Train Iteration 8230: loss: 0.0684, d_k_M range: [0.0005, 0.1924], d_k_M_hat range: [0.7390, 0.9988]
2025-03-11 20:49:23 - Train Iteration 8231: loss: 0.2578, d_k_M range: [0.0034, 0.4977], d_k_M_hat range: [0.9331, 0.9983]
2025-03-11 20:49:23 - Train Iteration 8232: loss: 0.3483, d_k_M range: [0.0001, 0.1209], d_k_M_hat range: [0.4099, 0.9987]
2025-03-11 20:49:24 - Train Iteration 8233: loss: 0.1553, d_k_M range: [0.0002, 0.1880], d_k_M_hat range: [0.6063, 0.9988]
2025-03-11 20:49:24 - Train Iteration 8234: loss: 0.1693, d_k_M range: [0.0022, 0.4058], d_k_M_hat range: [0.9399, 0.9982]
2025-03-11 20:49:24 - Train Iteration 8235: loss: 0.1926, d_k_M range: [0.0001, 0.4348], d_k_M_hat range: [0.9104, 0.9959]
2025-03-11 20:49:25 - Train Iteration 8236: loss: 0.5420, d_k_M range: [0.0002, 0.0261], d_k_M_hat range: [0.2640, 0.9853]
2025-03-11 20:49:25 - Train Iteration 8237: loss: 0.3306, d_k_M range: [0.0018, 0.5734], d_k_M_hat range: [0.8544, 0.9999]
2025-03-11 20:49:26 - Train Iteration 8238: loss: 0.6645, d_k_M range: [0.0000, 0.0593], d_k_M_hat range: [0.1849, 0.9848]
2025-03-11 20:49:26 - Train Iteration 8239: loss: 0.1400, d_k_M range: [0.0104, 0.3724], d_k_M_hat range: [0.8129, 0.9997]
2025-03-11 20:49:27 - Train Iteration 8240: loss: 0.1226, d_k_M range: [0.0007, 0.3321], d_k_M_hat range: [0.6588, 0.9897]
2025-03-11 20:49:27 - Train Iteration 8241: loss: 0.1319, d_k_M range: [0.0001, 0.3607], d_k_M_hat range: [0.7408, 0.9978]
2025-03-11 20:49:27 - Train Iteration 8242: loss: 0.1120, d_k_M range: [0.0002, 0.3329], d_k_M_hat range: [0.8139, 0.9987]
2025-03-11 20:49:28 - Train Iteration 8243: loss: 0.1537, d_k_M range: [0.0001, 0.1421], d_k_M_hat range: [0.6082, 0.9703]
2025-03-11 20:49:28 - Train Iteration 8244: loss: 0.1386, d_k_M range: [0.0033, 0.3698], d_k_M_hat range: [0.9789, 0.9989]
2025-03-11 20:49:29 - Train Iteration 8245: loss: 0.2044, d_k_M range: [0.0003, 0.4504], d_k_M_hat range: [0.7251, 0.9983]
2025-03-11 20:49:29 - Train Iteration 8246: loss: 0.3718, d_k_M range: [0.0002, 0.6097], d_k_M_hat range: [0.4151, 1.0000]
2025-03-11 20:49:30 - Train Iteration 8247: loss: 0.4078, d_k_M range: [0.0000, 0.0118], d_k_M_hat range: [0.3614, 0.8719]
2025-03-11 20:49:30 - Train Iteration 8248: loss: 0.0278, d_k_M range: [0.0002, 0.1657], d_k_M_hat range: [0.8640, 0.9991]
2025-03-11 20:49:30 - Train Iteration 8249: loss: 0.4633, d_k_M range: [0.0001, 0.0432], d_k_M_hat range: [0.3194, 0.9581]
2025-03-11 20:49:31 - Train Iteration 8250: loss: 0.4610, d_k_M range: [0.0128, 0.6789], d_k_M_hat range: [0.9817, 0.9999]
2025-03-11 20:49:31 - Train Iteration 8251: loss: 0.1719, d_k_M range: [0.0000, 0.4059], d_k_M_hat range: [0.6083, 0.9968]
2025-03-11 20:49:32 - Train Iteration 8252: loss: 0.2115, d_k_M range: [0.0002, 0.4484], d_k_M_hat range: [0.7881, 0.9972]
2025-03-11 20:49:32 - Train Iteration 8253: loss: 0.2978, d_k_M range: [0.0001, 0.1346], d_k_M_hat range: [0.4561, 0.9802]
2025-03-11 20:49:33 - Train Iteration 8254: loss: 0.1975, d_k_M range: [0.0003, 0.3879], d_k_M_hat range: [0.5559, 0.9998]
2025-03-11 20:49:33 - Train Iteration 8255: loss: 0.1317, d_k_M range: [0.0008, 0.2747], d_k_M_hat range: [0.6379, 0.9958]
2025-03-11 20:49:33 - Train Iteration 8256: loss: 0.1252, d_k_M range: [0.0006, 0.1919], d_k_M_hat range: [0.6467, 0.9964]
2025-03-11 20:49:34 - Train Iteration 8257: loss: 0.5084, d_k_M range: [0.0006, 0.3910], d_k_M_hat range: [0.2877, 0.9988]
2025-03-11 20:49:34 - Train Iteration 8258: loss: 0.2810, d_k_M range: [0.0000, 0.5298], d_k_M_hat range: [0.5504, 0.9997]
2025-03-11 20:49:35 - Train Iteration 8259: loss: 0.1231, d_k_M range: [0.0000, 0.0920], d_k_M_hat range: [0.6572, 0.9721]
2025-03-11 20:49:35 - Train Iteration 8260: loss: 0.5807, d_k_M range: [0.0717, 0.7620], d_k_M_hat range: [0.9384, 0.9999]
2025-03-11 20:49:36 - Train Iteration 8261: loss: 0.4705, d_k_M range: [0.0000, 0.0159], d_k_M_hat range: [0.3141, 0.7529]
2025-03-11 20:49:36 - Train Iteration 8262: loss: 0.2891, d_k_M range: [0.0110, 0.5354], d_k_M_hat range: [0.9094, 0.9977]
2025-03-11 20:49:36 - Train Iteration 8263: loss: 0.2229, d_k_M range: [0.0009, 0.4625], d_k_M_hat range: [0.9613, 0.9982]
2025-03-11 20:49:37 - Train Iteration 8264: loss: 0.0997, d_k_M range: [0.0006, 0.0514], d_k_M_hat range: [0.6887, 0.9924]
2025-03-11 20:49:37 - Train Iteration 8265: loss: 0.1296, d_k_M range: [0.0005, 0.3559], d_k_M_hat range: [0.8487, 0.9970]
2025-03-11 20:49:38 - Train Iteration 8266: loss: 0.1348, d_k_M range: [0.0005, 0.1226], d_k_M_hat range: [0.6341, 0.9869]
2025-03-11 20:49:38 - Train Iteration 8267: loss: 0.3700, d_k_M range: [0.0031, 0.6066], d_k_M_hat range: [0.8626, 0.9995]
2025-03-11 20:49:38 - Train Iteration 8268: loss: 0.2070, d_k_M range: [0.0002, 0.2386], d_k_M_hat range: [0.5452, 0.9987]
2025-03-11 20:49:39 - Train Iteration 8269: loss: 0.1132, d_k_M range: [0.0066, 0.3334], d_k_M_hat range: [0.9682, 0.9995]
2025-03-11 20:49:39 - Train Iteration 8270: loss: 0.4512, d_k_M range: [0.0000, 0.6687], d_k_M_hat range: [0.5469, 0.9970]
2025-03-11 20:49:40 - Train Iteration 8271: loss: 0.1163, d_k_M range: [0.0001, 0.2377], d_k_M_hat range: [0.6591, 0.9965]
2025-03-11 20:49:40 - Train Iteration 8272: loss: 0.1831, d_k_M range: [0.0012, 0.4275], d_k_M_hat range: [0.6115, 0.9999]
2025-03-11 20:49:41 - Train Iteration 8273: loss: 0.5249, d_k_M range: [0.0000, 0.0133], d_k_M_hat range: [0.2756, 0.9588]
2025-03-11 20:49:41 - Train Iteration 8274: loss: 0.1490, d_k_M range: [0.0036, 0.3658], d_k_M_hat range: [0.8115, 0.9962]
2025-03-11 20:49:42 - Train Iteration 8275: loss: 0.3951, d_k_M range: [0.0000, 0.1225], d_k_M_hat range: [0.3715, 0.9933]
2025-03-11 20:49:42 - Train Iteration 8276: loss: 0.0731, d_k_M range: [0.0010, 0.2642], d_k_M_hat range: [0.9127, 0.9977]
2025-03-11 20:49:42 - Train Iteration 8277: loss: 0.4388, d_k_M range: [0.0003, 0.1504], d_k_M_hat range: [0.3379, 0.9605]
2025-03-11 20:49:43 - Train Iteration 8278: loss: 0.1223, d_k_M range: [0.0334, 0.3498], d_k_M_hat range: [0.9736, 1.0000]
2025-03-11 20:49:43 - Train Iteration 8279: loss: 0.1488, d_k_M range: [0.0000, 0.3212], d_k_M_hat range: [0.6142, 0.9919]
2025-03-11 20:49:44 - Train Iteration 8280: loss: 0.3199, d_k_M range: [0.0002, 0.3077], d_k_M_hat range: [0.4346, 0.9984]
2025-03-11 20:49:44 - Train Iteration 8281: loss: 0.3162, d_k_M range: [0.0003, 0.1529], d_k_M_hat range: [0.4379, 0.9980]
2025-03-11 20:49:45 - Train Iteration 8282: loss: 0.0505, d_k_M range: [0.0002, 0.0776], d_k_M_hat range: [0.8405, 0.9979]
2025-03-11 20:49:45 - Train Iteration 8283: loss: 0.0398, d_k_M range: [0.0006, 0.1942], d_k_M_hat range: [0.8425, 0.9989]
2025-03-11 20:49:45 - Train Iteration 8284: loss: 0.0769, d_k_M range: [0.0008, 0.2662], d_k_M_hat range: [0.8353, 0.9994]
2025-03-11 20:49:46 - Train Iteration 8285: loss: 0.3102, d_k_M range: [0.0001, 0.0135], d_k_M_hat range: [0.4432, 0.9928]
2025-03-11 20:49:46 - Train Iteration 8286: loss: 0.1288, d_k_M range: [0.0006, 0.3499], d_k_M_hat range: [0.8489, 1.0000]
2025-03-11 20:49:47 - Train Iteration 8287: loss: 0.1174, d_k_M range: [0.0005, 0.2617], d_k_M_hat range: [0.6884, 0.9673]
2025-03-11 20:49:47 - Train Iteration 8288: loss: 0.2069, d_k_M range: [0.0000, 0.3486], d_k_M_hat range: [0.5451, 0.9994]
2025-03-11 20:49:47 - Train Iteration 8289: loss: 0.4806, d_k_M range: [0.0001, 0.6932], d_k_M_hat range: [0.6480, 1.0000]
2025-03-11 20:49:48 - Train Iteration 8290: loss: 0.3066, d_k_M range: [0.0000, 0.0462], d_k_M_hat range: [0.4463, 0.9899]
2025-03-11 20:49:48 - Train Iteration 8291: loss: 0.1772, d_k_M range: [0.0003, 0.4208], d_k_M_hat range: [0.8311, 0.9999]
2025-03-11 20:49:49 - Train Iteration 8292: loss: 0.1564, d_k_M range: [0.0018, 0.3946], d_k_M_hat range: [0.6459, 0.9992]
2025-03-11 20:49:49 - Train Iteration 8293: loss: 0.1226, d_k_M range: [0.0002, 0.3450], d_k_M_hat range: [0.6678, 0.9982]
2025-03-11 20:49:49 - Train Iteration 8294: loss: 0.4619, d_k_M range: [0.0000, 0.0710], d_k_M_hat range: [0.3204, 0.9408]
2025-03-11 20:49:50 - Train Iteration 8295: loss: 0.0972, d_k_M range: [0.0011, 0.2120], d_k_M_hat range: [0.6893, 0.9991]
2025-03-11 20:49:50 - Train Iteration 8296: loss: 0.3223, d_k_M range: [0.0000, 0.3891], d_k_M_hat range: [0.4323, 0.9900]
2025-03-11 20:49:51 - Train Iteration 8297: loss: 0.1220, d_k_M range: [0.0001, 0.3434], d_k_M_hat range: [0.8553, 0.9954]
2025-03-11 20:49:51 - Train Iteration 8298: loss: 0.3081, d_k_M range: [0.0001, 0.2709], d_k_M_hat range: [0.4471, 0.9971]
2025-03-11 20:49:52 - Train Iteration 8299: loss: 0.1232, d_k_M range: [0.0007, 0.3502], d_k_M_hat range: [0.7867, 0.9992]
2025-03-11 20:49:52 - Train Iteration 8300: loss: 0.3363, d_k_M range: [0.0001, 0.0326], d_k_M_hat range: [0.4205, 0.9146]
2025-03-11 20:49:52 - Train Iteration 8301: loss: 0.2732, d_k_M range: [0.0019, 0.0691], d_k_M_hat range: [0.4898, 0.9833]
2025-03-11 20:49:53 - Train Iteration 8302: loss: 0.1194, d_k_M range: [0.0004, 0.2912], d_k_M_hat range: [0.6549, 0.9970]
2025-03-11 20:49:53 - Train Iteration 8303: loss: 0.4074, d_k_M range: [0.0037, 0.6364], d_k_M_hat range: [0.8343, 0.9981]
2025-03-11 20:49:54 - Train Iteration 8304: loss: 0.1552, d_k_M range: [0.0003, 0.2551], d_k_M_hat range: [0.6064, 0.9917]
2025-03-11 20:49:54 - Train Iteration 8305: loss: 0.3461, d_k_M range: [0.0014, 0.5859], d_k_M_hat range: [0.8809, 0.9983]
2025-03-11 20:49:55 - Train Iteration 8306: loss: 0.3516, d_k_M range: [0.0001, 0.1185], d_k_M_hat range: [0.4883, 0.9810]
2025-03-11 20:49:55 - Train Iteration 8307: loss: 0.3481, d_k_M range: [0.0025, 0.5895], d_k_M_hat range: [0.7706, 0.9995]
2025-03-11 20:49:56 - Train Iteration 8308: loss: 0.2776, d_k_M range: [0.0000, 0.0320], d_k_M_hat range: [0.4734, 0.8696]
2025-03-11 20:49:56 - Train Iteration 8309: loss: 0.0544, d_k_M range: [0.0000, 0.2312], d_k_M_hat range: [0.8107, 0.9981]
2025-03-11 20:49:57 - Train Iteration 8310: loss: 0.0721, d_k_M range: [0.0001, 0.2651], d_k_M_hat range: [0.9022, 0.9966]
2025-03-11 20:49:57 - Train Iteration 8311: loss: 0.1820, d_k_M range: [0.0001, 0.1735], d_k_M_hat range: [0.5735, 0.9909]
2025-03-11 20:49:57 - Train Iteration 8312: loss: 0.0692, d_k_M range: [0.0134, 0.2606], d_k_M_hat range: [0.8003, 0.9979]
2025-03-11 20:49:58 - Train Iteration 8313: loss: 0.2402, d_k_M range: [0.0000, 0.0393], d_k_M_hat range: [0.5104, 0.9447]
2025-03-11 20:49:58 - Train Iteration 8314: loss: 0.1868, d_k_M range: [0.0002, 0.3384], d_k_M_hat range: [0.5680, 0.9967]
2025-03-11 20:49:59 - Train Iteration 8315: loss: 0.0540, d_k_M range: [0.0003, 0.2278], d_k_M_hat range: [0.8716, 0.9974]
2025-03-11 20:49:59 - Train Iteration 8316: loss: 0.3083, d_k_M range: [0.0000, 0.0207], d_k_M_hat range: [0.4463, 0.9269]
2025-03-11 20:49:59 - Train Iteration 8317: loss: 0.2684, d_k_M range: [0.0001, 0.5075], d_k_M_hat range: [0.5423, 0.9986]
2025-03-11 20:50:00 - Train Iteration 8318: loss: 0.1250, d_k_M range: [0.0008, 0.0543], d_k_M_hat range: [0.6489, 0.9833]
2025-03-11 20:50:00 - Train Iteration 8319: loss: 0.1322, d_k_M range: [0.0069, 0.3558], d_k_M_hat range: [0.8896, 0.9972]
2025-03-11 20:50:01 - Train Iteration 8320: loss: 0.0657, d_k_M range: [0.0010, 0.0976], d_k_M_hat range: [0.7447, 0.9925]
2025-03-11 20:50:01 - Train Iteration 8321: loss: 0.5942, d_k_M range: [0.0006, 0.7708], d_k_M_hat range: [0.8407, 0.9999]
2025-03-11 20:50:02 - Train Iteration 8322: loss: 0.4457, d_k_M range: [0.0001, 0.0164], d_k_M_hat range: [0.3325, 0.9538]
2025-03-11 20:50:02 - Train Iteration 8323: loss: 0.1666, d_k_M range: [0.0005, 0.4057], d_k_M_hat range: [0.7700, 0.9975]
2025-03-11 20:50:03 - Train Iteration 8324: loss: 0.7238, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.1493, 0.9647]
2025-03-11 20:50:03 - Train Iteration 8325: loss: 0.0842, d_k_M range: [0.0111, 0.2866], d_k_M_hat range: [0.8614, 0.9976]
2025-03-11 20:50:04 - Train Iteration 8326: loss: 0.0584, d_k_M range: [0.0002, 0.2350], d_k_M_hat range: [0.7676, 0.9933]
2025-03-11 20:50:04 - Train Iteration 8327: loss: 0.1807, d_k_M range: [0.0045, 0.4243], d_k_M_hat range: [0.8415, 0.9993]
2025-03-11 20:50:04 - Train Iteration 8328: loss: 0.1738, d_k_M range: [0.0002, 0.4006], d_k_M_hat range: [0.7248, 0.9983]
2025-03-11 20:50:05 - Train Iteration 8329: loss: 0.2821, d_k_M range: [0.0000, 0.5220], d_k_M_hat range: [0.6082, 0.9909]
2025-03-11 20:50:05 - Train Iteration 8330: loss: 0.0481, d_k_M range: [0.0035, 0.1764], d_k_M_hat range: [0.7963, 0.9908]
2025-03-11 20:50:06 - Train Iteration 8331: loss: 0.1855, d_k_M range: [0.0002, 0.4267], d_k_M_hat range: [0.6928, 0.9990]
2025-03-11 20:50:06 - Train Iteration 8332: loss: 0.0854, d_k_M range: [0.0007, 0.1443], d_k_M_hat range: [0.7109, 0.9758]
2025-03-11 20:50:07 - Train Iteration 8333: loss: 0.1825, d_k_M range: [0.0003, 0.4238], d_k_M_hat range: [0.7148, 0.9966]
2025-03-11 20:50:07 - Train Iteration 8334: loss: 0.4252, d_k_M range: [0.0000, 0.1090], d_k_M_hat range: [0.3480, 0.9923]
2025-03-11 20:50:07 - Train Iteration 8335: loss: 0.1234, d_k_M range: [0.0001, 0.3460], d_k_M_hat range: [0.8603, 0.9952]
2025-03-11 20:50:08 - Train Iteration 8336: loss: 0.1943, d_k_M range: [0.0000, 0.0182], d_k_M_hat range: [0.5632, 0.9860]
2025-03-11 20:50:08 - Train Iteration 8337: loss: 0.1249, d_k_M range: [0.0083, 0.3524], d_k_M_hat range: [0.9195, 0.9990]
2025-03-11 20:50:09 - Train Iteration 8338: loss: 0.1693, d_k_M range: [0.0006, 0.0204], d_k_M_hat range: [0.5899, 0.9835]
2025-03-11 20:50:09 - Train Iteration 8339: loss: 0.1504, d_k_M range: [0.0000, 0.3872], d_k_M_hat range: [0.8835, 0.9994]
2025-03-11 20:50:10 - Train Iteration 8340: loss: 0.3644, d_k_M range: [0.0000, 0.5942], d_k_M_hat range: [0.5823, 0.9906]
2025-03-11 20:50:10 - Train Iteration 8341: loss: 0.3501, d_k_M range: [0.0018, 0.4501], d_k_M_hat range: [0.4101, 0.9991]
2025-03-11 20:50:11 - Train Iteration 8342: loss: 0.1052, d_k_M range: [0.0160, 0.2904], d_k_M_hat range: [0.6949, 0.9998]
2025-03-11 20:50:11 - Train Iteration 8343: loss: 0.1313, d_k_M range: [0.0054, 0.3540], d_k_M_hat range: [0.7289, 0.9977]
2025-03-11 20:50:11 - Train Iteration 8344: loss: 0.5053, d_k_M range: [0.0007, 0.7093], d_k_M_hat range: [0.8350, 0.9985]
2025-03-11 20:50:12 - Train Iteration 8345: loss: 0.2086, d_k_M range: [0.0002, 0.4521], d_k_M_hat range: [0.5762, 0.9953]
2025-03-11 20:50:12 - Train Iteration 8346: loss: 0.0846, d_k_M range: [0.0005, 0.2448], d_k_M_hat range: [0.7879, 0.9930]
2025-03-11 20:50:13 - Train Iteration 8347: loss: 0.6819, d_k_M range: [0.0001, 0.5641], d_k_M_hat range: [0.1743, 0.9997]
2025-03-11 20:50:13 - Train Iteration 8348: loss: 0.2901, d_k_M range: [0.0006, 0.2488], d_k_M_hat range: [0.4620, 0.9899]
2025-03-11 20:50:13 - Train Iteration 8349: loss: 0.5039, d_k_M range: [0.0141, 0.7076], d_k_M_hat range: [0.9143, 0.9977]
2025-03-11 20:50:14 - Train Iteration 8350: loss: 0.3449, d_k_M range: [0.0000, 0.0934], d_k_M_hat range: [0.4210, 0.9852]
2025-03-11 20:50:14 - Train Iteration 8351: loss: 0.0859, d_k_M range: [0.0117, 0.2894], d_k_M_hat range: [0.9793, 0.9988]
2025-03-11 20:50:15 - Train Iteration 8352: loss: 0.4092, d_k_M range: [0.0000, 0.3803], d_k_M_hat range: [0.3715, 0.9959]
2025-03-11 20:50:15 - Train Iteration 8353: loss: 0.3856, d_k_M range: [0.0349, 0.6206], d_k_M_hat range: [0.9456, 0.9997]
2025-03-11 20:50:16 - Train Iteration 8354: loss: 0.2977, d_k_M range: [0.0003, 0.1407], d_k_M_hat range: [0.4547, 0.9915]
2025-03-11 20:50:16 - Train Iteration 8355: loss: 0.3568, d_k_M range: [0.0196, 0.5947], d_k_M_hat range: [0.9073, 0.9993]
2025-03-11 20:50:17 - Train Iteration 8356: loss: 0.2023, d_k_M range: [0.0008, 0.4327], d_k_M_hat range: [0.7732, 0.9984]
2025-03-11 20:50:17 - Train Iteration 8357: loss: 0.0920, d_k_M range: [0.0004, 0.0850], d_k_M_hat range: [0.6983, 0.9892]
2025-03-11 20:50:18 - Train Iteration 8358: loss: 0.0940, d_k_M range: [0.0002, 0.0712], d_k_M_hat range: [0.6937, 0.9955]
2025-03-11 20:50:18 - Train Iteration 8359: loss: 0.2814, d_k_M range: [0.0002, 0.5296], d_k_M_hat range: [0.8612, 0.9991]
2025-03-11 20:50:19 - Train Iteration 8360: loss: 0.2503, d_k_M range: [0.0007, 0.0715], d_k_M_hat range: [0.5004, 0.9826]
2025-03-11 20:50:19 - Train Iteration 8361: loss: 0.2658, d_k_M range: [0.0646, 0.5152], d_k_M_hat range: [0.9490, 0.9996]
2025-03-11 20:50:20 - Train Iteration 8362: loss: 0.1213, d_k_M range: [0.0000, 0.1696], d_k_M_hat range: [0.6524, 0.9841]
2025-03-11 20:50:20 - Train Iteration 8363: loss: 0.2281, d_k_M range: [0.0004, 0.4464], d_k_M_hat range: [0.5228, 0.9976]
2025-03-11 20:50:21 - Train Iteration 8364: loss: 0.1807, d_k_M range: [0.0000, 0.0757], d_k_M_hat range: [0.5758, 0.9897]
2025-03-11 20:50:21 - Train Iteration 8365: loss: 0.1748, d_k_M range: [0.0054, 0.3871], d_k_M_hat range: [0.9666, 0.9998]
2025-03-11 20:50:22 - Train Iteration 8366: loss: 0.2893, d_k_M range: [0.0000, 0.2473], d_k_M_hat range: [0.4623, 0.9912]
2025-03-11 20:50:22 - Train Iteration 8367: loss: 0.0821, d_k_M range: [0.0032, 0.2434], d_k_M_hat range: [0.7638, 0.9962]
2025-03-11 20:50:23 - Train Iteration 8368: loss: 0.2004, d_k_M range: [0.0023, 0.4450], d_k_M_hat range: [0.8724, 0.9974]
2025-03-11 20:50:23 - Train Iteration 8369: loss: 0.0819, d_k_M range: [0.0000, 0.2555], d_k_M_hat range: [0.7143, 0.9940]
2025-03-11 20:50:23 - Train Iteration 8370: loss: 0.0335, d_k_M range: [0.0053, 0.1199], d_k_M_hat range: [0.8236, 0.9977]
2025-03-11 20:50:24 - Train Iteration 8371: loss: 0.1785, d_k_M range: [0.0041, 0.3401], d_k_M_hat range: [0.6746, 0.9975]
2025-03-11 20:50:24 - Train Iteration 8372: loss: 0.5199, d_k_M range: [0.0002, 0.0609], d_k_M_hat range: [0.2802, 0.9702]
2025-03-11 20:50:25 - Train Iteration 8373: loss: 0.0907, d_k_M range: [0.0097, 0.3005], d_k_M_hat range: [0.9298, 0.9995]
2025-03-11 20:50:25 - Train Iteration 8374: loss: 0.0770, d_k_M range: [0.0036, 0.2630], d_k_M_hat range: [0.8274, 0.9960]
2025-03-11 20:50:26 - Train Iteration 8375: loss: 0.1999, d_k_M range: [0.0003, 0.4441], d_k_M_hat range: [0.6401, 0.9971]
2025-03-11 20:50:26 - Train Iteration 8376: loss: 0.1898, d_k_M range: [0.0002, 0.2140], d_k_M_hat range: [0.5654, 0.9867]
2025-03-11 20:50:26 - Train Iteration 8377: loss: 0.5366, d_k_M range: [0.0132, 0.7127], d_k_M_hat range: [0.9017, 0.9979]
2025-03-11 20:50:27 - Train Iteration 8378: loss: 0.0638, d_k_M range: [0.0004, 0.1172], d_k_M_hat range: [0.7478, 0.9927]
2025-03-11 20:50:27 - Train Iteration 8379: loss: 0.1019, d_k_M range: [0.0013, 0.3184], d_k_M_hat range: [0.8464, 0.9992]
2025-03-11 20:50:28 - Train Iteration 8380: loss: 0.1438, d_k_M range: [0.0001, 0.1680], d_k_M_hat range: [0.6211, 0.9396]
2025-03-11 20:50:28 - Train Iteration 8381: loss: 0.2261, d_k_M range: [0.0006, 0.4750], d_k_M_hat range: [0.8573, 0.9995]
2025-03-11 20:50:29 - Train Iteration 8382: loss: 0.2581, d_k_M range: [0.0004, 0.5008], d_k_M_hat range: [0.6126, 0.9950]
2025-03-11 20:50:29 - Train Iteration 8383: loss: 0.1886, d_k_M range: [0.0010, 0.3067], d_k_M_hat range: [0.5668, 0.9985]
2025-03-11 20:50:30 - Train Iteration 8384: loss: 0.0207, d_k_M range: [0.0014, 0.1245], d_k_M_hat range: [0.9166, 0.9989]
2025-03-11 20:50:30 - Train Iteration 8385: loss: 0.1390, d_k_M range: [0.0003, 0.2519], d_k_M_hat range: [0.6360, 0.9978]
2025-03-11 20:50:31 - Train Iteration 8386: loss: 0.1593, d_k_M range: [0.0001, 0.3940], d_k_M_hat range: [0.6739, 0.9948]
2025-03-11 20:50:31 - Train Iteration 8387: loss: 0.3516, d_k_M range: [0.0000, 0.0189], d_k_M_hat range: [0.4073, 0.9529]
2025-03-11 20:50:32 - Train Iteration 8388: loss: 0.1453, d_k_M range: [0.0217, 0.3646], d_k_M_hat range: [0.8942, 0.9994]
2025-03-11 20:50:32 - Train Iteration 8389: loss: 0.2470, d_k_M range: [0.0002, 0.0566], d_k_M_hat range: [0.5036, 0.9574]
2025-03-11 20:50:32 - Train Iteration 8390: loss: 0.1900, d_k_M range: [0.0000, 0.4315], d_k_M_hat range: [0.7049, 0.9983]
2025-03-11 20:50:33 - Train Iteration 8391: loss: 0.3967, d_k_M range: [0.0000, 0.0709], d_k_M_hat range: [0.3702, 0.9844]
2025-03-11 20:50:33 - Train Iteration 8392: loss: 0.2338, d_k_M range: [0.0008, 0.4834], d_k_M_hat range: [0.8591, 0.9999]
2025-03-11 20:50:34 - Train Iteration 8393: loss: 0.0400, d_k_M range: [0.0004, 0.0629], d_k_M_hat range: [0.8005, 0.9790]
2025-03-11 20:50:34 - Train Iteration 8394: loss: 0.0976, d_k_M range: [0.0015, 0.3121], d_k_M_hat range: [0.7714, 0.9997]
2025-03-11 20:50:34 - Train Iteration 8395: loss: 0.4852, d_k_M range: [0.0002, 0.0406], d_k_M_hat range: [0.3056, 0.9747]
2025-03-11 20:50:35 - Train Iteration 8396: loss: 0.1186, d_k_M range: [0.0031, 0.3370], d_k_M_hat range: [0.6992, 0.9978]
2025-03-11 20:50:35 - Train Iteration 8397: loss: 0.0403, d_k_M range: [0.0012, 0.1721], d_k_M_hat range: [0.8433, 0.9951]
2025-03-11 20:50:36 - Train Iteration 8398: loss: 0.2103, d_k_M range: [0.0002, 0.4585], d_k_M_hat range: [0.8621, 0.9999]
2025-03-11 20:50:36 - Train Iteration 8399: loss: 0.0603, d_k_M range: [0.0003, 0.2241], d_k_M_hat range: [0.8425, 0.9890]
2025-03-11 20:50:37 - Train Iteration 8400: loss: 0.1857, d_k_M range: [0.0000, 0.1263], d_k_M_hat range: [0.5698, 0.9757]
2025-03-11 20:50:37 - Train Iteration 8401: loss: 0.3672, d_k_M range: [0.0008, 0.6060], d_k_M_hat range: [0.9683, 1.0000]
2025-03-11 20:50:38 - Train Iteration 8402: loss: 0.1159, d_k_M range: [0.0003, 0.3275], d_k_M_hat range: [0.6780, 0.9871]
2025-03-11 20:50:38 - Train Iteration 8403: loss: 0.3240, d_k_M range: [0.0001, 0.1666], d_k_M_hat range: [0.4309, 0.9956]
2025-03-11 20:50:38 - Train Iteration 8404: loss: 0.2900, d_k_M range: [0.0028, 0.5385], d_k_M_hat range: [0.7537, 1.0000]
2025-03-11 20:50:39 - Train Iteration 8405: loss: 0.1630, d_k_M range: [0.0004, 0.0517], d_k_M_hat range: [0.5967, 0.9848]
2025-03-11 20:50:39 - Train Iteration 8406: loss: 0.1631, d_k_M range: [0.0033, 0.4032], d_k_M_hat range: [0.8965, 0.9994]
2025-03-11 20:50:40 - Train Iteration 8407: loss: 0.0216, d_k_M range: [0.0003, 0.0739], d_k_M_hat range: [0.8763, 0.9800]
2025-03-11 20:50:40 - Train Iteration 8408: loss: 0.1646, d_k_M range: [0.0002, 0.3156], d_k_M_hat range: [0.5946, 0.9946]
2025-03-11 20:50:41 - Train Iteration 8409: loss: 0.2267, d_k_M range: [0.0036, 0.4759], d_k_M_hat range: [0.7964, 0.9998]
2025-03-11 20:50:42 - Train Iteration 8410: loss: 0.1368, d_k_M range: [0.0007, 0.1807], d_k_M_hat range: [0.6325, 0.9985]
2025-03-11 20:50:42 - Train Iteration 8411: loss: 0.1419, d_k_M range: [0.0016, 0.3729], d_k_M_hat range: [0.8288, 0.9971]
2025-03-11 20:50:42 - Train Iteration 8412: loss: 0.1942, d_k_M range: [0.0001, 0.4403], d_k_M_hat range: [0.7364, 0.9996]
2025-03-11 20:50:43 - Train Iteration 8413: loss: 0.5482, d_k_M range: [0.0001, 0.4364], d_k_M_hat range: [0.2631, 0.9911]
2025-03-11 20:50:43 - Train Iteration 8414: loss: 0.3644, d_k_M range: [0.0000, 0.1746], d_k_M_hat range: [0.3965, 0.9966]
2025-03-11 20:50:44 - Train Iteration 8415: loss: 0.3891, d_k_M range: [0.0026, 0.6235], d_k_M_hat range: [0.6506, 0.9998]
2025-03-11 20:50:44 - Train Iteration 8416: loss: 0.3414, d_k_M range: [0.0003, 0.2499], d_k_M_hat range: [0.4160, 0.9940]
2025-03-11 20:50:45 - Train Iteration 8417: loss: 0.2799, d_k_M range: [0.0013, 0.5288], d_k_M_hat range: [0.9395, 0.9998]
2025-03-11 20:50:45 - Train Iteration 8418: loss: 0.1080, d_k_M range: [0.0001, 0.3234], d_k_M_hat range: [0.6798, 0.9948]
2025-03-11 20:50:45 - Train Iteration 8419: loss: 0.2306, d_k_M range: [0.0002, 0.4785], d_k_M_hat range: [0.8480, 0.9983]
2025-03-11 20:50:46 - Train Iteration 8420: loss: 0.3218, d_k_M range: [0.0002, 0.0658], d_k_M_hat range: [0.4329, 0.9877]
2025-03-11 20:50:46 - Train Iteration 8421: loss: 0.1575, d_k_M range: [0.0007, 0.3948], d_k_M_hat range: [0.8402, 0.9989]
2025-03-11 20:50:47 - Train Iteration 8422: loss: 0.2344, d_k_M range: [0.0000, 0.2045], d_k_M_hat range: [0.5158, 0.9960]
2025-03-11 20:50:47 - Train Iteration 8423: loss: 0.0736, d_k_M range: [0.0007, 0.2541], d_k_M_hat range: [0.9303, 0.9990]
2025-03-11 20:50:48 - Train Iteration 8424: loss: 0.1045, d_k_M range: [0.0001, 0.0428], d_k_M_hat range: [0.6791, 0.9980]
2025-03-11 20:50:48 - Train Iteration 8425: loss: 0.1509, d_k_M range: [0.0007, 0.3849], d_k_M_hat range: [0.6309, 0.9964]
2025-03-11 20:50:49 - Train Iteration 8426: loss: 0.6433, d_k_M range: [0.0008, 0.8007], d_k_M_hat range: [0.9498, 0.9986]
2025-03-11 20:50:49 - Train Iteration 8427: loss: 0.1454, d_k_M range: [0.0008, 0.0330], d_k_M_hat range: [0.6219, 0.9737]
2025-03-11 20:50:49 - Train Iteration 8428: loss: 0.1947, d_k_M range: [0.0080, 0.4411], d_k_M_hat range: [0.9887, 1.0000]
2025-03-11 20:50:50 - Train Iteration 8429: loss: 0.6048, d_k_M range: [0.0000, 0.0150], d_k_M_hat range: [0.2223, 0.9673]
2025-03-11 20:50:50 - Train Iteration 8430: loss: 0.0944, d_k_M range: [0.0013, 0.0997], d_k_M_hat range: [0.6941, 0.9905]
2025-03-11 20:50:51 - Train Iteration 8431: loss: 0.4694, d_k_M range: [0.0093, 0.6591], d_k_M_hat range: [0.9267, 0.9988]
2025-03-11 20:50:51 - Train Iteration 8432: loss: 0.2041, d_k_M range: [0.0003, 0.4484], d_k_M_hat range: [0.6194, 0.9966]
2025-03-11 20:50:52 - Train Iteration 8433: loss: 0.1113, d_k_M range: [0.0004, 0.3312], d_k_M_hat range: [0.8386, 0.9975]
2025-03-11 20:50:52 - Train Iteration 8434: loss: 0.2283, d_k_M range: [0.0012, 0.1801], d_k_M_hat range: [0.5234, 0.9961]
2025-03-11 20:50:53 - Train Iteration 8435: loss: 0.2670, d_k_M range: [0.0000, 0.3393], d_k_M_hat range: [0.4833, 0.9892]
2025-03-11 20:50:53 - Train Iteration 8436: loss: 0.0706, d_k_M range: [0.0002, 0.1239], d_k_M_hat range: [0.7483, 0.9982]
2025-03-11 20:50:54 - Train Iteration 8437: loss: 0.2863, d_k_M range: [0.0000, 0.0207], d_k_M_hat range: [0.4650, 0.9850]
2025-03-11 20:50:54 - Train Iteration 8438: loss: 0.4978, d_k_M range: [0.0005, 0.7021], d_k_M_hat range: [0.8110, 0.9983]
2025-03-11 20:50:54 - Train Iteration 8439: loss: 0.1372, d_k_M range: [0.0000, 0.0783], d_k_M_hat range: [0.6304, 0.9901]
2025-03-11 20:50:55 - Train Iteration 8440: loss: 0.1802, d_k_M range: [0.0019, 0.4244], d_k_M_hat range: [0.9613, 0.9999]
2025-03-11 20:50:55 - Train Iteration 8441: loss: 0.2000, d_k_M range: [0.0000, 0.0111], d_k_M_hat range: [0.5613, 0.9376]
2025-03-11 20:50:56 - Train Iteration 8442: loss: 0.4552, d_k_M range: [0.0004, 0.6728], d_k_M_hat range: [0.8165, 0.9981]
2025-03-11 20:50:56 - Train Iteration 8443: loss: 0.5314, d_k_M range: [0.0000, 0.1157], d_k_M_hat range: [0.2729, 0.9855]
2025-03-11 20:50:57 - Train Iteration 8444: loss: 0.1113, d_k_M range: [0.0016, 0.2145], d_k_M_hat range: [0.6680, 0.9968]
2025-03-11 20:50:57 - Train Iteration 8445: loss: 0.3319, d_k_M range: [0.0003, 0.2108], d_k_M_hat range: [0.4242, 0.9909]
2025-03-11 20:50:57 - Train Iteration 8446: loss: 0.4756, d_k_M range: [0.0000, 0.6888], d_k_M_hat range: [0.6239, 0.9991]
2025-03-11 20:50:58 - Train Iteration 8447: loss: 0.5772, d_k_M range: [0.0001, 0.4851], d_k_M_hat range: [0.4225, 0.9952]
2025-03-11 20:50:58 - Train Iteration 8448: loss: 0.0199, d_k_M range: [0.0005, 0.0926], d_k_M_hat range: [0.8905, 0.9913]
2025-03-11 20:50:59 - Train Iteration 8449: loss: 0.0195, d_k_M range: [0.0001, 0.1115], d_k_M_hat range: [0.8838, 0.9939]
2025-03-11 20:50:59 - Train Iteration 8450: loss: 0.2925, d_k_M range: [0.0000, 0.5400], d_k_M_hat range: [0.7447, 0.9996]
2025-03-11 20:51:00 - Train Iteration 8451: loss: 0.1847, d_k_M range: [0.0019, 0.4292], d_k_M_hat range: [0.7878, 0.9994]
2025-03-11 20:51:00 - Train Iteration 8452: loss: 0.2057, d_k_M range: [0.0008, 0.1775], d_k_M_hat range: [0.5472, 0.9952]
2025-03-11 20:51:01 - Train Iteration 8453: loss: 0.3178, d_k_M range: [0.0002, 0.5624], d_k_M_hat range: [0.7943, 0.9986]
2025-03-11 20:51:01 - Train Iteration 8454: loss: 0.3927, d_k_M range: [0.0000, 0.0504], d_k_M_hat range: [0.3733, 0.9918]
2025-03-11 20:51:02 - Train Iteration 8455: loss: 0.1175, d_k_M range: [0.0000, 0.1764], d_k_M_hat range: [0.6572, 0.9995]
2025-03-11 20:51:02 - Train Iteration 8456: loss: 0.1656, d_k_M range: [0.0005, 0.4068], d_k_M_hat range: [0.9762, 0.9999]
2025-03-11 20:51:03 - Train Iteration 8457: loss: 0.4334, d_k_M range: [0.0000, 0.2283], d_k_M_hat range: [0.3428, 0.9873]
2025-03-11 20:51:03 - Train Iteration 8458: loss: 0.3398, d_k_M range: [0.0001, 0.5827], d_k_M_hat range: [0.5887, 0.9998]
2025-03-11 20:51:04 - Train Iteration 8459: loss: 0.0493, d_k_M range: [0.0034, 0.0533], d_k_M_hat range: [0.8312, 0.9991]
2025-03-11 20:51:04 - Train Iteration 8460: loss: 0.0941, d_k_M range: [0.0008, 0.3044], d_k_M_hat range: [0.8679, 0.9976]
2025-03-11 20:51:04 - Train Iteration 8461: loss: 0.3465, d_k_M range: [0.0004, 0.0235], d_k_M_hat range: [0.4128, 0.9859]
2025-03-11 20:51:05 - Train Iteration 8462: loss: 0.3052, d_k_M range: [0.0001, 0.5515], d_k_M_hat range: [0.7129, 0.9991]
2025-03-11 20:51:05 - Train Iteration 8463: loss: 0.1108, d_k_M range: [0.0017, 0.0272], d_k_M_hat range: [0.6689, 0.9893]
2025-03-11 20:51:06 - Train Iteration 8464: loss: 0.2247, d_k_M range: [0.0004, 0.1157], d_k_M_hat range: [0.5267, 0.9875]
2025-03-11 20:51:06 - Train Iteration 8465: loss: 0.1454, d_k_M range: [0.0007, 0.2679], d_k_M_hat range: [0.6194, 0.9956]
2025-03-11 20:51:07 - Train Iteration 8466: loss: 0.4107, d_k_M range: [0.0000, 0.0598], d_k_M_hat range: [0.3591, 0.9501]
2025-03-11 20:51:07 - Train Iteration 8467: loss: 0.3875, d_k_M range: [0.0033, 0.6214], d_k_M_hat range: [0.9346, 0.9989]
2025-03-11 20:51:07 - Train Iteration 8468: loss: 0.1386, d_k_M range: [0.0000, 0.3377], d_k_M_hat range: [0.6658, 0.9818]
2025-03-11 20:51:08 - Train Iteration 8469: loss: 0.1318, d_k_M range: [0.0008, 0.3589], d_k_M_hat range: [0.7618, 0.9958]
2025-03-11 20:51:08 - Train Iteration 8470: loss: 0.3176, d_k_M range: [0.0000, 0.0942], d_k_M_hat range: [0.4366, 0.9974]
2025-03-11 20:51:09 - Train Iteration 8471: loss: 0.1003, d_k_M range: [0.0005, 0.1197], d_k_M_hat range: [0.6844, 0.9825]
2025-03-11 20:51:09 - Train Iteration 8472: loss: 0.1882, d_k_M range: [0.0003, 0.4315], d_k_M_hat range: [0.9057, 0.9991]
2025-03-11 20:51:10 - Train Iteration 8473: loss: 0.0942, d_k_M range: [0.0001, 0.2801], d_k_M_hat range: [0.7800, 0.9983]
2025-03-11 20:51:10 - Train Iteration 8474: loss: 0.4189, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.3528, 0.9112]
2025-03-11 20:51:11 - Train Iteration 8475: loss: 0.3274, d_k_M range: [0.0001, 0.5712], d_k_M_hat range: [0.9565, 0.9992]
2025-03-11 20:51:11 - Train Iteration 8476: loss: 0.0772, d_k_M range: [0.0004, 0.0145], d_k_M_hat range: [0.7235, 0.9997]
2025-03-11 20:51:11 - Train Iteration 8477: loss: 0.7750, d_k_M range: [0.0077, 0.8791], d_k_M_hat range: [0.7189, 0.9995]
2025-03-11 20:51:12 - Train Iteration 8478: loss: 0.5934, d_k_M range: [0.0000, 0.0340], d_k_M_hat range: [0.2297, 0.9890]
2025-03-11 20:51:12 - Train Iteration 8479: loss: 0.2681, d_k_M range: [0.0005, 0.5160], d_k_M_hat range: [0.7240, 0.9990]
2025-03-11 20:51:13 - Train Iteration 8480: loss: 0.3166, d_k_M range: [0.0000, 0.3133], d_k_M_hat range: [0.4390, 0.9938]
2025-03-11 20:51:13 - Train Iteration 8481: loss: 0.0622, d_k_M range: [0.0012, 0.2479], d_k_M_hat range: [0.9397, 0.9985]
2025-03-11 20:51:14 - Train Iteration 8482: loss: 0.1501, d_k_M range: [0.0003, 0.3849], d_k_M_hat range: [0.6986, 0.9975]
2025-03-11 20:51:14 - Train Iteration 8483: loss: 0.2201, d_k_M range: [0.0000, 0.1843], d_k_M_hat range: [0.5310, 0.9971]
2025-03-11 20:51:15 - Train Iteration 8484: loss: 0.1950, d_k_M range: [0.0011, 0.4365], d_k_M_hat range: [0.8025, 0.9949]
2025-03-11 20:51:15 - Train Iteration 8485: loss: 0.0795, d_k_M range: [0.0003, 0.0914], d_k_M_hat range: [0.7184, 0.9910]
2025-03-11 20:51:16 - Train Iteration 8486: loss: 0.1515, d_k_M range: [0.0019, 0.3890], d_k_M_hat range: [0.9339, 0.9997]
2025-03-11 20:51:16 - Train Iteration 8487: loss: 0.4381, d_k_M range: [0.0001, 0.1916], d_k_M_hat range: [0.3382, 0.9986]
2025-03-11 20:51:16 - Train Iteration 8488: loss: 0.0760, d_k_M range: [0.0007, 0.2728], d_k_M_hat range: [0.8474, 0.9970]
2025-03-11 20:51:17 - Train Iteration 8489: loss: 0.3480, d_k_M range: [0.0000, 0.0090], d_k_M_hat range: [0.4102, 0.9873]
2025-03-11 20:51:17 - Train Iteration 8490: loss: 0.7912, d_k_M range: [0.0003, 0.8883], d_k_M_hat range: [0.9714, 0.9999]
2025-03-11 20:51:18 - Train Iteration 8491: loss: 0.2865, d_k_M range: [0.0001, 0.1100], d_k_M_hat range: [0.4710, 0.9770]
2025-03-11 20:51:18 - Train Iteration 8492: loss: 0.1038, d_k_M range: [0.0003, 0.3197], d_k_M_hat range: [0.8545, 0.9974]
2025-03-11 20:51:19 - Train Iteration 8493: loss: 0.1599, d_k_M range: [0.0003, 0.1563], d_k_M_hat range: [0.6005, 0.9731]
2025-03-11 20:51:19 - Train Iteration 8494: loss: 0.2299, d_k_M range: [0.0000, 0.1541], d_k_M_hat range: [0.5206, 0.9959]
2025-03-11 20:51:19 - Train Iteration 8495: loss: 0.2253, d_k_M range: [0.0001, 0.4738], d_k_M_hat range: [0.8019, 0.9994]
2025-03-11 20:51:20 - Train Iteration 8496: loss: 0.4204, d_k_M range: [0.0001, 0.0089], d_k_M_hat range: [0.3518, 0.9923]
2025-03-11 20:51:20 - Train Iteration 8497: loss: 0.1271, d_k_M range: [0.0001, 0.3368], d_k_M_hat range: [0.7584, 0.9979]
2025-03-11 20:51:21 - Train Iteration 8498: loss: 0.3217, d_k_M range: [0.0001, 0.2625], d_k_M_hat range: [0.4801, 0.9847]
2025-03-11 20:51:21 - Train Iteration 8499: loss: 0.5988, d_k_M range: [0.0013, 0.7485], d_k_M_hat range: [0.9309, 0.9990]
2025-03-11 20:51:22 - Train Iteration 8500: loss: 0.0902, d_k_M range: [0.0000, 0.0657], d_k_M_hat range: [0.6997, 0.9788]
2025-03-11 20:51:22 - Train Iteration 8501: loss: 0.1263, d_k_M range: [0.0004, 0.3533], d_k_M_hat range: [0.6925, 0.9993]
2025-03-11 20:51:23 - Train Iteration 8502: loss: 0.1828, d_k_M range: [0.0008, 0.0828], d_k_M_hat range: [0.5737, 0.9931]
2025-03-11 20:51:23 - Train Iteration 8503: loss: 0.1053, d_k_M range: [0.0002, 0.2882], d_k_M_hat range: [0.6757, 0.9861]
2025-03-11 20:51:24 - Train Iteration 8504: loss: 0.1030, d_k_M range: [0.0001, 0.3100], d_k_M_hat range: [0.8425, 0.9949]
2025-03-11 20:51:24 - Train Iteration 8505: loss: 0.2478, d_k_M range: [0.0001, 0.1908], d_k_M_hat range: [0.5030, 0.9866]
2025-03-11 20:51:25 - Train Iteration 8506: loss: 0.1706, d_k_M range: [0.0002, 0.4104], d_k_M_hat range: [0.9454, 0.9975]
2025-03-11 20:51:25 - Train Iteration 8507: loss: 0.3780, d_k_M range: [0.0023, 0.1645], d_k_M_hat range: [0.3875, 0.9944]
2025-03-11 20:51:25 - Train Iteration 8508: loss: 0.1628, d_k_M range: [0.0051, 0.4026], d_k_M_hat range: [0.9802, 0.9992]
2025-03-11 20:51:26 - Train Iteration 8509: loss: 0.1324, d_k_M range: [0.0000, 0.1312], d_k_M_hat range: [0.6373, 0.9987]
2025-03-11 20:51:26 - Train Iteration 8510: loss: 0.1887, d_k_M range: [0.0000, 0.0998], d_k_M_hat range: [0.5656, 0.9937]
2025-03-11 20:51:27 - Train Iteration 8511: loss: 0.1461, d_k_M range: [0.0006, 0.3786], d_k_M_hat range: [0.7751, 0.9968]
2025-03-11 20:51:27 - Train Iteration 8512: loss: 0.0405, d_k_M range: [0.0000, 0.1959], d_k_M_hat range: [0.9700, 0.9951]
2025-03-11 20:51:28 - Train Iteration 8513: loss: 0.2282, d_k_M range: [0.0001, 0.0300], d_k_M_hat range: [0.5249, 0.9879]
2025-03-11 20:51:28 - Train Iteration 8514: loss: 0.0552, d_k_M range: [0.0002, 0.0925], d_k_M_hat range: [0.7651, 0.9946]
2025-03-11 20:51:29 - Train Iteration 8515: loss: 0.1381, d_k_M range: [0.0000, 0.2045], d_k_M_hat range: [0.6288, 0.9827]
2025-03-11 20:51:29 - Train Iteration 8516: loss: 0.1333, d_k_M range: [0.0010, 0.3564], d_k_M_hat range: [0.8391, 0.9952]
2025-03-11 20:51:29 - Train Iteration 8517: loss: 0.1711, d_k_M range: [0.0000, 0.2770], d_k_M_hat range: [0.5864, 0.9998]
2025-03-11 20:51:30 - Train Iteration 8518: loss: 0.1622, d_k_M range: [0.0019, 0.3720], d_k_M_hat range: [0.9187, 0.9992]
2025-03-11 20:51:30 - Train Iteration 8519: loss: 0.1142, d_k_M range: [0.0001, 0.2204], d_k_M_hat range: [0.6622, 0.9887]
2025-03-11 20:51:31 - Train Iteration 8520: loss: 0.1452, d_k_M range: [0.0029, 0.3616], d_k_M_hat range: [0.8926, 0.9991]
2025-03-11 20:51:31 - Train Iteration 8521: loss: 0.1268, d_k_M range: [0.0006, 0.1082], d_k_M_hat range: [0.6459, 0.9982]
2025-03-11 20:51:32 - Train Iteration 8522: loss: 0.2191, d_k_M range: [0.0008, 0.4280], d_k_M_hat range: [0.5327, 0.9999]
2025-03-11 20:51:32 - Train Iteration 8523: loss: 0.1359, d_k_M range: [0.0002, 0.0974], d_k_M_hat range: [0.6315, 0.9966]
2025-03-11 20:51:33 - Train Iteration 8524: loss: 0.0363, d_k_M range: [0.0004, 0.0918], d_k_M_hat range: [0.8692, 0.9980]
2025-03-11 20:51:33 - Train Iteration 8525: loss: 0.1394, d_k_M range: [0.0000, 0.3333], d_k_M_hat range: [0.6267, 0.9946]
2025-03-11 20:51:33 - Train Iteration 8526: loss: 0.4009, d_k_M range: [0.0000, 0.1666], d_k_M_hat range: [0.3668, 0.9966]
2025-03-11 20:51:34 - Train Iteration 8527: loss: 0.1372, d_k_M range: [0.0004, 0.0950], d_k_M_hat range: [0.6301, 0.9994]
2025-03-11 20:51:34 - Train Iteration 8528: loss: 0.5016, d_k_M range: [0.0000, 0.6996], d_k_M_hat range: [0.8213, 0.9978]
2025-03-11 20:51:35 - Train Iteration 8529: loss: 0.5959, d_k_M range: [0.0000, 0.0139], d_k_M_hat range: [0.2281, 0.9779]
2025-03-11 20:51:35 - Train Iteration 8530: loss: 0.4652, d_k_M range: [0.0203, 0.6797], d_k_M_hat range: [0.8779, 0.9998]
2025-03-11 20:51:36 - Train Iteration 8531: loss: 0.1860, d_k_M range: [0.0000, 0.3410], d_k_M_hat range: [0.5688, 0.9998]
2025-03-11 20:51:36 - Train Iteration 8532: loss: 0.1446, d_k_M range: [0.0012, 0.3653], d_k_M_hat range: [0.9798, 0.9997]
2025-03-11 20:51:36 - Train Iteration 8533: loss: 0.0606, d_k_M range: [0.0017, 0.1849], d_k_M_hat range: [0.7567, 0.9945]
2025-03-11 20:51:37 - Train Iteration 8534: loss: 0.2516, d_k_M range: [0.0051, 0.5009], d_k_M_hat range: [0.9404, 0.9997]
2025-03-11 20:51:37 - Train Iteration 8535: loss: 0.4530, d_k_M range: [0.0000, 0.0129], d_k_M_hat range: [0.3271, 0.9146]
2025-03-11 20:51:38 - Train Iteration 8536: loss: 0.1096, d_k_M range: [0.0007, 0.3197], d_k_M_hat range: [0.9383, 0.9984]
2025-03-11 20:51:38 - Train Iteration 8537: loss: 0.0460, d_k_M range: [0.0003, 0.2106], d_k_M_hat range: [0.8628, 0.9961]
2025-03-11 20:51:39 - Train Iteration 8538: loss: 0.4204, d_k_M range: [0.0006, 0.0753], d_k_M_hat range: [0.3553, 0.9962]
2025-03-11 20:51:39 - Train Iteration 8539: loss: 0.5473, d_k_M range: [0.0029, 0.7391], d_k_M_hat range: [0.9818, 0.9993]
2025-03-11 20:51:39 - Train Iteration 8540: loss: 0.1962, d_k_M range: [0.0002, 0.1519], d_k_M_hat range: [0.5573, 0.9896]
2025-03-11 20:51:40 - Train Iteration 8541: loss: 0.2289, d_k_M range: [0.0066, 0.4783], d_k_M_hat range: [0.9766, 0.9998]
2025-03-11 20:51:40 - Train Iteration 8542: loss: 0.1126, d_k_M range: [0.0002, 0.1602], d_k_M_hat range: [0.6647, 0.9972]
2025-03-11 20:51:41 - Train Iteration 8543: loss: 0.1186, d_k_M range: [0.0026, 0.2579], d_k_M_hat range: [0.8528, 0.9993]
2025-03-11 20:51:41 - Train Iteration 8544: loss: 0.3379, d_k_M range: [0.0002, 0.3512], d_k_M_hat range: [0.4189, 0.9996]
2025-03-11 20:51:42 - Train Iteration 8545: loss: 0.1130, d_k_M range: [0.0014, 0.3326], d_k_M_hat range: [0.9376, 0.9965]
2025-03-11 20:51:42 - Train Iteration 8546: loss: 0.0574, d_k_M range: [0.0014, 0.1432], d_k_M_hat range: [0.8578, 0.9959]
2025-03-11 20:51:43 - Train Iteration 8547: loss: 0.2824, d_k_M range: [0.0008, 0.5304], d_k_M_hat range: [0.6271, 0.9994]
2025-03-11 20:51:43 - Train Iteration 8548: loss: 0.0543, d_k_M range: [0.0022, 0.1806], d_k_M_hat range: [0.7824, 0.9971]
2025-03-11 20:51:43 - Train Iteration 8549: loss: 0.0611, d_k_M range: [0.0003, 0.0083], d_k_M_hat range: [0.7537, 0.9621]
2025-03-11 20:51:44 - Train Iteration 8550: loss: 0.1078, d_k_M range: [0.0008, 0.3259], d_k_M_hat range: [0.8300, 0.9990]
2025-03-11 20:51:44 - Train Iteration 8551: loss: 0.1145, d_k_M range: [0.0000, 0.1124], d_k_M_hat range: [0.6685, 0.9824]
2025-03-11 20:51:45 - Train Iteration 8552: loss: 0.4366, d_k_M range: [0.0025, 0.6603], d_k_M_hat range: [0.5979, 1.0000]
2025-03-11 20:51:45 - Train Iteration 8553: loss: 0.2542, d_k_M range: [0.0001, 0.0900], d_k_M_hat range: [0.4959, 0.9728]
2025-03-11 20:51:46 - Train Iteration 8554: loss: 0.2163, d_k_M range: [0.0006, 0.4642], d_k_M_hat range: [0.9798, 0.9999]
2025-03-11 20:51:46 - Train Iteration 8555: loss: 0.1652, d_k_M range: [0.0001, 0.0374], d_k_M_hat range: [0.5986, 0.9976]
2025-03-11 20:51:47 - Train Iteration 8556: loss: 0.0543, d_k_M range: [0.0017, 0.2329], d_k_M_hat range: [0.8740, 0.9999]
2025-03-11 20:51:47 - Train Iteration 8557: loss: 0.1468, d_k_M range: [0.0005, 0.3822], d_k_M_hat range: [0.7691, 0.9991]
2025-03-11 20:51:47 - Train Iteration 8558: loss: 0.3120, d_k_M range: [0.0001, 0.5584], d_k_M_hat range: [0.6627, 0.9998]
2025-03-11 20:51:48 - Train Iteration 8559: loss: 0.2389, d_k_M range: [0.0000, 0.4873], d_k_M_hat range: [0.7190, 0.9986]
2025-03-11 20:51:48 - Train Iteration 8560: loss: 0.2278, d_k_M range: [0.0000, 0.1936], d_k_M_hat range: [0.5235, 0.9879]
2025-03-11 20:51:49 - Train Iteration 8561: loss: 0.1034, d_k_M range: [0.0006, 0.2367], d_k_M_hat range: [0.6790, 0.9958]
2025-03-11 20:51:49 - Train Iteration 8562: loss: 0.3392, d_k_M range: [0.0003, 0.0419], d_k_M_hat range: [0.4190, 0.9978]
2025-03-11 20:51:50 - Train Iteration 8563: loss: 0.0816, d_k_M range: [0.0003, 0.1978], d_k_M_hat range: [0.9121, 0.9992]
2025-03-11 20:51:50 - Train Iteration 8564: loss: 0.1706, d_k_M range: [0.0002, 0.3041], d_k_M_hat range: [0.6089, 0.9996]
2025-03-11 20:51:51 - Train Iteration 8565: loss: 0.1090, d_k_M range: [0.0005, 0.3252], d_k_M_hat range: [0.8335, 0.9997]
2025-03-11 20:51:51 - Train Iteration 8566: loss: 0.3827, d_k_M range: [0.0099, 0.6186], d_k_M_hat range: [0.9910, 0.9999]
2025-03-11 20:51:51 - Train Iteration 8567: loss: 0.2777, d_k_M range: [0.0000, 0.0592], d_k_M_hat range: [0.4825, 0.9830]
2025-03-11 20:51:52 - Train Iteration 8568: loss: 0.1227, d_k_M range: [0.0065, 0.3469], d_k_M_hat range: [0.9348, 0.9997]
2025-03-11 20:51:52 - Train Iteration 8569: loss: 0.0279, d_k_M range: [0.0004, 0.0631], d_k_M_hat range: [0.8333, 0.9980]
2025-03-11 20:51:53 - Train Iteration 8570: loss: 0.0998, d_k_M range: [0.0000, 0.0689], d_k_M_hat range: [0.6840, 0.9911]
2025-03-11 20:51:53 - Train Iteration 8571: loss: 0.3588, d_k_M range: [0.0008, 0.5989], d_k_M_hat range: [0.6488, 0.9999]
2025-03-11 20:51:54 - Train Iteration 8572: loss: 0.5137, d_k_M range: [0.0003, 0.1595], d_k_M_hat range: [0.2835, 0.9979]
2025-03-11 20:51:54 - Train Iteration 8573: loss: 0.1780, d_k_M range: [0.0002, 0.4219], d_k_M_hat range: [0.9257, 0.9999]
2025-03-11 20:51:55 - Train Iteration 8574: loss: 0.2201, d_k_M range: [0.0003, 0.4649], d_k_M_hat range: [0.8954, 0.9957]
2025-03-11 20:51:55 - Train Iteration 8575: loss: 0.4101, d_k_M range: [0.0019, 0.6400], d_k_M_hat range: [0.9633, 0.9999]
2025-03-11 20:51:55 - Train Iteration 8576: loss: 0.0149, d_k_M range: [0.0003, 0.1118], d_k_M_hat range: [0.9124, 0.9980]
2025-03-11 20:51:56 - Train Iteration 8577: loss: 0.0841, d_k_M range: [0.0022, 0.1351], d_k_M_hat range: [0.7155, 0.9963]
2025-03-11 20:51:56 - Train Iteration 8578: loss: 0.2427, d_k_M range: [0.0009, 0.4923], d_k_M_hat range: [0.9276, 0.9996]
2025-03-11 20:51:57 - Train Iteration 8579: loss: 0.1257, d_k_M range: [0.0000, 0.0211], d_k_M_hat range: [0.6460, 0.8466]
2025-03-11 20:51:57 - Train Iteration 8580: loss: 0.0314, d_k_M range: [0.0013, 0.1599], d_k_M_hat range: [0.8548, 0.9960]
2025-03-11 20:51:57 - Train Iteration 8581: loss: 0.0768, d_k_M range: [0.0003, 0.1431], d_k_M_hat range: [0.7239, 0.9812]
2025-03-11 20:51:58 - Train Iteration 8582: loss: 0.1333, d_k_M range: [0.0109, 0.3581], d_k_M_hat range: [0.9849, 0.9998]
2025-03-11 20:51:59 - Train Iteration 8583: loss: 0.2842, d_k_M range: [0.0003, 0.2322], d_k_M_hat range: [0.4672, 0.9989]
2025-03-11 20:51:59 - Train Iteration 8584: loss: 0.3952, d_k_M range: [0.0011, 0.6286], d_k_M_hat range: [0.9066, 1.0000]
2025-03-11 20:51:59 - Train Iteration 8585: loss: 0.0950, d_k_M range: [0.0000, 0.0392], d_k_M_hat range: [0.6921, 0.9630]
2025-03-11 20:52:00 - Train Iteration 8586: loss: 0.0556, d_k_M range: [0.0019, 0.2344], d_k_M_hat range: [0.8557, 0.9995]
2025-03-11 20:52:00 - Train Iteration 8587: loss: 0.5073, d_k_M range: [0.0002, 0.3238], d_k_M_hat range: [0.2879, 0.9984]
2025-03-11 20:52:01 - Train Iteration 8588: loss: 0.0230, d_k_M range: [0.0002, 0.1471], d_k_M_hat range: [0.8596, 0.9999]
2025-03-11 20:52:01 - Train Iteration 8589: loss: 0.3891, d_k_M range: [0.0006, 0.6237], d_k_M_hat range: [0.8811, 0.9999]
2025-03-11 20:52:01 - Train Iteration 8590: loss: 0.1391, d_k_M range: [0.0000, 0.2402], d_k_M_hat range: [0.6271, 0.9993]
2025-03-11 20:52:02 - Train Iteration 8591: loss: 0.7303, d_k_M range: [0.0005, 0.8546], d_k_M_hat range: [0.9813, 1.0000]
2025-03-11 20:52:02 - Train Iteration 8592: loss: 0.1547, d_k_M range: [0.0000, 0.3926], d_k_M_hat range: [0.6744, 0.9992]
2025-03-11 20:52:03 - Train Iteration 8593: loss: 0.2048, d_k_M range: [0.0000, 0.4523], d_k_M_hat range: [0.7121, 0.9997]
2025-03-11 20:52:03 - Train Iteration 8594: loss: 0.2159, d_k_M range: [0.0000, 0.0520], d_k_M_hat range: [0.5354, 0.9899]
2025-03-11 20:52:04 - Train Iteration 8595: loss: 0.0354, d_k_M range: [0.0039, 0.1864], d_k_M_hat range: [0.9590, 0.9982]
2025-03-11 20:52:04 - Train Iteration 8596: loss: 0.5942, d_k_M range: [0.0004, 0.3392], d_k_M_hat range: [0.2315, 0.9981]
2025-03-11 20:52:05 - Train Iteration 8597: loss: 0.7835, d_k_M range: [0.0063, 0.8851], d_k_M_hat range: [0.9943, 1.0000]
2025-03-11 20:52:05 - Train Iteration 8598: loss: 0.3570, d_k_M range: [0.0001, 0.1816], d_k_M_hat range: [0.4026, 0.9970]
2025-03-11 20:52:05 - Train Iteration 8599: loss: 0.1548, d_k_M range: [0.0197, 0.3931], d_k_M_hat range: [0.9311, 0.9996]
2025-03-11 20:52:06 - Train Iteration 8600: loss: 0.1442, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.6203, 0.9670]
2025-03-11 20:52:06 - Train Iteration 8601: loss: 0.3260, d_k_M range: [0.0095, 0.5704], d_k_M_hat range: [0.9848, 0.9997]
2025-03-11 20:52:07 - Train Iteration 8602: loss: 0.3916, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.3742, 0.9560]
2025-03-11 20:52:07 - Train Iteration 8603: loss: 0.3948, d_k_M range: [0.0054, 0.6281], d_k_M_hat range: [0.9805, 0.9998]
2025-03-11 20:52:08 - Train Iteration 8604: loss: 0.1607, d_k_M range: [0.0000, 0.0167], d_k_M_hat range: [0.5992, 0.9648]
2025-03-11 20:52:08 - Train Iteration 8605: loss: 0.1308, d_k_M range: [0.0001, 0.0147], d_k_M_hat range: [0.6396, 0.9973]
2025-03-11 20:52:09 - Train Iteration 8606: loss: 0.3946, d_k_M range: [0.0986, 0.6281], d_k_M_hat range: [0.9915, 1.0000]
2025-03-11 20:52:09 - Train Iteration 8607: loss: 0.2206, d_k_M range: [0.0004, 0.0139], d_k_M_hat range: [0.5308, 0.9958]
2025-03-11 20:52:09 - Train Iteration 8608: loss: 0.4344, d_k_M range: [0.0012, 0.6591], d_k_M_hat range: [0.8203, 0.9999]
2025-03-11 20:52:10 - Train Iteration 8609: loss: 0.1277, d_k_M range: [0.0001, 0.1712], d_k_M_hat range: [0.6427, 0.9923]
2025-03-11 20:52:10 - Train Iteration 8610: loss: 0.0529, d_k_M range: [0.0000, 0.2207], d_k_M_hat range: [0.8094, 0.9979]
2025-03-11 20:52:11 - Train Iteration 8611: loss: 0.0927, d_k_M range: [0.0001, 0.1819], d_k_M_hat range: [0.6959, 0.9796]
2025-03-11 20:52:11 - Train Iteration 8612: loss: 0.0737, d_k_M range: [0.0002, 0.2696], d_k_M_hat range: [0.9826, 0.9989]
2025-03-11 20:52:12 - Train Iteration 8613: loss: 0.0855, d_k_M range: [0.0010, 0.1657], d_k_M_hat range: [0.7228, 0.9970]
2025-03-11 20:52:12 - Train Iteration 8614: loss: 0.2754, d_k_M range: [0.0000, 0.1416], d_k_M_hat range: [0.4766, 0.9861]
2025-03-11 20:52:13 - Train Iteration 8615: loss: 0.1581, d_k_M range: [0.0012, 0.3854], d_k_M_hat range: [0.6457, 0.9992]
2025-03-11 20:52:13 - Train Iteration 8616: loss: 0.1316, d_k_M range: [0.0003, 0.3611], d_k_M_hat range: [0.9340, 0.9983]
2025-03-11 20:52:13 - Train Iteration 8617: loss: 0.1791, d_k_M range: [0.0000, 0.2226], d_k_M_hat range: [0.5768, 0.9865]
2025-03-11 20:52:14 - Train Iteration 8618: loss: 0.0990, d_k_M range: [0.0001, 0.3077], d_k_M_hat range: [0.9729, 0.9960]
2025-03-11 20:52:14 - Train Iteration 8619: loss: 0.1450, d_k_M range: [0.0004, 0.3081], d_k_M_hat range: [0.8309, 0.9972]
2025-03-11 20:52:15 - Train Iteration 8620: loss: 0.1450, d_k_M range: [0.0000, 0.0717], d_k_M_hat range: [0.6193, 0.9954]
2025-03-11 20:52:15 - Train Iteration 8621: loss: 0.1359, d_k_M range: [0.0000, 0.2602], d_k_M_hat range: [0.6315, 0.9972]
2025-03-11 20:52:16 - Train Iteration 8622: loss: 0.1453, d_k_M range: [0.0001, 0.1153], d_k_M_hat range: [0.6190, 0.9932]
2025-03-11 20:52:16 - Train Iteration 8623: loss: 0.0600, d_k_M range: [0.0005, 0.2439], d_k_M_hat range: [0.7696, 0.9990]
2025-03-11 20:52:17 - Train Iteration 8624: loss: 0.2758, d_k_M range: [0.0000, 0.0613], d_k_M_hat range: [0.4749, 0.9982]
2025-03-11 20:52:17 - Train Iteration 8625: loss: 0.2090, d_k_M range: [0.0045, 0.4493], d_k_M_hat range: [0.9754, 0.9988]
2025-03-11 20:52:17 - Train Iteration 8626: loss: 0.0248, d_k_M range: [0.0003, 0.0231], d_k_M_hat range: [0.8434, 0.9977]
2025-03-11 20:52:18 - Train Iteration 8627: loss: 0.3289, d_k_M range: [0.0002, 0.5734], d_k_M_hat range: [0.9598, 0.9999]
2025-03-11 20:52:18 - Train Iteration 8628: loss: 0.3053, d_k_M range: [0.0000, 0.0429], d_k_M_hat range: [0.4556, 0.9552]
2025-03-11 20:52:19 - Train Iteration 8629: loss: 0.0943, d_k_M range: [0.0001, 0.2972], d_k_M_hat range: [0.8470, 0.9980]
2025-03-11 20:52:19 - Train Iteration 8630: loss: 0.3290, d_k_M range: [0.0000, 0.0200], d_k_M_hat range: [0.4265, 0.9983]
2025-03-11 20:52:20 - Train Iteration 8631: loss: 0.0088, d_k_M range: [0.0121, 0.0783], d_k_M_hat range: [0.9639, 0.9974]
2025-03-11 20:52:20 - Train Iteration 8632: loss: 0.2401, d_k_M range: [0.0010, 0.4798], d_k_M_hat range: [0.6450, 0.9981]
2025-03-11 20:52:21 - Train Iteration 8633: loss: 0.0414, d_k_M range: [0.0003, 0.2023], d_k_M_hat range: [0.8895, 0.9989]
2025-03-11 20:52:21 - Train Iteration 8634: loss: 0.0275, d_k_M range: [0.0015, 0.1450], d_k_M_hat range: [0.8883, 0.9997]
2025-03-11 20:52:21 - Train Iteration 8635: loss: 0.1405, d_k_M range: [0.0000, 0.1735], d_k_M_hat range: [0.6255, 0.9923]
2025-03-11 20:52:22 - Train Iteration 8636: loss: 0.0769, d_k_M range: [0.0000, 0.1652], d_k_M_hat range: [0.7227, 0.9952]
2025-03-11 20:52:22 - Train Iteration 8637: loss: 0.2978, d_k_M range: [0.0005, 0.5086], d_k_M_hat range: [0.4548, 0.9998]
2025-03-11 20:52:23 - Train Iteration 8638: loss: 0.3431, d_k_M range: [0.0103, 0.5857], d_k_M_hat range: [0.9938, 1.0000]
2025-03-11 20:52:23 - Train Iteration 8639: loss: 0.0965, d_k_M range: [0.0007, 0.3105], d_k_M_hat range: [0.8810, 0.9999]
2025-03-11 20:52:23 - Train Iteration 8640: loss: 0.3218, d_k_M range: [0.0003, 0.0225], d_k_M_hat range: [0.4340, 0.9858]
2025-03-11 20:52:24 - Train Iteration 8641: loss: 0.1632, d_k_M range: [0.0053, 0.4035], d_k_M_hat range: [0.9038, 0.9998]
2025-03-11 20:52:24 - Train Iteration 8642: loss: 0.1010, d_k_M range: [0.0001, 0.0394], d_k_M_hat range: [0.6826, 0.9968]
2025-03-11 20:52:25 - Train Iteration 8643: loss: 0.0688, d_k_M range: [0.0015, 0.2520], d_k_M_hat range: [0.8559, 0.9952]
2025-03-11 20:52:25 - Train Iteration 8644: loss: 0.3368, d_k_M range: [0.0001, 0.0255], d_k_M_hat range: [0.4198, 0.9872]
2025-03-11 20:52:26 - Train Iteration 8645: loss: 0.1009, d_k_M range: [0.0205, 0.3174], d_k_M_hat range: [0.9718, 0.9998]
2025-03-11 20:52:26 - Train Iteration 8646: loss: 0.1444, d_k_M range: [0.0009, 0.1449], d_k_M_hat range: [0.6209, 0.9998]
2025-03-11 20:52:27 - Train Iteration 8647: loss: 0.0306, d_k_M range: [0.0001, 0.0591], d_k_M_hat range: [0.8251, 0.9966]
2025-03-11 20:52:27 - Train Iteration 8648: loss: 0.5791, d_k_M range: [0.0002, 0.7604], d_k_M_hat range: [0.9058, 1.0000]
2025-03-11 20:52:28 - Train Iteration 8649: loss: 0.1964, d_k_M range: [0.0003, 0.0752], d_k_M_hat range: [0.5601, 0.9836]
2025-03-11 20:52:28 - Train Iteration 8650: loss: 0.0404, d_k_M range: [0.0004, 0.1989], d_k_M_hat range: [0.9194, 0.9980]
2025-03-11 20:52:28 - Train Iteration 8651: loss: 0.3138, d_k_M range: [0.0000, 0.0217], d_k_M_hat range: [0.4417, 0.9823]
2025-03-11 20:52:29 - Train Iteration 8652: loss: 0.1120, d_k_M range: [0.0015, 0.3284], d_k_M_hat range: [0.9739, 0.9990]
2025-03-11 20:52:29 - Train Iteration 8653: loss: 0.7686, d_k_M range: [0.0000, 0.0129], d_k_M_hat range: [0.1234, 0.9932]
2025-03-11 20:52:30 - Train Iteration 8654: loss: 0.1916, d_k_M range: [0.0171, 0.4373], d_k_M_hat range: [0.9553, 0.9999]
2025-03-11 20:52:30 - Train Iteration 8655: loss: 0.0503, d_k_M range: [0.0015, 0.0644], d_k_M_hat range: [0.7776, 0.9956]
2025-03-11 20:52:31 - Train Iteration 8656: loss: 0.0725, d_k_M range: [0.0001, 0.2668], d_k_M_hat range: [0.8266, 0.9975]
2025-03-11 20:52:31 - Train Iteration 8657: loss: 0.3445, d_k_M range: [0.0002, 0.0861], d_k_M_hat range: [0.4133, 0.9910]
2025-03-11 20:52:32 - Train Iteration 8658: loss: 0.3202, d_k_M range: [0.0003, 0.5652], d_k_M_hat range: [0.8096, 0.9996]
2025-03-11 20:52:32 - Train Iteration 8659: loss: 0.1244, d_k_M range: [0.0009, 0.3277], d_k_M_hat range: [0.8919, 0.9980]
2025-03-11 20:52:33 - Train Iteration 8660: loss: 0.0395, d_k_M range: [0.0002, 0.1001], d_k_M_hat range: [0.8016, 0.9993]
2025-03-11 20:52:33 - Train Iteration 8661: loss: 0.2844, d_k_M range: [0.0017, 0.5331], d_k_M_hat range: [0.9660, 0.9998]
2025-03-11 20:52:33 - Train Iteration 8662: loss: 0.1100, d_k_M range: [0.0000, 0.0978], d_k_M_hat range: [0.6719, 0.9989]
2025-03-11 20:52:34 - Train Iteration 8663: loss: 0.2551, d_k_M range: [0.0071, 0.5029], d_k_M_hat range: [0.9854, 0.9998]
2025-03-11 20:52:34 - Train Iteration 8664: loss: 0.0650, d_k_M range: [0.0001, 0.2485], d_k_M_hat range: [0.8786, 0.9970]
2025-03-11 20:52:35 - Train Iteration 8665: loss: 0.0991, d_k_M range: [0.0001, 0.0790], d_k_M_hat range: [0.6868, 0.9922]
2025-03-11 20:52:35 - Train Iteration 8666: loss: 0.4044, d_k_M range: [0.0432, 0.6356], d_k_M_hat range: [0.9931, 0.9996]
2025-03-11 20:52:36 - Train Iteration 8667: loss: 0.0907, d_k_M range: [0.0000, 0.2427], d_k_M_hat range: [0.6990, 0.9937]
2025-03-11 20:52:36 - Train Iteration 8668: loss: 0.0256, d_k_M range: [0.0022, 0.1567], d_k_M_hat range: [0.8895, 0.9987]
2025-03-11 20:52:36 - Train Iteration 8669: loss: 0.8181, d_k_M range: [0.0005, 0.9045], d_k_M_hat range: [0.8001, 1.0000]
2025-03-11 20:52:37 - Train Iteration 8670: loss: 0.0074, d_k_M range: [0.0000, 0.0828], d_k_M_hat range: [0.9168, 0.9971]
2025-03-11 20:52:37 - Train Iteration 8671: loss: 0.7627, d_k_M range: [0.0040, 0.8731], d_k_M_hat range: [0.9905, 0.9998]
2025-03-11 20:52:38 - Train Iteration 8672: loss: 0.3405, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.4165, 0.9984]
2025-03-11 20:52:38 - Train Iteration 8673: loss: 0.3924, d_k_M range: [0.0001, 0.6263], d_k_M_hat range: [0.9920, 0.9999]
2025-03-11 20:52:39 - Train Iteration 8674: loss: 0.2370, d_k_M range: [0.0005, 0.2891], d_k_M_hat range: [0.5138, 0.9990]
2025-03-11 20:52:39 - Train Iteration 8675: loss: 0.1668, d_k_M range: [0.0006, 0.0503], d_k_M_hat range: [0.5921, 0.9984]
2025-03-11 20:52:40 - Train Iteration 8676: loss: 0.3308, d_k_M range: [0.0000, 0.5584], d_k_M_hat range: [0.9013, 0.9999]
2025-03-11 20:52:40 - Train Iteration 8677: loss: 0.0606, d_k_M range: [0.0000, 0.0753], d_k_M_hat range: [0.7537, 0.9962]
2025-03-11 20:52:40 - Train Iteration 8678: loss: 0.2924, d_k_M range: [0.0016, 0.5400], d_k_M_hat range: [0.9014, 0.9993]
2025-03-11 20:52:41 - Train Iteration 8679: loss: 0.3446, d_k_M range: [0.0000, 0.0243], d_k_M_hat range: [0.4129, 0.9988]
2025-03-11 20:52:41 - Train Iteration 8680: loss: 0.3632, d_k_M range: [0.0000, 0.3994], d_k_M_hat range: [0.3974, 0.9999]
2025-03-11 20:52:42 - Train Iteration 8681: loss: 0.0511, d_k_M range: [0.0002, 0.0443], d_k_M_hat range: [0.7753, 0.9995]
2025-03-11 20:52:42 - Train Iteration 8682: loss: 0.8978, d_k_M range: [0.0000, 0.9474], d_k_M_hat range: [0.7637, 0.9999]
2025-03-11 20:52:43 - Train Iteration 8683: loss: 0.1195, d_k_M range: [0.0001, 0.1377], d_k_M_hat range: [0.6544, 0.9906]
2025-03-11 20:52:43 - Train Iteration 8684: loss: 0.1939, d_k_M range: [0.0001, 0.4400], d_k_M_hat range: [0.9576, 0.9997]
2025-03-11 20:52:44 - Train Iteration 8685: loss: 0.1078, d_k_M range: [0.0009, 0.1898], d_k_M_hat range: [0.6740, 0.9996]
2025-03-11 20:52:44 - Train Iteration 8686: loss: 0.3576, d_k_M range: [0.0002, 0.5939], d_k_M_hat range: [0.9682, 0.9984]
2025-03-11 20:52:44 - Train Iteration 8687: loss: 0.1274, d_k_M range: [0.0000, 0.0160], d_k_M_hat range: [0.6434, 0.9954]
2025-03-11 20:52:45 - Train Iteration 8688: loss: 0.0253, d_k_M range: [0.0001, 0.1221], d_k_M_hat range: [0.9411, 0.9967]
2025-03-11 20:52:45 - Train Iteration 8689: loss: 0.1408, d_k_M range: [0.0001, 0.3024], d_k_M_hat range: [0.6277, 0.9821]
2025-03-11 20:52:46 - Train Iteration 8690: loss: 0.8611, d_k_M range: [0.0001, 0.9256], d_k_M_hat range: [0.9822, 0.9999]
2025-03-11 20:52:46 - Train Iteration 8691: loss: 0.1601, d_k_M range: [0.0001, 0.3993], d_k_M_hat range: [0.9102, 0.9992]
2025-03-11 20:52:47 - Train Iteration 8692: loss: 0.1050, d_k_M range: [0.0000, 0.3236], d_k_M_hat range: [0.6790, 0.9996]
2025-03-11 20:52:47 - Train Iteration 8693: loss: 0.2532, d_k_M range: [0.0000, 0.0512], d_k_M_hat range: [0.4968, 0.9886]
2025-03-11 20:52:48 - Train Iteration 8694: loss: 0.1104, d_k_M range: [0.0019, 0.3187], d_k_M_hat range: [0.9737, 0.9997]
2025-03-11 20:52:48 - Train Iteration 8695: loss: 0.3125, d_k_M range: [0.0000, 0.0336], d_k_M_hat range: [0.4410, 0.9946]
2025-03-11 20:52:49 - Train Iteration 8696: loss: 0.0774, d_k_M range: [0.0024, 0.2707], d_k_M_hat range: [0.7305, 0.9954]
2025-03-11 20:52:49 - Train Iteration 8697: loss: 0.7050, d_k_M range: [0.0000, 0.0239], d_k_M_hat range: [0.1608, 0.9888]
2025-03-11 20:52:49 - Train Iteration 8698: loss: 0.4098, d_k_M range: [0.0052, 0.6377], d_k_M_hat range: [0.9661, 0.9994]
2025-03-11 20:52:50 - Train Iteration 8699: loss: 0.0422, d_k_M range: [0.0001, 0.0409], d_k_M_hat range: [0.7946, 0.9943]
2025-03-11 20:52:50 - Train Iteration 8700: loss: 0.0958, d_k_M range: [0.0067, 0.3094], d_k_M_hat range: [0.9468, 0.9999]
2025-03-11 20:52:51 - Train Iteration 8701: loss: 0.2546, d_k_M range: [0.0001, 0.1730], d_k_M_hat range: [0.4955, 0.9986]
2025-03-11 20:52:51 - Train Iteration 8702: loss: 0.7065, d_k_M range: [0.0024, 0.8405], d_k_M_hat range: [0.9135, 1.0000]
2025-03-11 20:52:52 - Train Iteration 8703: loss: 0.3911, d_k_M range: [0.0001, 0.3946], d_k_M_hat range: [0.3747, 0.9997]
2025-03-11 20:52:52 - Train Iteration 8704: loss: 0.1870, d_k_M range: [0.0237, 0.4321], d_k_M_hat range: [0.9916, 1.0000]
2025-03-11 20:52:53 - Train Iteration 8705: loss: 0.1982, d_k_M range: [0.0000, 0.1685], d_k_M_hat range: [0.5554, 0.9992]
2025-03-11 20:52:53 - Train Iteration 8706: loss: 0.3638, d_k_M range: [0.0001, 0.5997], d_k_M_hat range: [0.9576, 0.9980]
2025-03-11 20:52:53 - Train Iteration 8707: loss: 0.1152, d_k_M range: [0.0001, 0.0960], d_k_M_hat range: [0.6606, 0.9899]
2025-03-11 20:52:54 - Train Iteration 8708: loss: 0.0651, d_k_M range: [0.0032, 0.2528], d_k_M_hat range: [0.9902, 0.9997]
2025-03-11 20:52:54 - Train Iteration 8709: loss: 0.0496, d_k_M range: [0.0006, 0.0959], d_k_M_hat range: [0.7778, 0.9974]
2025-03-11 20:52:55 - Train Iteration 8710: loss: 0.1735, d_k_M range: [0.0003, 0.4127], d_k_M_hat range: [0.9327, 0.9994]
2025-03-11 20:52:55 - Train Iteration 8711: loss: 0.3165, d_k_M range: [0.0004, 0.0173], d_k_M_hat range: [0.4381, 0.9662]
2025-03-11 20:52:56 - Train Iteration 8712: loss: 0.0326, d_k_M range: [0.0006, 0.1084], d_k_M_hat range: [0.8201, 0.9942]
2025-03-11 20:52:56 - Train Iteration 8713: loss: 0.1895, d_k_M range: [0.0087, 0.4341], d_k_M_hat range: [0.9723, 0.9998]
2025-03-11 20:52:57 - Train Iteration 8714: loss: 0.0981, d_k_M range: [0.0004, 0.2070], d_k_M_hat range: [0.6886, 0.9927]
2025-03-11 20:52:57 - Train Iteration 8715: loss: 0.1338, d_k_M range: [0.0018, 0.3650], d_k_M_hat range: [0.8119, 0.9992]
2025-03-11 20:52:58 - Train Iteration 8716: loss: 0.0719, d_k_M range: [0.0001, 0.1261], d_k_M_hat range: [0.7319, 0.9845]
2025-03-11 20:52:58 - Train Iteration 8717: loss: 0.3434, d_k_M range: [0.0021, 0.5855], d_k_M_hat range: [0.9598, 0.9995]
2025-03-11 20:52:59 - Train Iteration 8718: loss: 0.0870, d_k_M range: [0.0001, 0.0876], d_k_M_hat range: [0.7052, 0.9985]
2025-03-11 20:52:59 - Train Iteration 8719: loss: 0.1514, d_k_M range: [0.0017, 0.3887], d_k_M_hat range: [0.9583, 0.9996]
2025-03-11 20:53:00 - Train Iteration 8720: loss: 0.0446, d_k_M range: [0.0006, 0.2067], d_k_M_hat range: [0.8606, 0.9993]
2025-03-11 20:53:00 - Train Iteration 8721: loss: 0.3357, d_k_M range: [0.0003, 0.5794], d_k_M_hat range: [0.5822, 1.0000]
2025-03-11 20:53:00 - Train Iteration 8722: loss: 0.1688, d_k_M range: [0.0003, 0.0335], d_k_M_hat range: [0.5952, 0.9784]
2025-03-11 20:53:01 - Train Iteration 8723: loss: 0.3619, d_k_M range: [0.0033, 0.6007], d_k_M_hat range: [0.9733, 0.9999]
2025-03-11 20:53:01 - Train Iteration 8724: loss: 0.3791, d_k_M range: [0.0000, 0.2758], d_k_M_hat range: [0.3843, 0.9968]
2025-03-11 20:53:02 - Train Iteration 8725: loss: 0.3211, d_k_M range: [0.0009, 0.5628], d_k_M_hat range: [0.9053, 0.9980]
2025-03-11 20:53:02 - Train Iteration 8726: loss: 0.2960, d_k_M range: [0.0001, 0.0963], d_k_M_hat range: [0.4562, 0.9975]
2025-03-11 20:53:03 - Train Iteration 8727: loss: 0.6633, d_k_M range: [0.0065, 0.8143], d_k_M_hat range: [0.9645, 0.9998]
2025-03-11 20:53:03 - Train Iteration 8728: loss: 0.0117, d_k_M range: [0.0000, 0.0585], d_k_M_hat range: [0.8919, 0.9981]
2025-03-11 20:53:04 - Train Iteration 8729: loss: 0.0596, d_k_M range: [0.0004, 0.2432], d_k_M_hat range: [0.8638, 0.9989]
2025-03-11 20:53:04 - Train Iteration 8730: loss: 0.2293, d_k_M range: [0.0018, 0.4772], d_k_M_hat range: [0.8966, 0.9983]
2025-03-11 20:53:04 - Train Iteration 8731: loss: 0.0741, d_k_M range: [0.0001, 0.0649], d_k_M_hat range: [0.7279, 0.9948]
2025-03-11 20:53:05 - Train Iteration 8732: loss: 0.2476, d_k_M range: [0.0001, 0.0493], d_k_M_hat range: [0.5285, 0.9937]
2025-03-11 20:53:05 - Train Iteration 8733: loss: 0.2758, d_k_M range: [0.0001, 0.5251], d_k_M_hat range: [0.9219, 0.9999]
2025-03-11 20:53:06 - Train Iteration 8734: loss: 0.0906, d_k_M range: [0.0000, 0.0819], d_k_M_hat range: [0.6994, 0.9867]
2025-03-11 20:53:06 - Train Iteration 8735: loss: 0.4581, d_k_M range: [0.0015, 0.6768], d_k_M_hat range: [0.6259, 1.0000]
2025-03-11 20:53:07 - Train Iteration 8736: loss: 0.1468, d_k_M range: [0.0000, 0.3810], d_k_M_hat range: [0.6539, 0.9978]
2025-03-11 20:53:07 - Train Iteration 8737: loss: 0.1124, d_k_M range: [0.0003, 0.0311], d_k_M_hat range: [0.6650, 0.9824]
2025-03-11 20:53:08 - Train Iteration 8738: loss: 0.2515, d_k_M range: [0.0000, 0.4992], d_k_M_hat range: [0.8298, 0.9977]
2025-03-11 20:53:08 - Train Iteration 8739: loss: 0.0769, d_k_M range: [0.0001, 0.2577], d_k_M_hat range: [0.8509, 0.9984]
2025-03-11 20:53:09 - Train Iteration 8740: loss: 0.2719, d_k_M range: [0.0001, 0.1080], d_k_M_hat range: [0.4786, 0.9982]
2025-03-11 20:53:09 - Train Iteration 8741: loss: 0.0251, d_k_M range: [0.0001, 0.0362], d_k_M_hat range: [0.8431, 0.9952]
2025-03-11 20:53:09 - Train Iteration 8742: loss: 0.2488, d_k_M range: [0.0015, 0.4966], d_k_M_hat range: [0.9181, 0.9983]
2025-03-11 20:53:10 - Train Iteration 8743: loss: 0.6437, d_k_M range: [0.0000, 0.2025], d_k_M_hat range: [0.1977, 0.9929]
2025-03-11 20:53:10 - Train Iteration 8744: loss: 0.4113, d_k_M range: [0.0095, 0.6408], d_k_M_hat range: [0.9321, 0.9998]
2025-03-11 20:53:11 - Train Iteration 8745: loss: 0.8790, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.0625, 0.9591]
2025-03-11 20:53:11 - Train Iteration 8746: loss: 0.0132, d_k_M range: [0.0007, 0.1081], d_k_M_hat range: [0.9388, 0.9997]
2025-03-11 20:53:12 - Train Iteration 8747: loss: 0.0093, d_k_M range: [0.0001, 0.0955], d_k_M_hat range: [0.9288, 0.9996]
2025-03-11 20:53:12 - Train Iteration 8748: loss: 0.1745, d_k_M range: [0.0003, 0.4158], d_k_M_hat range: [0.7935, 0.9980]
2025-03-11 20:53:13 - Train Iteration 8749: loss: 0.1792, d_k_M range: [0.0003, 0.4171], d_k_M_hat range: [0.8630, 0.9960]
2025-03-11 20:53:13 - Train Iteration 8750: loss: 0.0847, d_k_M range: [0.0000, 0.0776], d_k_M_hat range: [0.7090, 0.9901]
2025-03-11 20:53:14 - Train Iteration 8751: loss: 0.1239, d_k_M range: [0.0007, 0.3519], d_k_M_hat range: [0.9791, 0.9999]
2025-03-11 20:53:14 - Train Iteration 8752: loss: 0.1767, d_k_M range: [0.0011, 0.3804], d_k_M_hat range: [0.6023, 0.9959]
2025-03-11 20:53:14 - Train Iteration 8753: loss: 0.3004, d_k_M range: [0.0142, 0.5475], d_k_M_hat range: [0.9375, 0.9994]
2025-03-11 20:53:15 - Train Iteration 8754: loss: 0.4497, d_k_M range: [0.0001, 0.0100], d_k_M_hat range: [0.3295, 0.9995]
2025-03-11 20:53:15 - Train Iteration 8755: loss: 0.2029, d_k_M range: [0.0001, 0.4502], d_k_M_hat range: [0.9756, 0.9997]
2025-03-11 20:53:16 - Train Iteration 8756: loss: 0.0945, d_k_M range: [0.0001, 0.0285], d_k_M_hat range: [0.6928, 0.9994]
2025-03-11 20:53:16 - Train Iteration 8757: loss: 0.1346, d_k_M range: [0.0065, 0.3643], d_k_M_hat range: [0.9775, 0.9973]
2025-03-11 20:53:17 - Train Iteration 8758: loss: 0.1797, d_k_M range: [0.0000, 0.4238], d_k_M_hat range: [0.7608, 0.9999]
2025-03-11 20:53:17 - Train Iteration 8759: loss: 0.1663, d_k_M range: [0.0025, 0.4073], d_k_M_hat range: [0.8794, 0.9995]
2025-03-11 20:53:18 - Train Iteration 8760: loss: 0.2095, d_k_M range: [0.0001, 0.3205], d_k_M_hat range: [0.5429, 0.9996]
2025-03-11 20:53:18 - Train Iteration 8761: loss: 0.3610, d_k_M range: [0.0032, 0.5997], d_k_M_hat range: [0.8757, 0.9996]
2025-03-11 20:53:19 - Train Iteration 8762: loss: 0.0858, d_k_M range: [0.0001, 0.1216], d_k_M_hat range: [0.7072, 0.9957]
2025-03-11 20:53:19 - Train Iteration 8763: loss: 0.0110, d_k_M range: [0.0013, 0.1032], d_k_M_hat range: [0.9188, 0.9982]
2025-03-11 20:53:19 - Train Iteration 8764: loss: 0.1688, d_k_M range: [0.0001, 0.0554], d_k_M_hat range: [0.5892, 0.9982]
2025-03-11 20:53:20 - Train Iteration 8765: loss: 0.2471, d_k_M range: [0.0175, 0.4965], d_k_M_hat range: [0.9783, 1.0000]
2025-03-11 20:53:20 - Train Iteration 8766: loss: 0.2151, d_k_M range: [0.0003, 0.4623], d_k_M_hat range: [0.7821, 0.9986]
2025-03-11 20:53:21 - Train Iteration 8767: loss: 0.1353, d_k_M range: [0.0000, 0.1054], d_k_M_hat range: [0.6328, 0.9750]
2025-03-11 20:53:21 - Train Iteration 8768: loss: 0.0727, d_k_M range: [0.0001, 0.2687], d_k_M_hat range: [0.8433, 0.9991]
2025-03-11 20:53:22 - Train Iteration 8769: loss: 0.0105, d_k_M range: [0.0039, 0.0933], d_k_M_hat range: [0.9570, 0.9997]
2025-03-11 20:53:22 - Train Iteration 8770: loss: 0.1747, d_k_M range: [0.0002, 0.0117], d_k_M_hat range: [0.5822, 0.9809]
2025-03-11 20:53:23 - Train Iteration 8771: loss: 0.5215, d_k_M range: [0.0002, 0.7221], d_k_M_hat range: [0.9570, 0.9999]
2025-03-11 20:53:23 - Train Iteration 8772: loss: 0.3273, d_k_M range: [0.0000, 0.0715], d_k_M_hat range: [0.4300, 0.9964]
2025-03-11 20:53:23 - Train Iteration 8773: loss: 0.3988, d_k_M range: [0.0074, 0.6305], d_k_M_hat range: [0.9692, 0.9998]
2025-03-11 20:53:24 - Train Iteration 8774: loss: 0.0414, d_k_M range: [0.0009, 0.0874], d_k_M_hat range: [0.7977, 0.9854]
2025-03-11 20:53:24 - Train Iteration 8775: loss: 0.1126, d_k_M range: [0.0005, 0.0782], d_k_M_hat range: [0.6661, 0.9989]
2025-03-11 20:53:25 - Train Iteration 8776: loss: 0.0698, d_k_M range: [0.0002, 0.2633], d_k_M_hat range: [0.9721, 0.9991]
2025-03-11 20:53:25 - Train Iteration 8777: loss: 0.0246, d_k_M range: [0.0000, 0.1453], d_k_M_hat range: [0.8521, 0.9992]
2025-03-11 20:53:26 - Train Iteration 8778: loss: 0.0108, d_k_M range: [0.0000, 0.0345], d_k_M_hat range: [0.8981, 0.9933]
2025-03-11 20:53:26 - Train Iteration 8779: loss: 0.0911, d_k_M range: [0.0005, 0.2993], d_k_M_hat range: [0.9440, 0.9982]
2025-03-11 20:53:27 - Train Iteration 8780: loss: 0.1750, d_k_M range: [0.0000, 0.0259], d_k_M_hat range: [0.5816, 0.9976]
2025-03-11 20:53:27 - Train Iteration 8781: loss: 0.7201, d_k_M range: [0.0041, 0.8485], d_k_M_hat range: [0.9668, 0.9999]
2025-03-11 20:53:28 - Train Iteration 8782: loss: 0.4229, d_k_M range: [0.0000, 0.2663], d_k_M_hat range: [0.3499, 0.9697]
2025-03-11 20:53:28 - Train Iteration 8783: loss: 0.1872, d_k_M range: [0.0007, 0.4311], d_k_M_hat range: [0.9146, 0.9998]
2025-03-11 20:53:29 - Train Iteration 8784: loss: 0.2119, d_k_M range: [0.0000, 0.2097], d_k_M_hat range: [0.5399, 0.9901]
2025-03-11 20:53:29 - Train Iteration 8785: loss: 0.8134, d_k_M range: [0.0006, 0.9018], d_k_M_hat range: [0.8047, 0.9999]
2025-03-11 20:53:30 - Train Iteration 8786: loss: 0.0765, d_k_M range: [0.0002, 0.0529], d_k_M_hat range: [0.7235, 0.9870]
2025-03-11 20:53:30 - Train Iteration 8787: loss: 0.1163, d_k_M range: [0.0000, 0.0676], d_k_M_hat range: [0.6593, 0.9951]
2025-03-11 20:53:31 - Train Iteration 8788: loss: 0.1004, d_k_M range: [0.0005, 0.3143], d_k_M_hat range: [0.8710, 0.9988]
2025-03-11 20:53:31 - Train Iteration 8789: loss: 0.1490, d_k_M range: [0.0001, 0.0702], d_k_M_hat range: [0.6142, 0.9969]
2025-03-11 20:53:32 - Train Iteration 8790: loss: 0.1960, d_k_M range: [0.0010, 0.1911], d_k_M_hat range: [0.5694, 0.9990]
2025-03-11 20:53:32 - Train Iteration 8791: loss: 0.1537, d_k_M range: [0.0003, 0.3319], d_k_M_hat range: [0.6671, 0.9976]
2025-03-11 20:53:32 - Train Iteration 8792: loss: 0.1998, d_k_M range: [0.0001, 0.4405], d_k_M_hat range: [0.7911, 0.9972]
2025-03-11 20:53:33 - Train Iteration 8793: loss: 0.3050, d_k_M range: [0.0014, 0.5451], d_k_M_hat range: [0.6526, 0.9986]
2025-03-11 20:53:33 - Train Iteration 8794: loss: 0.3552, d_k_M range: [0.0001, 0.0139], d_k_M_hat range: [0.4043, 0.9451]
2025-03-11 20:53:34 - Train Iteration 8795: loss: 0.2049, d_k_M range: [0.0005, 0.4525], d_k_M_hat range: [0.9756, 0.9998]
2025-03-11 20:53:34 - Train Iteration 8796: loss: 0.2497, d_k_M range: [0.0001, 0.4984], d_k_M_hat range: [0.6786, 0.9987]
2025-03-11 20:53:35 - Train Iteration 8797: loss: 0.1250, d_k_M range: [0.0005, 0.3373], d_k_M_hat range: [0.6670, 0.9957]
2025-03-11 20:53:35 - Train Iteration 8798: loss: 0.0418, d_k_M range: [0.0000, 0.0373], d_k_M_hat range: [0.7959, 0.9924]
2025-03-11 20:53:35 - Train Iteration 8799: loss: 0.1860, d_k_M range: [0.0001, 0.2620], d_k_M_hat range: [0.5748, 0.9995]
2025-03-11 20:53:36 - Train Iteration 8800: loss: 0.5972, d_k_M range: [0.0011, 0.7726], d_k_M_hat range: [0.9866, 0.9999]
2025-03-11 20:53:36 - Train Iteration 8801: loss: 0.5508, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.2579, 0.8925]
2025-03-11 20:53:37 - Train Iteration 8802: loss: 0.0790, d_k_M range: [0.0036, 0.2606], d_k_M_hat range: [0.9238, 0.9993]
2025-03-11 20:53:37 - Train Iteration 8803: loss: 0.0614, d_k_M range: [0.0004, 0.2239], d_k_M_hat range: [0.7578, 0.9965]
2025-03-11 20:53:38 - Train Iteration 8804: loss: 0.1518, d_k_M range: [0.0012, 0.0714], d_k_M_hat range: [0.6134, 0.9989]
2025-03-11 20:53:38 - Train Iteration 8805: loss: 0.1095, d_k_M range: [0.0003, 0.2080], d_k_M_hat range: [0.6695, 0.9984]
2025-03-11 20:53:38 - Train Iteration 8806: loss: 0.5764, d_k_M range: [0.0016, 0.7578], d_k_M_hat range: [0.9698, 0.9986]
2025-03-11 20:53:39 - Train Iteration 8807: loss: 0.0292, d_k_M range: [0.0001, 0.1689], d_k_M_hat range: [0.8920, 0.9998]
2025-03-11 20:53:39 - Train Iteration 8808: loss: 0.4856, d_k_M range: [0.0003, 0.6963], d_k_M_hat range: [0.4681, 0.9994]
2025-03-11 20:53:40 - Train Iteration 8809: loss: 0.1340, d_k_M range: [0.0001, 0.1907], d_k_M_hat range: [0.6347, 0.9986]
2025-03-11 20:53:40 - Train Iteration 8810: loss: 0.1776, d_k_M range: [0.0008, 0.4202], d_k_M_hat range: [0.9751, 0.9994]
2025-03-11 20:53:41 - Train Iteration 8811: loss: 0.0214, d_k_M range: [0.0001, 0.1427], d_k_M_hat range: [0.8684, 0.9963]
2025-03-11 20:53:41 - Train Iteration 8812: loss: 0.1551, d_k_M range: [0.0000, 0.1480], d_k_M_hat range: [0.6079, 0.9970]
2025-03-11 20:53:41 - Train Iteration 8813: loss: 0.0094, d_k_M range: [0.0007, 0.0948], d_k_M_hat range: [0.9115, 0.9979]
2025-03-11 20:53:42 - Train Iteration 8814: loss: 0.6036, d_k_M range: [0.0350, 0.7767], d_k_M_hat range: [0.9591, 0.9998]
2025-03-11 20:53:42 - Train Iteration 8815: loss: 0.2254, d_k_M range: [0.0004, 0.0959], d_k_M_hat range: [0.5256, 0.9970]
2025-03-11 20:53:43 - Train Iteration 8816: loss: 0.0535, d_k_M range: [0.0003, 0.2310], d_k_M_hat range: [0.9224, 0.9996]
2025-03-11 20:53:43 - Train Iteration 8817: loss: 0.4150, d_k_M range: [0.0003, 0.3655], d_k_M_hat range: [0.3561, 0.9983]
2025-03-11 20:53:44 - Train Iteration 8818: loss: 0.4060, d_k_M range: [0.0011, 0.6371], d_k_M_hat range: [0.7649, 0.9999]
2025-03-11 20:53:44 - Train Iteration 8819: loss: 0.1235, d_k_M range: [0.0010, 0.3501], d_k_M_hat range: [0.9444, 0.9987]
2025-03-11 20:53:45 - Train Iteration 8820: loss: 0.2641, d_k_M range: [0.0000, 0.5056], d_k_M_hat range: [0.7615, 0.9995]
2025-03-11 20:53:45 - Train Iteration 8821: loss: 0.3604, d_k_M range: [0.0000, 0.0091], d_k_M_hat range: [0.4000, 0.9765]
2025-03-11 20:53:46 - Train Iteration 8822: loss: 0.2292, d_k_M range: [0.0006, 0.2552], d_k_M_hat range: [0.5219, 0.9928]
2025-03-11 20:53:46 - Train Iteration 8823: loss: 0.2776, d_k_M range: [0.0001, 0.5237], d_k_M_hat range: [0.9509, 0.9968]
2025-03-11 20:53:47 - Train Iteration 8824: loss: 0.3576, d_k_M range: [0.0000, 0.3645], d_k_M_hat range: [0.4020, 0.9986]
2025-03-11 20:53:47 - Train Iteration 8825: loss: 0.0176, d_k_M range: [0.0007, 0.0518], d_k_M_hat range: [0.9043, 0.9924]
2025-03-11 20:53:48 - Train Iteration 8826: loss: 0.2174, d_k_M range: [0.0006, 0.4655], d_k_M_hat range: [0.7989, 0.9996]
2025-03-11 20:53:48 - Train Iteration 8827: loss: 0.0622, d_k_M range: [0.0000, 0.0751], d_k_M_hat range: [0.7507, 0.9971]
2025-03-11 20:53:48 - Train Iteration 8828: loss: 0.0853, d_k_M range: [0.0001, 0.2904], d_k_M_hat range: [0.7846, 0.9983]
2025-03-11 20:53:49 - Train Iteration 8829: loss: 0.0404, d_k_M range: [0.0001, 0.0517], d_k_M_hat range: [0.7990, 0.9980]
2025-03-11 20:53:49 - Train Iteration 8830: loss: 0.1583, d_k_M range: [0.0000, 0.2534], d_k_M_hat range: [0.6022, 0.9921]
2025-03-11 20:53:50 - Train Iteration 8831: loss: 0.6241, d_k_M range: [0.0006, 0.2909], d_k_M_hat range: [0.2128, 0.9983]
2025-03-11 20:53:50 - Train Iteration 8832: loss: 0.6577, d_k_M range: [0.0002, 0.8102], d_k_M_hat range: [0.8414, 0.9992]
2025-03-11 20:53:51 - Train Iteration 8833: loss: 0.2921, d_k_M range: [0.0000, 0.3017], d_k_M_hat range: [0.4611, 0.9979]
2025-03-11 20:53:51 - Train Iteration 8834: loss: 0.0873, d_k_M range: [0.0002, 0.2917], d_k_M_hat range: [0.9567, 0.9995]
2025-03-11 20:53:52 - Train Iteration 8835: loss: 0.0242, d_k_M range: [0.0003, 0.1527], d_k_M_hat range: [0.8602, 0.9970]
2025-03-11 20:53:52 - Train Iteration 8836: loss: 0.0036, d_k_M range: [0.0006, 0.0492], d_k_M_hat range: [0.9602, 0.9983]
2025-03-11 20:53:52 - Train Iteration 8837: loss: 0.2409, d_k_M range: [0.0001, 0.4893], d_k_M_hat range: [0.7912, 0.9985]
2025-03-11 20:53:53 - Train Iteration 8838: loss: 0.3292, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.4263, 0.9332]
2025-03-11 20:53:53 - Train Iteration 8839: loss: 0.1541, d_k_M range: [0.0007, 0.0348], d_k_M_hat range: [0.6082, 0.9981]
2025-03-11 20:53:54 - Train Iteration 8840: loss: 0.2506, d_k_M range: [0.0000, 0.0172], d_k_M_hat range: [0.5005, 0.9717]
2025-03-11 20:53:54 - Train Iteration 8841: loss: 0.2609, d_k_M range: [0.0006, 0.4362], d_k_M_hat range: [0.4898, 0.9994]
2025-03-11 20:53:55 - Train Iteration 8842: loss: 0.0919, d_k_M range: [0.0001, 0.0468], d_k_M_hat range: [0.6970, 0.9973]
2025-03-11 20:53:55 - Train Iteration 8843: loss: 0.0711, d_k_M range: [0.0006, 0.2586], d_k_M_hat range: [0.9490, 0.9979]
2025-03-11 20:53:55 - Train Iteration 8844: loss: 0.1486, d_k_M range: [0.0005, 0.3834], d_k_M_hat range: [0.9618, 0.9979]
2025-03-11 20:53:56 - Train Iteration 8845: loss: 0.4424, d_k_M range: [0.0000, 0.0079], d_k_M_hat range: [0.3350, 0.9140]
2025-03-11 20:53:56 - Train Iteration 8846: loss: 0.6333, d_k_M range: [0.0055, 0.7956], d_k_M_hat range: [0.9494, 0.9999]
2025-03-11 20:53:57 - Train Iteration 8847: loss: 0.1498, d_k_M range: [0.0000, 0.0466], d_k_M_hat range: [0.6130, 0.9740]
2025-03-11 20:53:57 - Train Iteration 8848: loss: 0.0954, d_k_M range: [0.0003, 0.3035], d_k_M_hat range: [0.8810, 0.9946]
2025-03-11 20:53:58 - Train Iteration 8849: loss: 0.1065, d_k_M range: [0.0001, 0.0065], d_k_M_hat range: [0.6742, 0.9848]
2025-03-11 20:53:58 - Train Iteration 8850: loss: 0.1041, d_k_M range: [0.0000, 0.1967], d_k_M_hat range: [0.6774, 0.9971]
2025-03-11 20:53:58 - Train Iteration 8851: loss: 0.1238, d_k_M range: [0.0011, 0.3515], d_k_M_hat range: [0.8110, 0.9998]
2025-03-11 20:53:59 - Train Iteration 8852: loss: 0.1821, d_k_M range: [0.0000, 0.2248], d_k_M_hat range: [0.5754, 0.9956]
2025-03-11 20:53:59 - Train Iteration 8853: loss: 0.1151, d_k_M range: [0.0024, 0.2818], d_k_M_hat range: [0.7924, 0.9954]
2025-03-11 20:54:00 - Train Iteration 8854: loss: 0.0779, d_k_M range: [0.0007, 0.0456], d_k_M_hat range: [0.7227, 0.9932]
2025-03-11 20:54:00 - Train Iteration 8855: loss: 0.0983, d_k_M range: [0.0007, 0.2358], d_k_M_hat range: [0.6874, 0.9949]
2025-03-11 20:54:01 - Train Iteration 8856: loss: 0.3249, d_k_M range: [0.0010, 0.0282], d_k_M_hat range: [0.4310, 0.9981]
2025-03-11 20:54:01 - Train Iteration 8857: loss: 0.0078, d_k_M range: [0.0008, 0.0871], d_k_M_hat range: [0.9448, 0.9990]
2025-03-11 20:54:01 - Train Iteration 8858: loss: 0.1679, d_k_M range: [0.0001, 0.3171], d_k_M_hat range: [0.8786, 0.9990]
2025-03-11 20:54:02 - Train Iteration 8859: loss: 0.1929, d_k_M range: [0.0002, 0.4385], d_k_M_hat range: [0.8698, 0.9993]
2025-03-11 20:54:02 - Train Iteration 8860: loss: 0.5497, d_k_M range: [0.0000, 0.1572], d_k_M_hat range: [0.2589, 0.9985]
2025-03-11 20:54:03 - Train Iteration 8861: loss: 0.5375, d_k_M range: [0.0029, 0.7300], d_k_M_hat range: [0.9882, 0.9998]
2025-03-11 20:54:03 - Train Iteration 8862: loss: 0.1250, d_k_M range: [0.0000, 0.0219], d_k_M_hat range: [0.6470, 0.9690]
2025-03-11 20:54:04 - Train Iteration 8863: loss: 0.2703, d_k_M range: [0.0004, 0.5095], d_k_M_hat range: [0.8915, 0.9992]
2025-03-11 20:54:04 - Train Iteration 8864: loss: 0.0206, d_k_M range: [0.0000, 0.0589], d_k_M_hat range: [0.8576, 0.9985]
2025-03-11 20:54:04 - Train Iteration 8865: loss: 0.1991, d_k_M range: [0.0004, 0.4433], d_k_M_hat range: [0.9633, 0.9980]
2025-03-11 20:54:05 - Train Iteration 8866: loss: 0.6748, d_k_M range: [0.0000, 0.0239], d_k_M_hat range: [0.1786, 0.9893]
2025-03-11 20:54:05 - Train Iteration 8867: loss: 0.2592, d_k_M range: [0.0058, 0.5053], d_k_M_hat range: [0.9876, 0.9989]
2025-03-11 20:54:06 - Train Iteration 8868: loss: 0.5801, d_k_M range: [0.0002, 0.7578], d_k_M_hat range: [0.7451, 0.9993]
2025-03-11 20:54:06 - Train Iteration 8869: loss: 0.0932, d_k_M range: [0.0001, 0.2297], d_k_M_hat range: [0.6948, 0.9881]
2025-03-11 20:54:07 - Train Iteration 8870: loss: 0.0168, d_k_M range: [0.0000, 0.0276], d_k_M_hat range: [0.8725, 0.9950]
2025-03-11 20:54:07 - Train Iteration 8871: loss: 0.0370, d_k_M range: [0.0001, 0.0644], d_k_M_hat range: [0.8490, 0.9991]
2025-03-11 20:54:08 - Train Iteration 8872: loss: 0.3053, d_k_M range: [0.0000, 0.3468], d_k_M_hat range: [0.4475, 0.9938]
2025-03-11 20:54:08 - Train Iteration 8873: loss: 0.0533, d_k_M range: [0.0002, 0.2305], d_k_M_hat range: [0.9108, 0.9997]
2025-03-11 20:54:09 - Train Iteration 8874: loss: 0.2268, d_k_M range: [0.0002, 0.3075], d_k_M_hat range: [0.5239, 0.9964]
2025-03-11 20:54:09 - Train Iteration 8875: loss: 0.0847, d_k_M range: [0.0001, 0.2908], d_k_M_hat range: [0.8857, 0.9997]
2025-03-11 20:54:10 - Train Iteration 8876: loss: 0.0525, d_k_M range: [0.0009, 0.2287], d_k_M_hat range: [0.8236, 0.9995]
2025-03-11 20:54:10 - Train Iteration 8877: loss: 0.0767, d_k_M range: [0.0003, 0.2754], d_k_M_hat range: [0.8649, 0.9985]
2025-03-11 20:54:11 - Train Iteration 8878: loss: 0.0637, d_k_M range: [0.0004, 0.2372], d_k_M_hat range: [0.7642, 0.9990]
2025-03-11 20:54:11 - Train Iteration 8879: loss: 0.0781, d_k_M range: [0.0000, 0.2791], d_k_M_hat range: [0.8080, 0.9997]
2025-03-11 20:54:11 - Train Iteration 8880: loss: 0.0880, d_k_M range: [0.0000, 0.0758], d_k_M_hat range: [0.7034, 0.9880]
2025-03-11 20:54:12 - Train Iteration 8881: loss: 0.2454, d_k_M range: [0.0028, 0.4780], d_k_M_hat range: [0.9121, 0.9994]
2025-03-11 20:54:12 - Train Iteration 8882: loss: 0.5128, d_k_M range: [0.0000, 0.0930], d_k_M_hat range: [0.2854, 0.9715]
2025-03-11 20:54:13 - Train Iteration 8883: loss: 0.2664, d_k_M range: [0.0001, 0.5146], d_k_M_hat range: [0.7913, 0.9997]
2025-03-11 20:54:13 - Train Iteration 8884: loss: 0.0293, d_k_M range: [0.0001, 0.0442], d_k_M_hat range: [0.8302, 0.9963]
2025-03-11 20:54:14 - Train Iteration 8885: loss: 0.0421, d_k_M range: [0.0007, 0.1922], d_k_M_hat range: [0.8819, 0.9990]
2025-03-11 20:54:14 - Train Iteration 8886: loss: 0.0037, d_k_M range: [0.0000, 0.0533], d_k_M_hat range: [0.9611, 0.9992]
2025-03-11 20:54:15 - Train Iteration 8887: loss: 0.3791, d_k_M range: [0.0007, 0.6070], d_k_M_hat range: [0.8742, 0.9914]
2025-03-11 20:54:15 - Train Iteration 8888: loss: 0.1784, d_k_M range: [0.0001, 0.4163], d_k_M_hat range: [0.5811, 1.0000]
2025-03-11 20:54:16 - Train Iteration 8889: loss: 0.3638, d_k_M range: [0.0006, 0.6026], d_k_M_hat range: [0.9253, 1.0000]
2025-03-11 20:54:16 - Train Iteration 8890: loss: 1.0000, d_k_M range: [0.0000, 0.0733], d_k_M_hat range: [0.0000, 0.9955]
2025-03-11 20:54:16 - Train Iteration 8891: loss: 0.0564, d_k_M range: [0.0000, 0.2223], d_k_M_hat range: [0.8680, 0.9995]
2025-03-11 20:54:17 - Train Iteration 8892: loss: 0.9206, d_k_M range: [0.0001, 0.0308], d_k_M_hat range: [0.0407, 0.9770]
2025-03-11 20:54:17 - Train Iteration 8893: loss: 0.0314, d_k_M range: [0.0006, 0.1052], d_k_M_hat range: [0.8235, 0.9991]
2025-03-11 20:54:18 - Train Iteration 8894: loss: 0.0386, d_k_M range: [0.0019, 0.1734], d_k_M_hat range: [0.8074, 0.9991]
2025-03-11 20:54:18 - Train Iteration 8895: loss: 0.0185, d_k_M range: [0.0000, 0.1349], d_k_M_hat range: [0.9029, 0.9994]
2025-03-11 20:54:19 - Train Iteration 8896: loss: 0.6055, d_k_M range: [0.0005, 0.0822], d_k_M_hat range: [0.2247, 0.9919]
2025-03-11 20:54:19 - Train Iteration 8897: loss: 0.0346, d_k_M range: [0.0002, 0.0355], d_k_M_hat range: [0.8143, 0.9905]
2025-03-11 20:54:20 - Train Iteration 8898: loss: 0.1617, d_k_M range: [0.0000, 0.4021], d_k_M_hat range: [0.8076, 0.9999]
2025-03-11 20:54:20 - Train Iteration 8899: loss: 0.4349, d_k_M range: [0.0000, 0.0071], d_k_M_hat range: [0.3406, 0.9390]
2025-03-11 20:54:20 - Train Iteration 8900: loss: 0.2341, d_k_M range: [0.0005, 0.4184], d_k_M_hat range: [0.5166, 0.9996]
2025-03-11 20:54:21 - Train Iteration 8901: loss: 0.2443, d_k_M range: [0.0103, 0.4922], d_k_M_hat range: [0.9053, 0.9998]
2025-03-11 20:54:21 - Train Iteration 8902: loss: 0.0596, d_k_M range: [0.0000, 0.1369], d_k_M_hat range: [0.7560, 0.9966]
2025-03-11 20:54:22 - Train Iteration 8903: loss: 0.5431, d_k_M range: [0.0000, 0.7360], d_k_M_hat range: [0.9725, 0.9996]
2025-03-11 20:54:22 - Train Iteration 8904: loss: 0.2740, d_k_M range: [0.0000, 0.0186], d_k_M_hat range: [0.4766, 0.9799]
2025-03-11 20:54:23 - Train Iteration 8905: loss: 0.0360, d_k_M range: [0.0019, 0.1823], d_k_M_hat range: [0.9772, 0.9999]
2025-03-11 20:54:23 - Train Iteration 8906: loss: 0.0210, d_k_M range: [0.0000, 0.0853], d_k_M_hat range: [0.8552, 1.0000]
2025-03-11 20:54:23 - Train Iteration 8907: loss: 0.3494, d_k_M range: [0.0006, 0.5870], d_k_M_hat range: [0.9538, 0.9996]
2025-03-11 20:54:24 - Train Iteration 8908: loss: 0.2318, d_k_M range: [0.0004, 0.4788], d_k_M_hat range: [0.9796, 0.9973]
2025-03-11 20:54:24 - Train Iteration 8909: loss: 0.1412, d_k_M range: [0.0004, 0.0659], d_k_M_hat range: [0.6247, 0.9996]
2025-03-11 20:54:25 - Train Iteration 8910: loss: 0.0130, d_k_M range: [0.0002, 0.0980], d_k_M_hat range: [0.9087, 0.9990]
2025-03-11 20:54:25 - Train Iteration 8911: loss: 0.0684, d_k_M range: [0.0043, 0.2581], d_k_M_hat range: [0.8244, 0.9990]
2025-03-11 20:54:26 - Train Iteration 8912: loss: 0.4118, d_k_M range: [0.0011, 0.6350], d_k_M_hat range: [0.9611, 0.9983]
2025-03-11 20:54:26 - Train Iteration 8913: loss: 0.2720, d_k_M range: [0.0000, 0.0742], d_k_M_hat range: [0.4786, 0.9943]
2025-03-11 20:54:27 - Train Iteration 8914: loss: 0.1804, d_k_M range: [0.0000, 0.4229], d_k_M_hat range: [0.9231, 0.9988]
2025-03-11 20:54:27 - Train Iteration 8915: loss: 0.0597, d_k_M range: [0.0144, 0.2032], d_k_M_hat range: [0.9588, 0.9988]
2025-03-11 20:54:28 - Train Iteration 8916: loss: 0.0388, d_k_M range: [0.0000, 0.1945], d_k_M_hat range: [0.9029, 0.9983]
2025-03-11 20:54:28 - Train Iteration 8917: loss: 0.0729, d_k_M range: [0.0000, 0.0471], d_k_M_hat range: [0.7303, 0.9935]
2025-03-11 20:54:29 - Train Iteration 8918: loss: 0.1672, d_k_M range: [0.0018, 0.4083], d_k_M_hat range: [0.9536, 0.9995]
2025-03-11 20:54:29 - Train Iteration 8919: loss: 0.0475, d_k_M range: [0.0004, 0.0096], d_k_M_hat range: [0.7830, 0.9903]
2025-03-11 20:54:30 - Train Iteration 8920: loss: 0.0746, d_k_M range: [0.0000, 0.2424], d_k_M_hat range: [0.9448, 0.9960]
2025-03-11 20:54:30 - Train Iteration 8921: loss: 0.0571, d_k_M range: [0.0000, 0.1788], d_k_M_hat range: [0.7610, 0.9976]
2025-03-11 20:54:30 - Train Iteration 8922: loss: 0.1997, d_k_M range: [0.0002, 0.4452], d_k_M_hat range: [0.8512, 0.9995]
2025-03-11 20:54:31 - Train Iteration 8923: loss: 0.0306, d_k_M range: [0.0000, 0.1503], d_k_M_hat range: [0.8876, 0.9966]
2025-03-11 20:54:31 - Train Iteration 8924: loss: 0.0189, d_k_M range: [0.0004, 0.1341], d_k_M_hat range: [0.9344, 0.9977]
2025-03-11 20:54:32 - Train Iteration 8925: loss: 0.1370, d_k_M range: [0.0021, 0.3698], d_k_M_hat range: [0.9846, 0.9998]
2025-03-11 20:54:32 - Train Iteration 8926: loss: 0.1943, d_k_M range: [0.0001, 0.2306], d_k_M_hat range: [0.5594, 0.9995]
2025-03-11 20:54:33 - Train Iteration 8927: loss: 0.9177, d_k_M range: [0.0036, 0.9579], d_k_M_hat range: [0.9893, 1.0000]
2025-03-11 20:54:33 - Train Iteration 8928: loss: 0.3381, d_k_M range: [0.0001, 0.4990], d_k_M_hat range: [0.4186, 1.0000]
2025-03-11 20:54:34 - Train Iteration 8929: loss: 0.7164, d_k_M range: [0.0000, 0.8443], d_k_M_hat range: [0.9578, 0.9997]
2025-03-11 20:54:34 - Train Iteration 8930: loss: 0.1275, d_k_M range: [0.0001, 0.0883], d_k_M_hat range: [0.6436, 0.9921]
2025-03-11 20:54:35 - Train Iteration 8931: loss: 0.2022, d_k_M range: [0.0002, 0.4496], d_k_M_hat range: [0.7774, 1.0000]
2025-03-11 20:54:35 - Train Iteration 8932: loss: 0.1148, d_k_M range: [0.0006, 0.3356], d_k_M_hat range: [0.9131, 0.9968]
2025-03-11 20:54:35 - Train Iteration 8933: loss: 0.3654, d_k_M range: [0.0000, 0.0209], d_k_M_hat range: [0.3956, 0.9925]
2025-03-11 20:54:36 - Train Iteration 8934: loss: 0.0082, d_k_M range: [0.0010, 0.0869], d_k_M_hat range: [0.9573, 0.9994]
2025-03-11 20:54:36 - Train Iteration 8935: loss: 0.0948, d_k_M range: [0.0009, 0.2638], d_k_M_hat range: [0.9559, 0.9944]
2025-03-11 20:54:37 - Train Iteration 8936: loss: 0.7579, d_k_M range: [0.0019, 0.8706], d_k_M_hat range: [0.6907, 1.0000]
2025-03-11 20:54:37 - Train Iteration 8937: loss: 0.0551, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.7653, 0.9680]
2025-03-11 20:54:38 - Train Iteration 8938: loss: 0.1767, d_k_M range: [0.0001, 0.4193], d_k_M_hat range: [0.9761, 0.9989]
2025-03-11 20:54:38 - Train Iteration 8939: loss: 0.4876, d_k_M range: [0.0001, 0.0839], d_k_M_hat range: [0.3019, 0.9928]
2025-03-11 20:54:39 - Train Iteration 8940: loss: 0.0749, d_k_M range: [0.0001, 0.2683], d_k_M_hat range: [0.8500, 0.9962]
2025-03-11 20:54:39 - Train Iteration 8941: loss: 0.0793, d_k_M range: [0.0000, 0.0171], d_k_M_hat range: [0.7354, 0.9975]
2025-03-11 20:54:39 - Train Iteration 8942: loss: 0.0572, d_k_M range: [0.0001, 0.0803], d_k_M_hat range: [0.7616, 0.9990]
2025-03-11 20:54:40 - Train Iteration 8943: loss: 0.1704, d_k_M range: [0.0000, 0.4126], d_k_M_hat range: [0.7412, 0.9998]
2025-03-11 20:54:40 - Train Iteration 8944: loss: 0.2919, d_k_M range: [0.0000, 0.0575], d_k_M_hat range: [0.4599, 0.9984]
2025-03-11 20:54:41 - Train Iteration 8945: loss: 0.0472, d_k_M range: [0.0001, 0.1930], d_k_M_hat range: [0.9449, 0.9986]
2025-03-11 20:54:41 - Train Iteration 8946: loss: 0.1502, d_k_M range: [0.0000, 0.0567], d_k_M_hat range: [0.6129, 0.9980]
2025-03-11 20:54:41 - Train Iteration 8947: loss: 0.0444, d_k_M range: [0.0000, 0.2093], d_k_M_hat range: [0.9615, 0.9985]
2025-03-11 20:54:42 - Train Iteration 8948: loss: 0.0180, d_k_M range: [0.0000, 0.0277], d_k_M_hat range: [0.8676, 0.9927]
2025-03-11 20:54:42 - Train Iteration 8949: loss: 0.0624, d_k_M range: [0.0000, 0.2472], d_k_M_hat range: [0.9456, 0.9997]
2025-03-11 20:54:43 - Train Iteration 8950: loss: 0.0064, d_k_M range: [0.0002, 0.0798], d_k_M_hat range: [0.9330, 0.9999]
2025-03-11 20:54:43 - Train Iteration 8951: loss: 0.0285, d_k_M range: [0.0000, 0.1678], d_k_M_hat range: [0.8526, 0.9991]
2025-03-11 20:54:44 - Train Iteration 8952: loss: 0.1341, d_k_M range: [0.0000, 0.3617], d_k_M_hat range: [0.6791, 0.9955]
2025-03-11 20:54:44 - Train Iteration 8953: loss: 0.1575, d_k_M range: [0.0000, 0.3953], d_k_M_hat range: [0.9776, 0.9984]
2025-03-11 20:54:44 - Train Iteration 8954: loss: 0.0781, d_k_M range: [0.0000, 0.0067], d_k_M_hat range: [0.7208, 0.9977]
2025-03-11 20:54:45 - Train Iteration 8955: loss: 0.0678, d_k_M range: [0.0001, 0.2597], d_k_M_hat range: [0.9201, 1.0000]
2025-03-11 20:54:45 - Train Iteration 8956: loss: 0.2921, d_k_M range: [0.0005, 0.0949], d_k_M_hat range: [0.4808, 0.9967]
2025-03-11 20:54:46 - Train Iteration 8957: loss: 0.0253, d_k_M range: [0.0001, 0.1145], d_k_M_hat range: [0.8427, 0.9986]
2025-03-11 20:54:46 - Train Iteration 8958: loss: 0.0021, d_k_M range: [0.0000, 0.0350], d_k_M_hat range: [0.9545, 0.9967]
2025-03-11 20:54:47 - Train Iteration 8959: loss: 0.0509, d_k_M range: [0.0000, 0.2248], d_k_M_hat range: [0.9649, 0.9992]
2025-03-11 20:54:47 - Train Iteration 8960: loss: 0.5381, d_k_M range: [0.0000, 0.0071], d_k_M_hat range: [0.2665, 0.9757]
2025-03-11 20:54:47 - Train Iteration 8961: loss: 0.0196, d_k_M range: [0.0000, 0.1308], d_k_M_hat range: [0.8643, 0.9999]
2025-03-11 20:54:48 - Train Iteration 8962: loss: 0.4099, d_k_M range: [0.0003, 0.0393], d_k_M_hat range: [0.3602, 0.9909]
2025-03-11 20:54:48 - Train Iteration 8963: loss: 0.1107, d_k_M range: [0.0010, 0.3325], d_k_M_hat range: [0.9649, 0.9998]
2025-03-11 20:54:49 - Train Iteration 8964: loss: 0.1679, d_k_M range: [0.0004, 0.0266], d_k_M_hat range: [0.5908, 0.9874]
2025-03-11 20:54:49 - Train Iteration 8965: loss: 0.2241, d_k_M range: [0.0004, 0.4692], d_k_M_hat range: [0.8532, 0.9998]
2025-03-11 20:54:50 - Train Iteration 8966: loss: 0.7621, d_k_M range: [0.0000, 0.0230], d_k_M_hat range: [0.1270, 0.9910]
2025-03-11 20:54:50 - Train Iteration 8967: loss: 0.0827, d_k_M range: [0.0013, 0.2862], d_k_M_hat range: [0.9552, 0.9999]
2025-03-11 20:54:51 - Train Iteration 8968: loss: 0.0523, d_k_M range: [0.0017, 0.2246], d_k_M_hat range: [0.9237, 0.9959]
2025-03-11 20:54:51 - Train Iteration 8969: loss: 0.0336, d_k_M range: [0.0032, 0.1726], d_k_M_hat range: [0.9576, 0.9973]
2025-03-11 20:54:51 - Train Iteration 8970: loss: 0.0481, d_k_M range: [0.0004, 0.0752], d_k_M_hat range: [0.8018, 0.9991]
2025-03-11 20:54:52 - Train Iteration 8971: loss: 0.0036, d_k_M range: [0.0001, 0.0559], d_k_M_hat range: [0.9562, 0.9996]
2025-03-11 20:54:52 - Train Iteration 8972: loss: 0.0547, d_k_M range: [0.0002, 0.0690], d_k_M_hat range: [0.7664, 0.9993]
2025-03-11 20:54:53 - Train Iteration 8973: loss: 0.0735, d_k_M range: [0.0000, 0.0668], d_k_M_hat range: [0.7304, 0.9980]
2025-03-11 20:54:53 - Train Iteration 8974: loss: 0.0040, d_k_M range: [0.0001, 0.0584], d_k_M_hat range: [0.9567, 0.9950]
2025-03-11 20:54:54 - Train Iteration 8975: loss: 0.0796, d_k_M range: [0.0001, 0.1742], d_k_M_hat range: [0.7267, 0.9968]
2025-03-11 20:54:54 - Train Iteration 8976: loss: 0.1788, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.5771, 0.9992]
2025-03-11 20:54:55 - Train Iteration 8977: loss: 0.5511, d_k_M range: [0.0187, 0.7423], d_k_M_hat range: [0.9886, 1.0000]
2025-03-11 20:54:55 - Train Iteration 8978: loss: 0.4564, d_k_M range: [0.0001, 0.0922], d_k_M_hat range: [0.3258, 0.9977]
2025-03-11 20:54:55 - Train Iteration 8979: loss: 0.2842, d_k_M range: [0.0017, 0.5331], d_k_M_hat range: [0.8888, 1.0000]
2025-03-11 20:54:56 - Train Iteration 8980: loss: 0.7802, d_k_M range: [0.0000, 0.0228], d_k_M_hat range: [0.1168, 0.9607]
2025-03-11 20:54:56 - Train Iteration 8981: loss: 0.0721, d_k_M range: [0.0094, 0.2684], d_k_M_hat range: [0.9875, 0.9998]
2025-03-11 20:54:57 - Train Iteration 8982: loss: 0.0496, d_k_M range: [0.0000, 0.0079], d_k_M_hat range: [0.7779, 0.9845]
2025-03-11 20:54:57 - Train Iteration 8983: loss: 0.1234, d_k_M range: [0.0001, 0.0458], d_k_M_hat range: [0.6946, 0.9959]
2025-03-11 20:54:58 - Train Iteration 8984: loss: 0.0151, d_k_M range: [0.0000, 0.1222], d_k_M_hat range: [0.9464, 0.9993]
2025-03-11 20:54:58 - Train Iteration 8985: loss: 0.1331, d_k_M range: [0.0002, 0.0536], d_k_M_hat range: [0.6354, 0.9952]
2025-03-11 20:54:59 - Train Iteration 8986: loss: 0.0421, d_k_M range: [0.0006, 0.0139], d_k_M_hat range: [0.7954, 0.9980]
2025-03-11 20:54:59 - Train Iteration 8987: loss: 0.1635, d_k_M range: [0.0013, 0.4025], d_k_M_hat range: [0.9652, 0.9998]
2025-03-11 20:54:59 - Train Iteration 8988: loss: 0.6868, d_k_M range: [0.0000, 0.8251], d_k_M_hat range: [0.9424, 0.9964]
2025-03-11 20:55:00 - Train Iteration 8989: loss: 0.1411, d_k_M range: [0.0016, 0.3734], d_k_M_hat range: [0.9801, 0.9994]
2025-03-11 20:55:00 - Train Iteration 8990: loss: 0.0745, d_k_M range: [0.0000, 0.0803], d_k_M_hat range: [0.7271, 0.9985]
2025-03-11 20:55:01 - Train Iteration 8991: loss: 0.3915, d_k_M range: [0.0004, 0.6248], d_k_M_hat range: [0.9795, 0.9996]
2025-03-11 20:55:01 - Train Iteration 8992: loss: 0.0938, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.6938, 0.9855]
2025-03-11 20:55:02 - Train Iteration 8993: loss: 0.2239, d_k_M range: [0.0013, 0.4703], d_k_M_hat range: [0.9406, 0.9998]
2025-03-11 20:55:02 - Train Iteration 8994: loss: 0.0722, d_k_M range: [0.0000, 0.0991], d_k_M_hat range: [0.7336, 0.9993]
2025-03-11 20:55:03 - Train Iteration 8995: loss: 0.0489, d_k_M range: [0.0003, 0.2147], d_k_M_hat range: [0.8717, 0.9985]
2025-03-11 20:55:03 - Train Iteration 8996: loss: 0.1707, d_k_M range: [0.0001, 0.1165], d_k_M_hat range: [0.5872, 0.9974]
2025-03-11 20:55:04 - Train Iteration 8997: loss: 0.5844, d_k_M range: [0.0060, 0.7643], d_k_M_hat range: [0.9584, 0.9998]
2025-03-11 20:55:04 - Train Iteration 8998: loss: 0.1818, d_k_M range: [0.0000, 0.0726], d_k_M_hat range: [0.5736, 0.9996]
2025-03-11 20:55:05 - Train Iteration 8999: loss: 0.0366, d_k_M range: [0.0006, 0.1853], d_k_M_hat range: [0.9789, 0.9994]
2025-03-11 20:55:05 - Train Iteration 9000: loss: 0.2488, d_k_M range: [0.0001, 0.4963], d_k_M_hat range: [0.8169, 0.9996]
2025-03-11 20:55:05 - Train Iteration 9001: loss: 0.0281, d_k_M range: [0.0000, 0.1671], d_k_M_hat range: [0.8826, 0.9996]
2025-03-11 20:55:06 - Train Iteration 9002: loss: 0.2249, d_k_M range: [0.0008, 0.0541], d_k_M_hat range: [0.5266, 0.9994]
2025-03-11 20:55:06 - Train Iteration 9003: loss: 0.0273, d_k_M range: [0.0008, 0.1648], d_k_M_hat range: [0.9155, 0.9996]
2025-03-11 20:55:07 - Train Iteration 9004: loss: 0.0482, d_k_M range: [0.0001, 0.0120], d_k_M_hat range: [0.7806, 0.9921]
2025-03-11 20:55:07 - Train Iteration 9005: loss: 0.0380, d_k_M range: [0.0014, 0.1937], d_k_M_hat range: [0.9682, 0.9992]
2025-03-11 20:55:08 - Train Iteration 9006: loss: 0.3666, d_k_M range: [0.0000, 0.5978], d_k_M_hat range: [0.6089, 0.9957]
2025-03-11 20:55:08 - Train Iteration 9007: loss: 0.0253, d_k_M range: [0.0001, 0.1536], d_k_M_hat range: [0.9359, 0.9995]
2025-03-11 20:55:08 - Train Iteration 9008: loss: 0.5647, d_k_M range: [0.0003, 0.1262], d_k_M_hat range: [0.2549, 0.9926]
2025-03-11 20:55:09 - Train Iteration 9009: loss: 0.6550, d_k_M range: [0.0001, 0.8090], d_k_M_hat range: [0.9727, 0.9997]
2025-03-11 20:55:09 - Train Iteration 9010: loss: 0.2095, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.5423, 0.9527]
2025-03-11 20:55:10 - Train Iteration 9011: loss: 0.0591, d_k_M range: [0.0001, 0.1429], d_k_M_hat range: [0.8998, 0.9981]
2025-03-11 20:55:10 - Train Iteration 9012: loss: 0.0788, d_k_M range: [0.0001, 0.2774], d_k_M_hat range: [0.7569, 0.9995]
2025-03-11 20:55:11 - Train Iteration 9013: loss: 0.2791, d_k_M range: [0.0001, 0.0868], d_k_M_hat range: [0.4727, 0.9972]
2025-03-11 20:55:11 - Train Iteration 9014: loss: 0.0785, d_k_M range: [0.0000, 0.2696], d_k_M_hat range: [0.8892, 0.9953]
2025-03-11 20:55:12 - Train Iteration 9015: loss: 0.7050, d_k_M range: [0.0001, 0.0197], d_k_M_hat range: [0.1612, 0.9637]
2025-03-11 20:55:12 - Train Iteration 9016: loss: 0.4364, d_k_M range: [0.0002, 0.6590], d_k_M_hat range: [0.9126, 0.9993]
2025-03-11 20:55:13 - Train Iteration 9017: loss: 0.1246, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.6481, 0.8703]
2025-03-11 20:55:13 - Train Iteration 9018: loss: 0.1828, d_k_M range: [0.0005, 0.4273], d_k_M_hat range: [0.9913, 0.9998]
2025-03-11 20:55:13 - Train Iteration 9019: loss: 0.1718, d_k_M range: [0.0001, 0.4132], d_k_M_hat range: [0.9624, 0.9987]
2025-03-11 20:55:14 - Train Iteration 9020: loss: 0.3355, d_k_M range: [0.0000, 0.0178], d_k_M_hat range: [0.4208, 0.9990]
2025-03-11 20:55:14 - Train Iteration 9021: loss: 0.5111, d_k_M range: [0.0046, 0.7142], d_k_M_hat range: [0.8350, 0.9994]
2025-03-11 20:55:15 - Train Iteration 9022: loss: 0.6724, d_k_M range: [0.0000, 0.0332], d_k_M_hat range: [0.1810, 0.9846]
2025-03-11 20:55:15 - Train Iteration 9023: loss: 0.1487, d_k_M range: [0.0000, 0.3413], d_k_M_hat range: [0.8264, 0.9958]
2025-03-11 20:55:16 - Train Iteration 9024: loss: 0.2388, d_k_M range: [0.0000, 0.1086], d_k_M_hat range: [0.5115, 0.9530]
2025-03-11 20:55:16 - Train Iteration 9025: loss: 0.2271, d_k_M range: [0.0146, 0.3742], d_k_M_hat range: [0.8976, 1.0000]
2025-03-11 20:55:17 - Train Iteration 9026: loss: 0.1291, d_k_M range: [0.0001, 0.3572], d_k_M_hat range: [0.9793, 0.9991]
2025-03-11 20:55:17 - Train Iteration 9027: loss: 0.8342, d_k_M range: [0.0000, 0.2715], d_k_M_hat range: [0.0867, 0.9999]
2025-03-11 20:55:18 - Train Iteration 9028: loss: 0.1426, d_k_M range: [0.0024, 0.3775], d_k_M_hat range: [0.9312, 0.9999]
2025-03-11 20:55:18 - Train Iteration 9029: loss: 0.1168, d_k_M range: [0.0000, 0.0293], d_k_M_hat range: [0.6589, 0.9979]
2025-03-11 20:55:19 - Train Iteration 9030: loss: 0.0414, d_k_M range: [0.0005, 0.2029], d_k_M_hat range: [0.8330, 1.0000]
2025-03-11 20:55:19 - Train Iteration 9031: loss: 0.1378, d_k_M range: [0.0001, 0.0407], d_k_M_hat range: [0.6292, 0.9946]
2025-03-11 20:55:20 - Train Iteration 9032: loss: 0.0411, d_k_M range: [0.0008, 0.0635], d_k_M_hat range: [0.7996, 0.9997]
2025-03-11 20:55:20 - Train Iteration 9033: loss: 0.0845, d_k_M range: [0.0000, 0.0174], d_k_M_hat range: [0.7094, 0.9982]
2025-03-11 20:55:21 - Train Iteration 9034: loss: 0.2721, d_k_M range: [0.0000, 0.1865], d_k_M_hat range: [0.4787, 0.9999]
2025-03-11 20:55:21 - Train Iteration 9035: loss: 0.1647, d_k_M range: [0.0001, 0.4053], d_k_M_hat range: [0.6960, 0.9996]
2025-03-11 20:55:21 - Train Iteration 9036: loss: 0.1272, d_k_M range: [0.0000, 0.0181], d_k_M_hat range: [0.6436, 0.9938]
2025-03-11 20:55:22 - Train Iteration 9037: loss: 0.2009, d_k_M range: [0.0014, 0.3389], d_k_M_hat range: [0.5614, 0.9997]
2025-03-11 20:55:22 - Train Iteration 9038: loss: 0.1666, d_k_M range: [0.0001, 0.4080], d_k_M_hat range: [0.9547, 0.9999]
2025-03-11 20:55:23 - Train Iteration 9039: loss: 0.0094, d_k_M range: [0.0002, 0.0960], d_k_M_hat range: [0.9654, 0.9993]
2025-03-11 20:55:23 - Train Iteration 9040: loss: 0.0438, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.7916, 0.9989]
2025-03-11 20:55:24 - Train Iteration 9041: loss: 0.2204, d_k_M range: [0.0001, 0.4663], d_k_M_hat range: [0.8420, 0.9993]
2025-03-11 20:55:24 - Train Iteration 9042: loss: 0.2377, d_k_M range: [0.0000, 0.2002], d_k_M_hat range: [0.5125, 0.9996]
2025-03-11 20:55:25 - Train Iteration 9043: loss: 0.4524, d_k_M range: [0.0046, 0.6725], d_k_M_hat range: [0.9747, 0.9999]
2025-03-11 20:55:25 - Train Iteration 9044: loss: 0.2228, d_k_M range: [0.0000, 0.0282], d_k_M_hat range: [0.5280, 0.9953]
2025-03-11 20:55:26 - Train Iteration 9045: loss: 0.2514, d_k_M range: [0.0030, 0.4971], d_k_M_hat range: [0.9809, 0.9999]
2025-03-11 20:55:26 - Train Iteration 9046: loss: 0.0294, d_k_M range: [0.0000, 0.1514], d_k_M_hat range: [0.8300, 0.9994]
2025-03-11 20:55:27 - Train Iteration 9047: loss: 0.0754, d_k_M range: [0.0003, 0.2742], d_k_M_hat range: [0.9777, 0.9997]
2025-03-11 20:55:27 - Train Iteration 9048: loss: 0.1065, d_k_M range: [0.0000, 0.1167], d_k_M_hat range: [0.6739, 0.9998]
2025-03-11 20:55:27 - Train Iteration 9049: loss: 0.2080, d_k_M range: [0.0012, 0.4546], d_k_M_hat range: [0.9358, 0.9985]
2025-03-11 20:55:28 - Train Iteration 9050: loss: 0.3088, d_k_M range: [0.0000, 0.1168], d_k_M_hat range: [0.4443, 0.9820]
2025-03-11 20:55:28 - Train Iteration 9051: loss: 0.0803, d_k_M range: [0.0026, 0.2765], d_k_M_hat range: [0.7703, 0.9998]
2025-03-11 20:55:29 - Train Iteration 9052: loss: 0.1968, d_k_M range: [0.0000, 0.4434], d_k_M_hat range: [0.7136, 0.9998]
2025-03-11 20:55:29 - Train Iteration 9053: loss: 0.1851, d_k_M range: [0.0000, 0.4217], d_k_M_hat range: [0.8780, 0.9989]
2025-03-11 20:55:30 - Train Iteration 9054: loss: 0.0671, d_k_M range: [0.0002, 0.1307], d_k_M_hat range: [0.7411, 0.9995]
2025-03-11 20:55:30 - Train Iteration 9055: loss: 0.0388, d_k_M range: [0.0000, 0.0833], d_k_M_hat range: [0.8036, 0.9991]
2025-03-11 20:55:30 - Train Iteration 9056: loss: 0.0565, d_k_M range: [0.0000, 0.2371], d_k_M_hat range: [0.9744, 1.0000]
2025-03-11 20:55:31 - Train Iteration 9057: loss: 0.0068, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.9193, 0.9923]
2025-03-11 20:55:31 - Train Iteration 9058: loss: 0.0368, d_k_M range: [0.0001, 0.1867], d_k_M_hat range: [0.8855, 0.9997]
2025-03-11 20:55:32 - Train Iteration 9059: loss: 0.0046, d_k_M range: [0.0000, 0.0455], d_k_M_hat range: [0.9436, 0.9983]
2025-03-11 20:55:32 - Train Iteration 9060: loss: 0.0914, d_k_M range: [0.0012, 0.3014], d_k_M_hat range: [0.9574, 0.9991]
2025-03-11 20:55:33 - Train Iteration 9061: loss: 0.2227, d_k_M range: [0.0018, 0.4718], d_k_M_hat range: [0.8179, 1.0000]
2025-03-11 20:55:33 - Train Iteration 9062: loss: 0.5904, d_k_M range: [0.0000, 0.0240], d_k_M_hat range: [0.2316, 0.9774]
2025-03-11 20:55:34 - Train Iteration 9063: loss: 0.3130, d_k_M range: [0.0458, 0.5593], d_k_M_hat range: [0.9927, 0.9999]
2025-03-11 20:55:34 - Train Iteration 9064: loss: 0.7224, d_k_M range: [0.0000, 0.1728], d_k_M_hat range: [0.1501, 0.9998]
2025-03-11 20:55:35 - Train Iteration 9065: loss: 0.0013, d_k_M range: [0.0001, 0.0117], d_k_M_hat range: [0.9672, 0.9984]
2025-03-11 20:55:35 - Train Iteration 9066: loss: 0.1740, d_k_M range: [0.0000, 0.0237], d_k_M_hat range: [0.5840, 0.9862]
2025-03-11 20:55:36 - Train Iteration 9067: loss: 0.2486, d_k_M range: [0.0000, 0.4813], d_k_M_hat range: [0.7154, 0.9999]
2025-03-11 20:55:36 - Train Iteration 9068: loss: 0.0657, d_k_M range: [0.0000, 0.1829], d_k_M_hat range: [0.7438, 0.9962]
2025-03-11 20:55:37 - Train Iteration 9069: loss: 0.4813, d_k_M range: [0.0024, 0.6932], d_k_M_hat range: [0.9725, 1.0000]
2025-03-11 20:55:37 - Train Iteration 9070: loss: 0.4158, d_k_M range: [0.0000, 0.0148], d_k_M_hat range: [0.3552, 0.9769]
2025-03-11 20:55:37 - Train Iteration 9071: loss: 0.0250, d_k_M range: [0.0001, 0.0957], d_k_M_hat range: [0.8542, 0.9970]
2025-03-11 20:55:38 - Train Iteration 9072: loss: 0.2196, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.5329, 0.9886]
2025-03-11 20:55:38 - Train Iteration 9073: loss: 0.0800, d_k_M range: [0.0025, 0.2800], d_k_M_hat range: [0.9729, 0.9978]
2025-03-11 20:55:39 - Train Iteration 9074: loss: 0.0205, d_k_M range: [0.0001, 0.0339], d_k_M_hat range: [0.8590, 0.9966]
2025-03-11 20:55:39 - Train Iteration 9075: loss: 0.1197, d_k_M range: [0.0000, 0.0725], d_k_M_hat range: [0.6672, 0.9992]
2025-03-11 20:55:40 - Train Iteration 9076: loss: 0.6267, d_k_M range: [0.0055, 0.7916], d_k_M_hat range: [0.9038, 1.0000]
2025-03-11 20:55:40 - Train Iteration 9077: loss: 0.0132, d_k_M range: [0.0005, 0.0582], d_k_M_hat range: [0.8875, 0.9916]
2025-03-11 20:55:41 - Train Iteration 9078: loss: 0.6443, d_k_M range: [0.0003, 0.8019], d_k_M_hat range: [0.6588, 0.9992]
2025-03-11 20:55:41 - Train Iteration 9079: loss: 0.0446, d_k_M range: [0.0001, 0.0620], d_k_M_hat range: [0.7890, 0.9935]
2025-03-11 20:55:41 - Train Iteration 9080: loss: 0.1540, d_k_M range: [0.0003, 0.3896], d_k_M_hat range: [0.9419, 0.9978]
2025-03-11 20:55:42 - Train Iteration 9081: loss: 0.0741, d_k_M range: [0.0003, 0.0344], d_k_M_hat range: [0.7292, 0.9975]
2025-03-11 20:55:42 - Train Iteration 9082: loss: 0.0595, d_k_M range: [0.0006, 0.2285], d_k_M_hat range: [0.9209, 0.9989]
2025-03-11 20:55:43 - Train Iteration 9083: loss: 0.6524, d_k_M range: [0.0000, 0.8075], d_k_M_hat range: [0.9570, 0.9998]
2025-03-11 20:55:43 - Train Iteration 9084: loss: 0.8566, d_k_M range: [0.0000, 0.0517], d_k_M_hat range: [0.0745, 0.9890]
2025-03-11 20:55:44 - Train Iteration 9085: loss: 0.2862, d_k_M range: [0.0024, 0.5267], d_k_M_hat range: [0.8342, 0.9983]
2025-03-11 20:55:44 - Train Iteration 9086: loss: 0.6157, d_k_M range: [0.0001, 0.0146], d_k_M_hat range: [0.2154, 0.9974]
2025-03-11 20:55:45 - Train Iteration 9087: loss: 0.2237, d_k_M range: [0.0023, 0.4719], d_k_M_hat range: [0.9596, 0.9994]
2025-03-11 20:55:45 - Train Iteration 9088: loss: 0.2380, d_k_M range: [0.0002, 0.3156], d_k_M_hat range: [0.6174, 0.9972]
2025-03-11 20:55:46 - Train Iteration 9089: loss: 0.2129, d_k_M range: [0.0028, 0.4612], d_k_M_hat range: [0.8297, 0.9997]
2025-03-11 20:55:46 - Train Iteration 9090: loss: 0.3139, d_k_M range: [0.0000, 0.1735], d_k_M_hat range: [0.4398, 0.9988]
2025-03-11 20:55:47 - Train Iteration 9091: loss: 0.6052, d_k_M range: [0.0016, 0.7776], d_k_M_hat range: [0.9481, 0.9999]
2025-03-11 20:55:47 - Train Iteration 9092: loss: 0.4132, d_k_M range: [0.0000, 0.0066], d_k_M_hat range: [0.3572, 0.9628]
2025-03-11 20:55:48 - Train Iteration 9093: loss: 0.1720, d_k_M range: [0.0094, 0.4147], d_k_M_hat range: [0.9902, 1.0000]
2025-03-11 20:55:48 - Train Iteration 9094: loss: 0.2378, d_k_M range: [0.0000, 0.0171], d_k_M_hat range: [0.5124, 0.9966]
2025-03-11 20:55:49 - Train Iteration 9095: loss: 0.2076, d_k_M range: [0.0002, 0.1073], d_k_M_hat range: [0.5476, 0.9986]
2025-03-11 20:55:49 - Train Iteration 9096: loss: 0.0588, d_k_M range: [0.0021, 0.2422], d_k_M_hat range: [0.9393, 0.9997]
2025-03-11 20:55:49 - Train Iteration 9097: loss: 0.0547, d_k_M range: [0.0007, 0.0933], d_k_M_hat range: [0.7678, 0.9973]
2025-03-11 20:55:50 - Train Iteration 9098: loss: 0.0696, d_k_M range: [0.0003, 0.2606], d_k_M_hat range: [0.8407, 0.9998]
2025-03-11 20:55:50 - Train Iteration 9099: loss: 0.0448, d_k_M range: [0.0002, 0.2075], d_k_M_hat range: [0.9629, 0.9993]
2025-03-11 20:55:51 - Train Iteration 9100: loss: 0.2013, d_k_M range: [0.0005, 0.4371], d_k_M_hat range: [0.9067, 0.9989]
2025-03-11 20:55:51 - Train Iteration 9101: loss: 0.2693, d_k_M range: [0.0082, 0.1602], d_k_M_hat range: [0.4899, 0.9996]
2025-03-11 20:55:52 - Train Iteration 9102: loss: 0.1618, d_k_M range: [0.0019, 0.3967], d_k_M_hat range: [0.9401, 0.9971]
2025-03-11 20:55:52 - Train Iteration 9103: loss: 0.2303, d_k_M range: [0.0014, 0.2615], d_k_M_hat range: [0.5215, 0.9954]
2025-03-11 20:55:53 - Train Iteration 9104: loss: 0.0248, d_k_M range: [0.0045, 0.1081], d_k_M_hat range: [0.8525, 0.9989]
2025-03-11 20:55:53 - Train Iteration 9105: loss: 0.0930, d_k_M range: [0.0007, 0.3026], d_k_M_hat range: [0.9442, 0.9994]
2025-03-11 20:55:54 - Train Iteration 9106: loss: 0.1248, d_k_M range: [0.0000, 0.2617], d_k_M_hat range: [0.6468, 0.9945]
2025-03-11 20:55:54 - Train Iteration 9107: loss: 0.0510, d_k_M range: [0.0000, 0.0972], d_k_M_hat range: [0.7756, 0.9937]
2025-03-11 20:55:55 - Train Iteration 9108: loss: 0.0052, d_k_M range: [0.0015, 0.0199], d_k_M_hat range: [0.9313, 0.9982]
2025-03-11 20:55:55 - Train Iteration 9109: loss: 0.1553, d_k_M range: [0.0000, 0.3570], d_k_M_hat range: [0.6059, 0.9975]
2025-03-11 20:55:56 - Train Iteration 9110: loss: 0.1049, d_k_M range: [0.0000, 0.0594], d_k_M_hat range: [0.6767, 0.9942]
2025-03-11 20:55:56 - Train Iteration 9111: loss: 0.1485, d_k_M range: [0.0000, 0.1384], d_k_M_hat range: [0.6182, 0.9981]
2025-03-11 20:55:57 - Train Iteration 9112: loss: 0.0227, d_k_M range: [0.0001, 0.1154], d_k_M_hat range: [0.8911, 1.0000]
2025-03-11 20:55:57 - Train Iteration 9113: loss: 0.0173, d_k_M range: [0.0025, 0.1281], d_k_M_hat range: [0.9658, 0.9993]
2025-03-11 20:55:58 - Train Iteration 9114: loss: 0.2550, d_k_M range: [0.0000, 0.0616], d_k_M_hat range: [0.4951, 0.9941]
2025-03-11 20:55:58 - Train Iteration 9115: loss: 0.1171, d_k_M range: [0.0006, 0.3420], d_k_M_hat range: [0.9128, 0.9997]
2025-03-11 20:55:59 - Train Iteration 9116: loss: 0.0823, d_k_M range: [0.0000, 0.2867], d_k_M_hat range: [0.9757, 0.9998]
2025-03-11 20:55:59 - Train Iteration 9117: loss: 0.2323, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.5181, 0.9872]
2025-03-11 20:56:00 - Train Iteration 9118: loss: 0.1664, d_k_M range: [0.0002, 0.4053], d_k_M_hat range: [0.7688, 0.9997]
2025-03-11 20:56:00 - Train Iteration 9119: loss: 0.0545, d_k_M range: [0.0003, 0.0763], d_k_M_hat range: [0.7668, 0.9900]
2025-03-11 20:56:01 - Train Iteration 9120: loss: 0.0499, d_k_M range: [0.0001, 0.2216], d_k_M_hat range: [0.8291, 1.0000]
2025-03-11 20:56:01 - Train Iteration 9121: loss: 0.4366, d_k_M range: [0.0070, 0.6606], d_k_M_hat range: [0.9537, 0.9999]
2025-03-11 20:56:02 - Train Iteration 9122: loss: 0.0311, d_k_M range: [0.0001, 0.1669], d_k_M_hat range: [0.8630, 0.9987]
2025-03-11 20:56:02 - Train Iteration 9123: loss: 0.1778, d_k_M range: [0.0006, 0.2573], d_k_M_hat range: [0.5789, 0.9992]
2025-03-11 20:56:03 - Train Iteration 9124: loss: 0.0877, d_k_M range: [0.0001, 0.0099], d_k_M_hat range: [0.7041, 0.9938]
2025-03-11 20:56:03 - Train Iteration 9125: loss: 0.1270, d_k_M range: [0.0002, 0.3560], d_k_M_hat range: [0.8317, 0.9996]
2025-03-11 20:56:04 - Train Iteration 9126: loss: 0.5375, d_k_M range: [0.0000, 0.0542], d_k_M_hat range: [0.2669, 0.9963]
2025-03-11 20:56:04 - Train Iteration 9127: loss: 0.2282, d_k_M range: [0.0001, 0.3277], d_k_M_hat range: [0.5262, 1.0000]
2025-03-11 20:56:05 - Train Iteration 9128: loss: 0.6029, d_k_M range: [0.0001, 0.7759], d_k_M_hat range: [0.4945, 0.9995]
2025-03-11 20:56:05 - Train Iteration 9129: loss: 0.8572, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.0742, 0.9078]
2025-03-11 20:56:06 - Train Iteration 9130: loss: 0.2407, d_k_M range: [0.0566, 0.4885], d_k_M_hat range: [0.9959, 1.0000]
2025-03-11 20:56:06 - Train Iteration 9131: loss: 0.0784, d_k_M range: [0.0000, 0.0412], d_k_M_hat range: [0.7203, 0.9969]
2025-03-11 20:56:07 - Train Iteration 9132: loss: 0.1167, d_k_M range: [0.0051, 0.3410], d_k_M_hat range: [0.9788, 0.9995]
2025-03-11 20:56:07 - Train Iteration 9133: loss: 0.1439, d_k_M range: [0.0001, 0.0296], d_k_M_hat range: [0.6209, 0.9942]
2025-03-11 20:56:08 - Train Iteration 9134: loss: 0.1523, d_k_M range: [0.0004, 0.3900], d_k_M_hat range: [0.9671, 0.9997]
2025-03-11 20:56:08 - Train Iteration 9135: loss: 0.0775, d_k_M range: [0.0001, 0.2720], d_k_M_hat range: [0.8006, 0.9995]
2025-03-11 20:56:08 - Train Iteration 9136: loss: 0.7925, d_k_M range: [0.0000, 0.0335], d_k_M_hat range: [0.1098, 0.9889]
2025-03-11 20:56:09 - Train Iteration 9137: loss: 0.0763, d_k_M range: [0.0000, 0.2750], d_k_M_hat range: [0.9510, 0.9988]
2025-03-11 20:56:09 - Train Iteration 9138: loss: 0.3055, d_k_M range: [0.0000, 0.0574], d_k_M_hat range: [0.4474, 0.9973]
2025-03-11 20:56:10 - Train Iteration 9139: loss: 0.2421, d_k_M range: [0.0007, 0.4914], d_k_M_hat range: [0.9922, 0.9996]
2025-03-11 20:56:11 - Train Iteration 9140: loss: 0.1112, d_k_M range: [0.0000, 0.1609], d_k_M_hat range: [0.6665, 0.9920]
2025-03-11 20:56:11 - Train Iteration 9141: loss: 0.6474, d_k_M range: [0.0000, 0.3372], d_k_M_hat range: [0.1955, 0.9989]
2025-03-11 20:56:11 - Train Iteration 9142: loss: 0.2153, d_k_M range: [0.0032, 0.4600], d_k_M_hat range: [0.9759, 1.0000]
2025-03-11 20:56:12 - Train Iteration 9143: loss: 0.6527, d_k_M range: [0.0001, 0.1078], d_k_M_hat range: [0.1922, 0.9994]
2025-03-11 20:56:12 - Train Iteration 9144: loss: 0.0754, d_k_M range: [0.0003, 0.2733], d_k_M_hat range: [0.8841, 0.9997]
2025-03-11 20:56:13 - Train Iteration 9145: loss: 0.7195, d_k_M range: [0.0003, 0.0776], d_k_M_hat range: [0.1521, 0.9988]
2025-03-11 20:56:13 - Train Iteration 9146: loss: 0.0289, d_k_M range: [0.0052, 0.1668], d_k_M_hat range: [0.9576, 0.9999]
2025-03-11 20:56:14 - Train Iteration 9147: loss: 0.2964, d_k_M range: [0.0000, 0.5400], d_k_M_hat range: [0.8142, 0.9996]
2025-03-11 20:56:14 - Train Iteration 9148: loss: 0.3898, d_k_M range: [0.0001, 0.0168], d_k_M_hat range: [0.3758, 0.9954]
2025-03-11 20:56:15 - Train Iteration 9149: loss: 0.4070, d_k_M range: [0.0001, 0.2705], d_k_M_hat range: [0.3622, 0.9990]
2025-03-11 20:56:15 - Train Iteration 9150: loss: 0.1420, d_k_M range: [0.0039, 0.3766], d_k_M_hat range: [0.9776, 0.9998]
2025-03-11 20:56:16 - Train Iteration 9151: loss: 0.8415, d_k_M range: [0.0000, 0.0937], d_k_M_hat range: [0.0827, 0.9955]
2025-03-11 20:56:16 - Train Iteration 9152: loss: 0.1707, d_k_M range: [0.0003, 0.0204], d_k_M_hat range: [0.5871, 0.9976]
2025-03-11 20:56:17 - Train Iteration 9153: loss: 0.0189, d_k_M range: [0.0001, 0.0116], d_k_M_hat range: [0.8634, 0.9904]
2025-03-11 20:56:17 - Train Iteration 9154: loss: 0.3393, d_k_M range: [0.0005, 0.5816], d_k_M_hat range: [0.9527, 0.9997]
2025-03-11 20:56:18 - Train Iteration 9155: loss: 0.0319, d_k_M range: [0.0001, 0.1561], d_k_M_hat range: [0.9060, 0.9979]
2025-03-11 20:56:18 - Train Iteration 9156: loss: 0.0280, d_k_M range: [0.0000, 0.0240], d_k_M_hat range: [0.8360, 0.9716]
2025-03-11 20:56:19 - Train Iteration 9157: loss: 0.0424, d_k_M range: [0.0000, 0.2052], d_k_M_hat range: [0.8969, 0.9998]
2025-03-11 20:56:19 - Train Iteration 9158: loss: 0.1947, d_k_M range: [0.0001, 0.1167], d_k_M_hat range: [0.5588, 0.9884]
2025-03-11 20:56:19 - Train Iteration 9159: loss: 0.3834, d_k_M range: [0.0002, 0.6086], d_k_M_hat range: [0.9419, 0.9984]
2025-03-11 20:56:20 - Train Iteration 9160: loss: 0.0162, d_k_M range: [0.0003, 0.0199], d_k_M_hat range: [0.8764, 0.9987]
2025-03-11 20:56:20 - Train Iteration 9161: loss: 0.0319, d_k_M range: [0.0001, 0.0333], d_k_M_hat range: [0.8218, 0.9986]
2025-03-11 20:56:21 - Train Iteration 9162: loss: 0.0139, d_k_M range: [0.0001, 0.1158], d_k_M_hat range: [0.9147, 0.9983]
2025-03-11 20:56:21 - Train Iteration 9163: loss: 0.0249, d_k_M range: [0.0024, 0.0822], d_k_M_hat range: [0.8633, 0.9998]
2025-03-11 20:56:22 - Train Iteration 9164: loss: 0.1403, d_k_M range: [0.0001, 0.1300], d_k_M_hat range: [0.6256, 0.9975]
2025-03-11 20:56:22 - Train Iteration 9165: loss: 0.2502, d_k_M range: [0.0000, 0.0669], d_k_M_hat range: [0.4998, 0.9987]
2025-03-11 20:56:23 - Train Iteration 9166: loss: 0.1789, d_k_M range: [0.0113, 0.4127], d_k_M_hat range: [0.9871, 0.9983]
2025-03-11 20:56:23 - Train Iteration 9167: loss: 0.0778, d_k_M range: [0.0000, 0.1482], d_k_M_hat range: [0.7210, 0.9981]
2025-03-11 20:56:23 - Train Iteration 9168: loss: 0.1120, d_k_M range: [0.0001, 0.3275], d_k_M_hat range: [0.9427, 0.9994]
2025-03-11 20:56:24 - Train Iteration 9169: loss: 0.9424, d_k_M range: [0.0000, 0.0070], d_k_M_hat range: [0.0295, 0.9885]
2025-03-11 20:56:24 - Train Iteration 9170: loss: 0.0468, d_k_M range: [0.0004, 0.1322], d_k_M_hat range: [0.7842, 0.9999]
2025-03-11 20:56:25 - Train Iteration 9171: loss: 0.1467, d_k_M range: [0.0005, 0.3800], d_k_M_hat range: [0.6651, 0.9969]
2025-03-11 20:56:25 - Train Iteration 9172: loss: 0.0170, d_k_M range: [0.0009, 0.0876], d_k_M_hat range: [0.8710, 0.9989]
2025-03-11 20:56:26 - Train Iteration 9173: loss: 0.1121, d_k_M range: [0.0003, 0.1848], d_k_M_hat range: [0.6679, 0.9986]
2025-03-11 20:56:26 - Train Iteration 9174: loss: 0.0725, d_k_M range: [0.0002, 0.2616], d_k_M_hat range: [0.9671, 0.9997]
2025-03-11 20:56:27 - Train Iteration 9175: loss: 0.0304, d_k_M range: [0.0002, 0.0661], d_k_M_hat range: [0.8258, 0.9993]
2025-03-11 20:56:27 - Train Iteration 9176: loss: 0.1354, d_k_M range: [0.0003, 0.3539], d_k_M_hat range: [0.7458, 0.9961]
2025-03-11 20:56:28 - Train Iteration 9177: loss: 0.0899, d_k_M range: [0.0001, 0.0033], d_k_M_hat range: [0.7010, 0.9866]
2025-03-11 20:56:28 - Train Iteration 9178: loss: 0.1491, d_k_M range: [0.0002, 0.3856], d_k_M_hat range: [0.9198, 0.9995]
2025-03-11 20:56:29 - Train Iteration 9179: loss: 0.2352, d_k_M range: [0.0000, 0.0305], d_k_M_hat range: [0.5153, 0.9863]
2025-03-11 20:56:30 - Train Iteration 9180: loss: 0.0649, d_k_M range: [0.0024, 0.2543], d_k_M_hat range: [0.9184, 0.9995]
2025-03-11 20:56:30 - Train Iteration 9181: loss: 0.0636, d_k_M range: [0.0004, 0.2378], d_k_M_hat range: [0.7486, 0.9997]
2025-03-11 20:56:31 - Train Iteration 9182: loss: 0.0868, d_k_M range: [0.0002, 0.2920], d_k_M_hat range: [0.9418, 0.9986]
2025-03-11 20:56:31 - Train Iteration 9183: loss: 0.1325, d_k_M range: [0.0000, 0.2012], d_k_M_hat range: [0.6361, 0.9960]
2025-03-11 20:56:31 - Train Iteration 9184: loss: 0.0516, d_k_M range: [0.0001, 0.2214], d_k_M_hat range: [0.7754, 0.9966]
2025-03-11 20:56:32 - Train Iteration 9185: loss: 0.1725, d_k_M range: [0.0028, 0.4086], d_k_M_hat range: [0.8975, 0.9971]
2025-03-11 20:56:32 - Train Iteration 9186: loss: 0.0156, d_k_M range: [0.0026, 0.1236], d_k_M_hat range: [0.9715, 0.9986]
2025-03-11 20:56:33 - Train Iteration 9187: loss: 0.0305, d_k_M range: [0.0005, 0.0132], d_k_M_hat range: [0.8258, 0.9977]
2025-03-11 20:56:33 - Train Iteration 9188: loss: 0.1648, d_k_M range: [0.0001, 0.3963], d_k_M_hat range: [0.7975, 0.9994]
2025-03-11 20:56:34 - Train Iteration 9189: loss: 0.4099, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.3598, 0.8446]
2025-03-11 20:56:34 - Train Iteration 9190: loss: 0.0991, d_k_M range: [0.0006, 0.3113], d_k_M_hat range: [0.8762, 0.9999]
2025-03-11 20:56:35 - Train Iteration 9191: loss: 0.0872, d_k_M range: [0.0000, 0.0368], d_k_M_hat range: [0.7093, 0.9917]
2025-03-11 20:56:35 - Train Iteration 9192: loss: 0.0125, d_k_M range: [0.0000, 0.1092], d_k_M_hat range: [0.9302, 0.9973]
2025-03-11 20:56:36 - Train Iteration 9193: loss: 0.1826, d_k_M range: [0.0005, 0.4267], d_k_M_hat range: [0.8087, 0.9994]
2025-03-11 20:56:36 - Train Iteration 9194: loss: 0.2288, d_k_M range: [0.0002, 0.4777], d_k_M_hat range: [0.8802, 0.9995]
2025-03-11 20:56:37 - Train Iteration 9195: loss: 0.1795, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.5775, 0.9760]
2025-03-11 20:56:38 - Train Iteration 9196: loss: 0.1900, d_k_M range: [0.0003, 0.0969], d_k_M_hat range: [0.5647, 0.9978]
2025-03-11 20:56:38 - Train Iteration 9197: loss: 0.0391, d_k_M range: [0.0004, 0.1145], d_k_M_hat range: [0.8026, 0.9962]
2025-03-11 20:56:39 - Train Iteration 9198: loss: 0.0427, d_k_M range: [0.0001, 0.2031], d_k_M_hat range: [0.7972, 0.9980]
2025-03-11 20:56:39 - Train Iteration 9199: loss: 0.0413, d_k_M range: [0.0000, 0.0608], d_k_M_hat range: [0.8025, 0.9961]
2025-03-11 20:56:40 - Train Iteration 9200: loss: 0.2767, d_k_M range: [0.0001, 0.5254], d_k_M_hat range: [0.8090, 0.9999]
2025-03-11 20:56:40 - Train Iteration 9201: loss: 0.0315, d_k_M range: [0.0000, 0.0334], d_k_M_hat range: [0.8226, 0.9764]
2025-03-11 20:56:41 - Train Iteration 9202: loss: 0.0141, d_k_M range: [0.0003, 0.0969], d_k_M_hat range: [0.9410, 0.9961]
2025-03-11 20:56:41 - Train Iteration 9203: loss: 0.7453, d_k_M range: [0.0000, 0.0441], d_k_M_hat range: [0.1368, 0.9657]
2025-03-11 20:56:41 - Train Iteration 9204: loss: 0.3250, d_k_M range: [0.0032, 0.5636], d_k_M_hat range: [0.8800, 0.9996]
2025-03-11 20:56:42 - Train Iteration 9205: loss: 0.9973, d_k_M range: [0.0000, 0.1265], d_k_M_hat range: [0.0014, 0.9865]
2025-03-11 20:56:42 - Train Iteration 9206: loss: 0.1188, d_k_M range: [0.0003, 0.1659], d_k_M_hat range: [0.6556, 0.9996]
2025-03-11 20:56:43 - Train Iteration 9207: loss: 0.7332, d_k_M range: [0.0005, 0.8554], d_k_M_hat range: [0.9830, 0.9995]
2025-03-11 20:56:43 - Train Iteration 9208: loss: 0.2156, d_k_M range: [0.0001, 0.4628], d_k_M_hat range: [0.7678, 0.9988]
2025-03-11 20:56:44 - Train Iteration 9209: loss: 0.0408, d_k_M range: [0.0005, 0.1975], d_k_M_hat range: [0.8039, 0.9998]
2025-03-11 20:56:44 - Train Iteration 9210: loss: 0.4865, d_k_M range: [0.0002, 0.6962], d_k_M_hat range: [0.5024, 0.9987]
2025-03-11 20:56:45 - Train Iteration 9211: loss: 0.3437, d_k_M range: [0.0002, 0.0436], d_k_M_hat range: [0.4142, 0.9990]
2025-03-11 20:56:45 - Train Iteration 9212: loss: 0.4650, d_k_M range: [0.0026, 0.6819], d_k_M_hat range: [0.9666, 1.0000]
2025-03-11 20:56:45 - Train Iteration 9213: loss: 0.3386, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.4183, 0.9950]
2025-03-11 20:56:46 - Train Iteration 9214: loss: 0.1963, d_k_M range: [0.0018, 0.4428], d_k_M_hat range: [0.9578, 0.9997]
2025-03-11 20:56:46 - Train Iteration 9215: loss: 0.3399, d_k_M range: [0.0000, 0.0141], d_k_M_hat range: [0.4171, 0.9988]
2025-03-11 20:56:47 - Train Iteration 9216: loss: 0.0875, d_k_M range: [0.0465, 0.2835], d_k_M_hat range: [0.9806, 0.9989]
2025-03-11 20:56:47 - Train Iteration 9217: loss: 0.2496, d_k_M range: [0.0002, 0.0542], d_k_M_hat range: [0.5545, 0.9937]
2025-03-11 20:56:48 - Train Iteration 9218: loss: 0.0390, d_k_M range: [0.0000, 0.0225], d_k_M_hat range: [0.8027, 0.9979]
2025-03-11 20:56:48 - Train Iteration 9219: loss: 0.0239, d_k_M range: [0.0001, 0.0302], d_k_M_hat range: [0.8457, 0.9999]
2025-03-11 20:56:49 - Train Iteration 9220: loss: 0.0593, d_k_M range: [0.0001, 0.2411], d_k_M_hat range: [0.8445, 0.9976]
2025-03-11 20:56:49 - Train Iteration 9221: loss: 0.0347, d_k_M range: [0.0001, 0.1281], d_k_M_hat range: [0.8158, 0.9991]
2025-03-11 20:56:50 - Train Iteration 9222: loss: 0.1989, d_k_M range: [0.0187, 0.4433], d_k_M_hat range: [0.9745, 0.9998]
2025-03-11 20:56:50 - Train Iteration 9223: loss: 0.1024, d_k_M range: [0.0002, 0.0072], d_k_M_hat range: [0.6809, 0.9779]
2025-03-11 20:56:51 - Train Iteration 9224: loss: 0.1213, d_k_M range: [0.0002, 0.3468], d_k_M_hat range: [0.8256, 0.9985]
2025-03-11 20:56:51 - Train Iteration 9225: loss: 0.0383, d_k_M range: [0.0000, 0.0216], d_k_M_hat range: [0.8050, 0.9966]
2025-03-11 20:56:52 - Train Iteration 9226: loss: 0.2248, d_k_M range: [0.0011, 0.4697], d_k_M_hat range: [0.9924, 0.9999]
2025-03-11 20:56:52 - Train Iteration 9227: loss: 0.0105, d_k_M range: [0.0000, 0.0931], d_k_M_hat range: [0.9492, 0.9975]
2025-03-11 20:56:53 - Train Iteration 9228: loss: 0.5073, d_k_M range: [0.0001, 0.6881], d_k_M_hat range: [0.2881, 0.9989]
2025-03-11 20:56:53 - Train Iteration 9229: loss: 0.6234, d_k_M range: [0.0039, 0.7851], d_k_M_hat range: [0.8483, 0.9998]
2025-03-11 20:56:54 - Train Iteration 9230: loss: 0.9392, d_k_M range: [0.0000, 0.0085], d_k_M_hat range: [0.0309, 0.9852]
2025-03-11 20:56:54 - Train Iteration 9231: loss: 0.7442, d_k_M range: [0.0002, 0.8627], d_k_M_hat range: [0.9192, 1.0000]
2025-03-11 20:56:54 - Train Iteration 9232: loss: 0.3011, d_k_M range: [0.0000, 0.0298], d_k_M_hat range: [0.4515, 0.9973]
2025-03-11 20:56:55 - Train Iteration 9233: loss: 0.0990, d_k_M range: [0.0001, 0.3143], d_k_M_hat range: [0.9572, 0.9997]
2025-03-11 20:56:55 - Train Iteration 9234: loss: 0.0031, d_k_M range: [0.0000, 0.0550], d_k_M_hat range: [0.9657, 0.9997]
2025-03-11 20:56:56 - Train Iteration 9235: loss: 0.0634, d_k_M range: [0.0000, 0.2045], d_k_M_hat range: [0.7485, 0.9977]
2025-03-11 20:56:56 - Train Iteration 9236: loss: 0.0031, d_k_M range: [0.0001, 0.0466], d_k_M_hat range: [0.9467, 0.9992]
2025-03-11 20:56:57 - Train Iteration 9237: loss: 0.0507, d_k_M range: [0.0003, 0.1243], d_k_M_hat range: [0.7752, 0.9963]
2025-03-11 20:56:57 - Train Iteration 9238: loss: 0.0743, d_k_M range: [0.0002, 0.1834], d_k_M_hat range: [0.7276, 0.9988]
2025-03-11 20:56:58 - Train Iteration 9239: loss: 0.7052, d_k_M range: [0.0001, 0.8380], d_k_M_hat range: [0.9919, 0.9994]
2025-03-11 20:56:58 - Train Iteration 9240: loss: 0.1290, d_k_M range: [0.0000, 0.0304], d_k_M_hat range: [0.6411, 0.9978]
2025-03-11 20:56:59 - Train Iteration 9241: loss: 0.5662, d_k_M range: [0.0003, 0.7512], d_k_M_hat range: [0.9815, 0.9998]
2025-03-11 20:56:59 - Train Iteration 9242: loss: 0.4481, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.3306, 0.9860]
2025-03-11 20:57:00 - Train Iteration 9243: loss: 0.2063, d_k_M range: [0.0010, 0.4470], d_k_M_hat range: [0.9716, 0.9982]
2025-03-11 20:57:00 - Train Iteration 9244: loss: 0.4993, d_k_M range: [0.0000, 0.0987], d_k_M_hat range: [0.2934, 0.9975]
2025-03-11 20:57:01 - Train Iteration 9245: loss: 0.0284, d_k_M range: [0.0036, 0.1684], d_k_M_hat range: [0.9827, 0.9999]
2025-03-11 20:57:01 - Train Iteration 9246: loss: 0.2955, d_k_M range: [0.0024, 0.5430], d_k_M_hat range: [0.9577, 1.0000]
2025-03-11 20:57:02 - Train Iteration 9247: loss: 0.0216, d_k_M range: [0.0001, 0.0302], d_k_M_hat range: [0.8701, 0.9985]
2025-03-11 20:57:02 - Train Iteration 9248: loss: 0.6512, d_k_M range: [0.0000, 0.0203], d_k_M_hat range: [0.1930, 0.9287]
2025-03-11 20:57:03 - Train Iteration 9249: loss: 0.0065, d_k_M range: [0.0013, 0.0734], d_k_M_hat range: [0.9370, 0.9993]
2025-03-11 20:57:03 - Train Iteration 9250: loss: 0.1395, d_k_M range: [0.0101, 0.3735], d_k_M_hat range: [0.9380, 1.0000]
2025-03-11 20:57:04 - Train Iteration 9251: loss: 0.1612, d_k_M range: [0.0000, 0.0500], d_k_M_hat range: [0.5985, 0.9976]
2025-03-11 20:57:04 - Train Iteration 9252: loss: 0.3540, d_k_M range: [0.0008, 0.2325], d_k_M_hat range: [0.4075, 0.9992]
2025-03-11 20:57:05 - Train Iteration 9253: loss: 0.0663, d_k_M range: [0.0027, 0.2553], d_k_M_hat range: [0.9577, 0.9994]
2025-03-11 20:57:05 - Train Iteration 9254: loss: 0.3147, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.4390, 0.9892]
2025-03-11 20:57:06 - Train Iteration 9255: loss: 0.0261, d_k_M range: [0.0002, 0.1109], d_k_M_hat range: [0.8401, 0.9994]
2025-03-11 20:57:06 - Train Iteration 9256: loss: 0.0785, d_k_M range: [0.0004, 0.2753], d_k_M_hat range: [0.8912, 0.9967]
2025-03-11 20:57:07 - Train Iteration 9257: loss: 0.0201, d_k_M range: [0.0010, 0.0110], d_k_M_hat range: [0.8630, 0.9957]
2025-03-11 20:57:07 - Train Iteration 9258: loss: 0.0349, d_k_M range: [0.0000, 0.1823], d_k_M_hat range: [0.9579, 0.9988]
2025-03-11 20:57:07 - Train Iteration 9259: loss: 0.2365, d_k_M range: [0.0001, 0.0765], d_k_M_hat range: [0.5141, 0.9986]
2025-03-11 20:57:08 - Train Iteration 9260: loss: 0.0367, d_k_M range: [0.0001, 0.1880], d_k_M_hat range: [0.8754, 0.9989]
2025-03-11 20:57:08 - Train Iteration 9261: loss: 0.4947, d_k_M range: [0.0000, 0.2478], d_k_M_hat range: [0.2967, 0.9977]
2025-03-11 20:57:09 - Train Iteration 9262: loss: 0.5454, d_k_M range: [0.0004, 0.7339], d_k_M_hat range: [0.9686, 0.9977]
2025-03-11 20:57:09 - Train Iteration 9263: loss: 0.1566, d_k_M range: [0.0000, 0.3948], d_k_M_hat range: [0.9184, 0.9991]
2025-03-11 20:57:09 - Train Iteration 9264: loss: 0.0329, d_k_M range: [0.0015, 0.1802], d_k_M_hat range: [0.9793, 0.9998]
2025-03-11 20:57:10 - Train Iteration 9265: loss: 0.2096, d_k_M range: [0.0000, 0.0763], d_k_M_hat range: [0.5422, 0.9857]
2025-03-11 20:57:11 - Train Iteration 9266: loss: 0.2862, d_k_M range: [0.0001, 0.5287], d_k_M_hat range: [0.8743, 0.9953]
2025-03-11 20:57:11 - Train Iteration 9267: loss: 0.0951, d_k_M range: [0.0009, 0.3083], d_k_M_hat range: [0.8929, 1.0000]
2025-03-11 20:57:12 - Train Iteration 9268: loss: 0.0836, d_k_M range: [0.0000, 0.0445], d_k_M_hat range: [0.7112, 0.9720]
2025-03-11 20:57:12 - Train Iteration 9269: loss: 0.0673, d_k_M range: [0.0024, 0.2594], d_k_M_hat range: [0.9917, 1.0000]
2025-03-11 20:57:13 - Train Iteration 9270: loss: 0.0418, d_k_M range: [0.0000, 0.1970], d_k_M_hat range: [0.9332, 0.9996]
2025-03-11 20:57:13 - Train Iteration 9271: loss: 0.0758, d_k_M range: [0.0001, 0.0604], d_k_M_hat range: [0.7255, 0.9887]
2025-03-11 20:57:14 - Train Iteration 9272: loss: 0.4575, d_k_M range: [0.0027, 0.6763], d_k_M_hat range: [0.9718, 1.0000]
2025-03-11 20:57:14 - Train Iteration 9273: loss: 0.1377, d_k_M range: [0.0001, 0.0151], d_k_M_hat range: [0.6296, 0.9947]
2025-03-11 20:57:15 - Train Iteration 9274: loss: 0.0660, d_k_M range: [0.0006, 0.0723], d_k_M_hat range: [0.7437, 0.9987]
2025-03-11 20:57:15 - Train Iteration 9275: loss: 0.0090, d_k_M range: [0.0003, 0.0481], d_k_M_hat range: [0.9129, 0.9993]
2025-03-11 20:57:15 - Train Iteration 9276: loss: 0.0270, d_k_M range: [0.0004, 0.1120], d_k_M_hat range: [0.8817, 0.9921]
2025-03-11 20:57:16 - Train Iteration 9277: loss: 0.0354, d_k_M range: [0.0000, 0.1760], d_k_M_hat range: [0.9794, 0.9984]
2025-03-11 20:57:16 - Train Iteration 9278: loss: 0.1336, d_k_M range: [0.0083, 0.3653], d_k_M_hat range: [0.9628, 0.9997]
2025-03-11 20:57:17 - Train Iteration 9279: loss: 0.0834, d_k_M range: [0.0000, 0.0072], d_k_M_hat range: [0.7113, 0.9723]
2025-03-11 20:57:17 - Train Iteration 9280: loss: 0.0138, d_k_M range: [0.0110, 0.1163], d_k_M_hat range: [0.9298, 0.9991]
2025-03-11 20:57:18 - Train Iteration 9281: loss: 0.2915, d_k_M range: [0.0000, 0.1537], d_k_M_hat range: [0.4602, 0.9995]
2025-03-11 20:57:18 - Train Iteration 9282: loss: 0.0239, d_k_M range: [0.0001, 0.1547], d_k_M_hat range: [0.9204, 1.0000]
2025-03-11 20:57:18 - Train Iteration 9283: loss: 0.0376, d_k_M range: [0.0017, 0.1913], d_k_M_hat range: [0.9595, 0.9994]
2025-03-11 20:57:19 - Train Iteration 9284: loss: 0.1230, d_k_M range: [0.0000, 0.3506], d_k_M_hat range: [0.9047, 0.9999]
2025-03-11 20:57:19 - Train Iteration 9285: loss: 0.1765, d_k_M range: [0.0001, 0.0300], d_k_M_hat range: [0.5828, 0.9442]
2025-03-11 20:57:20 - Train Iteration 9286: loss: 0.2023, d_k_M range: [0.0002, 0.4380], d_k_M_hat range: [0.8558, 0.9993]
2025-03-11 20:57:21 - Train Iteration 9287: loss: 0.0315, d_k_M range: [0.0000, 0.0185], d_k_M_hat range: [0.8246, 0.9954]
2025-03-11 20:57:21 - Train Iteration 9288: loss: 0.0261, d_k_M range: [0.0000, 0.1595], d_k_M_hat range: [0.8449, 0.9978]
2025-03-11 20:57:22 - Train Iteration 9289: loss: 0.2730, d_k_M range: [0.0000, 0.5218], d_k_M_hat range: [0.8903, 0.9996]
2025-03-11 20:57:22 - Train Iteration 9290: loss: 0.0303, d_k_M range: [0.0000, 0.0503], d_k_M_hat range: [0.8262, 0.9909]
2025-03-11 20:57:23 - Train Iteration 9291: loss: 0.8692, d_k_M range: [0.0000, 0.0224], d_k_M_hat range: [0.0678, 0.9871]
2025-03-11 20:57:23 - Train Iteration 9292: loss: 0.1841, d_k_M range: [0.0001, 0.4267], d_k_M_hat range: [0.6532, 0.9998]
2025-03-11 20:57:24 - Train Iteration 9293: loss: 0.9479, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.0264, 0.7710]
2025-03-11 20:57:24 - Train Iteration 9294: loss: 0.4292, d_k_M range: [0.0000, 0.1885], d_k_M_hat range: [0.3449, 0.9977]
2025-03-11 20:57:25 - Train Iteration 9295: loss: 0.4874, d_k_M range: [0.0255, 0.6948], d_k_M_hat range: [0.9801, 0.9985]
2025-03-11 20:57:25 - Train Iteration 9296: loss: 0.0073, d_k_M range: [0.0000, 0.0091], d_k_M_hat range: [0.9146, 0.9952]
2025-03-11 20:57:25 - Train Iteration 9297: loss: 0.0680, d_k_M range: [0.0001, 0.2590], d_k_M_hat range: [0.8806, 0.9988]
2025-03-11 20:57:26 - Train Iteration 9298: loss: 0.0580, d_k_M range: [0.0000, 0.2265], d_k_M_hat range: [0.8778, 0.9963]
2025-03-11 20:57:26 - Train Iteration 9299: loss: 0.3658, d_k_M range: [0.0000, 0.6037], d_k_M_hat range: [0.5696, 0.9989]
2025-03-11 20:57:27 - Train Iteration 9300: loss: 0.4657, d_k_M range: [0.0004, 0.6814], d_k_M_hat range: [0.8430, 0.9990]
2025-03-11 20:57:27 - Train Iteration 9301: loss: 0.1027, d_k_M range: [0.0000, 0.2973], d_k_M_hat range: [0.6796, 0.9972]
2025-03-11 20:57:28 - Train Iteration 9302: loss: 0.1351, d_k_M range: [0.0002, 0.1597], d_k_M_hat range: [0.6326, 0.9933]
2025-03-11 20:57:28 - Train Iteration 9303: loss: 0.0675, d_k_M range: [0.0001, 0.2249], d_k_M_hat range: [0.7409, 0.9976]
2025-03-11 20:57:28 - Train Iteration 9304: loss: 0.2968, d_k_M range: [0.0003, 0.5440], d_k_M_hat range: [0.9408, 0.9992]
2025-03-11 20:57:29 - Train Iteration 9305: loss: 0.2100, d_k_M range: [0.0000, 0.0255], d_k_M_hat range: [0.5420, 0.9888]
2025-03-11 20:57:29 - Train Iteration 9306: loss: 0.0780, d_k_M range: [0.0018, 0.2714], d_k_M_hat range: [0.9522, 0.9979]
2025-03-11 20:57:30 - Train Iteration 9307: loss: 0.0838, d_k_M range: [0.0004, 0.2891], d_k_M_hat range: [0.8645, 0.9996]
2025-03-11 20:57:30 - Train Iteration 9308: loss: 0.1618, d_k_M range: [0.0000, 0.3999], d_k_M_hat range: [0.7069, 0.9977]
2025-03-11 20:57:31 - Train Iteration 9309: loss: 0.0264, d_k_M range: [0.0000, 0.0271], d_k_M_hat range: [0.8438, 0.9880]
2025-03-11 20:57:31 - Train Iteration 9310: loss: 0.1030, d_k_M range: [0.0008, 0.1503], d_k_M_hat range: [0.6942, 0.9998]
2025-03-11 20:57:32 - Train Iteration 9311: loss: 0.1564, d_k_M range: [0.0019, 0.3949], d_k_M_hat range: [0.9853, 0.9997]
2025-03-11 20:57:32 - Train Iteration 9312: loss: 0.0585, d_k_M range: [0.0050, 0.1543], d_k_M_hat range: [0.9125, 0.9961]
2025-03-11 20:57:33 - Train Iteration 9313: loss: 0.2314, d_k_M range: [0.0000, 0.4808], d_k_M_hat range: [0.5624, 0.9998]
2025-03-11 20:57:33 - Train Iteration 9314: loss: 0.1872, d_k_M range: [0.0000, 0.0141], d_k_M_hat range: [0.5687, 0.9681]
2025-03-11 20:57:34 - Train Iteration 9315: loss: 0.1769, d_k_M range: [0.0004, 0.4116], d_k_M_hat range: [0.9536, 0.9973]
2025-03-11 20:57:34 - Train Iteration 9316: loss: 0.0577, d_k_M range: [0.0001, 0.0955], d_k_M_hat range: [0.7602, 0.9970]
2025-03-11 20:57:35 - Train Iteration 9317: loss: 0.3973, d_k_M range: [0.0012, 0.6302], d_k_M_hat range: [0.9833, 0.9999]
2025-03-11 20:57:35 - Train Iteration 9318: loss: 0.2362, d_k_M range: [0.0000, 0.0111], d_k_M_hat range: [0.5156, 0.9822]
2025-03-11 20:57:36 - Train Iteration 9319: loss: 0.1100, d_k_M range: [0.0004, 0.3297], d_k_M_hat range: [0.9317, 0.9997]
2025-03-11 20:57:36 - Train Iteration 9320: loss: 0.0319, d_k_M range: [0.0001, 0.0445], d_k_M_hat range: [0.8251, 0.9974]
2025-03-11 20:57:37 - Train Iteration 9321: loss: 0.2338, d_k_M range: [0.0000, 0.4014], d_k_M_hat range: [0.5165, 0.9977]
2025-03-11 20:57:37 - Train Iteration 9322: loss: 0.1340, d_k_M range: [0.0003, 0.3660], d_k_M_hat range: [0.9331, 0.9999]
2025-03-11 20:57:38 - Train Iteration 9323: loss: 0.1220, d_k_M range: [0.0000, 0.1683], d_k_M_hat range: [0.6507, 0.9597]
2025-03-11 20:57:38 - Train Iteration 9324: loss: 0.0578, d_k_M range: [0.0001, 0.2404], d_k_M_hat range: [0.8817, 0.9999]
2025-03-11 20:57:39 - Train Iteration 9325: loss: 0.0278, d_k_M range: [0.0004, 0.1598], d_k_M_hat range: [0.8959, 0.9929]
2025-03-11 20:57:39 - Train Iteration 9326: loss: 0.1449, d_k_M range: [0.0000, 0.0084], d_k_M_hat range: [0.6195, 0.9995]
2025-03-11 20:57:39 - Train Iteration 9327: loss: 0.0262, d_k_M range: [0.0011, 0.1563], d_k_M_hat range: [0.9191, 0.9993]
2025-03-11 20:57:40 - Train Iteration 9328: loss: 0.1420, d_k_M range: [0.0000, 0.2314], d_k_M_hat range: [0.6235, 0.9984]
2025-03-11 20:57:40 - Train Iteration 9329: loss: 0.1257, d_k_M range: [0.0021, 0.3520], d_k_M_hat range: [0.9501, 0.9998]
2025-03-11 20:57:41 - Train Iteration 9330: loss: 0.0210, d_k_M range: [0.0000, 0.1442], d_k_M_hat range: [0.9008, 0.9997]
2025-03-11 20:57:41 - Train Iteration 9331: loss: 0.2713, d_k_M range: [0.0000, 0.0892], d_k_M_hat range: [0.4796, 0.9988]
2025-03-11 20:57:42 - Train Iteration 9332: loss: 0.0914, d_k_M range: [0.0000, 0.0718], d_k_M_hat range: [0.6977, 0.9946]
2025-03-11 20:57:42 - Train Iteration 9333: loss: 0.1907, d_k_M range: [0.0011, 0.4343], d_k_M_hat range: [0.9480, 0.9976]
2025-03-11 20:57:43 - Train Iteration 9334: loss: 0.1508, d_k_M range: [0.0000, 0.0436], d_k_M_hat range: [0.6117, 0.9943]
2025-03-11 20:57:43 - Train Iteration 9335: loss: 0.8554, d_k_M range: [0.0221, 0.9246], d_k_M_hat range: [0.9957, 1.0000]
2025-03-11 20:57:44 - Train Iteration 9336: loss: 0.1307, d_k_M range: [0.0001, 0.1675], d_k_M_hat range: [0.6458, 0.9993]
2025-03-11 20:57:44 - Train Iteration 9337: loss: 0.0400, d_k_M range: [0.0000, 0.1795], d_k_M_hat range: [0.8978, 0.9995]
2025-03-11 20:57:45 - Train Iteration 9338: loss: 0.0948, d_k_M range: [0.0000, 0.0292], d_k_M_hat range: [0.6921, 0.9993]
2025-03-11 20:57:45 - Train Iteration 9339: loss: 0.0238, d_k_M range: [0.0000, 0.0111], d_k_M_hat range: [0.8499, 0.9972]
2025-03-11 20:57:46 - Train Iteration 9340: loss: 0.5790, d_k_M range: [0.0000, 0.0516], d_k_M_hat range: [0.2397, 0.9972]
2025-03-11 20:57:46 - Train Iteration 9341: loss: 0.1015, d_k_M range: [0.0001, 0.3033], d_k_M_hat range: [0.9715, 0.9994]
2025-03-11 20:57:47 - Train Iteration 9342: loss: 0.0877, d_k_M range: [0.0000, 0.0608], d_k_M_hat range: [0.7040, 0.9987]
2025-03-11 20:57:47 - Train Iteration 9343: loss: 0.0325, d_k_M range: [0.0000, 0.1732], d_k_M_hat range: [0.9343, 0.9965]
2025-03-11 20:57:48 - Train Iteration 9344: loss: 0.0074, d_k_M range: [0.0000, 0.0651], d_k_M_hat range: [0.9148, 0.9999]
2025-03-11 20:57:48 - Train Iteration 9345: loss: 0.8121, d_k_M range: [0.0000, 0.5855], d_k_M_hat range: [0.0989, 1.0000]
2025-03-11 20:57:49 - Train Iteration 9346: loss: 0.0097, d_k_M range: [0.0001, 0.0908], d_k_M_hat range: [0.9523, 0.9970]
2025-03-11 20:57:49 - Train Iteration 9347: loss: 0.0270, d_k_M range: [0.0002, 0.1173], d_k_M_hat range: [0.8360, 0.9978]
2025-03-11 20:57:50 - Train Iteration 9348: loss: 0.0241, d_k_M range: [0.0000, 0.1546], d_k_M_hat range: [0.8488, 0.9999]
2025-03-11 20:57:50 - Train Iteration 9349: loss: 0.0115, d_k_M range: [0.0006, 0.0481], d_k_M_hat range: [0.8948, 0.9986]
2025-03-11 20:57:50 - Train Iteration 9350: loss: 0.1230, d_k_M range: [0.0001, 0.3487], d_k_M_hat range: [0.8758, 0.9980]
2025-03-11 20:57:51 - Train Iteration 9351: loss: 0.0970, d_k_M range: [0.0005, 0.3049], d_k_M_hat range: [0.8052, 0.9947]
2025-03-11 20:57:51 - Train Iteration 9352: loss: 0.0383, d_k_M range: [0.0007, 0.1933], d_k_M_hat range: [0.8424, 0.9977]
2025-03-11 20:57:52 - Train Iteration 9353: loss: 0.0406, d_k_M range: [0.0000, 0.0161], d_k_M_hat range: [0.8003, 0.9732]
2025-03-11 20:57:52 - Train Iteration 9354: loss: 0.0049, d_k_M range: [0.0000, 0.0091], d_k_M_hat range: [0.9362, 0.9998]
2025-03-11 20:57:53 - Train Iteration 9355: loss: 0.2690, d_k_M range: [0.0001, 0.1682], d_k_M_hat range: [0.4817, 0.9987]
2025-03-11 20:57:53 - Train Iteration 9356: loss: 0.0369, d_k_M range: [0.0003, 0.1902], d_k_M_hat range: [0.9723, 0.9995]
2025-03-11 20:57:54 - Train Iteration 9357: loss: 0.0654, d_k_M range: [0.0001, 0.2514], d_k_M_hat range: [0.8533, 0.9987]
2025-03-11 20:57:54 - Train Iteration 9358: loss: 0.0874, d_k_M range: [0.0001, 0.2947], d_k_M_hat range: [0.8950, 0.9991]
2025-03-11 20:57:55 - Train Iteration 9359: loss: 0.3293, d_k_M range: [0.0000, 0.0125], d_k_M_hat range: [0.4264, 0.9059]
2025-03-11 20:57:55 - Train Iteration 9360: loss: 0.0158, d_k_M range: [0.0000, 0.1253], d_k_M_hat range: [0.9344, 0.9998]
2025-03-11 20:57:56 - Train Iteration 9361: loss: 0.2066, d_k_M range: [0.0000, 0.0100], d_k_M_hat range: [0.5463, 0.9955]
2025-03-11 20:57:56 - Train Iteration 9362: loss: 0.5727, d_k_M range: [0.0039, 0.7553], d_k_M_hat range: [0.9334, 0.9993]
2025-03-11 20:57:57 - Train Iteration 9363: loss: 0.1013, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.6832, 0.9954]
2025-03-11 20:57:57 - Train Iteration 9364: loss: 0.0067, d_k_M range: [0.0001, 0.0753], d_k_M_hat range: [0.9478, 0.9987]
2025-03-11 20:57:58 - Train Iteration 9365: loss: 0.0300, d_k_M range: [0.0000, 0.0960], d_k_M_hat range: [0.8268, 0.9940]
2025-03-11 20:57:58 - Train Iteration 9366: loss: 0.0162, d_k_M range: [0.0002, 0.1183], d_k_M_hat range: [0.9458, 0.9994]
2025-03-11 20:57:58 - Train Iteration 9367: loss: 0.3537, d_k_M range: [0.0000, 0.0151], d_k_M_hat range: [0.4053, 0.9880]
2025-03-11 20:57:59 - Train Iteration 9368: loss: 0.0029, d_k_M range: [0.0003, 0.0493], d_k_M_hat range: [0.9571, 0.9988]
2025-03-11 20:57:59 - Train Iteration 9369: loss: 0.1561, d_k_M range: [0.0000, 0.0527], d_k_M_hat range: [0.6050, 0.9955]
2025-03-11 20:58:00 - Train Iteration 9370: loss: 0.1322, d_k_M range: [0.0004, 0.3568], d_k_M_hat range: [0.9932, 0.9998]
2025-03-11 20:58:00 - Train Iteration 9371: loss: 0.2724, d_k_M range: [0.0001, 0.5197], d_k_M_hat range: [0.6715, 0.9978]
2025-03-11 20:58:01 - Train Iteration 9372: loss: 0.2166, d_k_M range: [0.0000, 0.1213], d_k_M_hat range: [0.5366, 0.9727]
2025-03-11 20:58:01 - Train Iteration 9373: loss: 0.1393, d_k_M range: [0.0059, 0.3668], d_k_M_hat range: [0.9911, 0.9992]
2025-03-11 20:58:02 - Train Iteration 9374: loss: 0.1082, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.6710, 0.9967]
2025-03-11 20:58:02 - Train Iteration 9375: loss: 0.0213, d_k_M range: [0.0014, 0.0459], d_k_M_hat range: [0.8681, 0.9982]
2025-03-11 20:58:03 - Train Iteration 9376: loss: 0.0381, d_k_M range: [0.0000, 0.1947], d_k_M_hat range: [0.8410, 0.9995]
2025-03-11 20:58:03 - Train Iteration 9377: loss: 0.0559, d_k_M range: [0.0000, 0.0403], d_k_M_hat range: [0.7639, 0.9982]
2025-03-11 20:58:04 - Train Iteration 9378: loss: 0.3394, d_k_M range: [0.0003, 0.0024], d_k_M_hat range: [0.4180, 0.9973]
2025-03-11 20:58:04 - Train Iteration 9379: loss: 0.5135, d_k_M range: [0.0022, 0.7163], d_k_M_hat range: [0.9711, 0.9997]
2025-03-11 20:58:05 - Train Iteration 9380: loss: 0.0473, d_k_M range: [0.0002, 0.0295], d_k_M_hat range: [0.7854, 0.9993]
2025-03-11 20:58:05 - Train Iteration 9381: loss: 0.2091, d_k_M range: [0.0000, 0.4341], d_k_M_hat range: [0.7470, 0.9979]
2025-03-11 20:58:06 - Train Iteration 9382: loss: 0.1636, d_k_M range: [0.0000, 0.1282], d_k_M_hat range: [0.5956, 0.9855]
2025-03-11 20:58:06 - Train Iteration 9383: loss: 0.2903, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.4614, 0.9824]
2025-03-11 20:58:07 - Train Iteration 9384: loss: 0.2445, d_k_M range: [0.0002, 0.4944], d_k_M_hat range: [0.9561, 0.9999]
2025-03-11 20:58:07 - Train Iteration 9385: loss: 0.0833, d_k_M range: [0.0000, 0.2557], d_k_M_hat range: [0.7117, 0.9952]
2025-03-11 20:58:08 - Train Iteration 9386: loss: 0.0200, d_k_M range: [0.0001, 0.0106], d_k_M_hat range: [0.8591, 0.9985]
2025-03-11 20:58:08 - Train Iteration 9387: loss: 0.0384, d_k_M range: [0.0002, 0.1952], d_k_M_hat range: [0.9470, 0.9993]
2025-03-11 20:58:09 - Train Iteration 9388: loss: 0.1475, d_k_M range: [0.0001, 0.3808], d_k_M_hat range: [0.9697, 0.9996]
2025-03-11 20:58:09 - Train Iteration 9389: loss: 0.0268, d_k_M range: [0.0000, 0.1611], d_k_M_hat range: [0.8741, 0.9973]
2025-03-11 20:58:10 - Train Iteration 9390: loss: 0.0148, d_k_M range: [0.0001, 0.0713], d_k_M_hat range: [0.8793, 0.9910]
2025-03-11 20:58:10 - Train Iteration 9391: loss: 0.1072, d_k_M range: [0.0002, 0.0394], d_k_M_hat range: [0.6728, 0.9980]
2025-03-11 20:58:11 - Train Iteration 9392: loss: 0.0823, d_k_M range: [0.0004, 0.2811], d_k_M_hat range: [0.8859, 0.9942]
2025-03-11 20:58:11 - Train Iteration 9393: loss: 0.1001, d_k_M range: [0.0001, 0.0025], d_k_M_hat range: [0.6837, 0.9957]
2025-03-11 20:58:11 - Train Iteration 9394: loss: 0.2127, d_k_M range: [0.0010, 0.4600], d_k_M_hat range: [0.9534, 0.9988]
2025-03-11 20:58:12 - Train Iteration 9395: loss: 0.2220, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.5288, 0.9780]
2025-03-11 20:58:12 - Train Iteration 9396: loss: 0.3101, d_k_M range: [0.0002, 0.5568], d_k_M_hat range: [0.9938, 1.0000]
2025-03-11 20:58:13 - Train Iteration 9397: loss: 0.1808, d_k_M range: [0.0000, 0.0223], d_k_M_hat range: [0.5749, 0.9859]
2025-03-11 20:58:13 - Train Iteration 9398: loss: 0.3721, d_k_M range: [0.0024, 0.6098], d_k_M_hat range: [0.9329, 0.9998]
2025-03-11 20:58:14 - Train Iteration 9399: loss: 0.3845, d_k_M range: [0.0000, 0.0202], d_k_M_hat range: [0.3802, 0.9533]
2025-03-11 20:58:14 - Train Iteration 9400: loss: 0.1979, d_k_M range: [0.0001, 0.4420], d_k_M_hat range: [0.6043, 0.9985]
2025-03-11 20:58:14 - Train Iteration 9401: loss: 0.9115, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.0453, 0.9550]
2025-03-11 20:58:15 - Train Iteration 9402: loss: 0.1614, d_k_M range: [0.0038, 0.3990], d_k_M_hat range: [0.9762, 0.9997]
2025-03-11 20:58:16 - Train Iteration 9403: loss: 0.2155, d_k_M range: [0.0000, 0.1322], d_k_M_hat range: [0.5359, 0.9978]
2025-03-11 20:58:16 - Train Iteration 9404: loss: 0.0061, d_k_M range: [0.0000, 0.0647], d_k_M_hat range: [0.9795, 0.9988]
2025-03-11 20:58:17 - Train Iteration 9405: loss: 0.0133, d_k_M range: [0.0000, 0.0945], d_k_M_hat range: [0.8892, 0.9970]
2025-03-11 20:58:17 - Train Iteration 9406: loss: 0.2045, d_k_M range: [0.0003, 0.4507], d_k_M_hat range: [0.8488, 0.9998]
2025-03-11 20:58:18 - Train Iteration 9407: loss: 0.0570, d_k_M range: [0.0000, 0.1289], d_k_M_hat range: [0.7614, 0.9994]
2025-03-11 20:58:18 - Train Iteration 9408: loss: 0.2438, d_k_M range: [0.0001, 0.4935], d_k_M_hat range: [0.9433, 0.9997]
2025-03-11 20:58:19 - Train Iteration 9409: loss: 0.0569, d_k_M range: [0.0001, 0.2291], d_k_M_hat range: [0.7672, 0.9960]
2025-03-11 20:58:19 - Train Iteration 9410: loss: 0.4725, d_k_M range: [0.0003, 0.3759], d_k_M_hat range: [0.3235, 0.9968]
2025-03-11 20:58:20 - Train Iteration 9411: loss: 0.4367, d_k_M range: [0.0001, 0.6603], d_k_M_hat range: [0.8715, 0.9999]
2025-03-11 20:58:20 - Train Iteration 9412: loss: 0.3913, d_k_M range: [0.0000, 0.1029], d_k_M_hat range: [0.3745, 0.9813]
2025-03-11 20:58:21 - Train Iteration 9413: loss: 0.2207, d_k_M range: [0.0001, 0.4658], d_k_M_hat range: [0.9314, 0.9999]
2025-03-11 20:58:21 - Train Iteration 9414: loss: 0.4400, d_k_M range: [0.0000, 0.0269], d_k_M_hat range: [0.3402, 0.9948]
2025-03-11 20:58:22 - Train Iteration 9415: loss: 0.0017, d_k_M range: [0.0001, 0.0245], d_k_M_hat range: [0.9741, 0.9998]
2025-03-11 20:58:22 - Train Iteration 9416: loss: 0.3065, d_k_M range: [0.0000, 0.1654], d_k_M_hat range: [0.4466, 0.9984]
2025-03-11 20:58:23 - Train Iteration 9417: loss: 0.4334, d_k_M range: [0.0006, 0.6582], d_k_M_hat range: [0.8732, 0.9998]
2025-03-11 20:58:23 - Train Iteration 9418: loss: 0.0402, d_k_M range: [0.0001, 0.0548], d_k_M_hat range: [0.7998, 0.9991]
2025-03-11 20:58:23 - Train Iteration 9419: loss: 0.0042, d_k_M range: [0.0013, 0.0580], d_k_M_hat range: [0.9404, 0.9983]
2025-03-11 20:58:24 - Train Iteration 9420: loss: 0.2356, d_k_M range: [0.0000, 0.0829], d_k_M_hat range: [0.5146, 0.9998]
2025-03-11 20:58:24 - Train Iteration 9421: loss: 0.3402, d_k_M range: [0.0002, 0.5816], d_k_M_hat range: [0.9282, 0.9999]
2025-03-11 20:58:25 - Train Iteration 9422: loss: 0.0846, d_k_M range: [0.0000, 0.2816], d_k_M_hat range: [0.8971, 0.9944]
2025-03-11 20:58:26 - Train Iteration 9423: loss: 0.0475, d_k_M range: [0.0000, 0.2123], d_k_M_hat range: [0.8630, 0.9996]
2025-03-11 20:58:26 - Train Iteration 9424: loss: 0.5119, d_k_M range: [0.0000, 0.0925], d_k_M_hat range: [0.2846, 0.8233]
2025-03-11 20:58:26 - Train Iteration 9425: loss: 0.1981, d_k_M range: [0.0005, 0.4433], d_k_M_hat range: [0.9805, 0.9996]
2025-03-11 20:58:27 - Train Iteration 9426: loss: 0.1307, d_k_M range: [0.0000, 0.0091], d_k_M_hat range: [0.6387, 0.9862]
2025-03-11 20:58:27 - Train Iteration 9427: loss: 0.3800, d_k_M range: [0.0023, 0.6139], d_k_M_hat range: [0.9474, 0.9996]
2025-03-11 20:58:28 - Train Iteration 9428: loss: 0.0141, d_k_M range: [0.0000, 0.0582], d_k_M_hat range: [0.8820, 0.9896]
2025-03-11 20:58:28 - Train Iteration 9429: loss: 0.2437, d_k_M range: [0.0000, 0.4933], d_k_M_hat range: [0.9619, 0.9996]
2025-03-11 20:58:29 - Train Iteration 9430: loss: 0.0524, d_k_M range: [0.0000, 0.1127], d_k_M_hat range: [0.7711, 0.9973]
2025-03-11 20:58:30 - Train Iteration 9431: loss: 0.0440, d_k_M range: [0.0000, 0.0302], d_k_M_hat range: [0.7904, 0.9984]
2025-03-11 20:58:30 - Train Iteration 9432: loss: 0.3103, d_k_M range: [0.0000, 0.5547], d_k_M_hat range: [0.8309, 0.9999]
2025-03-11 20:58:31 - Train Iteration 9433: loss: 0.5222, d_k_M range: [0.0000, 0.2330], d_k_M_hat range: [0.2774, 0.9992]
2025-03-11 20:58:31 - Train Iteration 9434: loss: 0.0775, d_k_M range: [0.0001, 0.2555], d_k_M_hat range: [0.9771, 0.9991]
2025-03-11 20:58:31 - Train Iteration 9435: loss: 0.4109, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.3590, 0.9920]
2025-03-11 20:58:32 - Train Iteration 9436: loss: 0.8238, d_k_M range: [0.0003, 0.9068], d_k_M_hat range: [0.8999, 0.9999]
2025-03-11 20:58:32 - Train Iteration 9437: loss: 0.0778, d_k_M range: [0.0001, 0.2720], d_k_M_hat range: [0.9624, 0.9986]
2025-03-11 20:58:33 - Train Iteration 9438: loss: 0.2351, d_k_M range: [0.0000, 0.0155], d_k_M_hat range: [0.5161, 0.9799]
2025-03-11 20:58:33 - Train Iteration 9439: loss: 0.4869, d_k_M range: [0.0001, 0.6812], d_k_M_hat range: [0.9711, 0.9996]
2025-03-11 20:58:33 - Train Iteration 9440: loss: 0.6842, d_k_M range: [0.0000, 0.0634], d_k_M_hat range: [0.1729, 0.9787]
2025-03-11 20:58:34 - Train Iteration 9441: loss: 0.0140, d_k_M range: [0.0012, 0.1181], d_k_M_hat range: [0.9601, 0.9999]
2025-03-11 20:58:34 - Train Iteration 9442: loss: 0.1555, d_k_M range: [0.0000, 0.3863], d_k_M_hat range: [0.8168, 0.9952]
2025-03-11 20:58:35 - Train Iteration 9443: loss: 0.2020, d_k_M range: [0.0000, 0.0214], d_k_M_hat range: [0.5506, 0.9988]
2025-03-11 20:58:35 - Train Iteration 9444: loss: 0.1189, d_k_M range: [0.0000, 0.0446], d_k_M_hat range: [0.6653, 0.9949]
2025-03-11 20:58:36 - Train Iteration 9445: loss: 0.1508, d_k_M range: [0.0001, 0.3524], d_k_M_hat range: [0.8543, 0.9995]
2025-03-11 20:58:36 - Train Iteration 9446: loss: 0.0396, d_k_M range: [0.0002, 0.0044], d_k_M_hat range: [0.8015, 0.9992]
2025-03-11 20:58:37 - Train Iteration 9447: loss: 0.1003, d_k_M range: [0.0001, 0.3069], d_k_M_hat range: [0.9477, 0.9952]
2025-03-11 20:58:37 - Train Iteration 9448: loss: 0.1082, d_k_M range: [0.0003, 0.2007], d_k_M_hat range: [0.6719, 0.9998]
2025-03-11 20:58:38 - Train Iteration 9449: loss: 0.1386, d_k_M range: [0.0008, 0.3711], d_k_M_hat range: [0.7397, 0.9993]
2025-03-11 20:58:38 - Train Iteration 9450: loss: 0.1050, d_k_M range: [0.0000, 0.0541], d_k_M_hat range: [0.6763, 0.9884]
2025-03-11 20:58:39 - Train Iteration 9451: loss: 0.1896, d_k_M range: [0.0002, 0.4287], d_k_M_hat range: [0.8649, 0.9999]
2025-03-11 20:58:39 - Train Iteration 9452: loss: 0.0158, d_k_M range: [0.0007, 0.1229], d_k_M_hat range: [0.9339, 0.9999]
2025-03-11 20:58:40 - Train Iteration 9453: loss: 0.0330, d_k_M range: [0.0003, 0.0813], d_k_M_hat range: [0.8189, 0.9994]
2025-03-11 20:58:40 - Train Iteration 9454: loss: 0.1950, d_k_M range: [0.0004, 0.0107], d_k_M_hat range: [0.5592, 0.9911]
2025-03-11 20:58:41 - Train Iteration 9455: loss: 0.0053, d_k_M range: [0.0002, 0.0348], d_k_M_hat range: [0.9271, 0.9990]
2025-03-11 20:58:41 - Train Iteration 9456: loss: 0.0743, d_k_M range: [0.0000, 0.1902], d_k_M_hat range: [0.7278, 0.9995]
2025-03-11 20:58:42 - Train Iteration 9457: loss: 0.0767, d_k_M range: [0.0000, 0.0487], d_k_M_hat range: [0.7293, 0.9994]
2025-03-11 20:58:42 - Train Iteration 9458: loss: 0.2092, d_k_M range: [0.0000, 0.4552], d_k_M_hat range: [0.7210, 0.9978]
2025-03-11 20:58:42 - Train Iteration 9459: loss: 0.1444, d_k_M range: [0.0002, 0.1646], d_k_M_hat range: [0.6234, 0.9996]
2025-03-11 20:58:43 - Train Iteration 9460: loss: 0.1370, d_k_M range: [0.0035, 0.3683], d_k_M_hat range: [0.9588, 0.9998]
2025-03-11 20:58:43 - Train Iteration 9461: loss: 0.0757, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.7250, 0.9953]
2025-03-11 20:58:44 - Train Iteration 9462: loss: 0.4483, d_k_M range: [0.0048, 0.6682], d_k_M_hat range: [0.9610, 0.9996]
2025-03-11 20:58:44 - Train Iteration 9463: loss: 0.1925, d_k_M range: [0.0000, 0.0182], d_k_M_hat range: [0.5616, 0.9947]
2025-03-11 20:58:45 - Train Iteration 9464: loss: 0.2249, d_k_M range: [0.0001, 0.2168], d_k_M_hat range: [0.5259, 0.9997]
2025-03-11 20:58:45 - Train Iteration 9465: loss: 0.2926, d_k_M range: [0.0001, 0.5399], d_k_M_hat range: [0.6610, 0.9990]
2025-03-11 20:58:45 - Train Iteration 9466: loss: 0.0923, d_k_M range: [0.0001, 0.3030], d_k_M_hat range: [0.8572, 0.9994]
2025-03-11 20:58:46 - Train Iteration 9467: loss: 0.0946, d_k_M range: [0.0003, 0.2112], d_k_M_hat range: [0.6966, 0.9983]
2025-03-11 20:58:47 - Train Iteration 9468: loss: 0.0054, d_k_M range: [0.0000, 0.0344], d_k_M_hat range: [0.9358, 0.9970]
2025-03-11 20:58:47 - Train Iteration 9469: loss: 0.1848, d_k_M range: [0.0001, 0.3647], d_k_M_hat range: [0.5712, 0.9976]
2025-03-11 20:58:48 - Train Iteration 9470: loss: 0.1158, d_k_M range: [0.0014, 0.3306], d_k_M_hat range: [0.9513, 0.9998]
2025-03-11 20:58:48 - Train Iteration 9471: loss: 0.5307, d_k_M range: [0.0000, 0.0296], d_k_M_hat range: [0.2715, 0.9885]
2025-03-11 20:58:48 - Train Iteration 9472: loss: 0.2183, d_k_M range: [0.0041, 0.4628], d_k_M_hat range: [0.9925, 0.9998]
2025-03-11 20:58:49 - Train Iteration 9473: loss: 0.0193, d_k_M range: [0.0000, 0.1085], d_k_M_hat range: [0.9508, 0.9958]
2025-03-11 20:58:49 - Train Iteration 9474: loss: 0.1006, d_k_M range: [0.0002, 0.3170], d_k_M_hat range: [0.9036, 1.0000]
2025-03-11 20:58:50 - Train Iteration 9475: loss: 0.2248, d_k_M range: [0.0000, 0.0510], d_k_M_hat range: [0.5262, 0.9998]
2025-03-11 20:58:50 - Train Iteration 9476: loss: 0.0197, d_k_M range: [0.0000, 0.0513], d_k_M_hat range: [0.8595, 0.9999]
2025-03-11 20:58:51 - Train Iteration 9477: loss: 0.0035, d_k_M range: [0.0001, 0.0250], d_k_M_hat range: [0.9477, 0.9957]
2025-03-11 20:58:51 - Train Iteration 9478: loss: 0.0616, d_k_M range: [0.0001, 0.0432], d_k_M_hat range: [0.7521, 0.9982]
2025-03-11 20:58:52 - Train Iteration 9479: loss: 0.1719, d_k_M range: [0.0015, 0.4128], d_k_M_hat range: [0.9407, 0.9995]
2025-03-11 20:58:52 - Train Iteration 9480: loss: 0.0266, d_k_M range: [0.0001, 0.0379], d_k_M_hat range: [0.8371, 0.9968]
2025-03-11 20:58:53 - Train Iteration 9481: loss: 0.0619, d_k_M range: [0.0000, 0.0274], d_k_M_hat range: [0.7552, 0.9807]
2025-03-11 20:58:53 - Train Iteration 9482: loss: 0.0399, d_k_M range: [0.0001, 0.1977], d_k_M_hat range: [0.9573, 0.9980]
2025-03-11 20:58:53 - Train Iteration 9483: loss: 0.3783, d_k_M range: [0.0001, 0.0152], d_k_M_hat range: [0.3850, 0.9947]
2025-03-11 20:58:54 - Train Iteration 9484: loss: 0.5957, d_k_M range: [0.0057, 0.7680], d_k_M_hat range: [0.8664, 0.9991]
2025-03-11 20:58:54 - Train Iteration 9485: loss: 0.0490, d_k_M range: [0.0001, 0.2212], d_k_M_hat range: [0.8153, 0.9999]
2025-03-11 20:58:55 - Train Iteration 9486: loss: 0.0885, d_k_M range: [0.0002, 0.0936], d_k_M_hat range: [0.7037, 0.9994]
2025-03-11 20:58:55 - Train Iteration 9487: loss: 0.0302, d_k_M range: [0.0001, 0.0510], d_k_M_hat range: [0.8269, 0.9978]
2025-03-11 20:58:55 - Train Iteration 9488: loss: 0.0063, d_k_M range: [0.0000, 0.0258], d_k_M_hat range: [0.9262, 0.9738]
2025-03-11 20:58:56 - Train Iteration 9489: loss: 0.0081, d_k_M range: [0.0003, 0.0207], d_k_M_hat range: [0.9178, 0.9988]
2025-03-11 20:58:56 - Train Iteration 9490: loss: 0.0255, d_k_M range: [0.0001, 0.0560], d_k_M_hat range: [0.8406, 0.9963]
2025-03-11 20:58:57 - Train Iteration 9491: loss: 0.2079, d_k_M range: [0.0002, 0.4375], d_k_M_hat range: [0.7661, 0.9999]
2025-03-11 20:58:57 - Train Iteration 9492: loss: 0.6609, d_k_M range: [0.0000, 0.0069], d_k_M_hat range: [0.1873, 0.8939]
2025-03-11 20:58:58 - Train Iteration 9493: loss: 0.1130, d_k_M range: [0.0000, 0.0901], d_k_M_hat range: [0.6641, 0.9910]
2025-03-11 20:58:58 - Train Iteration 9494: loss: 0.3208, d_k_M range: [0.0000, 0.5654], d_k_M_hat range: [0.9146, 0.9994]
2025-03-11 20:58:59 - Train Iteration 9495: loss: 0.0393, d_k_M range: [0.0004, 0.1612], d_k_M_hat range: [0.8022, 0.9961]
2025-03-11 20:58:59 - Train Iteration 9496: loss: 0.7678, d_k_M range: [0.0001, 0.8761], d_k_M_hat range: [0.7692, 0.9999]
2025-03-11 20:59:00 - Train Iteration 9497: loss: 0.1237, d_k_M range: [0.0000, 0.1713], d_k_M_hat range: [0.6483, 0.9929]
2025-03-11 20:59:00 - Train Iteration 9498: loss: 0.1666, d_k_M range: [0.0000, 0.1322], d_k_M_hat range: [0.5938, 0.9986]
2025-03-11 20:59:01 - Train Iteration 9499: loss: 0.0213, d_k_M range: [0.0013, 0.1124], d_k_M_hat range: [0.9665, 0.9973]
2025-03-11 20:59:01 - Train Iteration 9500: loss: 0.5190, d_k_M range: [0.0032, 0.7145], d_k_M_hat range: [0.9705, 0.9986]
2025-03-11 20:59:02 - Train Iteration 9501: loss: 0.0585, d_k_M range: [0.0000, 0.0226], d_k_M_hat range: [0.7585, 0.9968]
2025-03-11 20:59:02 - Train Iteration 9502: loss: 0.0599, d_k_M range: [0.0017, 0.2392], d_k_M_hat range: [0.8714, 0.9999]
2025-03-11 20:59:03 - Train Iteration 9503: loss: 0.6575, d_k_M range: [0.0002, 0.8106], d_k_M_hat range: [0.5533, 0.9998]
2025-03-11 20:59:03 - Train Iteration 9504: loss: 0.1149, d_k_M range: [0.0056, 0.3346], d_k_M_hat range: [0.9180, 0.9997]
2025-03-11 20:59:03 - Train Iteration 9505: loss: 0.0935, d_k_M range: [0.0000, 0.2574], d_k_M_hat range: [0.7803, 0.9997]
2025-03-11 20:59:04 - Train Iteration 9506: loss: 0.1002, d_k_M range: [0.0001, 0.0339], d_k_M_hat range: [0.6835, 0.9982]
2025-03-11 20:59:04 - Train Iteration 9507: loss: 0.1547, d_k_M range: [0.0005, 0.3923], d_k_M_hat range: [0.6155, 0.9994]
2025-03-11 20:59:05 - Train Iteration 9508: loss: 0.0492, d_k_M range: [0.0019, 0.2183], d_k_M_hat range: [0.9421, 0.9987]
2025-03-11 20:59:05 - Train Iteration 9509: loss: 0.0027, d_k_M range: [0.0000, 0.0485], d_k_M_hat range: [0.9480, 0.9996]
2025-03-11 20:59:06 - Train Iteration 9510: loss: 0.1779, d_k_M range: [0.0004, 0.4052], d_k_M_hat range: [0.9717, 0.9998]
2025-03-11 20:59:06 - Train Iteration 9511: loss: 0.3795, d_k_M range: [0.0003, 0.1407], d_k_M_hat range: [0.3875, 0.9959]
2025-03-11 20:59:07 - Train Iteration 9512: loss: 0.2500, d_k_M range: [0.0038, 0.4992], d_k_M_hat range: [0.9742, 0.9999]
2025-03-11 20:59:07 - Train Iteration 9513: loss: 0.0788, d_k_M range: [0.0001, 0.0122], d_k_M_hat range: [0.7198, 0.9976]
2025-03-11 20:59:08 - Train Iteration 9514: loss: 0.2811, d_k_M range: [0.0001, 0.5298], d_k_M_hat range: [0.9008, 0.9996]
2025-03-11 20:59:08 - Train Iteration 9515: loss: 0.0278, d_k_M range: [0.0000, 0.0325], d_k_M_hat range: [0.8332, 0.9940]
2025-03-11 20:59:09 - Train Iteration 9516: loss: 0.0541, d_k_M range: [0.0000, 0.1045], d_k_M_hat range: [0.7740, 0.9971]
2025-03-11 20:59:09 - Train Iteration 9517: loss: 0.0658, d_k_M range: [0.0001, 0.0089], d_k_M_hat range: [0.7435, 0.9997]
2025-03-11 20:59:09 - Train Iteration 9518: loss: 0.2246, d_k_M range: [0.0000, 0.4732], d_k_M_hat range: [0.7610, 0.9999]
2025-03-11 20:59:10 - Train Iteration 9519: loss: 0.0203, d_k_M range: [0.0000, 0.0943], d_k_M_hat range: [0.8641, 0.9970]
2025-03-11 20:59:10 - Train Iteration 9520: loss: 0.6070, d_k_M range: [0.0001, 0.0358], d_k_M_hat range: [0.2218, 0.9961]
2025-03-11 20:59:11 - Train Iteration 9521: loss: 0.6278, d_k_M range: [0.0004, 0.7920], d_k_M_hat range: [0.9862, 0.9997]
2025-03-11 20:59:12 - Train Iteration 9522: loss: 0.0882, d_k_M range: [0.0001, 0.2951], d_k_M_hat range: [0.8458, 0.9995]
2025-03-11 20:59:12 - Train Iteration 9523: loss: 0.0858, d_k_M range: [0.0001, 0.2140], d_k_M_hat range: [0.7072, 0.9964]
2025-03-11 20:59:13 - Train Iteration 9524: loss: 0.0259, d_k_M range: [0.0000, 0.1543], d_k_M_hat range: [0.9642, 0.9972]
2025-03-11 20:59:13 - Train Iteration 9525: loss: 0.1895, d_k_M range: [0.0038, 0.4339], d_k_M_hat range: [0.9876, 0.9995]
2025-03-11 20:59:14 - Train Iteration 9526: loss: 0.0107, d_k_M range: [0.0000, 0.0131], d_k_M_hat range: [0.8964, 0.9947]
2025-03-11 20:59:14 - Train Iteration 9527: loss: 0.0450, d_k_M range: [0.0029, 0.1740], d_k_M_hat range: [0.9608, 0.9991]
2025-03-11 20:59:15 - Train Iteration 9528: loss: 0.2140, d_k_M range: [0.0000, 0.1379], d_k_M_hat range: [0.5383, 0.9971]
2025-03-11 20:59:15 - Train Iteration 9529: loss: 0.0117, d_k_M range: [0.0013, 0.1037], d_k_M_hat range: [0.9781, 0.9992]
2025-03-11 20:59:15 - Train Iteration 9530: loss: 0.0532, d_k_M range: [0.0001, 0.2261], d_k_M_hat range: [0.9519, 0.9954]
2025-03-11 20:59:16 - Train Iteration 9531: loss: 0.1364, d_k_M range: [0.0001, 0.0424], d_k_M_hat range: [0.6308, 0.9984]
2025-03-11 20:59:16 - Train Iteration 9532: loss: 0.1945, d_k_M range: [0.0000, 0.0553], d_k_M_hat range: [0.5590, 0.9995]
2025-03-11 20:59:17 - Train Iteration 9533: loss: 0.0769, d_k_M range: [0.0063, 0.2767], d_k_M_hat range: [0.9929, 0.9997]
2025-03-11 20:59:17 - Train Iteration 9534: loss: 0.0010, d_k_M range: [0.0000, 0.0097], d_k_M_hat range: [0.9748, 0.9928]
2025-03-11 20:59:17 - Train Iteration 9535: loss: 0.0539, d_k_M range: [0.0001, 0.2272], d_k_M_hat range: [0.8484, 0.9995]
2025-03-11 20:59:18 - Train Iteration 9536: loss: 0.2328, d_k_M range: [0.0000, 0.1207], d_k_M_hat range: [0.5175, 0.9987]
2025-03-11 20:59:18 - Train Iteration 9537: loss: 0.6612, d_k_M range: [0.0001, 0.8131], d_k_M_hat range: [0.9971, 1.0000]
2025-03-11 20:59:19 - Train Iteration 9538: loss: 0.2591, d_k_M range: [0.0000, 0.0235], d_k_M_hat range: [0.4910, 0.9971]
2025-03-11 20:59:19 - Train Iteration 9539: loss: 0.8099, d_k_M range: [0.0110, 0.8998], d_k_M_hat range: [0.6942, 1.0000]
2025-03-11 20:59:20 - Train Iteration 9540: loss: 0.1760, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.5805, 0.9982]
2025-03-11 20:59:20 - Train Iteration 9541: loss: 0.3393, d_k_M range: [0.0004, 0.5045], d_k_M_hat range: [0.4179, 0.9987]
2025-03-11 20:59:21 - Train Iteration 9542: loss: 0.0224, d_k_M range: [0.0001, 0.1209], d_k_M_hat range: [0.9582, 0.9999]
2025-03-11 20:59:21 - Train Iteration 9543: loss: 0.6289, d_k_M range: [0.0008, 0.7928], d_k_M_hat range: [0.8424, 0.9998]
2025-03-11 20:59:22 - Train Iteration 9544: loss: 0.0760, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.7244, 0.9816]
2025-03-11 20:59:22 - Train Iteration 9545: loss: 0.2664, d_k_M range: [0.0011, 0.5149], d_k_M_hat range: [0.6997, 0.9999]
2025-03-11 20:59:23 - Train Iteration 9546: loss: 0.2858, d_k_M range: [0.0001, 0.0242], d_k_M_hat range: [0.4655, 0.9880]
2025-03-11 20:59:23 - Train Iteration 9547: loss: 0.3854, d_k_M range: [0.0033, 0.6167], d_k_M_hat range: [0.9814, 0.9998]
2025-03-11 20:59:24 - Train Iteration 9548: loss: 0.0322, d_k_M range: [0.0000, 0.0899], d_k_M_hat range: [0.8222, 0.9983]
2025-03-11 20:59:24 - Train Iteration 9549: loss: 0.0262, d_k_M range: [0.0017, 0.1616], d_k_M_hat range: [0.9766, 0.9998]
2025-03-11 20:59:25 - Train Iteration 9550: loss: 0.1192, d_k_M range: [0.0000, 0.1379], d_k_M_hat range: [0.6723, 0.9946]
2025-03-11 20:59:25 - Train Iteration 9551: loss: 0.0273, d_k_M range: [0.0001, 0.1552], d_k_M_hat range: [0.9542, 0.9983]
2025-03-11 20:59:25 - Train Iteration 9552: loss: 0.0715, d_k_M range: [0.0002, 0.0192], d_k_M_hat range: [0.7327, 0.9963]
2025-03-11 20:59:26 - Train Iteration 9553: loss: 0.2798, d_k_M range: [0.0000, 0.0208], d_k_M_hat range: [0.4717, 0.9957]
2025-03-11 20:59:26 - Train Iteration 9554: loss: 0.1024, d_k_M range: [0.0001, 0.3199], d_k_M_hat range: [0.9082, 0.9999]
2025-03-11 20:59:27 - Train Iteration 9555: loss: 0.1268, d_k_M range: [0.0000, 0.3558], d_k_M_hat range: [0.7535, 0.9996]
2025-03-11 20:59:27 - Train Iteration 9556: loss: 0.1112, d_k_M range: [0.0000, 0.0078], d_k_M_hat range: [0.6665, 0.9940]
2025-03-11 20:59:27 - Train Iteration 9557: loss: 0.0803, d_k_M range: [0.0002, 0.1467], d_k_M_hat range: [0.7186, 0.9980]
2025-03-11 20:59:28 - Train Iteration 9558: loss: 0.0259, d_k_M range: [0.0000, 0.0843], d_k_M_hat range: [0.8392, 0.9986]
2025-03-11 20:59:28 - Train Iteration 9559: loss: 0.3331, d_k_M range: [0.0002, 0.5771], d_k_M_hat range: [0.9566, 1.0000]
2025-03-11 20:59:29 - Train Iteration 9560: loss: 0.6530, d_k_M range: [0.0000, 0.8081], d_k_M_hat range: [0.9761, 1.0000]
2025-03-11 20:59:30 - Train Iteration 9561: loss: 0.0520, d_k_M range: [0.0000, 0.0662], d_k_M_hat range: [0.7806, 0.9985]
2025-03-11 20:59:30 - Train Iteration 9562: loss: 0.0227, d_k_M range: [0.0000, 0.0426], d_k_M_hat range: [0.8577, 0.9963]
2025-03-11 20:59:30 - Train Iteration 9563: loss: 0.0282, d_k_M range: [0.0004, 0.1674], d_k_M_hat range: [0.9928, 0.9996]
2025-03-11 20:59:31 - Train Iteration 9564: loss: 0.0457, d_k_M range: [0.0000, 0.0356], d_k_M_hat range: [0.7863, 0.9934]
2025-03-11 20:59:31 - Train Iteration 9565: loss: 0.0941, d_k_M range: [0.0007, 0.3054], d_k_M_hat range: [0.9844, 0.9993]
2025-03-11 20:59:32 - Train Iteration 9566: loss: 0.0962, d_k_M range: [0.0000, 0.0735], d_k_M_hat range: [0.6901, 0.9976]
2025-03-11 20:59:33 - Train Iteration 9567: loss: 0.2953, d_k_M range: [0.0001, 0.5434], d_k_M_hat range: [0.9951, 1.0000]
2025-03-11 20:59:33 - Train Iteration 9568: loss: 0.2441, d_k_M range: [0.0001, 0.4929], d_k_M_hat range: [0.8860, 0.9989]
2025-03-11 20:59:34 - Train Iteration 9569: loss: 0.0534, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.7706, 0.9794]
2025-03-11 20:59:34 - Train Iteration 9570: loss: 0.4837, d_k_M range: [0.0003, 0.6952], d_k_M_hat range: [0.8724, 0.9997]
2025-03-11 20:59:35 - Train Iteration 9571: loss: 0.0174, d_k_M range: [0.0001, 0.0664], d_k_M_hat range: [0.8684, 0.9947]
2025-03-11 20:59:35 - Train Iteration 9572: loss: 0.0365, d_k_M range: [0.0011, 0.0538], d_k_M_hat range: [0.8153, 0.9933]
2025-03-11 20:59:36 - Train Iteration 9573: loss: 0.0236, d_k_M range: [0.0000, 0.1071], d_k_M_hat range: [0.8606, 0.9934]
2025-03-11 20:59:36 - Train Iteration 9574: loss: 0.0064, d_k_M range: [0.0001, 0.0739], d_k_M_hat range: [0.9296, 0.9966]
2025-03-11 20:59:36 - Train Iteration 9575: loss: 0.0151, d_k_M range: [0.0000, 0.0251], d_k_M_hat range: [0.8785, 0.9936]
2025-03-11 20:59:37 - Train Iteration 9576: loss: 0.3361, d_k_M range: [0.0000, 0.1382], d_k_M_hat range: [0.4202, 0.9949]
2025-03-11 20:59:37 - Train Iteration 9577: loss: 0.0338, d_k_M range: [0.0005, 0.0688], d_k_M_hat range: [0.8171, 0.9979]
2025-03-11 20:59:38 - Train Iteration 9578: loss: 0.0666, d_k_M range: [0.0000, 0.0393], d_k_M_hat range: [0.7420, 0.9975]
2025-03-11 20:59:38 - Train Iteration 9579: loss: 0.1686, d_k_M range: [0.0000, 0.0492], d_k_M_hat range: [0.5893, 0.9965]
2025-03-11 20:59:38 - Train Iteration 9580: loss: 0.0329, d_k_M range: [0.0054, 0.1784], d_k_M_hat range: [0.9903, 0.9999]
2025-03-11 20:59:39 - Train Iteration 9581: loss: 0.2439, d_k_M range: [0.0001, 0.0012], d_k_M_hat range: [0.5073, 0.9900]
2025-03-11 20:59:39 - Train Iteration 9582: loss: 0.5074, d_k_M range: [0.0022, 0.7115], d_k_M_hat range: [0.9666, 1.0000]
2025-03-11 20:59:40 - Train Iteration 9583: loss: 0.0209, d_k_M range: [0.0002, 0.1410], d_k_M_hat range: [0.8990, 0.9983]
2025-03-11 20:59:40 - Train Iteration 9584: loss: 0.2334, d_k_M range: [0.0002, 0.0192], d_k_M_hat range: [0.5187, 0.9991]
2025-03-11 20:59:41 - Train Iteration 9585: loss: 0.5777, d_k_M range: [0.0000, 0.7600], d_k_M_hat range: [0.9691, 1.0000]
2025-03-11 20:59:41 - Train Iteration 9586: loss: 0.2572, d_k_M range: [0.0001, 0.4926], d_k_M_hat range: [0.6784, 0.9967]
2025-03-11 20:59:42 - Train Iteration 9587: loss: 0.0323, d_k_M range: [0.0001, 0.0325], d_k_M_hat range: [0.8203, 0.9938]
2025-03-11 20:59:42 - Train Iteration 9588: loss: 0.6015, d_k_M range: [0.0001, 0.7754], d_k_M_hat range: [0.9923, 0.9998]
2025-03-11 20:59:42 - Train Iteration 9589: loss: 0.0847, d_k_M range: [0.0001, 0.0251], d_k_M_hat range: [0.7091, 0.9988]
2025-03-11 20:59:43 - Train Iteration 9590: loss: 0.1050, d_k_M range: [0.0001, 0.0502], d_k_M_hat range: [0.6761, 0.9952]
2025-03-11 20:59:43 - Train Iteration 9591: loss: 0.9235, d_k_M range: [0.0000, 0.9604], d_k_M_hat range: [0.6142, 0.9994]
2025-03-11 20:59:44 - Train Iteration 9592: loss: 0.1201, d_k_M range: [0.0002, 0.2806], d_k_M_hat range: [0.9341, 0.9982]
2025-03-11 20:59:44 - Train Iteration 9593: loss: 0.0552, d_k_M range: [0.0023, 0.2341], d_k_M_hat range: [0.9240, 0.9992]
2025-03-11 20:59:45 - Train Iteration 9594: loss: 0.0833, d_k_M range: [0.0008, 0.2886], d_k_M_hat range: [0.9584, 1.0000]
2025-03-11 20:59:45 - Train Iteration 9595: loss: 0.3824, d_k_M range: [0.0000, 0.0349], d_k_M_hat range: [0.3836, 0.9968]
2025-03-11 20:59:46 - Train Iteration 9596: loss: 0.2518, d_k_M range: [0.0006, 0.4995], d_k_M_hat range: [0.9561, 0.9994]
2025-03-11 20:59:46 - Train Iteration 9597: loss: 0.0191, d_k_M range: [0.0002, 0.0487], d_k_M_hat range: [0.8619, 0.9991]
2025-03-11 20:59:46 - Train Iteration 9598: loss: 0.0646, d_k_M range: [0.0003, 0.2537], d_k_M_hat range: [0.7476, 0.9995]
2025-03-11 20:59:47 - Train Iteration 9599: loss: 0.0440, d_k_M range: [0.0000, 0.0216], d_k_M_hat range: [0.7903, 0.9942]
2025-03-11 20:59:47 - Train Iteration 9600: loss: 0.0670, d_k_M range: [0.0000, 0.1605], d_k_M_hat range: [0.7411, 0.9995]
2025-03-11 20:59:48 - Train Iteration 9601: loss: 0.1172, d_k_M range: [0.0003, 0.1352], d_k_M_hat range: [0.6579, 0.9999]
2025-03-11 20:59:48 - Train Iteration 9602: loss: 0.2262, d_k_M range: [0.0001, 0.4755], d_k_M_hat range: [0.9931, 0.9999]
2025-03-11 20:59:48 - Train Iteration 9603: loss: 0.0415, d_k_M range: [0.0000, 0.0263], d_k_M_hat range: [0.7974, 0.9994]
2025-03-11 20:59:49 - Train Iteration 9604: loss: 0.9180, d_k_M range: [0.0000, 0.9578], d_k_M_hat range: [0.9215, 0.9998]
2025-03-11 20:59:49 - Train Iteration 9605: loss: 0.0130, d_k_M range: [0.0002, 0.1106], d_k_M_hat range: [0.9515, 0.9994]
2025-03-11 20:59:50 - Train Iteration 9606: loss: 0.1300, d_k_M range: [0.0000, 0.3598], d_k_M_hat range: [0.9804, 0.9992]
2025-03-11 20:59:50 - Train Iteration 9607: loss: 0.0191, d_k_M range: [0.0000, 0.1012], d_k_M_hat range: [0.8654, 0.9980]
2025-03-11 20:59:50 - Train Iteration 9608: loss: 0.3334, d_k_M range: [0.0001, 0.5769], d_k_M_hat range: [0.6180, 0.9995]
2025-03-11 20:59:51 - Train Iteration 9609: loss: 0.1395, d_k_M range: [0.0000, 0.0344], d_k_M_hat range: [0.6274, 0.9865]
2025-03-11 20:59:51 - Train Iteration 9610: loss: 0.0478, d_k_M range: [0.0005, 0.2159], d_k_M_hat range: [0.9952, 0.9999]
2025-03-11 20:59:52 - Train Iteration 9611: loss: 0.1160, d_k_M range: [0.0000, 0.0569], d_k_M_hat range: [0.6597, 0.9734]
2025-03-11 20:59:52 - Train Iteration 9612: loss: 0.1416, d_k_M range: [0.0007, 0.3738], d_k_M_hat range: [0.9477, 0.9995]
2025-03-11 20:59:53 - Train Iteration 9613: loss: 0.1338, d_k_M range: [0.0002, 0.1147], d_k_M_hat range: [0.6345, 0.9937]
2025-03-11 20:59:53 - Train Iteration 9614: loss: 0.2513, d_k_M range: [0.0000, 0.0084], d_k_M_hat range: [0.4987, 0.9926]
2025-03-11 20:59:54 - Train Iteration 9615: loss: 0.1632, d_k_M range: [0.0002, 0.4029], d_k_M_hat range: [0.9841, 0.9989]
2025-03-11 20:59:54 - Train Iteration 9616: loss: 0.0522, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.7718, 0.9917]
2025-03-11 20:59:55 - Train Iteration 9617: loss: 0.3060, d_k_M range: [0.0002, 0.5530], d_k_M_hat range: [0.7238, 0.9999]
2025-03-11 20:59:55 - Train Iteration 9618: loss: 0.0191, d_k_M range: [0.0001, 0.1371], d_k_M_hat range: [0.9793, 0.9996]
2025-03-11 20:59:56 - Train Iteration 9619: loss: 0.5083, d_k_M range: [0.0000, 0.2356], d_k_M_hat range: [0.2878, 0.9985]
2025-03-11 20:59:56 - Train Iteration 9620: loss: 0.0431, d_k_M range: [0.0001, 0.2058], d_k_M_hat range: [0.9657, 0.9999]
2025-03-11 20:59:57 - Train Iteration 9621: loss: 0.0775, d_k_M range: [0.0010, 0.2757], d_k_M_hat range: [0.9908, 0.9997]
2025-03-11 20:59:57 - Train Iteration 9622: loss: 0.0387, d_k_M range: [0.0009, 0.1177], d_k_M_hat range: [0.8041, 0.9976]
2025-03-11 20:59:57 - Train Iteration 9623: loss: 0.0431, d_k_M range: [0.0000, 0.2052], d_k_M_hat range: [0.9051, 0.9995]
2025-03-11 20:59:58 - Train Iteration 9624: loss: 0.1825, d_k_M range: [0.0000, 0.0200], d_k_M_hat range: [0.5730, 0.9872]
2025-03-11 20:59:58 - Train Iteration 9625: loss: 0.3327, d_k_M range: [0.0000, 0.5294], d_k_M_hat range: [0.9527, 0.9995]
2025-03-11 20:59:59 - Train Iteration 9626: loss: 0.0063, d_k_M range: [0.0000, 0.0327], d_k_M_hat range: [0.9238, 0.9944]
2025-03-11 20:59:59 - Train Iteration 9627: loss: 0.0283, d_k_M range: [0.0006, 0.1646], d_k_M_hat range: [0.9926, 0.9992]
2025-03-11 21:00:00 - Train Iteration 9628: loss: 0.1993, d_k_M range: [0.0001, 0.0044], d_k_M_hat range: [0.5558, 0.9993]
2025-03-11 21:00:00 - Train Iteration 9629: loss: 0.0145, d_k_M range: [0.0010, 0.0510], d_k_M_hat range: [0.9199, 0.9994]
2025-03-11 21:00:00 - Train Iteration 9630: loss: 0.2704, d_k_M range: [0.0000, 0.5200], d_k_M_hat range: [0.8704, 1.0000]
2025-03-11 21:00:01 - Train Iteration 9631: loss: 0.3195, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.4349, 0.9884]
2025-03-11 21:00:01 - Train Iteration 9632: loss: 0.4608, d_k_M range: [0.0001, 0.6760], d_k_M_hat range: [0.9718, 0.9998]
2025-03-11 21:00:02 - Train Iteration 9633: loss: 0.0350, d_k_M range: [0.0001, 0.0090], d_k_M_hat range: [0.8131, 0.9953]
2025-03-11 21:00:02 - Train Iteration 9634: loss: 0.0144, d_k_M range: [0.0003, 0.0901], d_k_M_hat range: [0.8814, 0.9993]
2025-03-11 21:00:03 - Train Iteration 9635: loss: 0.1016, d_k_M range: [0.0001, 0.3178], d_k_M_hat range: [0.8873, 0.9991]
2025-03-11 21:00:03 - Train Iteration 9636: loss: 0.4966, d_k_M range: [0.0000, 0.0424], d_k_M_hat range: [0.2954, 0.9365]
2025-03-11 21:00:04 - Train Iteration 9637: loss: 0.0067, d_k_M range: [0.0000, 0.0668], d_k_M_hat range: [0.9711, 0.9985]
2025-03-11 21:00:04 - Train Iteration 9638: loss: 0.0376, d_k_M range: [0.0000, 0.0445], d_k_M_hat range: [0.8061, 0.9970]
2025-03-11 21:00:04 - Train Iteration 9639: loss: 0.1425, d_k_M range: [0.0022, 0.3773], d_k_M_hat range: [0.9393, 0.9997]
2025-03-11 21:00:05 - Train Iteration 9640: loss: 0.0305, d_k_M range: [0.0001, 0.0509], d_k_M_hat range: [0.8253, 0.9971]
2025-03-11 21:00:05 - Train Iteration 9641: loss: 0.0833, d_k_M range: [0.0000, 0.1242], d_k_M_hat range: [0.7117, 0.9997]
2025-03-11 21:00:06 - Train Iteration 9642: loss: 0.0227, d_k_M range: [0.0000, 0.0159], d_k_M_hat range: [0.8504, 0.9998]
2025-03-11 21:00:06 - Train Iteration 9643: loss: 0.0333, d_k_M range: [0.0000, 0.1057], d_k_M_hat range: [0.8914, 0.9932]
2025-03-11 21:00:06 - Train Iteration 9644: loss: 0.0045, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.9385, 0.9995]
2025-03-11 21:00:07 - Train Iteration 9645: loss: 0.0271, d_k_M range: [0.0009, 0.0967], d_k_M_hat range: [0.8373, 0.9998]
2025-03-11 21:00:07 - Train Iteration 9646: loss: 0.0592, d_k_M range: [0.0000, 0.2427], d_k_M_hat range: [0.9252, 0.9993]
2025-03-11 21:00:08 - Train Iteration 9647: loss: 0.0396, d_k_M range: [0.0003, 0.1987], d_k_M_hat range: [0.9292, 0.9998]
2025-03-11 21:00:08 - Train Iteration 9648: loss: 0.1746, d_k_M range: [0.0000, 0.0343], d_k_M_hat range: [0.5823, 0.9920]
2025-03-11 21:00:08 - Train Iteration 9649: loss: 0.0373, d_k_M range: [0.0001, 0.1883], d_k_M_hat range: [0.9459, 0.9999]
2025-03-11 21:00:09 - Train Iteration 9650: loss: 0.0092, d_k_M range: [0.0001, 0.0231], d_k_M_hat range: [0.9041, 0.9997]
2025-03-11 21:00:09 - Train Iteration 9651: loss: 0.6195, d_k_M range: [0.0005, 0.7869], d_k_M_hat range: [0.9922, 0.9999]
2025-03-11 21:00:10 - Train Iteration 9652: loss: 0.3681, d_k_M range: [0.0000, 0.0157], d_k_M_hat range: [0.3934, 0.9918]
2025-03-11 21:00:10 - Train Iteration 9653: loss: 0.1121, d_k_M range: [0.0001, 0.2899], d_k_M_hat range: [0.9551, 0.9998]
2025-03-11 21:00:10 - Train Iteration 9654: loss: 0.0046, d_k_M range: [0.0004, 0.0474], d_k_M_hat range: [0.9597, 0.9998]
2025-03-11 21:00:11 - Train Iteration 9655: loss: 0.7860, d_k_M range: [0.0000, 0.8829], d_k_M_hat range: [0.3013, 0.9996]
2025-03-11 21:00:11 - Train Iteration 9656: loss: 0.1580, d_k_M range: [0.0000, 0.3960], d_k_M_hat range: [0.9683, 0.9996]
2025-03-11 21:00:12 - Train Iteration 9657: loss: 0.0255, d_k_M range: [0.0002, 0.1252], d_k_M_hat range: [0.8974, 0.9979]
2025-03-11 21:00:12 - Train Iteration 9658: loss: 0.0871, d_k_M range: [0.0003, 0.0482], d_k_M_hat range: [0.7530, 0.9981]
2025-03-11 21:00:13 - Train Iteration 9659: loss: 0.1261, d_k_M range: [0.0005, 0.3549], d_k_M_hat range: [0.9883, 0.9999]
2025-03-11 21:00:13 - Train Iteration 9660: loss: 0.0074, d_k_M range: [0.0000, 0.0311], d_k_M_hat range: [0.9314, 0.9995]
2025-03-11 21:00:14 - Train Iteration 9661: loss: 0.0208, d_k_M range: [0.0001, 0.1416], d_k_M_hat range: [0.9025, 0.9997]
2025-03-11 21:00:14 - Train Iteration 9662: loss: 0.0184, d_k_M range: [0.0004, 0.1351], d_k_M_hat range: [0.8945, 0.9995]
2025-03-11 21:00:15 - Train Iteration 9663: loss: 0.0133, d_k_M range: [0.0013, 0.0478], d_k_M_hat range: [0.8860, 0.9999]
2025-03-11 21:00:15 - Train Iteration 9664: loss: 0.0146, d_k_M range: [0.0000, 0.1071], d_k_M_hat range: [0.8794, 0.9999]
2025-03-11 21:00:16 - Train Iteration 9665: loss: 0.0060, d_k_M range: [0.0006, 0.0759], d_k_M_hat range: [0.9744, 0.9995]
2025-03-11 21:00:16 - Train Iteration 9666: loss: 0.6327, d_k_M range: [0.0004, 0.7924], d_k_M_hat range: [0.9691, 1.0000]
2025-03-11 21:00:16 - Train Iteration 9667: loss: 0.0173, d_k_M range: [0.0001, 0.1308], d_k_M_hat range: [0.9604, 0.9994]
2025-03-11 21:00:17 - Train Iteration 9668: loss: 0.2402, d_k_M range: [0.0001, 0.4898], d_k_M_hat range: [0.9908, 1.0000]
2025-03-11 21:00:17 - Train Iteration 9669: loss: 0.1677, d_k_M range: [0.0000, 0.0831], d_k_M_hat range: [0.5906, 0.9984]
2025-03-11 21:00:18 - Train Iteration 9670: loss: 0.0159, d_k_M range: [0.0010, 0.1161], d_k_M_hat range: [0.9898, 0.9997]
2025-03-11 21:00:18 - Train Iteration 9671: loss: 0.0833, d_k_M range: [0.0004, 0.0347], d_k_M_hat range: [0.7117, 0.9998]
2025-03-11 21:00:19 - Train Iteration 9672: loss: 0.0358, d_k_M range: [0.0000, 0.0079], d_k_M_hat range: [0.8118, 0.9985]
2025-03-11 21:00:19 - Train Iteration 9673: loss: 0.2767, d_k_M range: [0.0061, 0.5259], d_k_M_hat range: [0.9762, 0.9999]
2025-03-11 21:00:19 - Train Iteration 9674: loss: 0.0085, d_k_M range: [0.0003, 0.0333], d_k_M_hat range: [0.9080, 0.9920]
2025-03-11 21:00:20 - Train Iteration 9675: loss: 0.5736, d_k_M range: [0.0014, 0.7573], d_k_M_hat range: [0.9941, 0.9999]
2025-03-11 21:00:20 - Train Iteration 9676: loss: 0.0352, d_k_M range: [0.0001, 0.0078], d_k_M_hat range: [0.8149, 0.9966]
2025-03-11 21:00:21 - Train Iteration 9677: loss: 0.0419, d_k_M range: [0.0000, 0.1719], d_k_M_hat range: [0.8705, 0.9987]
2025-03-11 21:00:21 - Train Iteration 9678: loss: 0.4429, d_k_M range: [0.0000, 0.6649], d_k_M_hat range: [0.8033, 0.9995]
2025-03-11 21:00:21 - Train Iteration 9679: loss: 0.2042, d_k_M range: [0.0000, 0.0255], d_k_M_hat range: [0.5482, 0.9984]
2025-03-11 21:00:22 - Train Iteration 9680: loss: 0.0059, d_k_M range: [0.0000, 0.0693], d_k_M_hat range: [0.9233, 0.9997]
2025-03-11 21:00:22 - Train Iteration 9681: loss: 0.4518, d_k_M range: [0.0002, 0.6698], d_k_M_hat range: [0.8618, 0.9998]
2025-03-11 21:00:23 - Train Iteration 9682: loss: 0.1202, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.6544, 0.9915]
2025-03-11 21:00:23 - Train Iteration 9683: loss: 0.2926, d_k_M range: [0.0002, 0.5337], d_k_M_hat range: [0.8955, 0.9970]
2025-03-11 21:00:24 - Train Iteration 9684: loss: 0.0958, d_k_M range: [0.0000, 0.2785], d_k_M_hat range: [0.6905, 0.9955]
2025-03-11 21:00:24 - Train Iteration 9685: loss: 0.0712, d_k_M range: [0.0000, 0.0484], d_k_M_hat range: [0.7332, 0.9989]
2025-03-11 21:00:24 - Train Iteration 9686: loss: 0.0175, d_k_M range: [0.0002, 0.1040], d_k_M_hat range: [0.8712, 0.9994]
2025-03-11 21:00:25 - Train Iteration 9687: loss: 0.0285, d_k_M range: [0.0000, 0.1662], d_k_M_hat range: [0.9609, 0.9993]
2025-03-11 21:00:25 - Train Iteration 9688: loss: 0.3390, d_k_M range: [0.0001, 0.5807], d_k_M_hat range: [0.7962, 0.9992]
2025-03-11 21:00:26 - Train Iteration 9689: loss: 0.0071, d_k_M range: [0.0000, 0.0682], d_k_M_hat range: [0.9230, 0.9974]
2025-03-11 21:00:26 - Train Iteration 9690: loss: 0.1591, d_k_M range: [0.0001, 0.3971], d_k_M_hat range: [0.9736, 0.9997]
2025-03-11 21:00:26 - Train Iteration 9691: loss: 0.0350, d_k_M range: [0.0003, 0.0238], d_k_M_hat range: [0.8135, 0.9990]
2025-03-11 21:00:27 - Train Iteration 9692: loss: 0.4031, d_k_M range: [0.0020, 0.6346], d_k_M_hat range: [0.9917, 0.9998]
2025-03-11 21:00:27 - Train Iteration 9693: loss: 0.2141, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.5373, 0.9924]
2025-03-11 21:00:28 - Train Iteration 9694: loss: 0.4355, d_k_M range: [0.0013, 0.6599], d_k_M_hat range: [0.9950, 1.0000]
2025-03-11 21:00:28 - Train Iteration 9695: loss: 0.1388, d_k_M range: [0.0000, 0.0232], d_k_M_hat range: [0.6276, 0.9978]
2025-03-11 21:00:29 - Train Iteration 9696: loss: 0.2085, d_k_M range: [0.0026, 0.4527], d_k_M_hat range: [0.9916, 0.9997]
2025-03-11 21:00:29 - Train Iteration 9697: loss: 0.2051, d_k_M range: [0.0001, 0.2112], d_k_M_hat range: [0.5472, 0.9986]
2025-03-11 21:00:29 - Train Iteration 9698: loss: 0.0020, d_k_M range: [0.0000, 0.0446], d_k_M_hat range: [0.9821, 0.9999]
2025-03-11 21:00:30 - Train Iteration 9699: loss: 0.0298, d_k_M range: [0.0000, 0.1640], d_k_M_hat range: [0.9294, 0.9983]
2025-03-11 21:00:30 - Train Iteration 9700: loss: 0.1029, d_k_M range: [0.0000, 0.0498], d_k_M_hat range: [0.6793, 0.9985]
2025-03-11 21:00:31 - Train Iteration 9701: loss: 0.2115, d_k_M range: [0.0000, 0.4596], d_k_M_hat range: [0.9549, 0.9997]
2025-03-11 21:00:31 - Train Iteration 9702: loss: 0.0335, d_k_M range: [0.0001, 0.0487], d_k_M_hat range: [0.8291, 0.9985]
2025-03-11 21:00:32 - Train Iteration 9703: loss: 0.0108, d_k_M range: [0.0000, 0.0766], d_k_M_hat range: [0.9437, 0.9997]
2025-03-11 21:00:32 - Train Iteration 9704: loss: 0.6130, d_k_M range: [0.0000, 0.2122], d_k_M_hat range: [0.2171, 0.9920]
2025-03-11 21:00:32 - Train Iteration 9705: loss: 0.1407, d_k_M range: [0.0007, 0.3645], d_k_M_hat range: [0.9570, 0.9999]
2025-03-11 21:00:33 - Train Iteration 9706: loss: 0.1164, d_k_M range: [0.0000, 0.0154], d_k_M_hat range: [0.6589, 0.9951]
2025-03-11 21:00:33 - Train Iteration 9707: loss: 0.0113, d_k_M range: [0.0000, 0.1052], d_k_M_hat range: [0.9569, 0.9992]
2025-03-11 21:00:34 - Train Iteration 9708: loss: 0.0381, d_k_M range: [0.0003, 0.1946], d_k_M_hat range: [0.8707, 0.9994]
2025-03-11 21:00:34 - Train Iteration 9709: loss: 0.1955, d_k_M range: [0.0000, 0.1630], d_k_M_hat range: [0.5578, 0.9967]
2025-03-11 21:00:34 - Train Iteration 9710: loss: 0.4098, d_k_M range: [0.0090, 0.6390], d_k_M_hat range: [0.9826, 1.0000]
2025-03-11 21:00:35 - Train Iteration 9711: loss: 0.4857, d_k_M range: [0.0000, 0.0437], d_k_M_hat range: [0.3034, 0.9973]
2025-03-11 21:00:35 - Train Iteration 9712: loss: 0.1885, d_k_M range: [0.0002, 0.4322], d_k_M_hat range: [0.8019, 0.9988]
2025-03-11 21:00:36 - Train Iteration 9713: loss: 0.0770, d_k_M range: [0.0000, 0.2723], d_k_M_hat range: [0.8708, 0.9954]
2025-03-11 21:00:36 - Train Iteration 9714: loss: 0.2843, d_k_M range: [0.0000, 0.0251], d_k_M_hat range: [0.4672, 0.9956]
2025-03-11 21:00:37 - Train Iteration 9715: loss: 0.1080, d_k_M range: [0.0064, 0.3241], d_k_M_hat range: [0.9928, 0.9999]
2025-03-11 21:00:37 - Train Iteration 9716: loss: 0.0158, d_k_M range: [0.0001, 0.0992], d_k_M_hat range: [0.8771, 0.9941]
2025-03-11 21:00:38 - Train Iteration 9717: loss: 0.2603, d_k_M range: [0.0000, 0.0217], d_k_M_hat range: [0.4900, 0.9858]
2025-03-11 21:00:38 - Train Iteration 9718: loss: 0.6328, d_k_M range: [0.0008, 0.7922], d_k_M_hat range: [0.9573, 0.9997]
2025-03-11 21:00:38 - Train Iteration 9719: loss: 0.1426, d_k_M range: [0.0000, 0.0067], d_k_M_hat range: [0.6225, 0.9799]
2025-03-11 21:00:39 - Train Iteration 9720: loss: 0.1561, d_k_M range: [0.0000, 0.3937], d_k_M_hat range: [0.9798, 0.9997]
2025-03-11 21:00:39 - Train Iteration 9721: loss: 0.0152, d_k_M range: [0.0001, 0.0098], d_k_M_hat range: [0.8786, 0.9803]
2025-03-11 21:00:40 - Train Iteration 9722: loss: 0.0959, d_k_M range: [0.0001, 0.3091], d_k_M_hat range: [0.9539, 0.9994]
2025-03-11 21:00:40 - Train Iteration 9723: loss: 0.0032, d_k_M range: [0.0002, 0.0270], d_k_M_hat range: [0.9437, 0.9986]
2025-03-11 21:00:41 - Train Iteration 9724: loss: 0.0094, d_k_M range: [0.0000, 0.0064], d_k_M_hat range: [0.9048, 0.9959]
2025-03-11 21:00:41 - Train Iteration 9725: loss: 0.5912, d_k_M range: [0.0001, 0.7577], d_k_M_hat range: [0.8083, 0.9994]
2025-03-11 21:00:41 - Train Iteration 9726: loss: 0.1152, d_k_M range: [0.0000, 0.0474], d_k_M_hat range: [0.6606, 0.9960]
2025-03-11 21:00:42 - Train Iteration 9727: loss: 0.0121, d_k_M range: [0.0000, 0.0189], d_k_M_hat range: [0.8902, 0.9998]
2025-03-11 21:00:42 - Train Iteration 9728: loss: 0.0529, d_k_M range: [0.0000, 0.0209], d_k_M_hat range: [0.7701, 0.9933]
2025-03-11 21:00:43 - Train Iteration 9729: loss: 0.3112, d_k_M range: [0.0001, 0.5578], d_k_M_hat range: [0.9277, 0.9999]
2025-03-11 21:00:43 - Train Iteration 9730: loss: 0.0494, d_k_M range: [0.0001, 0.0305], d_k_M_hat range: [0.7796, 0.9884]
2025-03-11 21:00:43 - Train Iteration 9731: loss: 0.0081, d_k_M range: [0.0035, 0.0428], d_k_M_hat range: [0.9307, 0.9994]
2025-03-11 21:00:44 - Train Iteration 9732: loss: 0.0293, d_k_M range: [0.0000, 0.1577], d_k_M_hat range: [0.9160, 0.9990]
2025-03-11 21:00:44 - Train Iteration 9733: loss: 0.3168, d_k_M range: [0.0002, 0.5628], d_k_M_hat range: [0.9103, 1.0000]
2025-03-11 21:00:45 - Train Iteration 9734: loss: 0.0023, d_k_M range: [0.0020, 0.0417], d_k_M_hat range: [0.9686, 0.9999]
2025-03-11 21:00:45 - Train Iteration 9735: loss: 0.2660, d_k_M range: [0.0000, 0.5157], d_k_M_hat range: [0.9433, 1.0000]
2025-03-11 21:00:46 - Train Iteration 9736: loss: 0.3838, d_k_M range: [0.0005, 0.2694], d_k_M_hat range: [0.3821, 0.9998]
2025-03-11 21:00:46 - Train Iteration 9737: loss: 0.2542, d_k_M range: [0.0001, 0.0680], d_k_M_hat range: [0.4959, 0.9992]
2025-03-11 21:00:47 - Train Iteration 9738: loss: 0.0997, d_k_M range: [0.0001, 0.0040], d_k_M_hat range: [0.6844, 0.9903]
2025-03-11 21:00:47 - Train Iteration 9739: loss: 0.0434, d_k_M range: [0.0015, 0.2082], d_k_M_hat range: [0.9760, 0.9999]
2025-03-11 21:00:48 - Train Iteration 9740: loss: 0.0765, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.7243, 0.9946]
2025-03-11 21:00:48 - Train Iteration 9741: loss: 0.0068, d_k_M range: [0.0000, 0.0115], d_k_M_hat range: [0.9177, 0.9993]
2025-03-11 21:00:48 - Train Iteration 9742: loss: 0.0200, d_k_M range: [0.0001, 0.0381], d_k_M_hat range: [0.8633, 0.9994]
2025-03-11 21:00:49 - Train Iteration 9743: loss: 0.0083, d_k_M range: [0.0005, 0.0647], d_k_M_hat range: [0.9611, 0.9958]
2025-03-11 21:00:49 - Train Iteration 9744: loss: 0.1311, d_k_M range: [0.0001, 0.3550], d_k_M_hat range: [0.9637, 0.9998]
2025-03-11 21:00:50 - Train Iteration 9745: loss: 0.0498, d_k_M range: [0.0000, 0.0104], d_k_M_hat range: [0.7842, 0.9918]
2025-03-11 21:00:50 - Train Iteration 9746: loss: 0.0092, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.9044, 0.9959]
2025-03-11 21:00:50 - Train Iteration 9747: loss: 0.0172, d_k_M range: [0.0003, 0.1304], d_k_M_hat range: [0.9211, 0.9999]
2025-03-11 21:00:51 - Train Iteration 9748: loss: 0.5451, d_k_M range: [0.0028, 0.7372], d_k_M_hat range: [0.9718, 0.9988]
2025-03-11 21:00:51 - Train Iteration 9749: loss: 0.5034, d_k_M range: [0.0000, 0.0137], d_k_M_hat range: [0.2905, 0.9919]
2025-03-11 21:00:52 - Train Iteration 9750: loss: 0.0693, d_k_M range: [0.0003, 0.2574], d_k_M_hat range: [0.9696, 0.9992]
2025-03-11 21:00:52 - Train Iteration 9751: loss: 0.1318, d_k_M range: [0.0001, 0.3627], d_k_M_hat range: [0.9078, 0.9996]
2025-03-11 21:00:53 - Train Iteration 9752: loss: 0.0068, d_k_M range: [0.0000, 0.0485], d_k_M_hat range: [0.9177, 0.9999]
2025-03-11 21:00:53 - Train Iteration 9753: loss: 0.0388, d_k_M range: [0.0000, 0.0106], d_k_M_hat range: [0.8034, 0.9962]
2025-03-11 21:00:53 - Train Iteration 9754: loss: 0.0322, d_k_M range: [0.0030, 0.1756], d_k_M_hat range: [0.9555, 0.9994]
2025-03-11 21:00:54 - Train Iteration 9755: loss: 0.0070, d_k_M range: [0.0002, 0.0319], d_k_M_hat range: [0.9480, 0.9994]
2025-03-11 21:00:54 - Train Iteration 9756: loss: 0.9788, d_k_M range: [0.0000, 0.9893], d_k_M_hat range: [0.9709, 1.0000]
2025-03-11 21:00:55 - Train Iteration 9757: loss: 0.1528, d_k_M range: [0.0004, 0.3907], d_k_M_hat range: [0.9850, 0.9999]
2025-03-11 21:00:55 - Train Iteration 9758: loss: 0.0011, d_k_M range: [0.0002, 0.0228], d_k_M_hat range: [0.9730, 0.9958]
2025-03-11 21:00:55 - Train Iteration 9759: loss: 0.1182, d_k_M range: [0.0000, 0.1236], d_k_M_hat range: [0.6563, 0.9980]
2025-03-11 21:00:56 - Train Iteration 9760: loss: 0.1500, d_k_M range: [0.0002, 0.3866], d_k_M_hat range: [0.9327, 0.9996]
2025-03-11 21:00:56 - Train Iteration 9761: loss: 0.5861, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.2346, 0.9921]
2025-03-11 21:00:57 - Train Iteration 9762: loss: 0.1161, d_k_M range: [0.0042, 0.3360], d_k_M_hat range: [0.9947, 0.9999]
2025-03-11 21:00:57 - Train Iteration 9763: loss: 0.0108, d_k_M range: [0.0001, 0.0083], d_k_M_hat range: [0.8966, 0.9947]
2025-03-11 21:00:58 - Train Iteration 9764: loss: 0.0052, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.9282, 0.9981]
2025-03-11 21:00:58 - Train Iteration 9765: loss: 0.0922, d_k_M range: [0.0001, 0.3023], d_k_M_hat range: [0.9145, 0.9992]
2025-03-11 21:00:59 - Train Iteration 9766: loss: 0.0774, d_k_M range: [0.0000, 0.1445], d_k_M_hat range: [0.7218, 0.9996]
2025-03-11 21:00:59 - Train Iteration 9767: loss: 0.3239, d_k_M range: [0.0000, 0.2679], d_k_M_hat range: [0.4309, 0.9989]
2025-03-11 21:01:00 - Train Iteration 9768: loss: 0.0619, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.7513, 0.9972]
2025-03-11 21:01:00 - Train Iteration 9769: loss: 0.0193, d_k_M range: [0.0001, 0.1387], d_k_M_hat range: [0.9546, 0.9998]
2025-03-11 21:01:00 - Train Iteration 9770: loss: 0.0169, d_k_M range: [0.0000, 0.0078], d_k_M_hat range: [0.8702, 0.9953]
2025-03-11 21:01:01 - Train Iteration 9771: loss: 0.0843, d_k_M range: [0.0004, 0.0443], d_k_M_hat range: [0.7254, 0.9992]
2025-03-11 21:01:01 - Train Iteration 9772: loss: 0.2751, d_k_M range: [0.0001, 0.5243], d_k_M_hat range: [0.9128, 0.9999]
2025-03-11 21:01:02 - Train Iteration 9773: loss: 0.7078, d_k_M range: [0.0000, 0.0261], d_k_M_hat range: [0.1587, 0.9998]
2025-03-11 21:01:02 - Train Iteration 9774: loss: 0.0338, d_k_M range: [0.0004, 0.1827], d_k_M_hat range: [0.9448, 1.0000]
2025-03-11 21:01:02 - Train Iteration 9775: loss: 0.0344, d_k_M range: [0.0002, 0.1850], d_k_M_hat range: [0.9660, 0.9994]
2025-03-11 21:01:03 - Train Iteration 9776: loss: 0.1547, d_k_M range: [0.0012, 0.1166], d_k_M_hat range: [0.6079, 0.9998]
2025-03-11 21:01:03 - Train Iteration 9777: loss: 0.5569, d_k_M range: [0.0002, 0.7453], d_k_M_hat range: [0.9348, 0.9995]
2025-03-11 21:01:04 - Train Iteration 9778: loss: 0.2153, d_k_M range: [0.0000, 0.0083], d_k_M_hat range: [0.5362, 0.9817]
2025-03-11 21:01:04 - Train Iteration 9779: loss: 0.0124, d_k_M range: [0.0001, 0.0283], d_k_M_hat range: [0.8886, 0.9989]
2025-03-11 21:01:05 - Train Iteration 9780: loss: 0.0609, d_k_M range: [0.0000, 0.2424], d_k_M_hat range: [0.8895, 0.9997]
2025-03-11 21:01:05 - Train Iteration 9781: loss: 0.0076, d_k_M range: [0.0004, 0.0677], d_k_M_hat range: [0.9752, 0.9992]
2025-03-11 21:01:05 - Train Iteration 9782: loss: 0.1209, d_k_M range: [0.0000, 0.3459], d_k_M_hat range: [0.7035, 0.9989]
2025-03-11 21:01:06 - Train Iteration 9783: loss: 0.0067, d_k_M range: [0.0000, 0.0796], d_k_M_hat range: [0.9258, 0.9996]
2025-03-11 21:01:06 - Train Iteration 9784: loss: 0.2997, d_k_M range: [0.0000, 0.0055], d_k_M_hat range: [0.4526, 0.9948]
2025-03-11 21:01:07 - Train Iteration 9785: loss: 0.5687, d_k_M range: [0.0003, 0.7476], d_k_M_hat range: [0.9935, 0.9999]
2025-03-11 21:01:07 - Train Iteration 9786: loss: 0.3942, d_k_M range: [0.0000, 0.6275], d_k_M_hat range: [0.5834, 0.9997]
2025-03-11 21:01:07 - Train Iteration 9787: loss: 0.0333, d_k_M range: [0.0002, 0.0157], d_k_M_hat range: [0.8179, 0.9997]
2025-03-11 21:01:08 - Train Iteration 9788: loss: 0.0289, d_k_M range: [0.0000, 0.0369], d_k_M_hat range: [0.8300, 0.9985]
2025-03-11 21:01:08 - Train Iteration 9789: loss: 0.1027, d_k_M range: [0.0002, 0.3128], d_k_M_hat range: [0.9802, 0.9970]
2025-03-11 21:01:09 - Train Iteration 9790: loss: 0.0045, d_k_M range: [0.0003, 0.0070], d_k_M_hat range: [0.9348, 0.9994]
2025-03-11 21:01:09 - Train Iteration 9791: loss: 0.0086, d_k_M range: [0.0001, 0.0142], d_k_M_hat range: [0.9073, 0.9985]
2025-03-11 21:01:10 - Train Iteration 9792: loss: 0.5406, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.2648, 0.9953]
2025-03-11 21:01:10 - Train Iteration 9793: loss: 0.2403, d_k_M range: [0.0001, 0.4896], d_k_M_hat range: [0.9972, 0.9998]
2025-03-11 21:01:11 - Train Iteration 9794: loss: 0.2331, d_k_M range: [0.0000, 0.0452], d_k_M_hat range: [0.5173, 0.9858]
2025-03-11 21:01:11 - Train Iteration 9795: loss: 0.1790, d_k_M range: [0.0000, 0.4192], d_k_M_hat range: [0.9755, 0.9994]
2025-03-11 21:01:12 - Train Iteration 9796: loss: 0.3689, d_k_M range: [0.0000, 0.0216], d_k_M_hat range: [0.3927, 0.9934]
2025-03-11 21:01:12 - Train Iteration 9797: loss: 0.4409, d_k_M range: [0.0000, 0.6632], d_k_M_hat range: [0.8765, 0.9999]
2025-03-11 21:01:12 - Train Iteration 9798: loss: 0.3516, d_k_M range: [0.0000, 0.0202], d_k_M_hat range: [0.4070, 0.9964]
2025-03-11 21:01:13 - Train Iteration 9799: loss: 0.3084, d_k_M range: [0.0001, 0.5549], d_k_M_hat range: [0.9792, 1.0000]
2025-03-11 21:01:13 - Train Iteration 9800: loss: 0.1141, d_k_M range: [0.0000, 0.0175], d_k_M_hat range: [0.6622, 0.9976]
2025-03-11 21:01:14 - Train Iteration 9801: loss: 0.4749, d_k_M range: [0.0032, 0.6891], d_k_M_hat range: [0.9898, 1.0000]
2025-03-11 21:01:14 - Train Iteration 9802: loss: 0.0146, d_k_M range: [0.0009, 0.0885], d_k_M_hat range: [0.9675, 0.9992]
2025-03-11 21:01:15 - Train Iteration 9803: loss: 0.0272, d_k_M range: [0.0000, 0.1581], d_k_M_hat range: [0.9011, 0.9988]
2025-03-11 21:01:15 - Train Iteration 9804: loss: 0.5604, d_k_M range: [0.0000, 0.7464], d_k_M_hat range: [0.8694, 0.9993]
2025-03-11 21:01:16 - Train Iteration 9805: loss: 0.3855, d_k_M range: [0.0003, 0.6208], d_k_M_hat range: [0.4792, 1.0000]
2025-03-11 21:01:16 - Train Iteration 9806: loss: 0.0654, d_k_M range: [0.0000, 0.1219], d_k_M_hat range: [0.7443, 0.9989]
2025-03-11 21:01:16 - Train Iteration 9807: loss: 0.6960, d_k_M range: [0.0000, 0.8339], d_k_M_hat range: [0.9768, 0.9997]
2025-03-11 21:01:17 - Train Iteration 9808: loss: 0.0682, d_k_M range: [0.0000, 0.0727], d_k_M_hat range: [0.7393, 0.9933]
2025-03-11 21:01:17 - Train Iteration 9809: loss: 0.0021, d_k_M range: [0.0002, 0.0269], d_k_M_hat range: [0.9704, 0.9995]
2025-03-11 21:01:18 - Train Iteration 9810: loss: 0.0629, d_k_M range: [0.0002, 0.0049], d_k_M_hat range: [0.7496, 0.9798]
2025-03-11 21:01:18 - Train Iteration 9811: loss: 0.1635, d_k_M range: [0.0000, 0.4041], d_k_M_hat range: [0.8949, 0.9998]
2025-03-11 21:01:19 - Train Iteration 9812: loss: 0.3308, d_k_M range: [0.0000, 0.5708], d_k_M_hat range: [0.8260, 0.9956]
2025-03-11 21:01:19 - Train Iteration 9813: loss: 0.2747, d_k_M range: [0.0000, 0.1651], d_k_M_hat range: [0.4759, 0.9965]
2025-03-11 21:01:20 - Train Iteration 9814: loss: 0.0208, d_k_M range: [0.0003, 0.0131], d_k_M_hat range: [0.8600, 0.9960]
2025-03-11 21:01:20 - Train Iteration 9815: loss: 0.2272, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.5239, 0.9957]
2025-03-11 21:01:20 - Train Iteration 9816: loss: 0.1705, d_k_M range: [0.0001, 0.4124], d_k_M_hat range: [0.9039, 0.9995]
2025-03-11 21:01:21 - Train Iteration 9817: loss: 0.1532, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.6091, 0.9979]
2025-03-11 21:01:21 - Train Iteration 9818: loss: 0.1529, d_k_M range: [0.0003, 0.3908], d_k_M_hat range: [0.8957, 0.9998]
2025-03-11 21:01:22 - Train Iteration 9819: loss: 0.0102, d_k_M range: [0.0000, 0.0949], d_k_M_hat range: [0.9671, 0.9938]
2025-03-11 21:01:22 - Train Iteration 9820: loss: 0.0167, d_k_M range: [0.0000, 0.0109], d_k_M_hat range: [0.8707, 0.9838]
2025-03-11 21:01:22 - Train Iteration 9821: loss: 0.3301, d_k_M range: [0.0000, 0.0697], d_k_M_hat range: [0.4254, 0.9967]
2025-03-11 21:01:23 - Train Iteration 9822: loss: 0.0057, d_k_M range: [0.0000, 0.0734], d_k_M_hat range: [0.9885, 0.9994]
2025-03-11 21:01:23 - Train Iteration 9823: loss: 0.3899, d_k_M range: [0.0000, 0.0504], d_k_M_hat range: [0.3759, 0.9988]
2025-03-11 21:01:24 - Train Iteration 9824: loss: 0.0152, d_k_M range: [0.0001, 0.1224], d_k_M_hat range: [0.8817, 0.9993]
2025-03-11 21:01:24 - Train Iteration 9825: loss: 0.0356, d_k_M range: [0.0001, 0.1828], d_k_M_hat range: [0.9811, 0.9976]
2025-03-11 21:01:25 - Train Iteration 9826: loss: 0.0547, d_k_M range: [0.0001, 0.0350], d_k_M_hat range: [0.8011, 0.9998]
2025-03-11 21:01:25 - Train Iteration 9827: loss: 0.0058, d_k_M range: [0.0001, 0.0233], d_k_M_hat range: [0.9470, 0.9966]
2025-03-11 21:01:25 - Train Iteration 9828: loss: 0.1345, d_k_M range: [0.0000, 0.1067], d_k_M_hat range: [0.6333, 0.9965]
2025-03-11 21:01:26 - Train Iteration 9829: loss: 0.0115, d_k_M range: [0.0001, 0.0151], d_k_M_hat range: [0.8930, 0.9954]
2025-03-11 21:01:26 - Train Iteration 9830: loss: 0.7022, d_k_M range: [0.0000, 0.0592], d_k_M_hat range: [0.1621, 0.9979]
2025-03-11 21:01:27 - Train Iteration 9831: loss: 0.2614, d_k_M range: [0.0010, 0.5111], d_k_M_hat range: [0.9877, 0.9999]
2025-03-11 21:01:27 - Train Iteration 9832: loss: 0.0142, d_k_M range: [0.0001, 0.0358], d_k_M_hat range: [0.8824, 0.9891]
2025-03-11 21:01:27 - Train Iteration 9833: loss: 0.0171, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.8692, 0.9981]
2025-03-11 21:01:28 - Train Iteration 9834: loss: 0.1938, d_k_M range: [0.0016, 0.4400], d_k_M_hat range: [0.9846, 0.9999]
2025-03-11 21:01:28 - Train Iteration 9835: loss: 0.6182, d_k_M range: [0.0000, 0.0149], d_k_M_hat range: [0.2286, 0.9874]
2025-03-11 21:01:29 - Train Iteration 9836: loss: 0.2555, d_k_M range: [0.0007, 0.4962], d_k_M_hat range: [0.9631, 0.9998]
2025-03-11 21:01:29 - Train Iteration 9837: loss: 0.2883, d_k_M range: [0.0000, 0.5356], d_k_M_hat range: [0.9109, 0.9987]
2025-03-11 21:01:30 - Train Iteration 9838: loss: 0.0349, d_k_M range: [0.0003, 0.1866], d_k_M_hat range: [0.9774, 0.9998]
2025-03-11 21:01:30 - Train Iteration 9839: loss: 0.0017, d_k_M range: [0.0000, 0.0407], d_k_M_hat range: [0.9748, 0.9997]
2025-03-11 21:01:31 - Train Iteration 9840: loss: 0.0416, d_k_M range: [0.0001, 0.2038], d_k_M_hat range: [0.9606, 0.9998]
2025-03-11 21:01:31 - Train Iteration 9841: loss: 0.2339, d_k_M range: [0.0000, 0.4483], d_k_M_hat range: [0.8714, 0.9904]
2025-03-11 21:01:31 - Train Iteration 9842: loss: 0.3928, d_k_M range: [0.0000, 0.0856], d_k_M_hat range: [0.3733, 0.9971]
2025-03-11 21:01:32 - Train Iteration 9843: loss: 0.0372, d_k_M range: [0.0010, 0.1925], d_k_M_hat range: [0.9885, 0.9998]
2025-03-11 21:01:32 - Train Iteration 9844: loss: 0.0877, d_k_M range: [0.0000, 0.0294], d_k_M_hat range: [0.7040, 0.9979]
2025-03-11 21:01:33 - Train Iteration 9845: loss: 0.7871, d_k_M range: [0.0096, 0.8860], d_k_M_hat range: [0.9722, 0.9995]
2025-03-11 21:01:33 - Train Iteration 9846: loss: 0.0193, d_k_M range: [0.0001, 0.0037], d_k_M_hat range: [0.8615, 0.9869]
2025-03-11 21:01:34 - Train Iteration 9847: loss: 0.0529, d_k_M range: [0.0000, 0.2190], d_k_M_hat range: [0.7701, 0.9993]
2025-03-11 21:01:34 - Train Iteration 9848: loss: 0.5746, d_k_M range: [0.0002, 0.7570], d_k_M_hat range: [0.9720, 0.9994]
2025-03-11 21:01:34 - Train Iteration 9849: loss: 0.0070, d_k_M range: [0.0002, 0.0288], d_k_M_hat range: [0.9233, 0.9986]
2025-03-11 21:01:35 - Train Iteration 9850: loss: 0.0046, d_k_M range: [0.0002, 0.0657], d_k_M_hat range: [0.9787, 0.9985]
2025-03-11 21:01:35 - Train Iteration 9851: loss: 0.1303, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.6391, 0.9920]
2025-03-11 21:01:36 - Train Iteration 9852: loss: 0.0813, d_k_M range: [0.0001, 0.2837], d_k_M_hat range: [0.8826, 0.9987]
2025-03-11 21:01:36 - Train Iteration 9853: loss: 0.0414, d_k_M range: [0.0000, 0.1962], d_k_M_hat range: [0.9029, 0.9960]
2025-03-11 21:01:37 - Train Iteration 9854: loss: 0.0247, d_k_M range: [0.0000, 0.0125], d_k_M_hat range: [0.8432, 0.9952]
2025-03-11 21:01:37 - Train Iteration 9855: loss: 0.1593, d_k_M range: [0.0013, 0.3962], d_k_M_hat range: [0.9588, 1.0000]
2025-03-11 21:01:37 - Train Iteration 9856: loss: 0.0938, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.6940, 0.9872]
2025-03-11 21:01:38 - Train Iteration 9857: loss: 0.0434, d_k_M range: [0.0000, 0.0133], d_k_M_hat range: [0.7917, 0.9978]
2025-03-11 21:01:38 - Train Iteration 9858: loss: 0.1152, d_k_M range: [0.0004, 0.3390], d_k_M_hat range: [0.8825, 0.9996]
2025-03-11 21:01:39 - Train Iteration 9859: loss: 0.0528, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.7702, 0.9995]
2025-03-11 21:01:39 - Train Iteration 9860: loss: 0.3793, d_k_M range: [0.0002, 0.5887], d_k_M_hat range: [0.9728, 1.0000]
2025-03-11 21:01:39 - Train Iteration 9861: loss: 0.0456, d_k_M range: [0.0000, 0.2120], d_k_M_hat range: [0.8971, 0.9985]
2025-03-11 21:01:40 - Train Iteration 9862: loss: 0.0235, d_k_M range: [0.0000, 0.1473], d_k_M_hat range: [0.8978, 0.9976]
2025-03-11 21:01:40 - Train Iteration 9863: loss: 0.4655, d_k_M range: [0.0000, 0.6822], d_k_M_hat range: [0.8479, 0.9999]
2025-03-11 21:01:41 - Train Iteration 9864: loss: 0.7679, d_k_M range: [0.0000, 0.0180], d_k_M_hat range: [0.1237, 0.9956]
2025-03-11 21:01:41 - Train Iteration 9865: loss: 0.0278, d_k_M range: [0.0009, 0.1343], d_k_M_hat range: [0.9611, 0.9981]
2025-03-11 21:01:42 - Train Iteration 9866: loss: 0.0647, d_k_M range: [0.0001, 0.2052], d_k_M_hat range: [0.7458, 0.9996]
2025-03-11 21:01:42 - Train Iteration 9867: loss: 0.1943, d_k_M range: [0.0078, 0.4408], d_k_M_hat range: [0.9654, 1.0000]
2025-03-11 21:01:43 - Train Iteration 9868: loss: 0.1205, d_k_M range: [0.0000, 0.0156], d_k_M_hat range: [0.6549, 0.9967]
2025-03-11 21:01:43 - Train Iteration 9869: loss: 0.0298, d_k_M range: [0.0007, 0.1714], d_k_M_hat range: [0.9956, 0.9997]
2025-03-11 21:01:43 - Train Iteration 9870: loss: 0.1409, d_k_M range: [0.0003, 0.0061], d_k_M_hat range: [0.6274, 0.9922]
2025-03-11 21:01:44 - Train Iteration 9871: loss: 0.0841, d_k_M range: [0.0001, 0.1822], d_k_M_hat range: [0.7103, 0.9997]
2025-03-11 21:01:44 - Train Iteration 9872: loss: 0.0161, d_k_M range: [0.0000, 0.0199], d_k_M_hat range: [0.8730, 0.9972]
2025-03-11 21:01:45 - Train Iteration 9873: loss: 0.2268, d_k_M range: [0.0000, 0.0057], d_k_M_hat range: [0.5251, 0.9908]
2025-03-11 21:01:45 - Train Iteration 9874: loss: 0.0332, d_k_M range: [0.0000, 0.1820], d_k_M_hat range: [0.9836, 0.9998]
2025-03-11 21:01:46 - Train Iteration 9875: loss: 0.0097, d_k_M range: [0.0001, 0.0361], d_k_M_hat range: [0.9017, 0.9992]
2025-03-11 21:01:46 - Train Iteration 9876: loss: 0.0714, d_k_M range: [0.0000, 0.0296], d_k_M_hat range: [0.7341, 0.9955]
2025-03-11 21:01:46 - Train Iteration 9877: loss: 0.0172, d_k_M range: [0.0004, 0.1307], d_k_M_hat range: [0.8942, 0.9995]
2025-03-11 21:01:47 - Train Iteration 9878: loss: 0.0300, d_k_M range: [0.0001, 0.0118], d_k_M_hat range: [0.8273, 0.9898]
2025-03-11 21:01:47 - Train Iteration 9879: loss: 0.0806, d_k_M range: [0.0000, 0.2838], d_k_M_hat range: [0.9177, 0.9999]
2025-03-11 21:01:48 - Train Iteration 9880: loss: 0.1268, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.6450, 0.9963]
2025-03-11 21:01:48 - Train Iteration 9881: loss: 0.0042, d_k_M range: [0.0000, 0.0238], d_k_M_hat range: [0.9355, 0.9999]
2025-03-11 21:01:49 - Train Iteration 9882: loss: 0.0293, d_k_M range: [0.0004, 0.1633], d_k_M_hat range: [0.9687, 0.9960]
2025-03-11 21:01:49 - Train Iteration 9883: loss: 0.0310, d_k_M range: [0.0000, 0.1759], d_k_M_hat range: [0.9705, 0.9997]
2025-03-11 21:01:49 - Train Iteration 9884: loss: 0.2157, d_k_M range: [0.0000, 0.0161], d_k_M_hat range: [0.5356, 0.9994]
2025-03-11 21:01:50 - Train Iteration 9885: loss: 0.0219, d_k_M range: [0.0001, 0.1439], d_k_M_hat range: [0.9774, 0.9996]
2025-03-11 21:01:50 - Train Iteration 9886: loss: 0.0064, d_k_M range: [0.0000, 0.0251], d_k_M_hat range: [0.9272, 0.9997]
2025-03-11 21:01:51 - Train Iteration 9887: loss: 0.8019, d_k_M range: [0.0000, 0.8919], d_k_M_hat range: [0.9476, 0.9996]
2025-03-11 21:01:51 - Train Iteration 9888: loss: 0.5850, d_k_M range: [0.0000, 0.0204], d_k_M_hat range: [0.2352, 0.9915]
2025-03-11 21:01:51 - Train Iteration 9889: loss: 0.6522, d_k_M range: [0.0010, 0.7969], d_k_M_hat range: [0.9004, 0.9997]
2025-03-11 21:01:52 - Train Iteration 9890: loss: 0.2321, d_k_M range: [0.0000, 0.0318], d_k_M_hat range: [0.5185, 0.9990]
2025-03-11 21:01:52 - Train Iteration 9891: loss: 0.0085, d_k_M range: [0.0000, 0.0332], d_k_M_hat range: [0.9079, 0.9989]
2025-03-11 21:01:53 - Train Iteration 9892: loss: 0.2231, d_k_M range: [0.0000, 0.0847], d_k_M_hat range: [0.5277, 0.9999]
2025-03-11 21:01:53 - Train Iteration 9893: loss: 0.0165, d_k_M range: [0.0002, 0.1198], d_k_M_hat range: [0.9786, 0.9973]
2025-03-11 21:01:54 - Train Iteration 9894: loss: 0.0241, d_k_M range: [0.0001, 0.0788], d_k_M_hat range: [0.8449, 0.9983]
2025-03-11 21:01:54 - Train Iteration 9895: loss: 0.2493, d_k_M range: [0.0007, 0.4990], d_k_M_hat range: [0.8762, 0.9997]
2025-03-11 21:01:54 - Train Iteration 9896: loss: 0.0285, d_k_M range: [0.0000, 0.0845], d_k_M_hat range: [0.8312, 0.9997]
2025-03-11 21:01:55 - Train Iteration 9897: loss: 0.0040, d_k_M range: [0.0003, 0.0158], d_k_M_hat range: [0.9385, 0.9976]
2025-03-11 21:01:55 - Train Iteration 9898: loss: 0.0100, d_k_M range: [0.0001, 0.0063], d_k_M_hat range: [0.9008, 0.9988]
2025-03-11 21:01:56 - Train Iteration 9899: loss: 0.2487, d_k_M range: [0.0005, 0.0937], d_k_M_hat range: [0.5155, 0.9998]
2025-03-11 21:01:56 - Train Iteration 9900: loss: 0.1514, d_k_M range: [0.0000, 0.3886], d_k_M_hat range: [0.8347, 0.9999]
2025-03-11 21:01:57 - Train Iteration 9901: loss: 0.0165, d_k_M range: [0.0000, 0.0220], d_k_M_hat range: [0.8719, 0.9882]
2025-03-11 21:01:57 - Train Iteration 9902: loss: 0.0350, d_k_M range: [0.0001, 0.1867], d_k_M_hat range: [0.9016, 0.9997]
2025-03-11 21:01:58 - Train Iteration 9903: loss: 0.2907, d_k_M range: [0.0000, 0.0129], d_k_M_hat range: [0.4609, 0.9897]
2025-03-11 21:01:58 - Train Iteration 9904: loss: 0.3791, d_k_M range: [0.0003, 0.6138], d_k_M_hat range: [0.9780, 0.9995]
2025-03-11 21:01:58 - Train Iteration 9905: loss: 0.0765, d_k_M range: [0.0000, 0.0208], d_k_M_hat range: [0.7234, 0.9871]
2025-03-11 21:01:59 - Train Iteration 9906: loss: 0.1902, d_k_M range: [0.0002, 0.4346], d_k_M_hat range: [0.9562, 0.9990]
2025-03-11 21:01:59 - Train Iteration 9907: loss: 0.2217, d_k_M range: [0.0000, 0.0098], d_k_M_hat range: [0.5292, 0.9750]
2025-03-11 21:02:00 - Train Iteration 9908: loss: 0.0136, d_k_M range: [0.0002, 0.0040], d_k_M_hat range: [0.8841, 0.9892]
2025-03-11 21:02:00 - Train Iteration 9909: loss: 0.8813, d_k_M range: [0.0009, 0.9387], d_k_M_hat range: [0.9653, 1.0000]
2025-03-11 21:02:00 - Train Iteration 9910: loss: 0.0043, d_k_M range: [0.0003, 0.0418], d_k_M_hat range: [0.9613, 0.9999]
2025-03-11 21:02:01 - Train Iteration 9911: loss: 0.0107, d_k_M range: [0.0004, 0.0730], d_k_M_hat range: [0.8970, 0.9995]
2025-03-11 21:02:01 - Train Iteration 9912: loss: 0.1320, d_k_M range: [0.0000, 0.2023], d_k_M_hat range: [0.6399, 0.9901]
2025-03-11 21:02:02 - Train Iteration 9913: loss: 0.3039, d_k_M range: [0.0000, 0.5407], d_k_M_hat range: [0.7855, 0.9972]
2025-03-11 21:02:02 - Train Iteration 9914: loss: 0.2516, d_k_M range: [0.0000, 0.0057], d_k_M_hat range: [0.4996, 0.9906]
2025-03-11 21:02:03 - Train Iteration 9915: loss: 0.0123, d_k_M range: [0.0001, 0.1072], d_k_M_hat range: [0.9468, 0.9963]
2025-03-11 21:02:03 - Train Iteration 9916: loss: 0.2212, d_k_M range: [0.0000, 0.4658], d_k_M_hat range: [0.6212, 0.9987]
2025-03-11 21:02:04 - Train Iteration 9917: loss: 0.3817, d_k_M range: [0.0001, 0.4382], d_k_M_hat range: [0.3823, 0.9989]
2025-03-11 21:02:04 - Train Iteration 9918: loss: 0.9448, d_k_M range: [0.0001, 0.9720], d_k_M_hat range: [0.9979, 1.0000]
2025-03-11 21:02:05 - Train Iteration 9919: loss: 0.0100, d_k_M range: [0.0002, 0.0283], d_k_M_hat range: [0.9002, 0.9984]
2025-03-11 21:02:05 - Train Iteration 9920: loss: 0.5095, d_k_M range: [0.0001, 0.7118], d_k_M_hat range: [0.9838, 0.9996]
2025-03-11 21:02:05 - Train Iteration 9921: loss: 0.1706, d_k_M range: [0.0000, 0.0546], d_k_M_hat range: [0.5871, 0.9638]
2025-03-11 21:02:06 - Train Iteration 9922: loss: 0.1499, d_k_M range: [0.0003, 0.3859], d_k_M_hat range: [0.9769, 0.9999]
2025-03-11 21:02:06 - Train Iteration 9923: loss: 0.0642, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.7469, 0.9966]
2025-03-11 21:02:07 - Train Iteration 9924: loss: 0.4674, d_k_M range: [0.0003, 0.6835], d_k_M_hat range: [0.9725, 0.9998]
2025-03-11 21:02:07 - Train Iteration 9925: loss: 0.0057, d_k_M range: [0.0002, 0.0659], d_k_M_hat range: [0.9873, 0.9972]
2025-03-11 21:02:07 - Train Iteration 9926: loss: 0.0114, d_k_M range: [0.0006, 0.0308], d_k_M_hat range: [0.8945, 0.9991]
2025-03-11 21:02:08 - Train Iteration 9927: loss: 0.0221, d_k_M range: [0.0000, 0.1483], d_k_M_hat range: [0.9650, 0.9995]
2025-03-11 21:02:08 - Train Iteration 9928: loss: 0.3482, d_k_M range: [0.0000, 0.3272], d_k_M_hat range: [0.4099, 0.9994]
2025-03-11 21:02:09 - Train Iteration 9929: loss: 0.0309, d_k_M range: [0.0002, 0.1738], d_k_M_hat range: [0.9721, 0.9997]
2025-03-11 21:02:09 - Train Iteration 9930: loss: 0.2519, d_k_M range: [0.0003, 0.0142], d_k_M_hat range: [0.5123, 0.9990]
2025-03-11 21:02:10 - Train Iteration 9931: loss: 0.1396, d_k_M range: [0.0036, 0.3582], d_k_M_hat range: [0.8895, 0.9972]
2025-03-11 21:02:10 - Train Iteration 9932: loss: 0.8173, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.0959, 0.9955]
2025-03-11 21:02:10 - Train Iteration 9933: loss: 0.1988, d_k_M range: [0.0004, 0.4456], d_k_M_hat range: [0.9588, 0.9999]
2025-03-11 21:02:11 - Train Iteration 9934: loss: 0.6427, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.1983, 0.9867]
2025-03-11 21:02:11 - Train Iteration 9935: loss: 0.0696, d_k_M range: [0.0006, 0.2630], d_k_M_hat range: [0.8439, 0.9995]
2025-03-11 21:02:12 - Train Iteration 9936: loss: 0.0065, d_k_M range: [0.0000, 0.0723], d_k_M_hat range: [0.9573, 0.9987]
2025-03-11 21:02:12 - Train Iteration 9937: loss: 0.0866, d_k_M range: [0.0000, 0.0079], d_k_M_hat range: [0.7057, 0.9887]
2025-03-11 21:02:12 - Train Iteration 9938: loss: 0.0028, d_k_M range: [0.0001, 0.0249], d_k_M_hat range: [0.9562, 0.9998]
2025-03-11 21:02:13 - Train Iteration 9939: loss: 0.2085, d_k_M range: [0.0003, 0.4563], d_k_M_hat range: [0.9911, 0.9997]
2025-03-11 21:02:13 - Train Iteration 9940: loss: 0.0041, d_k_M range: [0.0006, 0.0634], d_k_M_hat range: [0.9608, 0.9996]
2025-03-11 21:02:14 - Train Iteration 9941: loss: 0.0054, d_k_M range: [0.0006, 0.0697], d_k_M_hat range: [0.9453, 0.9960]
2025-03-11 21:02:14 - Train Iteration 9942: loss: 0.1461, d_k_M range: [0.0014, 0.3746], d_k_M_hat range: [0.9702, 0.9999]
2025-03-11 21:02:14 - Train Iteration 9943: loss: 0.0156, d_k_M range: [0.0003, 0.0846], d_k_M_hat range: [0.9546, 0.9974]
2025-03-11 21:02:15 - Train Iteration 9944: loss: 0.1446, d_k_M range: [0.0001, 0.0330], d_k_M_hat range: [0.6200, 0.9986]
2025-03-11 21:02:15 - Train Iteration 9945: loss: 0.4974, d_k_M range: [0.0779, 0.7053], d_k_M_hat range: [0.9964, 1.0000]
2025-03-11 21:02:16 - Train Iteration 9946: loss: 0.0530, d_k_M range: [0.0000, 0.0264], d_k_M_hat range: [0.7701, 0.9994]
2025-03-11 21:02:16 - Train Iteration 9947: loss: 0.0079, d_k_M range: [0.0001, 0.0320], d_k_M_hat range: [0.9110, 1.0000]
2025-03-11 21:02:17 - Train Iteration 9948: loss: 0.0208, d_k_M range: [0.0002, 0.1415], d_k_M_hat range: [0.9844, 0.9989]
2025-03-11 21:02:17 - Train Iteration 9949: loss: 0.2126, d_k_M range: [0.0000, 0.4600], d_k_M_hat range: [0.9612, 0.9997]
2025-03-11 21:02:17 - Train Iteration 9950: loss: 0.3048, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.4479, 0.9784]
2025-03-11 21:02:18 - Train Iteration 9951: loss: 0.1119, d_k_M range: [0.0000, 0.3340], d_k_M_hat range: [0.9793, 0.9997]
2025-03-11 21:02:18 - Train Iteration 9952: loss: 0.1205, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.6531, 0.9818]
2025-03-11 21:02:19 - Train Iteration 9953: loss: 0.0860, d_k_M range: [0.0016, 0.2931], d_k_M_hat range: [0.9658, 0.9999]
2025-03-11 21:02:19 - Train Iteration 9954: loss: 0.1374, d_k_M range: [0.0001, 0.0014], d_k_M_hat range: [0.6301, 0.9839]
2025-03-11 21:02:20 - Train Iteration 9955: loss: 0.1469, d_k_M range: [0.0005, 0.2061], d_k_M_hat range: [0.6172, 0.9997]
2025-03-11 21:02:20 - Train Iteration 9956: loss: 0.0643, d_k_M range: [0.0004, 0.2534], d_k_M_hat range: [0.8351, 0.9998]
2025-03-11 21:02:20 - Train Iteration 9957: loss: 0.0068, d_k_M range: [0.0000, 0.0195], d_k_M_hat range: [0.9176, 0.9981]
2025-03-11 21:02:21 - Train Iteration 9958: loss: 0.0136, d_k_M range: [0.0001, 0.0307], d_k_M_hat range: [0.8936, 0.9986]
2025-03-11 21:02:21 - Train Iteration 9959: loss: 0.0496, d_k_M range: [0.0000, 0.1610], d_k_M_hat range: [0.7775, 0.9997]
2025-03-11 21:02:22 - Train Iteration 9960: loss: 0.0337, d_k_M range: [0.0010, 0.1752], d_k_M_hat range: [0.9299, 0.9999]
2025-03-11 21:02:22 - Train Iteration 9961: loss: 0.3999, d_k_M range: [0.0001, 0.0127], d_k_M_hat range: [0.3677, 0.9937]
2025-03-11 21:02:22 - Train Iteration 9962: loss: 0.0187, d_k_M range: [0.0004, 0.1356], d_k_M_hat range: [0.9693, 0.9991]
2025-03-11 21:02:23 - Train Iteration 9963: loss: 0.0027, d_k_M range: [0.0000, 0.0340], d_k_M_hat range: [0.9548, 0.9962]
2025-03-11 21:02:23 - Train Iteration 9964: loss: 0.0196, d_k_M range: [0.0004, 0.0481], d_k_M_hat range: [0.8629, 0.9986]
2025-03-11 21:02:24 - Train Iteration 9965: loss: 0.3108, d_k_M range: [0.0000, 0.0183], d_k_M_hat range: [0.4425, 0.9968]
2025-03-11 21:02:24 - Train Iteration 9966: loss: 0.0923, d_k_M range: [0.0006, 0.3028], d_k_M_hat range: [0.9765, 0.9998]
2025-03-11 21:02:25 - Train Iteration 9967: loss: 0.0658, d_k_M range: [0.0000, 0.0066], d_k_M_hat range: [0.7435, 0.9584]
2025-03-11 21:02:25 - Train Iteration 9968: loss: 0.0092, d_k_M range: [0.0000, 0.0919], d_k_M_hat range: [0.9111, 0.9992]
2025-03-11 21:02:25 - Train Iteration 9969: loss: 0.0063, d_k_M range: [0.0001, 0.0477], d_k_M_hat range: [0.9305, 0.9992]
2025-03-11 21:02:26 - Train Iteration 9970: loss: 0.1370, d_k_M range: [0.0001, 0.3690], d_k_M_hat range: [0.9262, 0.9992]
2025-03-11 21:02:26 - Train Iteration 9971: loss: 0.3186, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.4357, 0.9640]
2025-03-11 21:02:27 - Train Iteration 9972: loss: 0.0215, d_k_M range: [0.0008, 0.1443], d_k_M_hat range: [0.9230, 0.9998]
2025-03-11 21:02:27 - Train Iteration 9973: loss: 0.0070, d_k_M range: [0.0001, 0.0191], d_k_M_hat range: [0.9164, 0.9988]
2025-03-11 21:02:28 - Train Iteration 9974: loss: 0.1223, d_k_M range: [0.0000, 0.2331], d_k_M_hat range: [0.6503, 0.9987]
2025-03-11 21:02:28 - Train Iteration 9975: loss: 0.0853, d_k_M range: [0.0007, 0.2920], d_k_M_hat range: [0.9942, 1.0000]
2025-03-11 21:02:28 - Train Iteration 9976: loss: 0.0103, d_k_M range: [0.0000, 0.0592], d_k_M_hat range: [0.8986, 0.9991]
2025-03-11 21:02:29 - Train Iteration 9977: loss: 0.3206, d_k_M range: [0.0000, 0.5661], d_k_M_hat range: [0.9424, 0.9999]
2025-03-11 21:02:29 - Train Iteration 9978: loss: 0.0173, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.8689, 0.9953]
2025-03-11 21:02:30 - Train Iteration 9979: loss: 0.0921, d_k_M range: [0.0000, 0.0165], d_k_M_hat range: [0.6965, 0.9978]
2025-03-11 21:02:30 - Train Iteration 9980: loss: 0.0128, d_k_M range: [0.0000, 0.0255], d_k_M_hat range: [0.8868, 0.9974]
2025-03-11 21:02:31 - Train Iteration 9981: loss: 0.0102, d_k_M range: [0.0001, 0.0886], d_k_M_hat range: [0.9423, 0.9998]
2025-03-11 21:02:31 - Train Iteration 9982: loss: 0.5357, d_k_M range: [0.0010, 0.7318], d_k_M_hat range: [0.9887, 0.9999]
2025-03-11 21:02:31 - Train Iteration 9983: loss: 0.7646, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.1256, 0.9934]
2025-03-11 21:02:32 - Train Iteration 9984: loss: 0.0522, d_k_M range: [0.0003, 0.2270], d_k_M_hat range: [0.9624, 0.9986]
2025-03-11 21:02:32 - Train Iteration 9985: loss: 0.0419, d_k_M range: [0.0000, 0.1537], d_k_M_hat range: [0.7952, 0.9994]
2025-03-11 21:02:33 - Train Iteration 9986: loss: 0.1969, d_k_M range: [0.0000, 0.1996], d_k_M_hat range: [0.5563, 0.9978]
2025-03-11 21:02:33 - Train Iteration 9987: loss: 0.0084, d_k_M range: [0.0000, 0.0882], d_k_M_hat range: [0.9332, 0.9964]
2025-03-11 21:02:34 - Train Iteration 9988: loss: 0.0183, d_k_M range: [0.0002, 0.1335], d_k_M_hat range: [0.9631, 0.9988]
2025-03-11 21:02:34 - Train Iteration 9989: loss: 0.1659, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.5928, 0.9960]
2025-03-11 21:02:34 - Train Iteration 9990: loss: 0.0083, d_k_M range: [0.0001, 0.0196], d_k_M_hat range: [0.9197, 0.9997]
2025-03-11 21:02:35 - Train Iteration 9991: loss: 0.0192, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.8619, 0.9992]
2025-03-11 21:02:35 - Train Iteration 9992: loss: 0.1303, d_k_M range: [0.0000, 0.3591], d_k_M_hat range: [0.9489, 0.9997]
2025-03-11 21:02:36 - Train Iteration 9993: loss: 0.1584, d_k_M range: [0.0000, 0.0102], d_k_M_hat range: [0.6021, 0.9961]
2025-03-11 21:02:36 - Train Iteration 9994: loss: 0.0041, d_k_M range: [0.0001, 0.0476], d_k_M_hat range: [0.9836, 0.9997]
2025-03-11 21:02:37 - Train Iteration 9995: loss: 0.0109, d_k_M range: [0.0000, 0.0057], d_k_M_hat range: [0.8980, 0.9997]
2025-03-11 21:02:37 - Train Iteration 9996: loss: 0.0638, d_k_M range: [0.0001, 0.0430], d_k_M_hat range: [0.7476, 0.9992]
2025-03-11 21:02:38 - Train Iteration 9997: loss: 0.0942, d_k_M range: [0.0000, 0.2470], d_k_M_hat range: [0.6931, 0.9999]
2025-03-11 21:02:38 - Train Iteration 9998: loss: 0.0137, d_k_M range: [0.0002, 0.1165], d_k_M_hat range: [0.9658, 0.9998]
2025-03-11 21:02:38 - Train Iteration 9999: loss: 0.0178, d_k_M range: [0.0000, 0.0955], d_k_M_hat range: [0.8706, 0.9993]
2025-03-11 21:02:39 - Train Iteration 10000: loss: 0.0734, d_k_M range: [0.0000, 0.2181], d_k_M_hat range: [0.8195, 0.9982]
2025-03-11 21:02:39 - Train Iteration 10001: loss: 0.0065, d_k_M range: [0.0000, 0.0805], d_k_M_hat range: [0.9437, 0.9999]
2025-03-11 21:02:40 - Train Iteration 10002: loss: 0.0986, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.6860, 0.9963]
2025-03-11 21:02:40 - Train Iteration 10003: loss: 0.3159, d_k_M range: [0.0000, 0.1505], d_k_M_hat range: [0.4380, 0.9988]
2025-03-11 21:02:41 - Train Iteration 10004: loss: 0.0204, d_k_M range: [0.0002, 0.1104], d_k_M_hat range: [0.8573, 0.9996]
2025-03-11 21:02:41 - Train Iteration 10005: loss: 0.1345, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.6336, 0.9904]
2025-03-11 21:02:41 - Train Iteration 10006: loss: 0.8883, d_k_M range: [0.0000, 0.9424], d_k_M_hat range: [0.9765, 0.9999]
2025-03-11 21:02:42 - Train Iteration 10007: loss: 0.0517, d_k_M range: [0.0000, 0.2270], d_k_M_hat range: [0.9013, 0.9996]
2025-03-11 21:02:42 - Train Iteration 10008: loss: 0.0014, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.9645, 0.9983]
2025-03-11 21:02:43 - Train Iteration 10009: loss: 0.0597, d_k_M range: [0.0003, 0.2441], d_k_M_hat range: [0.9561, 0.9997]
2025-03-11 21:02:43 - Train Iteration 10010: loss: 0.3385, d_k_M range: [0.0000, 0.0057], d_k_M_hat range: [0.4182, 0.9903]
2025-03-11 21:02:43 - Train Iteration 10011: loss: 0.2011, d_k_M range: [0.0002, 0.4481], d_k_M_hat range: [0.9857, 0.9997]
2025-03-11 21:02:44 - Train Iteration 10012: loss: 0.0152, d_k_M range: [0.0003, 0.0135], d_k_M_hat range: [0.8773, 0.9989]
2025-03-11 21:02:44 - Train Iteration 10013: loss: 0.0109, d_k_M range: [0.0000, 0.0310], d_k_M_hat range: [0.9052, 0.9997]
2025-03-11 21:02:45 - Train Iteration 10014: loss: 0.2167, d_k_M range: [0.0004, 0.4595], d_k_M_hat range: [0.8966, 0.9979]
2025-03-11 21:02:45 - Train Iteration 10015: loss: 0.0471, d_k_M range: [0.0000, 0.0700], d_k_M_hat range: [0.7856, 0.9994]
2025-03-11 21:02:46 - Train Iteration 10016: loss: 0.0036, d_k_M range: [0.0000, 0.0560], d_k_M_hat range: [0.9403, 0.9994]
2025-03-11 21:02:46 - Train Iteration 10017: loss: 0.9726, d_k_M range: [0.0001, 0.9862], d_k_M_hat range: [0.9453, 1.0000]
2025-03-11 21:02:46 - Train Iteration 10018: loss: 0.0214, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.8554, 0.9976]
2025-03-11 21:02:47 - Train Iteration 10019: loss: 0.9819, d_k_M range: [0.0027, 0.9909], d_k_M_hat range: [0.9861, 1.0000]
2025-03-11 21:02:47 - Train Iteration 10020: loss: 0.0199, d_k_M range: [0.0003, 0.0562], d_k_M_hat range: [0.8594, 0.9968]
2025-03-11 21:02:48 - Train Iteration 10021: loss: 0.0077, d_k_M range: [0.0002, 0.0872], d_k_M_hat range: [0.9842, 0.9998]
2025-03-11 21:02:48 - Train Iteration 10022: loss: 0.0371, d_k_M range: [0.0000, 0.0254], d_k_M_hat range: [0.8139, 0.9997]
2025-03-11 21:02:49 - Train Iteration 10023: loss: 0.8887, d_k_M range: [0.0001, 0.1343], d_k_M_hat range: [0.0573, 0.9999]
2025-03-11 21:02:49 - Train Iteration 10024: loss: 0.2129, d_k_M range: [0.0004, 0.4594], d_k_M_hat range: [0.9158, 0.9991]
2025-03-11 21:02:49 - Train Iteration 10025: loss: 0.0019, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9576, 0.9971]
2025-03-11 21:02:50 - Train Iteration 10026: loss: 0.2798, d_k_M range: [0.0016, 0.5276], d_k_M_hat range: [0.8614, 0.9999]
2025-03-11 21:02:50 - Train Iteration 10027: loss: 0.5731, d_k_M range: [0.0000, 0.0913], d_k_M_hat range: [0.2429, 0.9983]
2025-03-11 21:02:51 - Train Iteration 10028: loss: 0.0517, d_k_M range: [0.0029, 0.2255], d_k_M_hat range: [0.9676, 0.9997]
2025-03-11 21:02:51 - Train Iteration 10029: loss: 0.0098, d_k_M range: [0.0000, 0.0131], d_k_M_hat range: [0.9083, 0.9968]
2025-03-11 21:02:52 - Train Iteration 10030: loss: 0.0123, d_k_M range: [0.0000, 0.0142], d_k_M_hat range: [0.8900, 0.9996]
2025-03-11 21:02:52 - Train Iteration 10031: loss: 0.1979, d_k_M range: [0.0007, 0.4448], d_k_M_hat range: [0.9733, 0.9999]
2025-03-11 21:02:52 - Train Iteration 10032: loss: 0.0058, d_k_M range: [0.0004, 0.0447], d_k_M_hat range: [0.9638, 0.9998]
2025-03-11 21:02:53 - Train Iteration 10033: loss: 0.0031, d_k_M range: [0.0000, 0.0365], d_k_M_hat range: [0.9461, 0.9992]
2025-03-11 21:02:53 - Train Iteration 10034: loss: 0.0392, d_k_M range: [0.0008, 0.1978], d_k_M_hat range: [0.9641, 0.9998]
2025-03-11 21:02:54 - Train Iteration 10035: loss: 0.0097, d_k_M range: [0.0000, 0.0897], d_k_M_hat range: [0.9734, 0.9992]
2025-03-11 21:02:54 - Train Iteration 10036: loss: 0.1096, d_k_M range: [0.0006, 0.3307], d_k_M_hat range: [0.9895, 0.9999]
2025-03-11 21:02:55 - Train Iteration 10037: loss: 0.0267, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.8372, 0.9987]
2025-03-11 21:02:55 - Train Iteration 10038: loss: 0.0314, d_k_M range: [0.0002, 0.1769], d_k_M_hat range: [0.9953, 0.9996]
2025-03-11 21:02:55 - Train Iteration 10039: loss: 0.1051, d_k_M range: [0.0000, 0.1995], d_k_M_hat range: [0.6765, 0.9972]
2025-03-11 21:02:56 - Train Iteration 10040: loss: 0.2797, d_k_M range: [0.0000, 0.5287], d_k_M_hat range: [0.8930, 0.9999]
2025-03-11 21:02:56 - Train Iteration 10041: loss: 0.4437, d_k_M range: [0.0000, 0.0102], d_k_M_hat range: [0.3342, 0.9876]
2025-03-11 21:02:57 - Train Iteration 10042: loss: 0.0186, d_k_M range: [0.0000, 0.1319], d_k_M_hat range: [0.9522, 0.9961]
2025-03-11 21:02:57 - Train Iteration 10043: loss: 0.0063, d_k_M range: [0.0000, 0.0388], d_k_M_hat range: [0.9312, 0.9996]
2025-03-11 21:02:58 - Train Iteration 10044: loss: 0.1762, d_k_M range: [0.0000, 0.4181], d_k_M_hat range: [0.8485, 0.9990]
2025-03-11 21:02:58 - Train Iteration 10045: loss: 0.0554, d_k_M range: [0.0003, 0.1672], d_k_M_hat range: [0.7651, 0.9998]
2025-03-11 21:02:58 - Train Iteration 10046: loss: 0.0118, d_k_M range: [0.0001, 0.0360], d_k_M_hat range: [0.8916, 0.9992]
2025-03-11 21:02:59 - Train Iteration 10047: loss: 0.0049, d_k_M range: [0.0000, 0.0179], d_k_M_hat range: [0.9304, 0.9988]
2025-03-11 21:02:59 - Train Iteration 10048: loss: 0.0697, d_k_M range: [0.0001, 0.2415], d_k_M_hat range: [0.7410, 0.9998]
2025-03-11 21:03:00 - Train Iteration 10049: loss: 0.0780, d_k_M range: [0.0000, 0.0495], d_k_M_hat range: [0.7209, 0.9989]
2025-03-11 21:03:00 - Train Iteration 10050: loss: 0.1141, d_k_M range: [0.0003, 0.3359], d_k_M_hat range: [0.9403, 0.9998]
2025-03-11 21:03:00 - Train Iteration 10051: loss: 0.6382, d_k_M range: [0.0000, 0.3549], d_k_M_hat range: [0.2012, 0.9994]
2025-03-11 21:03:01 - Train Iteration 10052: loss: 0.8403, d_k_M range: [0.0022, 0.9166], d_k_M_hat range: [0.9970, 1.0000]
2025-03-11 21:03:01 - Train Iteration 10053: loss: 0.0221, d_k_M range: [0.0001, 0.1472], d_k_M_hat range: [0.9313, 0.9986]
2025-03-11 21:03:02 - Train Iteration 10054: loss: 0.0147, d_k_M range: [0.0000, 0.0868], d_k_M_hat range: [0.8792, 0.9989]
2025-03-11 21:03:02 - Train Iteration 10055: loss: 0.1175, d_k_M range: [0.0000, 0.0377], d_k_M_hat range: [0.6572, 1.0000]
2025-03-11 21:03:03 - Train Iteration 10056: loss: 0.1870, d_k_M range: [0.0003, 0.4321], d_k_M_hat range: [0.9930, 0.9999]
2025-03-11 21:03:03 - Train Iteration 10057: loss: 0.0157, d_k_M range: [0.0003, 0.0785], d_k_M_hat range: [0.8750, 0.9998]
2025-03-11 21:03:03 - Train Iteration 10058: loss: 0.7746, d_k_M range: [0.0000, 0.0621], d_k_M_hat range: [0.1200, 0.9849]
2025-03-11 21:03:04 - Train Iteration 10059: loss: 0.4454, d_k_M range: [0.0001, 0.6669], d_k_M_hat range: [0.7551, 0.9999]
2025-03-11 21:03:04 - Train Iteration 10060: loss: 0.0052, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9291, 0.9987]
2025-03-11 21:03:05 - Train Iteration 10061: loss: 0.0490, d_k_M range: [0.0005, 0.2205], d_k_M_hat range: [0.9819, 0.9994]
2025-03-11 21:03:05 - Train Iteration 10062: loss: 0.0368, d_k_M range: [0.0000, 0.0260], d_k_M_hat range: [0.8083, 0.9957]
2025-03-11 21:03:05 - Train Iteration 10063: loss: 0.0169, d_k_M range: [0.0000, 0.0568], d_k_M_hat range: [0.9267, 0.9971]
2025-03-11 21:03:06 - Train Iteration 10064: loss: 0.0289, d_k_M range: [0.0001, 0.1697], d_k_M_hat range: [0.9303, 0.9996]
2025-03-11 21:03:06 - Train Iteration 10065: loss: 0.0048, d_k_M range: [0.0006, 0.0695], d_k_M_hat range: [0.9522, 0.9999]
2025-03-11 21:03:07 - Train Iteration 10066: loss: 0.0796, d_k_M range: [0.0000, 0.0380], d_k_M_hat range: [0.7361, 0.9983]
2025-03-11 21:03:07 - Train Iteration 10067: loss: 0.0915, d_k_M range: [0.0001, 0.2991], d_k_M_hat range: [0.9611, 0.9984]
2025-03-11 21:03:07 - Train Iteration 10068: loss: 0.0327, d_k_M range: [0.0000, 0.1226], d_k_M_hat range: [0.8195, 0.9965]
2025-03-11 21:03:08 - Train Iteration 10069: loss: 0.5883, d_k_M range: [0.0003, 0.7670], d_k_M_hat range: [0.9766, 1.0000]
2025-03-11 21:03:08 - Train Iteration 10070: loss: 0.3423, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.4149, 0.9666]
2025-03-11 21:03:09 - Train Iteration 10071: loss: 0.4646, d_k_M range: [0.0004, 0.6815], d_k_M_hat range: [0.9568, 0.9998]
2025-03-11 21:03:09 - Train Iteration 10072: loss: 0.0596, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.7560, 0.9899]
2025-03-11 21:03:10 - Train Iteration 10073: loss: 0.5931, d_k_M range: [0.0003, 0.7701], d_k_M_hat range: [0.9974, 1.0000]
2025-03-11 21:03:10 - Train Iteration 10074: loss: 0.0379, d_k_M range: [0.0000, 0.0328], d_k_M_hat range: [0.8061, 0.9985]
2025-03-11 21:03:10 - Train Iteration 10075: loss: 0.0579, d_k_M range: [0.0000, 0.2398], d_k_M_hat range: [0.9669, 0.9992]
2025-03-11 21:03:11 - Train Iteration 10076: loss: 0.1669, d_k_M range: [0.0000, 0.2375], d_k_M_hat range: [0.6024, 0.9966]
2025-03-11 21:03:11 - Train Iteration 10077: loss: 0.0191, d_k_M range: [0.0003, 0.1360], d_k_M_hat range: [0.9564, 0.9999]
2025-03-11 21:03:12 - Train Iteration 10078: loss: 0.0036, d_k_M range: [0.0000, 0.0162], d_k_M_hat range: [0.9400, 0.9992]
2025-03-11 21:03:12 - Train Iteration 10079: loss: 0.0373, d_k_M range: [0.0000, 0.1913], d_k_M_hat range: [0.9737, 0.9998]
2025-03-11 21:03:13 - Train Iteration 10080: loss: 0.4688, d_k_M range: [0.0000, 0.6845], d_k_M_hat range: [0.9472, 0.9999]
2025-03-11 21:03:13 - Train Iteration 10081: loss: 0.1530, d_k_M range: [0.0000, 0.0204], d_k_M_hat range: [0.6089, 0.9950]
2025-03-11 21:03:14 - Train Iteration 10082: loss: 0.4566, d_k_M range: [0.0006, 0.6756], d_k_M_hat range: [0.9971, 0.9998]
2025-03-11 21:03:14 - Train Iteration 10083: loss: 0.0829, d_k_M range: [0.0000, 0.0168], d_k_M_hat range: [0.7122, 0.9948]
2025-03-11 21:03:14 - Train Iteration 10084: loss: 0.2001, d_k_M range: [0.0013, 0.4465], d_k_M_hat range: [0.9870, 0.9994]
2025-03-11 21:03:15 - Train Iteration 10085: loss: 0.0219, d_k_M range: [0.0000, 0.1431], d_k_M_hat range: [0.9777, 0.9994]
2025-03-11 21:03:15 - Train Iteration 10086: loss: 0.0724, d_k_M range: [0.0000, 0.0539], d_k_M_hat range: [0.7372, 0.9963]
2025-03-11 21:03:16 - Train Iteration 10087: loss: 0.2953, d_k_M range: [0.0000, 0.5434], d_k_M_hat range: [0.9597, 1.0000]
2025-03-11 21:03:16 - Train Iteration 10088: loss: 0.0320, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.8223, 0.9953]
2025-03-11 21:03:17 - Train Iteration 10089: loss: 0.0088, d_k_M range: [0.0000, 0.0919], d_k_M_hat range: [0.9388, 0.9982]
2025-03-11 21:03:17 - Train Iteration 10090: loss: 0.1230, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.6493, 0.9993]
2025-03-11 21:03:17 - Train Iteration 10091: loss: 0.0024, d_k_M range: [0.0000, 0.0152], d_k_M_hat range: [0.9512, 0.9994]
2025-03-11 21:03:18 - Train Iteration 10092: loss: 0.0177, d_k_M range: [0.0000, 0.0071], d_k_M_hat range: [0.8669, 0.9987]
2025-03-11 21:03:18 - Train Iteration 10093: loss: 0.0032, d_k_M range: [0.0000, 0.0160], d_k_M_hat range: [0.9441, 0.9992]
2025-03-11 21:03:19 - Train Iteration 10094: loss: 0.0023, d_k_M range: [0.0001, 0.0150], d_k_M_hat range: [0.9543, 0.9997]
2025-03-11 21:03:19 - Train Iteration 10095: loss: 0.0342, d_k_M range: [0.0001, 0.0036], d_k_M_hat range: [0.8150, 0.9830]
2025-03-11 21:03:20 - Train Iteration 10096: loss: 0.0028, d_k_M range: [0.0001, 0.0069], d_k_M_hat range: [0.9469, 0.9995]
2025-03-11 21:03:20 - Train Iteration 10097: loss: 0.3921, d_k_M range: [0.0001, 0.0377], d_k_M_hat range: [0.3757, 0.9933]
2025-03-11 21:03:21 - Train Iteration 10098: loss: 0.9497, d_k_M range: [0.0204, 0.9745], d_k_M_hat range: [0.9978, 1.0000]
2025-03-11 21:03:21 - Train Iteration 10099: loss: 0.4617, d_k_M range: [0.0010, 0.6794], d_k_M_hat range: [0.9823, 0.9999]
2025-03-11 21:03:22 - Train Iteration 10100: loss: 0.2765, d_k_M range: [0.0000, 0.0095], d_k_M_hat range: [0.4742, 0.9969]
2025-03-11 21:03:22 - Train Iteration 10101: loss: 0.0127, d_k_M range: [0.0000, 0.0443], d_k_M_hat range: [0.8946, 0.9997]
2025-03-11 21:03:23 - Train Iteration 10102: loss: 0.4362, d_k_M range: [0.0001, 0.4117], d_k_M_hat range: [0.3396, 0.9976]
2025-03-11 21:03:23 - Train Iteration 10103: loss: 0.6691, d_k_M range: [0.0002, 0.8179], d_k_M_hat range: [0.9800, 0.9999]
2025-03-11 21:03:23 - Train Iteration 10104: loss: 0.0180, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.8660, 0.9987]
2025-03-11 21:03:24 - Train Iteration 10105: loss: 0.0503, d_k_M range: [0.0000, 0.2177], d_k_M_hat range: [0.7878, 0.9997]
2025-03-11 21:03:24 - Train Iteration 10106: loss: 0.0708, d_k_M range: [0.0007, 0.2639], d_k_M_hat range: [0.9750, 0.9999]
2025-03-11 21:03:25 - Train Iteration 10107: loss: 0.0432, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.7923, 0.9989]
2025-03-11 21:03:25 - Train Iteration 10108: loss: 0.1316, d_k_M range: [0.0000, 0.3602], d_k_M_hat range: [0.9806, 0.9994]
2025-03-11 21:03:26 - Train Iteration 10109: loss: 0.0260, d_k_M range: [0.0000, 0.1438], d_k_M_hat range: [0.8540, 0.9995]
2025-03-11 21:03:26 - Train Iteration 10110: loss: 0.0307, d_k_M range: [0.0000, 0.0610], d_k_M_hat range: [0.8566, 0.9990]
2025-03-11 21:03:26 - Train Iteration 10111: loss: 0.4451, d_k_M range: [0.0010, 0.6666], d_k_M_hat range: [0.9279, 0.9998]
2025-03-11 21:03:27 - Train Iteration 10112: loss: 0.1438, d_k_M range: [0.0001, 0.0110], d_k_M_hat range: [0.6241, 0.9973]
2025-03-11 21:03:27 - Train Iteration 10113: loss: 0.0152, d_k_M range: [0.0001, 0.1060], d_k_M_hat range: [0.9736, 0.9984]
2025-03-11 21:03:28 - Train Iteration 10114: loss: 0.4124, d_k_M range: [0.0000, 0.6418], d_k_M_hat range: [0.9826, 0.9999]
2025-03-11 21:03:28 - Train Iteration 10115: loss: 0.1224, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.6501, 0.9906]
2025-03-11 21:03:28 - Train Iteration 10116: loss: 0.2238, d_k_M range: [0.0001, 0.1347], d_k_M_hat range: [0.5271, 0.9991]
2025-03-11 21:03:29 - Train Iteration 10117: loss: 0.1526, d_k_M range: [0.0010, 0.3894], d_k_M_hat range: [0.9014, 0.9998]
2025-03-11 21:03:29 - Train Iteration 10118: loss: 0.3000, d_k_M range: [0.0000, 0.0502], d_k_M_hat range: [0.4524, 0.9972]
2025-03-11 21:03:30 - Train Iteration 10119: loss: 0.9815, d_k_M range: [0.0080, 0.9907], d_k_M_hat range: [0.9878, 1.0000]
2025-03-11 21:03:30 - Train Iteration 10120: loss: 0.0131, d_k_M range: [0.0000, 0.0684], d_k_M_hat range: [0.8860, 0.9988]
2025-03-11 21:03:30 - Train Iteration 10121: loss: 0.0060, d_k_M range: [0.0001, 0.0696], d_k_M_hat range: [0.9274, 0.9993]
2025-03-11 21:03:31 - Train Iteration 10122: loss: 0.2388, d_k_M range: [0.0002, 0.4837], d_k_M_hat range: [0.9520, 1.0000]
2025-03-11 21:03:31 - Train Iteration 10123: loss: 0.0037, d_k_M range: [0.0011, 0.0554], d_k_M_hat range: [0.9709, 0.9996]
2025-03-11 21:03:32 - Train Iteration 10124: loss: 0.0200, d_k_M range: [0.0000, 0.0366], d_k_M_hat range: [0.8586, 0.9905]
2025-03-11 21:03:32 - Train Iteration 10125: loss: 0.0349, d_k_M range: [0.0000, 0.1817], d_k_M_hat range: [0.9344, 0.9989]
2025-03-11 21:03:33 - Train Iteration 10126: loss: 0.1368, d_k_M range: [0.0000, 0.0129], d_k_M_hat range: [0.6303, 0.9986]
2025-03-11 21:03:33 - Train Iteration 10127: loss: 0.0112, d_k_M range: [0.0000, 0.1049], d_k_M_hat range: [0.9534, 0.9993]
2025-03-11 21:03:34 - Train Iteration 10128: loss: 0.0258, d_k_M range: [0.0000, 0.1525], d_k_M_hat range: [0.8394, 0.9981]
2025-03-11 21:03:34 - Train Iteration 10129: loss: 0.6349, d_k_M range: [0.0000, 0.0200], d_k_M_hat range: [0.2032, 0.9971]
2025-03-11 21:03:34 - Train Iteration 10130: loss: 0.0080, d_k_M range: [0.0007, 0.0840], d_k_M_hat range: [0.9839, 0.9995]
2025-03-11 21:03:35 - Train Iteration 10131: loss: 0.0284, d_k_M range: [0.0000, 0.1655], d_k_M_hat range: [0.9584, 0.9984]
2025-03-11 21:03:35 - Train Iteration 10132: loss: 0.6471, d_k_M range: [0.0000, 0.0285], d_k_M_hat range: [0.1956, 0.9992]
2025-03-11 21:03:36 - Train Iteration 10133: loss: 0.0030, d_k_M range: [0.0001, 0.0134], d_k_M_hat range: [0.9525, 0.9993]
2025-03-11 21:03:36 - Train Iteration 10134: loss: 0.0610, d_k_M range: [0.0002, 0.2466], d_k_M_hat range: [0.9283, 0.9998]
2025-03-11 21:03:37 - Train Iteration 10135: loss: 0.8316, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.0881, 0.9854]
2025-03-11 21:03:37 - Train Iteration 10136: loss: 0.0334, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.8176, 0.9955]
2025-03-11 21:03:37 - Train Iteration 10137: loss: 0.4612, d_k_M range: [0.0030, 0.6780], d_k_M_hat range: [0.8955, 0.9999]
2025-03-11 21:03:38 - Train Iteration 10138: loss: 0.1829, d_k_M range: [0.0000, 0.0538], d_k_M_hat range: [0.5776, 0.9990]
2025-03-11 21:03:38 - Train Iteration 10139: loss: 0.0048, d_k_M range: [0.0000, 0.0256], d_k_M_hat range: [0.9325, 0.9997]
2025-03-11 21:03:39 - Train Iteration 10140: loss: 0.3151, d_k_M range: [0.0000, 0.0079], d_k_M_hat range: [0.4386, 0.9658]
2025-03-11 21:03:39 - Train Iteration 10141: loss: 0.1946, d_k_M range: [0.0003, 0.4410], d_k_M_hat range: [0.9914, 0.9999]
2025-03-11 21:03:39 - Train Iteration 10142: loss: 0.0891, d_k_M range: [0.0000, 0.1303], d_k_M_hat range: [0.7015, 0.9988]
2025-03-11 21:03:40 - Train Iteration 10143: loss: 0.0566, d_k_M range: [0.0006, 0.2374], d_k_M_hat range: [0.9542, 0.9994]
2025-03-11 21:03:40 - Train Iteration 10144: loss: 0.0021, d_k_M range: [0.0000, 0.0094], d_k_M_hat range: [0.9543, 0.9939]
2025-03-11 21:03:41 - Train Iteration 10145: loss: 0.0453, d_k_M range: [0.0000, 0.0629], d_k_M_hat range: [0.7879, 0.9999]
2025-03-11 21:03:41 - Train Iteration 10146: loss: 0.0184, d_k_M range: [0.0001, 0.0436], d_k_M_hat range: [0.8644, 0.9999]
2025-03-11 21:03:42 - Train Iteration 10147: loss: 0.3574, d_k_M range: [0.0010, 0.5978], d_k_M_hat range: [0.9802, 0.9999]
2025-03-11 21:03:42 - Train Iteration 10148: loss: 0.6567, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.1906, 0.9845]
2025-03-11 21:03:43 - Train Iteration 10149: loss: 0.0137, d_k_M range: [0.0001, 0.1160], d_k_M_hat range: [0.9708, 0.9994]
2025-03-11 21:03:44 - Train Iteration 10150: loss: 0.4539, d_k_M range: [0.0001, 0.6725], d_k_M_hat range: [0.9429, 0.9988]
2025-03-11 21:03:44 - Train Iteration 10151: loss: 0.3381, d_k_M range: [0.0000, 0.0075], d_k_M_hat range: [0.4186, 0.9990]
2025-03-11 21:03:44 - Train Iteration 10152: loss: 0.1959, d_k_M range: [0.0006, 0.4425], d_k_M_hat range: [0.9798, 0.9999]
2025-03-11 21:03:45 - Train Iteration 10153: loss: 0.1084, d_k_M range: [0.0006, 0.0072], d_k_M_hat range: [0.6748, 0.9964]
2025-03-11 21:03:45 - Train Iteration 10154: loss: 0.0219, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.8522, 0.9976]
2025-03-11 21:03:46 - Train Iteration 10155: loss: 0.0024, d_k_M range: [0.0000, 0.0101], d_k_M_hat range: [0.9505, 0.9981]
2025-03-11 21:03:46 - Train Iteration 10156: loss: 0.5344, d_k_M range: [0.0012, 0.7303], d_k_M_hat range: [0.6531, 0.9999]
2025-03-11 21:03:46 - Train Iteration 10157: loss: 0.7816, d_k_M range: [0.0000, 0.0515], d_k_M_hat range: [0.1195, 0.9950]
2025-03-11 21:03:47 - Train Iteration 10158: loss: 0.0082, d_k_M range: [0.0000, 0.0816], d_k_M_hat range: [0.9434, 0.9996]
2025-03-11 21:03:47 - Train Iteration 10159: loss: 0.0606, d_k_M range: [0.0000, 0.2435], d_k_M_hat range: [0.7891, 0.9974]
2025-03-11 21:03:48 - Train Iteration 10160: loss: 0.0776, d_k_M range: [0.0001, 0.2755], d_k_M_hat range: [0.9289, 0.9989]
2025-03-11 21:03:48 - Train Iteration 10161: loss: 0.0290, d_k_M range: [0.0004, 0.1692], d_k_M_hat range: [0.9584, 0.9995]
2025-03-11 21:03:48 - Train Iteration 10162: loss: 0.0369, d_k_M range: [0.0000, 0.0334], d_k_M_hat range: [0.8079, 0.9969]
2025-03-11 21:03:49 - Train Iteration 10163: loss: 0.0278, d_k_M range: [0.0021, 0.1655], d_k_M_hat range: [0.9898, 0.9999]
2025-03-11 21:03:49 - Train Iteration 10164: loss: 0.0317, d_k_M range: [0.0001, 0.1634], d_k_M_hat range: [0.8588, 0.9966]
2025-03-11 21:03:50 - Train Iteration 10165: loss: 0.1008, d_k_M range: [0.0020, 0.3131], d_k_M_hat range: [0.8771, 0.9997]
2025-03-11 21:03:50 - Train Iteration 10166: loss: 0.3087, d_k_M range: [0.0001, 0.5497], d_k_M_hat range: [0.9618, 0.9991]
2025-03-11 21:03:51 - Train Iteration 10167: loss: 0.3064, d_k_M range: [0.0000, 0.0166], d_k_M_hat range: [0.4468, 0.9813]
2025-03-11 21:03:51 - Train Iteration 10168: loss: 0.0133, d_k_M range: [0.0000, 0.1134], d_k_M_hat range: [0.9832, 0.9995]
2025-03-11 21:03:51 - Train Iteration 10169: loss: 0.0383, d_k_M range: [0.0001, 0.1917], d_k_M_hat range: [0.8704, 0.9978]
2025-03-11 21:03:52 - Train Iteration 10170: loss: 0.3352, d_k_M range: [0.0024, 0.5784], d_k_M_hat range: [0.9751, 0.9997]
2025-03-11 21:03:52 - Train Iteration 10171: loss: 0.0368, d_k_M range: [0.0001, 0.0135], d_k_M_hat range: [0.8087, 0.9977]
2025-03-11 21:03:53 - Train Iteration 10172: loss: 0.0091, d_k_M range: [0.0000, 0.0312], d_k_M_hat range: [0.9045, 0.9995]
2025-03-11 21:03:53 - Train Iteration 10173: loss: 0.0229, d_k_M range: [0.0003, 0.1505], d_k_M_hat range: [0.8849, 0.9992]
2025-03-11 21:03:53 - Train Iteration 10174: loss: 0.0072, d_k_M range: [0.0001, 0.0825], d_k_M_hat range: [0.9730, 0.9989]
2025-03-11 21:03:54 - Train Iteration 10175: loss: 0.0764, d_k_M range: [0.0008, 0.0708], d_k_M_hat range: [0.7245, 0.9991]
2025-03-11 21:03:54 - Train Iteration 10176: loss: 0.0773, d_k_M range: [0.0001, 0.2758], d_k_M_hat range: [0.9657, 0.9996]
2025-03-11 21:03:55 - Train Iteration 10177: loss: 0.0177, d_k_M range: [0.0004, 0.0913], d_k_M_hat range: [0.8677, 0.9998]
2025-03-11 21:03:55 - Train Iteration 10178: loss: 0.0359, d_k_M range: [0.0002, 0.1631], d_k_M_hat range: [0.8111, 0.9989]
2025-03-11 21:03:56 - Train Iteration 10179: loss: 0.0152, d_k_M range: [0.0000, 0.0911], d_k_M_hat range: [0.8767, 0.9978]
2025-03-11 21:03:56 - Train Iteration 10180: loss: 0.0021, d_k_M range: [0.0000, 0.0431], d_k_M_hat range: [0.9638, 0.9974]
2025-03-11 21:03:57 - Train Iteration 10181: loss: 0.0077, d_k_M range: [0.0003, 0.0442], d_k_M_hat range: [0.9564, 0.9966]
2025-03-11 21:03:57 - Train Iteration 10182: loss: 0.2624, d_k_M range: [0.0000, 0.5115], d_k_M_hat range: [0.6257, 0.9993]
2025-03-11 21:03:57 - Train Iteration 10183: loss: 0.2193, d_k_M range: [0.0001, 0.0460], d_k_M_hat range: [0.5356, 0.9961]
2025-03-11 21:03:58 - Train Iteration 10184: loss: 0.1454, d_k_M range: [0.0001, 0.3812], d_k_M_hat range: [0.9864, 1.0000]
2025-03-11 21:03:58 - Train Iteration 10185: loss: 0.0100, d_k_M range: [0.0000, 0.0854], d_k_M_hat range: [0.9004, 0.9991]
2025-03-11 21:03:59 - Train Iteration 10186: loss: 0.0572, d_k_M range: [0.0003, 0.2355], d_k_M_hat range: [0.9783, 0.9993]
2025-03-11 21:03:59 - Train Iteration 10187: loss: 0.0100, d_k_M range: [0.0000, 0.0991], d_k_M_hat range: [0.9187, 0.9994]
2025-03-11 21:03:59 - Train Iteration 10188: loss: 0.0063, d_k_M range: [0.0000, 0.0214], d_k_M_hat range: [0.9204, 0.9992]
2025-03-11 21:04:00 - Train Iteration 10189: loss: 0.0054, d_k_M range: [0.0000, 0.0731], d_k_M_hat range: [0.9542, 0.9998]
2025-03-11 21:04:00 - Train Iteration 10190: loss: 0.0187, d_k_M range: [0.0000, 0.0418], d_k_M_hat range: [0.8632, 0.9948]
2025-03-11 21:04:01 - Train Iteration 10191: loss: 0.0098, d_k_M range: [0.0003, 0.0860], d_k_M_hat range: [0.9374, 0.9984]
2025-03-11 21:04:01 - Train Iteration 10192: loss: 0.1453, d_k_M range: [0.0009, 0.3702], d_k_M_hat range: [0.9383, 0.9975]
2025-03-11 21:04:02 - Train Iteration 10193: loss: 0.0220, d_k_M range: [0.0000, 0.0184], d_k_M_hat range: [0.8685, 0.9998]
2025-03-11 21:04:02 - Train Iteration 10194: loss: 0.3743, d_k_M range: [0.0003, 0.6102], d_k_M_hat range: [0.9572, 0.9999]
2025-03-11 21:04:03 - Train Iteration 10195: loss: 0.9065, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.0479, 0.9903]
2025-03-11 21:04:03 - Train Iteration 10196: loss: 0.0035, d_k_M range: [0.0001, 0.0441], d_k_M_hat range: [0.9410, 0.9985]
2025-03-11 21:04:04 - Train Iteration 10197: loss: 0.3242, d_k_M range: [0.0000, 0.5656], d_k_M_hat range: [0.9904, 0.9997]
2025-03-11 21:04:04 - Train Iteration 10198: loss: 0.0258, d_k_M range: [0.0002, 0.0155], d_k_M_hat range: [0.8400, 0.9959]
2025-03-11 21:04:04 - Train Iteration 10199: loss: 0.1441, d_k_M range: [0.0005, 0.3796], d_k_M_hat range: [0.9888, 0.9999]
2025-03-11 21:04:05 - Train Iteration 10200: loss: 0.7962, d_k_M range: [0.0000, 0.0805], d_k_M_hat range: [0.1077, 0.9968]
2025-03-11 21:04:05 - Train Iteration 10201: loss: 0.1370, d_k_M range: [0.0000, 0.3458], d_k_M_hat range: [0.6299, 0.9999]
2025-03-11 21:04:06 - Train Iteration 10202: loss: 0.3715, d_k_M range: [0.0006, 0.6060], d_k_M_hat range: [0.9622, 1.0000]
2025-03-11 21:04:06 - Train Iteration 10203: loss: 0.4042, d_k_M range: [0.0000, 0.0601], d_k_M_hat range: [0.3649, 0.9922]
2025-03-11 21:04:07 - Train Iteration 10204: loss: 0.0439, d_k_M range: [0.0001, 0.2068], d_k_M_hat range: [0.9492, 0.9992]
2025-03-11 21:04:07 - Train Iteration 10205: loss: 0.0047, d_k_M range: [0.0004, 0.0111], d_k_M_hat range: [0.9330, 0.9967]
2025-03-11 21:04:07 - Train Iteration 10206: loss: 0.0412, d_k_M range: [0.0000, 0.1493], d_k_M_hat range: [0.9236, 0.9960]
2025-03-11 21:04:08 - Train Iteration 10207: loss: 0.4299, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.3443, 0.9989]
2025-03-11 21:04:08 - Train Iteration 10208: loss: 0.8402, d_k_M range: [0.0014, 0.9166], d_k_M_hat range: [0.9843, 1.0000]
2025-03-11 21:04:09 - Train Iteration 10209: loss: 0.0025, d_k_M range: [0.0001, 0.0470], d_k_M_hat range: [0.9583, 0.9997]
2025-03-11 21:04:09 - Train Iteration 10210: loss: 0.0600, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.7550, 0.9986]
2025-03-11 21:04:10 - Train Iteration 10211: loss: 0.0244, d_k_M range: [0.0001, 0.0815], d_k_M_hat range: [0.8441, 0.9990]
2025-03-11 21:04:10 - Train Iteration 10212: loss: 0.0098, d_k_M range: [0.0002, 0.0963], d_k_M_hat range: [0.9089, 0.9997]
2025-03-11 21:04:10 - Train Iteration 10213: loss: 0.0014, d_k_M range: [0.0000, 0.0312], d_k_M_hat range: [0.9620, 0.9981]
2025-03-11 21:04:11 - Train Iteration 10214: loss: 0.1033, d_k_M range: [0.0000, 0.0632], d_k_M_hat range: [0.6787, 0.9997]
2025-03-11 21:04:11 - Train Iteration 10215: loss: 0.0281, d_k_M range: [0.0004, 0.1670], d_k_M_hat range: [0.8842, 0.9999]
2025-03-11 21:04:12 - Train Iteration 10216: loss: 0.0174, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.8694, 0.9961]
2025-03-11 21:04:12 - Train Iteration 10217: loss: 0.0107, d_k_M range: [0.0008, 0.0887], d_k_M_hat range: [0.9219, 0.9981]
2025-03-11 21:04:12 - Train Iteration 10218: loss: 0.1025, d_k_M range: [0.0000, 0.0559], d_k_M_hat range: [0.6800, 0.9956]
2025-03-11 21:04:13 - Train Iteration 10219: loss: 0.1148, d_k_M range: [0.0002, 0.0573], d_k_M_hat range: [0.6623, 0.9969]
2025-03-11 21:04:13 - Train Iteration 10220: loss: 0.0055, d_k_M range: [0.0000, 0.0399], d_k_M_hat range: [0.9257, 0.9983]
2025-03-11 21:04:14 - Train Iteration 10221: loss: 0.0198, d_k_M range: [0.0000, 0.0069], d_k_M_hat range: [0.8605, 0.9996]
2025-03-11 21:04:14 - Train Iteration 10222: loss: 0.0500, d_k_M range: [0.0001, 0.2233], d_k_M_hat range: [0.9050, 0.9996]
2025-03-11 21:04:15 - Train Iteration 10223: loss: 0.1034, d_k_M range: [0.0000, 0.1181], d_k_M_hat range: [0.6784, 0.9994]
2025-03-11 21:04:15 - Train Iteration 10224: loss: 0.0029, d_k_M range: [0.0001, 0.0216], d_k_M_hat range: [0.9462, 0.9996]
2025-03-11 21:04:15 - Train Iteration 10225: loss: 0.1808, d_k_M range: [0.0000, 0.4005], d_k_M_hat range: [0.5749, 0.9985]
2025-03-11 21:04:16 - Train Iteration 10226: loss: 0.0134, d_k_M range: [0.0030, 0.1139], d_k_M_hat range: [0.9823, 0.9994]
2025-03-11 21:04:16 - Train Iteration 10227: loss: 0.0016, d_k_M range: [0.0000, 0.0124], d_k_M_hat range: [0.9624, 0.9978]
2025-03-11 21:04:17 - Train Iteration 10228: loss: 0.0256, d_k_M range: [0.0000, 0.0102], d_k_M_hat range: [0.8404, 0.9822]
2025-03-11 21:04:17 - Train Iteration 10229: loss: 0.0859, d_k_M range: [0.0000, 0.0187], d_k_M_hat range: [0.7071, 0.9998]
2025-03-11 21:04:18 - Train Iteration 10230: loss: 0.0170, d_k_M range: [0.0001, 0.1283], d_k_M_hat range: [0.9691, 0.9996]
2025-03-11 21:04:18 - Train Iteration 10231: loss: 0.0428, d_k_M range: [0.0000, 0.2062], d_k_M_hat range: [0.8268, 0.9999]
2025-03-11 21:04:19 - Train Iteration 10232: loss: 0.3595, d_k_M range: [0.0000, 0.5970], d_k_M_hat range: [0.8214, 0.9975]
2025-03-11 21:04:19 - Train Iteration 10233: loss: 0.5900, d_k_M range: [0.0000, 0.0048], d_k_M_hat range: [0.2319, 0.9837]
2025-03-11 21:04:19 - Train Iteration 10234: loss: 0.0089, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9073, 0.9996]
2025-03-11 21:04:20 - Train Iteration 10235: loss: 0.0301, d_k_M range: [0.0002, 0.0630], d_k_M_hat range: [0.8268, 0.9996]
2025-03-11 21:04:20 - Train Iteration 10236: loss: 0.4297, d_k_M range: [0.0000, 0.6553], d_k_M_hat range: [0.8809, 0.9998]
2025-03-11 21:04:21 - Train Iteration 10237: loss: 0.1740, d_k_M range: [0.0000, 0.0171], d_k_M_hat range: [0.5829, 0.9977]
2025-03-11 21:04:21 - Train Iteration 10238: loss: 0.0023, d_k_M range: [0.0001, 0.0064], d_k_M_hat range: [0.9520, 0.9995]
2025-03-11 21:04:21 - Train Iteration 10239: loss: 0.0455, d_k_M range: [0.0000, 0.0285], d_k_M_hat range: [0.7870, 0.9977]
2025-03-11 21:04:22 - Train Iteration 10240: loss: 0.0061, d_k_M range: [0.0014, 0.0483], d_k_M_hat range: [0.9504, 0.9998]
2025-03-11 21:04:22 - Train Iteration 10241: loss: 0.0842, d_k_M range: [0.0000, 0.1406], d_k_M_hat range: [0.7200, 0.9953]
2025-03-11 21:04:23 - Train Iteration 10242: loss: 0.0090, d_k_M range: [0.0001, 0.0126], d_k_M_hat range: [0.9054, 0.9999]
2025-03-11 21:04:23 - Train Iteration 10243: loss: 0.0946, d_k_M range: [0.0001, 0.0063], d_k_M_hat range: [0.6924, 0.9920]
2025-03-11 21:04:23 - Train Iteration 10244: loss: 0.1903, d_k_M range: [0.0000, 0.0252], d_k_M_hat range: [0.5637, 0.9930]
2025-03-11 21:04:24 - Train Iteration 10245: loss: 0.0824, d_k_M range: [0.0025, 0.2871], d_k_M_hat range: [0.9826, 1.0000]
2025-03-11 21:04:24 - Train Iteration 10246: loss: 0.5270, d_k_M range: [0.0000, 0.7241], d_k_M_hat range: [0.8293, 0.9999]
2025-03-11 21:04:25 - Train Iteration 10247: loss: 0.0107, d_k_M range: [0.0001, 0.0458], d_k_M_hat range: [0.8964, 0.9989]
2025-03-11 21:04:25 - Train Iteration 10248: loss: 0.0847, d_k_M range: [0.0000, 0.0245], d_k_M_hat range: [0.7091, 0.9921]
2025-03-11 21:04:26 - Train Iteration 10249: loss: 0.9850, d_k_M range: [0.0000, 0.9924], d_k_M_hat range: [0.5275, 1.0000]
2025-03-11 21:04:26 - Train Iteration 10250: loss: 0.6314, d_k_M range: [0.0005, 0.7946], d_k_M_hat range: [0.9868, 1.0000]
2025-03-11 21:04:27 - Train Iteration 10251: loss: 0.1695, d_k_M range: [0.0000, 0.0863], d_k_M_hat range: [0.5884, 0.9965]
2025-03-11 21:04:27 - Train Iteration 10252: loss: 0.0545, d_k_M range: [0.0001, 0.0185], d_k_M_hat range: [0.7667, 0.9998]
2025-03-11 21:04:27 - Train Iteration 10253: loss: 0.0026, d_k_M range: [0.0008, 0.0288], d_k_M_hat range: [0.9500, 0.9998]
2025-03-11 21:04:28 - Train Iteration 10254: loss: 0.1385, d_k_M range: [0.0002, 0.3656], d_k_M_hat range: [0.9702, 0.9997]
2025-03-11 21:04:28 - Train Iteration 10255: loss: 0.0061, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.9220, 0.9997]
2025-03-11 21:04:29 - Train Iteration 10256: loss: 0.0192, d_k_M range: [0.0000, 0.1249], d_k_M_hat range: [0.9348, 0.9996]
2025-03-11 21:04:29 - Train Iteration 10257: loss: 0.0099, d_k_M range: [0.0001, 0.0277], d_k_M_hat range: [0.9041, 0.9978]
2025-03-11 21:04:29 - Train Iteration 10258: loss: 0.0942, d_k_M range: [0.0002, 0.2557], d_k_M_hat range: [0.7573, 0.9997]
2025-03-11 21:04:30 - Train Iteration 10259: loss: 0.0148, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.8789, 0.9996]
2025-03-11 21:04:30 - Train Iteration 10260: loss: 0.3264, d_k_M range: [0.0000, 0.2349], d_k_M_hat range: [0.4287, 0.9994]
2025-03-11 21:04:31 - Train Iteration 10261: loss: 0.0164, d_k_M range: [0.0000, 0.1263], d_k_M_hat range: [0.9627, 0.9983]
2025-03-11 21:04:31 - Train Iteration 10262: loss: 0.1300, d_k_M range: [0.0006, 0.3518], d_k_M_hat range: [0.9504, 0.9995]
2025-03-11 21:04:32 - Train Iteration 10263: loss: 0.0772, d_k_M range: [0.0001, 0.0277], d_k_M_hat range: [0.7228, 0.9995]
2025-03-11 21:04:32 - Train Iteration 10264: loss: 0.0316, d_k_M range: [0.0000, 0.0073], d_k_M_hat range: [0.8222, 0.9987]
2025-03-11 21:04:32 - Train Iteration 10265: loss: 0.0055, d_k_M range: [0.0005, 0.0735], d_k_M_hat range: [0.9603, 0.9993]
2025-03-11 21:04:33 - Train Iteration 10266: loss: 0.1687, d_k_M range: [0.0000, 0.4102], d_k_M_hat range: [0.9541, 0.9999]
2025-03-11 21:04:33 - Train Iteration 10267: loss: 0.0288, d_k_M range: [0.0000, 0.0055], d_k_M_hat range: [0.8311, 0.9978]
2025-03-11 21:04:34 - Train Iteration 10268: loss: 0.0203, d_k_M range: [0.0000, 0.0196], d_k_M_hat range: [0.8581, 0.9985]
2025-03-11 21:04:34 - Train Iteration 10269: loss: 0.0405, d_k_M range: [0.0002, 0.0610], d_k_M_hat range: [0.7996, 0.9999]
2025-03-11 21:04:34 - Train Iteration 10270: loss: 0.0272, d_k_M range: [0.0001, 0.0245], d_k_M_hat range: [0.8360, 0.9998]
2025-03-11 21:04:35 - Train Iteration 10271: loss: 0.4496, d_k_M range: [0.0000, 0.6705], d_k_M_hat range: [0.8960, 1.0000]
2025-03-11 21:04:35 - Train Iteration 10272: loss: 0.2085, d_k_M range: [0.0000, 0.4549], d_k_M_hat range: [0.7200, 0.9982]
2025-03-11 21:04:36 - Train Iteration 10273: loss: 0.9101, d_k_M range: [0.0001, 0.0296], d_k_M_hat range: [0.0461, 0.9969]
2025-03-11 21:04:36 - Train Iteration 10274: loss: 0.3602, d_k_M range: [0.0033, 0.6000], d_k_M_hat range: [0.9955, 1.0000]
2025-03-11 21:04:37 - Train Iteration 10275: loss: 0.0025, d_k_M range: [0.0000, 0.0128], d_k_M_hat range: [0.9521, 0.9986]
2025-03-11 21:04:37 - Train Iteration 10276: loss: 0.0043, d_k_M range: [0.0003, 0.0642], d_k_M_hat range: [0.9900, 1.0000]
2025-03-11 21:04:37 - Train Iteration 10277: loss: 0.0050, d_k_M range: [0.0000, 0.0235], d_k_M_hat range: [0.9315, 0.9976]
2025-03-11 21:04:38 - Train Iteration 10278: loss: 0.0075, d_k_M range: [0.0000, 0.0846], d_k_M_hat range: [0.9739, 0.9983]
2025-03-11 21:04:38 - Train Iteration 10279: loss: 0.0114, d_k_M range: [0.0000, 0.1057], d_k_M_hat range: [0.9454, 0.9998]
2025-03-11 21:04:39 - Train Iteration 10280: loss: 0.0532, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.7703, 0.9951]
2025-03-11 21:04:39 - Train Iteration 10281: loss: 0.0350, d_k_M range: [0.0000, 0.1817], d_k_M_hat range: [0.9860, 0.9997]
2025-03-11 21:04:40 - Train Iteration 10282: loss: 0.0250, d_k_M range: [0.0001, 0.0177], d_k_M_hat range: [0.8431, 0.9990]
2025-03-11 21:04:40 - Train Iteration 10283: loss: 0.9197, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.0410, 0.9954]
2025-03-11 21:04:41 - Train Iteration 10284: loss: 0.0177, d_k_M range: [0.0000, 0.1297], d_k_M_hat range: [0.9533, 0.9986]
2025-03-11 21:04:41 - Train Iteration 10285: loss: 0.0137, d_k_M range: [0.0000, 0.1126], d_k_M_hat range: [0.9399, 0.9957]
2025-03-11 21:04:41 - Train Iteration 10286: loss: 0.1800, d_k_M range: [0.0000, 0.3050], d_k_M_hat range: [0.5758, 0.9998]
2025-03-11 21:04:42 - Train Iteration 10287: loss: 0.0566, d_k_M range: [0.0000, 0.2354], d_k_M_hat range: [0.9571, 0.9988]
2025-03-11 21:04:42 - Train Iteration 10288: loss: 0.0303, d_k_M range: [0.0002, 0.0124], d_k_M_hat range: [0.8270, 0.9988]
2025-03-11 21:04:43 - Train Iteration 10289: loss: 0.0342, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.8152, 0.9933]
2025-03-11 21:04:43 - Train Iteration 10290: loss: 0.0189, d_k_M range: [0.0013, 0.1367], d_k_M_hat range: [0.9848, 0.9993]
2025-03-11 21:04:43 - Train Iteration 10291: loss: 0.9640, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.0182, 0.9965]
2025-03-11 21:04:44 - Train Iteration 10292: loss: 0.0099, d_k_M range: [0.0003, 0.0967], d_k_M_hat range: [0.9411, 0.9997]
2025-03-11 21:04:44 - Train Iteration 10293: loss: 0.0087, d_k_M range: [0.0005, 0.0861], d_k_M_hat range: [0.9070, 0.9998]
2025-03-11 21:04:45 - Train Iteration 10294: loss: 0.0226, d_k_M range: [0.0000, 0.1407], d_k_M_hat range: [0.9240, 0.9996]
2025-03-11 21:04:45 - Train Iteration 10295: loss: 0.0154, d_k_M range: [0.0000, 0.1209], d_k_M_hat range: [0.9538, 0.9966]
2025-03-11 21:04:45 - Train Iteration 10296: loss: 0.0491, d_k_M range: [0.0001, 0.0838], d_k_M_hat range: [0.7785, 0.9991]
2025-03-11 21:04:46 - Train Iteration 10297: loss: 0.0084, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9082, 0.9994]
2025-03-11 21:04:46 - Train Iteration 10298: loss: 0.7208, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.1510, 0.9921]
2025-03-11 21:04:47 - Train Iteration 10299: loss: 0.0288, d_k_M range: [0.0017, 0.1695], d_k_M_hat range: [0.9729, 0.9997]
2025-03-11 21:04:47 - Train Iteration 10300: loss: 0.0151, d_k_M range: [0.0001, 0.1200], d_k_M_hat range: [0.9964, 0.9995]
2025-03-11 21:04:48 - Train Iteration 10301: loss: 0.0137, d_k_M range: [0.0001, 0.0818], d_k_M_hat range: [0.8830, 0.9982]
2025-03-11 21:04:48 - Train Iteration 10302: loss: 0.0966, d_k_M range: [0.0001, 0.3052], d_k_M_hat range: [0.9747, 0.9972]
2025-03-11 21:04:49 - Train Iteration 10303: loss: 0.0092, d_k_M range: [0.0001, 0.0729], d_k_M_hat range: [0.9050, 0.9989]
2025-03-11 21:04:49 - Train Iteration 10304: loss: 0.2290, d_k_M range: [0.0000, 0.4762], d_k_M_hat range: [0.6948, 0.9988]
2025-03-11 21:04:49 - Train Iteration 10305: loss: 0.0671, d_k_M range: [0.0000, 0.0665], d_k_M_hat range: [0.7875, 0.9927]
2025-03-11 21:04:50 - Train Iteration 10306: loss: 0.1862, d_k_M range: [0.0000, 0.0327], d_k_M_hat range: [0.5686, 0.9964]
2025-03-11 21:04:50 - Train Iteration 10307: loss: 0.0427, d_k_M range: [0.0004, 0.2057], d_k_M_hat range: [0.9932, 0.9994]
2025-03-11 21:04:51 - Train Iteration 10308: loss: 0.0022, d_k_M range: [0.0002, 0.0372], d_k_M_hat range: [0.9741, 0.9927]
2025-03-11 21:04:51 - Train Iteration 10309: loss: 0.2812, d_k_M range: [0.0001, 0.5302], d_k_M_hat range: [0.8940, 0.9999]
2025-03-11 21:04:52 - Train Iteration 10310: loss: 0.0384, d_k_M range: [0.0001, 0.0797], d_k_M_hat range: [0.8045, 0.9979]
2025-03-11 21:04:52 - Train Iteration 10311: loss: 0.0290, d_k_M range: [0.0001, 0.0625], d_k_M_hat range: [0.8298, 0.9994]
2025-03-11 21:04:52 - Train Iteration 10312: loss: 0.0002, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9860, 0.9998]
2025-03-11 21:04:53 - Train Iteration 10313: loss: 0.2886, d_k_M range: [0.0000, 0.5362], d_k_M_hat range: [0.5467, 0.9990]
2025-03-11 21:04:53 - Train Iteration 10314: loss: 0.7478, d_k_M range: [0.0000, 0.0124], d_k_M_hat range: [0.1353, 0.9991]
2025-03-11 21:04:54 - Train Iteration 10315: loss: 0.0007, d_k_M range: [0.0001, 0.0133], d_k_M_hat range: [0.9819, 0.9999]
2025-03-11 21:04:54 - Train Iteration 10316: loss: 0.0058, d_k_M range: [0.0000, 0.0201], d_k_M_hat range: [0.9242, 0.9999]
2025-03-11 21:04:55 - Train Iteration 10317: loss: 0.0109, d_k_M range: [0.0001, 0.1035], d_k_M_hat range: [0.9814, 0.9989]
2025-03-11 21:04:55 - Train Iteration 10318: loss: 0.0674, d_k_M range: [0.0000, 0.2593], d_k_M_hat range: [0.9722, 0.9997]
2025-03-11 21:04:56 - Train Iteration 10319: loss: 0.0015, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9609, 0.9956]
2025-03-11 21:04:56 - Train Iteration 10320: loss: 0.0489, d_k_M range: [0.0001, 0.2210], d_k_M_hat range: [0.9882, 0.9998]
2025-03-11 21:04:56 - Train Iteration 10321: loss: 0.1083, d_k_M range: [0.0000, 0.3275], d_k_M_hat range: [0.8613, 0.9992]
2025-03-11 21:04:57 - Train Iteration 10322: loss: 0.0128, d_k_M range: [0.0000, 0.0475], d_k_M_hat range: [0.8872, 0.9994]
2025-03-11 21:04:57 - Train Iteration 10323: loss: 0.0104, d_k_M range: [0.0002, 0.0332], d_k_M_hat range: [0.9260, 0.9990]
2025-03-11 21:04:58 - Train Iteration 10324: loss: 0.0136, d_k_M range: [0.0000, 0.0085], d_k_M_hat range: [0.8836, 0.9999]
2025-03-11 21:04:58 - Train Iteration 10325: loss: 0.2503, d_k_M range: [0.0001, 0.4997], d_k_M_hat range: [0.7511, 0.9997]
2025-03-11 21:04:58 - Train Iteration 10326: loss: 0.0315, d_k_M range: [0.0000, 0.0080], d_k_M_hat range: [0.8226, 0.9930]
2025-03-11 21:04:59 - Train Iteration 10327: loss: 0.0402, d_k_M range: [0.0010, 0.1985], d_k_M_hat range: [0.9933, 0.9991]
2025-03-11 21:04:59 - Train Iteration 10328: loss: 0.0287, d_k_M range: [0.0001, 0.1691], d_k_M_hat range: [0.8794, 0.9997]
2025-03-11 21:05:00 - Train Iteration 10329: loss: 0.4441, d_k_M range: [0.0000, 0.0847], d_k_M_hat range: [0.3336, 0.9975]
2025-03-11 21:05:00 - Train Iteration 10330: loss: 0.8167, d_k_M range: [0.0019, 0.9036], d_k_M_hat range: [0.9929, 1.0000]
2025-03-11 21:05:01 - Train Iteration 10331: loss: 0.0094, d_k_M range: [0.0001, 0.0926], d_k_M_hat range: [0.9395, 0.9983]
2025-03-11 21:05:01 - Train Iteration 10332: loss: 0.0006, d_k_M range: [0.0000, 0.0143], d_k_M_hat range: [0.9900, 0.9995]
2025-03-11 21:05:02 - Train Iteration 10333: loss: 0.0204, d_k_M range: [0.0000, 0.0087], d_k_M_hat range: [0.8572, 0.9980]
2025-03-11 21:05:02 - Train Iteration 10334: loss: 0.4027, d_k_M range: [0.0000, 0.6323], d_k_M_hat range: [0.9500, 0.9996]
2025-03-11 21:05:03 - Train Iteration 10335: loss: 0.9177, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.0421, 0.9605]
2025-03-11 21:05:03 - Train Iteration 10336: loss: 0.0015, d_k_M range: [0.0003, 0.0252], d_k_M_hat range: [0.9857, 0.9998]
2025-03-11 21:05:03 - Train Iteration 10337: loss: 0.0031, d_k_M range: [0.0002, 0.0256], d_k_M_hat range: [0.9443, 0.9992]
2025-03-11 21:05:04 - Train Iteration 10338: loss: 0.1535, d_k_M range: [0.0001, 0.0700], d_k_M_hat range: [0.6083, 1.0000]
2025-03-11 21:05:04 - Train Iteration 10339: loss: 0.0843, d_k_M range: [0.0001, 0.2891], d_k_M_hat range: [0.9964, 0.9999]
2025-03-11 21:05:05 - Train Iteration 10340: loss: 0.0211, d_k_M range: [0.0009, 0.1411], d_k_M_hat range: [0.9404, 0.9989]
2025-03-11 21:05:05 - Train Iteration 10341: loss: 0.8077, d_k_M range: [0.0000, 0.8987], d_k_M_hat range: [0.8553, 1.0000]
2025-03-11 21:05:05 - Train Iteration 10342: loss: 0.0573, d_k_M range: [0.0000, 0.2181], d_k_M_hat range: [0.8275, 0.9939]
2025-03-11 21:05:06 - Train Iteration 10343: loss: 0.0148, d_k_M range: [0.0001, 0.0145], d_k_M_hat range: [0.8785, 0.9980]
2025-03-11 21:05:06 - Train Iteration 10344: loss: 0.0157, d_k_M range: [0.0041, 0.1218], d_k_M_hat range: [0.9829, 0.9997]
2025-03-11 21:05:07 - Train Iteration 10345: loss: 0.0054, d_k_M range: [0.0000, 0.0325], d_k_M_hat range: [0.9264, 0.9928]
2025-03-11 21:05:07 - Train Iteration 10346: loss: 0.0546, d_k_M range: [0.0000, 0.0371], d_k_M_hat range: [0.7667, 0.9991]
2025-03-11 21:05:07 - Train Iteration 10347: loss: 0.0284, d_k_M range: [0.0000, 0.1207], d_k_M_hat range: [0.8314, 0.9988]
2025-03-11 21:05:08 - Train Iteration 10348: loss: 0.7318, d_k_M range: [0.0007, 0.8554], d_k_M_hat range: [0.9336, 0.9999]
2025-03-11 21:05:08 - Train Iteration 10349: loss: 0.0025, d_k_M range: [0.0000, 0.0201], d_k_M_hat range: [0.9615, 0.9984]
2025-03-11 21:05:09 - Train Iteration 10350: loss: 0.0035, d_k_M range: [0.0004, 0.0274], d_k_M_hat range: [0.9529, 0.9994]
2025-03-11 21:05:09 - Train Iteration 10351: loss: 0.0628, d_k_M range: [0.0003, 0.1787], d_k_M_hat range: [0.7517, 0.9998]
2025-03-11 21:05:10 - Train Iteration 10352: loss: 0.0447, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.7887, 0.9979]
2025-03-11 21:05:10 - Train Iteration 10353: loss: 0.0031, d_k_M range: [0.0000, 0.0307], d_k_M_hat range: [0.9447, 0.9975]
2025-03-11 21:05:11 - Train Iteration 10354: loss: 0.0238, d_k_M range: [0.0002, 0.1415], d_k_M_hat range: [0.9872, 1.0000]
2025-03-11 21:05:11 - Train Iteration 10355: loss: 0.0050, d_k_M range: [0.0000, 0.0688], d_k_M_hat range: [0.9324, 0.9994]
2025-03-11 21:05:11 - Train Iteration 10356: loss: 0.0435, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.7915, 0.9874]
2025-03-11 21:05:12 - Train Iteration 10357: loss: 0.0788, d_k_M range: [0.0000, 0.2728], d_k_M_hat range: [0.9240, 0.9961]
2025-03-11 21:05:12 - Train Iteration 10358: loss: 0.0207, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.8562, 0.9960]
2025-03-11 21:05:13 - Train Iteration 10359: loss: 0.0152, d_k_M range: [0.0000, 0.1221], d_k_M_hat range: [0.9795, 0.9988]
2025-03-11 21:05:13 - Train Iteration 10360: loss: 0.3339, d_k_M range: [0.0001, 0.0150], d_k_M_hat range: [0.4235, 0.9983]
2025-03-11 21:05:14 - Train Iteration 10361: loss: 0.0153, d_k_M range: [0.0005, 0.1231], d_k_M_hat range: [0.9601, 0.9995]
2025-03-11 21:05:14 - Train Iteration 10362: loss: 0.0055, d_k_M range: [0.0001, 0.0061], d_k_M_hat range: [0.9263, 0.9974]
2025-03-11 21:05:14 - Train Iteration 10363: loss: 0.0217, d_k_M range: [0.0002, 0.1416], d_k_M_hat range: [0.9633, 0.9981]
2025-03-11 21:05:15 - Train Iteration 10364: loss: 0.0110, d_k_M range: [0.0000, 0.0740], d_k_M_hat range: [0.9136, 0.9979]
2025-03-11 21:05:15 - Train Iteration 10365: loss: 0.0363, d_k_M range: [0.0001, 0.1899], d_k_M_hat range: [0.9864, 0.9994]
2025-03-11 21:05:16 - Train Iteration 10366: loss: 0.0231, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.8481, 0.9912]
2025-03-11 21:05:16 - Train Iteration 10367: loss: 0.0093, d_k_M range: [0.0003, 0.0952], d_k_M_hat range: [0.9852, 0.9993]
2025-03-11 21:05:17 - Train Iteration 10368: loss: 0.1616, d_k_M range: [0.0000, 0.0595], d_k_M_hat range: [0.5995, 0.9996]
2025-03-11 21:05:17 - Train Iteration 10369: loss: 0.2723, d_k_M range: [0.0004, 0.5199], d_k_M_hat range: [0.9622, 0.9996]
2025-03-11 21:05:17 - Train Iteration 10370: loss: 0.8416, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.0826, 0.9750]
2025-03-11 21:05:18 - Train Iteration 10371: loss: 0.0127, d_k_M range: [0.0002, 0.0133], d_k_M_hat range: [0.8875, 0.9985]
2025-03-11 21:05:18 - Train Iteration 10372: loss: 0.0287, d_k_M range: [0.0001, 0.0047], d_k_M_hat range: [0.8316, 0.9969]
2025-03-11 21:05:19 - Train Iteration 10373: loss: 0.4188, d_k_M range: [0.0078, 0.6458], d_k_M_hat range: [0.9867, 1.0000]
2025-03-11 21:05:19 - Train Iteration 10374: loss: 0.0130, d_k_M range: [0.0010, 0.1114], d_k_M_hat range: [0.9860, 0.9991]
2025-03-11 21:05:19 - Train Iteration 10375: loss: 0.0273, d_k_M range: [0.0004, 0.1597], d_k_M_hat range: [0.9134, 0.9985]
2025-03-11 21:05:20 - Train Iteration 10376: loss: 0.0364, d_k_M range: [0.0000, 0.0741], d_k_M_hat range: [0.8092, 0.9976]
2025-03-11 21:05:20 - Train Iteration 10377: loss: 0.3435, d_k_M range: [0.0000, 0.0432], d_k_M_hat range: [0.4139, 0.9976]
2025-03-11 21:05:21 - Train Iteration 10378: loss: 0.0109, d_k_M range: [0.0000, 0.1037], d_k_M_hat range: [0.9520, 0.9995]
2025-03-11 21:05:21 - Train Iteration 10379: loss: 0.0941, d_k_M range: [0.0020, 0.3050], d_k_M_hat range: [0.9369, 0.9994]
2025-03-11 21:05:22 - Train Iteration 10380: loss: 0.1049, d_k_M range: [0.0002, 0.0173], d_k_M_hat range: [0.6763, 0.9985]
2025-03-11 21:05:22 - Train Iteration 10381: loss: 0.1319, d_k_M range: [0.0000, 0.0663], d_k_M_hat range: [0.6369, 0.9929]
2025-03-11 21:05:22 - Train Iteration 10382: loss: 0.0047, d_k_M range: [0.0000, 0.0371], d_k_M_hat range: [0.9327, 0.9942]
2025-03-11 21:05:23 - Train Iteration 10383: loss: 0.0103, d_k_M range: [0.0001, 0.0804], d_k_M_hat range: [0.9653, 0.9994]
2025-03-11 21:05:23 - Train Iteration 10384: loss: 0.0032, d_k_M range: [0.0003, 0.0561], d_k_M_hat range: [0.9581, 0.9991]
2025-03-11 21:05:24 - Train Iteration 10385: loss: 0.0135, d_k_M range: [0.0001, 0.0579], d_k_M_hat range: [0.8841, 0.9990]
2025-03-11 21:05:24 - Train Iteration 10386: loss: 0.0104, d_k_M range: [0.0003, 0.1014], d_k_M_hat range: [0.9395, 0.9997]
2025-03-11 21:05:25 - Train Iteration 10387: loss: 0.0859, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.7069, 0.9871]
2025-03-11 21:05:25 - Train Iteration 10388: loss: 0.0495, d_k_M range: [0.0000, 0.2213], d_k_M_hat range: [0.7982, 0.9988]
2025-03-11 21:05:26 - Train Iteration 10389: loss: 0.0789, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.7200, 0.9962]
2025-03-11 21:05:26 - Train Iteration 10390: loss: 0.0016, d_k_M range: [0.0000, 0.0143], d_k_M_hat range: [0.9606, 0.9993]
2025-03-11 21:05:26 - Train Iteration 10391: loss: 0.0253, d_k_M range: [0.0000, 0.1481], d_k_M_hat range: [0.8409, 0.9999]
2025-03-11 21:05:27 - Train Iteration 10392: loss: 0.1168, d_k_M range: [0.0000, 0.0313], d_k_M_hat range: [0.6583, 0.9981]
2025-03-11 21:05:27 - Train Iteration 10393: loss: 0.4846, d_k_M range: [0.0007, 0.6950], d_k_M_hat range: [0.9788, 0.9999]
2025-03-11 21:05:28 - Train Iteration 10394: loss: 0.1230, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.6494, 0.9866]
2025-03-11 21:05:28 - Train Iteration 10395: loss: 0.0037, d_k_M range: [0.0002, 0.0253], d_k_M_hat range: [0.9406, 0.9989]
2025-03-11 21:05:29 - Train Iteration 10396: loss: 0.0227, d_k_M range: [0.0000, 0.1008], d_k_M_hat range: [0.8537, 0.9969]
2025-03-11 21:05:29 - Train Iteration 10397: loss: 0.0977, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.6875, 0.9953]
2025-03-11 21:05:29 - Train Iteration 10398: loss: 0.0008, d_k_M range: [0.0001, 0.0118], d_k_M_hat range: [0.9732, 0.9982]
2025-03-11 21:05:30 - Train Iteration 10399: loss: 0.1796, d_k_M range: [0.0000, 0.4187], d_k_M_hat range: [0.9775, 0.9974]
2025-03-11 21:05:30 - Train Iteration 10400: loss: 0.0017, d_k_M range: [0.0000, 0.0345], d_k_M_hat range: [0.9635, 0.9970]
2025-03-11 21:05:31 - Train Iteration 10401: loss: 0.0047, d_k_M range: [0.0001, 0.0220], d_k_M_hat range: [0.9334, 0.9995]
2025-03-11 21:05:31 - Train Iteration 10402: loss: 0.1184, d_k_M range: [0.0000, 0.3435], d_k_M_hat range: [0.8838, 0.9995]
2025-03-11 21:05:32 - Train Iteration 10403: loss: 0.1658, d_k_M range: [0.0001, 0.4070], d_k_M_hat range: [0.9793, 0.9999]
2025-03-11 21:05:32 - Train Iteration 10404: loss: 0.0081, d_k_M range: [0.0000, 0.0095], d_k_M_hat range: [0.9109, 0.9964]
2025-03-11 21:05:33 - Train Iteration 10405: loss: 0.0218, d_k_M range: [0.0002, 0.1468], d_k_M_hat range: [0.9610, 0.9990]
2025-03-11 21:05:33 - Train Iteration 10406: loss: 0.0925, d_k_M range: [0.0000, 0.3042], d_k_M_hat range: [0.9611, 0.9999]
2025-03-11 21:05:33 - Train Iteration 10407: loss: 0.1601, d_k_M range: [0.0000, 0.0079], d_k_M_hat range: [0.5999, 0.9980]
2025-03-11 21:05:34 - Train Iteration 10408: loss: 0.0329, d_k_M range: [0.0012, 0.1810], d_k_M_hat range: [0.9938, 0.9997]
2025-03-11 21:05:34 - Train Iteration 10409: loss: 0.7051, d_k_M range: [0.0001, 0.8397], d_k_M_hat range: [0.9540, 1.0000]
2025-03-11 21:05:35 - Train Iteration 10410: loss: 0.0642, d_k_M range: [0.0000, 0.0212], d_k_M_hat range: [0.7467, 0.9978]
2025-03-11 21:05:35 - Train Iteration 10411: loss: 0.0857, d_k_M range: [0.0001, 0.2923], d_k_M_hat range: [0.9452, 0.9996]
2025-03-11 21:05:36 - Train Iteration 10412: loss: 0.0080, d_k_M range: [0.0000, 0.0892], d_k_M_hat range: [0.9975, 1.0000]
2025-03-11 21:05:36 - Train Iteration 10413: loss: 0.0081, d_k_M range: [0.0001, 0.0898], d_k_M_hat range: [0.9808, 0.9998]
2025-03-11 21:05:37 - Train Iteration 10414: loss: 0.0451, d_k_M range: [0.0000, 0.2081], d_k_M_hat range: [0.9609, 0.9993]
2025-03-11 21:05:37 - Train Iteration 10415: loss: 0.0268, d_k_M range: [0.0002, 0.1627], d_k_M_hat range: [0.9850, 0.9998]
2025-03-11 21:05:37 - Train Iteration 10416: loss: 0.0405, d_k_M range: [0.0001, 0.0068], d_k_M_hat range: [0.7989, 0.9991]
2025-03-11 21:05:38 - Train Iteration 10417: loss: 0.0159, d_k_M range: [0.0000, 0.1250], d_k_M_hat range: [0.9379, 0.9988]
2025-03-11 21:05:38 - Train Iteration 10418: loss: 0.0096, d_k_M range: [0.0001, 0.0948], d_k_M_hat range: [0.9688, 0.9988]
2025-03-11 21:05:39 - Train Iteration 10419: loss: 0.0026, d_k_M range: [0.0000, 0.0498], d_k_M_hat range: [0.9727, 0.9999]
2025-03-11 21:05:39 - Train Iteration 10420: loss: 0.0067, d_k_M range: [0.0000, 0.0752], d_k_M_hat range: [0.9349, 0.9991]
2025-03-11 21:05:39 - Train Iteration 10421: loss: 0.0033, d_k_M range: [0.0000, 0.0412], d_k_M_hat range: [0.9482, 0.9989]
2025-03-11 21:05:40 - Train Iteration 10422: loss: 0.2724, d_k_M range: [0.0001, 0.3131], d_k_M_hat range: [0.4782, 0.9991]
2025-03-11 21:05:40 - Train Iteration 10423: loss: 0.0358, d_k_M range: [0.0000, 0.1204], d_k_M_hat range: [0.8109, 1.0000]
2025-03-11 21:05:41 - Train Iteration 10424: loss: 0.0039, d_k_M range: [0.0000, 0.0539], d_k_M_hat range: [0.9913, 0.9995]
2025-03-11 21:05:41 - Train Iteration 10425: loss: 0.0007, d_k_M range: [0.0000, 0.0109], d_k_M_hat range: [0.9825, 0.9985]
2025-03-11 21:05:42 - Train Iteration 10426: loss: 0.0719, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.7323, 0.9958]
2025-03-11 21:05:42 - Train Iteration 10427: loss: 0.8278, d_k_M range: [0.0005, 0.9096], d_k_M_hat range: [0.9716, 0.9999]
2025-03-11 21:05:42 - Train Iteration 10428: loss: 0.0233, d_k_M range: [0.0001, 0.0052], d_k_M_hat range: [0.8486, 0.9944]
2025-03-11 21:05:43 - Train Iteration 10429: loss: 0.0008, d_k_M range: [0.0002, 0.0170], d_k_M_hat range: [0.9841, 0.9992]
2025-03-11 21:05:43 - Train Iteration 10430: loss: 0.3788, d_k_M range: [0.0002, 0.6143], d_k_M_hat range: [0.7685, 0.9988]
2025-03-11 21:05:44 - Train Iteration 10431: loss: 0.2593, d_k_M range: [0.0000, 0.0115], d_k_M_hat range: [0.4908, 0.9987]
2025-03-11 21:05:44 - Train Iteration 10432: loss: 0.3701, d_k_M range: [0.0011, 0.6083], d_k_M_hat range: [0.9928, 1.0000]
2025-03-11 21:05:45 - Train Iteration 10433: loss: 0.1943, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.5592, 0.9966]
2025-03-11 21:05:45 - Train Iteration 10434: loss: 0.0229, d_k_M range: [0.0001, 0.1512], d_k_M_hat range: [0.9895, 0.9998]
2025-03-11 21:05:45 - Train Iteration 10435: loss: 0.7394, d_k_M range: [0.0000, 0.8558], d_k_M_hat range: [0.9621, 0.9998]
2025-03-11 21:05:46 - Train Iteration 10436: loss: 0.2645, d_k_M range: [0.0004, 0.5114], d_k_M_hat range: [0.8526, 0.9994]
2025-03-11 21:05:46 - Train Iteration 10437: loss: 0.0024, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.9508, 0.9971]
2025-03-11 21:05:47 - Train Iteration 10438: loss: 0.0616, d_k_M range: [0.0000, 0.0161], d_k_M_hat range: [0.7518, 0.9994]
2025-03-11 21:05:47 - Train Iteration 10439: loss: 0.0163, d_k_M range: [0.0003, 0.0188], d_k_M_hat range: [0.8728, 0.9994]
2025-03-11 21:05:48 - Train Iteration 10440: loss: 0.0243, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.8443, 0.9956]
2025-03-11 21:05:48 - Train Iteration 10441: loss: 0.0111, d_k_M range: [0.0038, 0.1044], d_k_M_hat range: [0.9057, 0.9993]
2025-03-11 21:05:48 - Train Iteration 10442: loss: 0.2389, d_k_M range: [0.0004, 0.1183], d_k_M_hat range: [0.5145, 0.9989]
2025-03-11 21:05:49 - Train Iteration 10443: loss: 0.0022, d_k_M range: [0.0001, 0.0329], d_k_M_hat range: [0.9550, 0.9998]
2025-03-11 21:05:50 - Train Iteration 10444: loss: 0.2218, d_k_M range: [0.0000, 0.4704], d_k_M_hat range: [0.9673, 0.9997]
2025-03-11 21:05:50 - Train Iteration 10445: loss: 0.0040, d_k_M range: [0.0001, 0.0080], d_k_M_hat range: [0.9366, 0.9949]
2025-03-11 21:05:51 - Train Iteration 10446: loss: 0.0932, d_k_M range: [0.0000, 0.3011], d_k_M_hat range: [0.9937, 0.9996]
2025-03-11 21:05:51 - Train Iteration 10447: loss: 0.0052, d_k_M range: [0.0000, 0.0254], d_k_M_hat range: [0.9281, 0.9987]
2025-03-11 21:05:52 - Train Iteration 10448: loss: 0.0079, d_k_M range: [0.0000, 0.0889], d_k_M_hat range: [0.9564, 1.0000]
2025-03-11 21:05:52 - Train Iteration 10449: loss: 0.4377, d_k_M range: [0.0001, 0.6613], d_k_M_hat range: [0.7517, 0.9997]
2025-03-11 21:05:53 - Train Iteration 10450: loss: 0.3474, d_k_M range: [0.0000, 0.5873], d_k_M_hat range: [0.6503, 0.9981]
2025-03-11 21:05:53 - Train Iteration 10451: loss: 0.0198, d_k_M range: [0.0008, 0.0566], d_k_M_hat range: [0.8614, 0.9992]
2025-03-11 21:05:53 - Train Iteration 10452: loss: 0.0063, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9217, 0.9981]
2025-03-11 21:05:54 - Train Iteration 10453: loss: 0.0138, d_k_M range: [0.0000, 0.1136], d_k_M_hat range: [0.9863, 0.9972]
2025-03-11 21:05:54 - Train Iteration 10454: loss: 0.1411, d_k_M range: [0.0000, 0.3706], d_k_M_hat range: [0.9591, 0.9989]
2025-03-11 21:05:55 - Train Iteration 10455: loss: 0.0683, d_k_M range: [0.0000, 0.0773], d_k_M_hat range: [0.7388, 0.9992]
2025-03-11 21:05:55 - Train Iteration 10456: loss: 0.0507, d_k_M range: [0.0001, 0.2227], d_k_M_hat range: [0.9850, 0.9996]
2025-03-11 21:05:56 - Train Iteration 10457: loss: 0.1108, d_k_M range: [0.0000, 0.3316], d_k_M_hat range: [0.9173, 0.9993]
2025-03-11 21:05:56 - Train Iteration 10458: loss: 0.0211, d_k_M range: [0.0000, 0.1431], d_k_M_hat range: [0.9439, 0.9980]
2025-03-11 21:05:57 - Train Iteration 10459: loss: 0.2388, d_k_M range: [0.0001, 0.0232], d_k_M_hat range: [0.5114, 0.9957]
2025-03-11 21:05:57 - Train Iteration 10460: loss: 0.3808, d_k_M range: [0.0002, 0.6170], d_k_M_hat range: [0.9598, 1.0000]
2025-03-11 21:05:57 - Train Iteration 10461: loss: 0.0279, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.8331, 0.9902]
2025-03-11 21:05:58 - Train Iteration 10462: loss: 0.0745, d_k_M range: [0.0007, 0.2726], d_k_M_hat range: [0.9484, 0.9999]
2025-03-11 21:05:58 - Train Iteration 10463: loss: 0.0028, d_k_M range: [0.0000, 0.0465], d_k_M_hat range: [0.9699, 0.9983]
2025-03-11 21:05:59 - Train Iteration 10464: loss: 0.0499, d_k_M range: [0.0001, 0.0014], d_k_M_hat range: [0.7767, 0.9995]
2025-03-11 21:05:59 - Train Iteration 10465: loss: 0.0007, d_k_M range: [0.0011, 0.0262], d_k_M_hat range: [0.9777, 0.9999]
2025-03-11 21:06:00 - Train Iteration 10466: loss: 0.1109, d_k_M range: [0.0000, 0.0137], d_k_M_hat range: [0.6670, 0.9986]
2025-03-11 21:06:00 - Train Iteration 10467: loss: 0.0197, d_k_M range: [0.0000, 0.1255], d_k_M_hat range: [0.8598, 0.9998]
2025-03-11 21:06:00 - Train Iteration 10468: loss: 0.1229, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.6509, 0.9974]
2025-03-11 21:06:01 - Train Iteration 10469: loss: 0.5541, d_k_M range: [0.0045, 0.7443], d_k_M_hat range: [0.9986, 1.0000]
2025-03-11 21:06:01 - Train Iteration 10470: loss: 0.1847, d_k_M range: [0.0000, 0.0169], d_k_M_hat range: [0.5702, 0.9947]
2025-03-11 21:06:02 - Train Iteration 10471: loss: 0.0030, d_k_M range: [0.0000, 0.0488], d_k_M_hat range: [0.9562, 0.9997]
2025-03-11 21:06:02 - Train Iteration 10472: loss: 0.0162, d_k_M range: [0.0001, 0.1253], d_k_M_hat range: [0.9769, 0.9991]
2025-03-11 21:06:03 - Train Iteration 10473: loss: 0.1519, d_k_M range: [0.0001, 0.3885], d_k_M_hat range: [0.9208, 0.9987]
2025-03-11 21:06:03 - Train Iteration 10474: loss: 0.0334, d_k_M range: [0.0000, 0.0219], d_k_M_hat range: [0.8175, 0.9990]
2025-03-11 21:06:03 - Train Iteration 10475: loss: 0.3212, d_k_M range: [0.0000, 0.0080], d_k_M_hat range: [0.4362, 0.9988]
2025-03-11 21:06:04 - Train Iteration 10476: loss: 0.0009, d_k_M range: [0.0001, 0.0232], d_k_M_hat range: [0.9707, 0.9999]
2025-03-11 21:06:04 - Train Iteration 10477: loss: 0.0966, d_k_M range: [0.0000, 0.3104], d_k_M_hat range: [0.8486, 0.9999]
2025-03-11 21:06:05 - Train Iteration 10478: loss: 0.2800, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.4711, 0.9976]
2025-03-11 21:06:05 - Train Iteration 10479: loss: 0.0111, d_k_M range: [0.0000, 0.1050], d_k_M_hat range: [0.9964, 0.9999]
2025-03-11 21:06:06 - Train Iteration 10480: loss: 0.1808, d_k_M range: [0.0000, 0.4217], d_k_M_hat range: [0.9278, 0.9997]
2025-03-11 21:06:06 - Train Iteration 10481: loss: 0.0250, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.8420, 0.9988]
2025-03-11 21:06:07 - Train Iteration 10482: loss: 0.5815, d_k_M range: [0.0000, 0.0905], d_k_M_hat range: [0.2375, 0.9995]
2025-03-11 21:06:07 - Train Iteration 10483: loss: 0.0850, d_k_M range: [0.0000, 0.2912], d_k_M_hat range: [0.9714, 0.9997]
2025-03-11 21:06:08 - Train Iteration 10484: loss: 0.0396, d_k_M range: [0.0000, 0.1968], d_k_M_hat range: [0.9432, 0.9994]
2025-03-11 21:06:08 - Train Iteration 10485: loss: 0.3372, d_k_M range: [0.0002, 0.5795], d_k_M_hat range: [0.9720, 0.9991]
2025-03-11 21:06:08 - Train Iteration 10486: loss: 0.7811, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.1162, 0.9737]
2025-03-11 21:06:09 - Train Iteration 10487: loss: 0.5566, d_k_M range: [0.0000, 0.7456], d_k_M_hat range: [0.9832, 0.9996]
2025-03-11 21:06:09 - Train Iteration 10488: loss: 0.0028, d_k_M range: [0.0000, 0.0171], d_k_M_hat range: [0.9470, 0.9968]
2025-03-11 21:06:10 - Train Iteration 10489: loss: 0.0160, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.8734, 0.9972]
2025-03-11 21:06:10 - Train Iteration 10490: loss: 0.1947, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.5589, 0.9988]
2025-03-11 21:06:11 - Train Iteration 10491: loss: 0.0002, d_k_M range: [0.0004, 0.0137], d_k_M_hat range: [0.9857, 0.9999]
2025-03-11 21:06:11 - Train Iteration 10492: loss: 0.7639, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.1261, 0.9839]
2025-03-11 21:06:12 - Train Iteration 10493: loss: 0.0086, d_k_M range: [0.0001, 0.0925], d_k_M_hat range: [0.9256, 0.9999]
2025-03-11 21:06:12 - Train Iteration 10494: loss: 0.0143, d_k_M range: [0.0000, 0.0178], d_k_M_hat range: [0.8814, 0.9948]
2025-03-11 21:06:12 - Train Iteration 10495: loss: 0.6561, d_k_M range: [0.0001, 0.8098], d_k_M_hat range: [0.9701, 0.9999]
2025-03-11 21:06:13 - Train Iteration 10496: loss: 0.2239, d_k_M range: [0.0000, 0.4724], d_k_M_hat range: [0.7768, 0.9998]
2025-03-11 21:06:13 - Train Iteration 10497: loss: 0.1248, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.6486, 0.9968]
2025-03-11 21:06:14 - Train Iteration 10498: loss: 0.0169, d_k_M range: [0.0000, 0.1290], d_k_M_hat range: [0.9337, 0.9998]
2025-03-11 21:06:14 - Train Iteration 10499: loss: 0.0050, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9299, 0.9976]
2025-03-11 21:06:15 - Train Iteration 10500: loss: 0.1829, d_k_M range: [0.0000, 0.4270], d_k_M_hat range: [0.8658, 0.9994]
2025-03-11 21:06:15 - Train Iteration 10501: loss: 0.5669, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.2471, 0.9859]
2025-03-11 21:06:16 - Train Iteration 10502: loss: 0.3153, d_k_M range: [0.0001, 0.5605], d_k_M_hat range: [0.9903, 0.9997]
2025-03-11 21:06:16 - Train Iteration 10503: loss: 0.0145, d_k_M range: [0.0000, 0.0449], d_k_M_hat range: [0.9244, 0.9950]
2025-03-11 21:06:16 - Train Iteration 10504: loss: 0.0021, d_k_M range: [0.0001, 0.0184], d_k_M_hat range: [0.9537, 0.9982]
2025-03-11 21:06:17 - Train Iteration 10505: loss: 0.4737, d_k_M range: [0.0001, 0.6539], d_k_M_hat range: [0.9657, 0.9996]
2025-03-11 21:06:17 - Train Iteration 10506: loss: 0.0348, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.8135, 0.9963]
2025-03-11 21:06:18 - Train Iteration 10507: loss: 0.0144, d_k_M range: [0.0002, 0.1184], d_k_M_hat range: [0.9815, 0.9996]
2025-03-11 21:06:18 - Train Iteration 10508: loss: 0.0065, d_k_M range: [0.0002, 0.0782], d_k_M_hat range: [0.9661, 0.9981]
2025-03-11 21:06:19 - Train Iteration 10509: loss: 0.1079, d_k_M range: [0.0001, 0.3282], d_k_M_hat range: [0.9452, 0.9997]
2025-03-11 21:06:19 - Train Iteration 10510: loss: 0.0146, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.8792, 0.9888]
2025-03-11 21:06:20 - Train Iteration 10511: loss: 0.0656, d_k_M range: [0.0000, 0.0128], d_k_M_hat range: [0.7439, 0.9971]
2025-03-11 21:06:20 - Train Iteration 10512: loss: 0.0277, d_k_M range: [0.0000, 0.1660], d_k_M_hat range: [0.9757, 0.9997]
2025-03-11 21:06:20 - Train Iteration 10513: loss: 0.2636, d_k_M range: [0.0000, 0.0428], d_k_M_hat range: [0.4866, 0.9998]
2025-03-11 21:06:21 - Train Iteration 10514: loss: 0.0067, d_k_M range: [0.0001, 0.0818], d_k_M_hat range: [0.9523, 0.9999]
2025-03-11 21:06:21 - Train Iteration 10515: loss: 0.0518, d_k_M range: [0.0011, 0.1761], d_k_M_hat range: [0.9485, 0.9998]
2025-03-11 21:06:22 - Train Iteration 10516: loss: 0.0079, d_k_M range: [0.0001, 0.0872], d_k_M_hat range: [0.9811, 0.9992]
2025-03-11 21:06:22 - Train Iteration 10517: loss: 0.1111, d_k_M range: [0.0001, 0.0397], d_k_M_hat range: [0.6668, 0.9983]
2025-03-11 21:06:23 - Train Iteration 10518: loss: 0.0035, d_k_M range: [0.0000, 0.0299], d_k_M_hat range: [0.9443, 0.9979]
2025-03-11 21:06:23 - Train Iteration 10519: loss: 0.0115, d_k_M range: [0.0001, 0.1043], d_k_M_hat range: [0.9347, 0.9991]
2025-03-11 21:06:24 - Train Iteration 10520: loss: 0.0293, d_k_M range: [0.0000, 0.0152], d_k_M_hat range: [0.8442, 0.9979]
2025-03-11 21:06:24 - Train Iteration 10521: loss: 0.4061, d_k_M range: [0.0000, 0.6369], d_k_M_hat range: [0.9458, 0.9996]
2025-03-11 21:06:25 - Train Iteration 10522: loss: 0.0052, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9279, 0.9994]
2025-03-11 21:06:25 - Train Iteration 10523: loss: 0.1160, d_k_M range: [0.0001, 0.0209], d_k_M_hat range: [0.6597, 0.9962]
2025-03-11 21:06:26 - Train Iteration 10524: loss: 0.7227, d_k_M range: [0.0000, 0.8493], d_k_M_hat range: [0.9904, 0.9999]
2025-03-11 21:06:26 - Train Iteration 10525: loss: 0.1849, d_k_M range: [0.0000, 0.0211], d_k_M_hat range: [0.5700, 0.9882]
2025-03-11 21:06:26 - Train Iteration 10526: loss: 0.0607, d_k_M range: [0.0000, 0.2428], d_k_M_hat range: [0.7985, 0.9998]
2025-03-11 21:06:27 - Train Iteration 10527: loss: 0.0964, d_k_M range: [0.0000, 0.0147], d_k_M_hat range: [0.6896, 0.9977]
2025-03-11 21:06:27 - Train Iteration 10528: loss: 0.0308, d_k_M range: [0.0000, 0.1689], d_k_M_hat range: [0.8245, 0.9994]
2025-03-11 21:06:28 - Train Iteration 10529: loss: 0.0257, d_k_M range: [0.0000, 0.1595], d_k_M_hat range: [0.9246, 0.9992]
2025-03-11 21:06:28 - Train Iteration 10530: loss: 0.2308, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.5196, 0.9992]
2025-03-11 21:06:29 - Train Iteration 10531: loss: 0.0508, d_k_M range: [0.0001, 0.2243], d_k_M_hat range: [0.9830, 0.9997]
2025-03-11 21:06:29 - Train Iteration 10532: loss: 0.0014, d_k_M range: [0.0000, 0.0322], d_k_M_hat range: [0.9864, 0.9993]
2025-03-11 21:06:30 - Train Iteration 10533: loss: 0.0122, d_k_M range: [0.0002, 0.1096], d_k_M_hat range: [0.9407, 0.9993]
2025-03-11 21:06:30 - Train Iteration 10534: loss: 0.0008, d_k_M range: [0.0000, 0.0125], d_k_M_hat range: [0.9840, 0.9995]
2025-03-11 21:06:30 - Train Iteration 10535: loss: 0.1498, d_k_M range: [0.0000, 0.0685], d_k_M_hat range: [0.6130, 0.9995]
2025-03-11 21:06:31 - Train Iteration 10536: loss: 0.1159, d_k_M range: [0.0001, 0.3393], d_k_M_hat range: [0.9177, 0.9993]
2025-03-11 21:06:31 - Train Iteration 10537: loss: 0.0089, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9078, 0.9970]
2025-03-11 21:06:32 - Train Iteration 10538: loss: 0.0858, d_k_M range: [0.0007, 0.2927], d_k_M_hat range: [0.8394, 0.9998]
2025-03-11 21:06:32 - Train Iteration 10539: loss: 0.2295, d_k_M range: [0.0001, 0.0382], d_k_M_hat range: [0.5215, 0.9988]
2025-03-11 21:06:33 - Train Iteration 10540: loss: 0.3622, d_k_M range: [0.0006, 0.5992], d_k_M_hat range: [0.9967, 0.9998]
2025-03-11 21:06:33 - Train Iteration 10541: loss: 0.0141, d_k_M range: [0.0002, 0.1136], d_k_M_hat range: [0.9767, 0.9995]
2025-03-11 21:06:33 - Train Iteration 10542: loss: 0.0025, d_k_M range: [0.0000, 0.0285], d_k_M_hat range: [0.9507, 0.9987]
2025-03-11 21:06:34 - Train Iteration 10543: loss: 0.0939, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.6936, 0.9978]
2025-03-11 21:06:34 - Train Iteration 10544: loss: 0.0268, d_k_M range: [0.0002, 0.1622], d_k_M_hat range: [0.9851, 0.9996]
2025-03-11 21:06:35 - Train Iteration 10545: loss: 0.0422, d_k_M range: [0.0001, 0.0314], d_k_M_hat range: [0.7949, 0.9993]
2025-03-11 21:06:35 - Train Iteration 10546: loss: 0.0037, d_k_M range: [0.0000, 0.0286], d_k_M_hat range: [0.9394, 0.9961]
2025-03-11 21:06:36 - Train Iteration 10547: loss: 0.0242, d_k_M range: [0.0000, 0.1544], d_k_M_hat range: [0.9793, 0.9993]
2025-03-11 21:06:36 - Train Iteration 10548: loss: 0.0053, d_k_M range: [0.0002, 0.0065], d_k_M_hat range: [0.9285, 0.9994]
2025-03-11 21:06:37 - Train Iteration 10549: loss: 0.6369, d_k_M range: [0.0000, 0.2092], d_k_M_hat range: [0.2019, 0.9993]
2025-03-11 21:06:37 - Train Iteration 10550: loss: 0.0543, d_k_M range: [0.0001, 0.2298], d_k_M_hat range: [0.9892, 0.9999]
2025-03-11 21:06:37 - Train Iteration 10551: loss: 0.0134, d_k_M range: [0.0000, 0.0066], d_k_M_hat range: [0.8843, 0.9998]
2025-03-11 21:06:38 - Train Iteration 10552: loss: 0.0011, d_k_M range: [0.0000, 0.0116], d_k_M_hat range: [0.9662, 0.9998]
2025-03-11 21:06:38 - Train Iteration 10553: loss: 0.1854, d_k_M range: [0.0001, 0.0302], d_k_M_hat range: [0.5695, 0.9993]
2025-03-11 21:06:39 - Train Iteration 10554: loss: 0.0202, d_k_M range: [0.0001, 0.1419], d_k_M_hat range: [0.9676, 0.9997]
2025-03-11 21:06:39 - Train Iteration 10555: loss: 0.2922, d_k_M range: [0.0000, 0.0211], d_k_M_hat range: [0.4594, 0.9961]
2025-03-11 21:06:40 - Train Iteration 10556: loss: 0.0418, d_k_M range: [0.0004, 0.2044], d_k_M_hat range: [0.9027, 0.9999]
2025-03-11 21:06:40 - Train Iteration 10557: loss: 0.0326, d_k_M range: [0.0000, 0.1802], d_k_M_hat range: [0.9314, 1.0000]
2025-03-11 21:06:41 - Train Iteration 10558: loss: 0.0298, d_k_M range: [0.0000, 0.0522], d_k_M_hat range: [0.8306, 0.9994]
2025-03-11 21:06:41 - Train Iteration 10559: loss: 0.2716, d_k_M range: [0.0000, 0.5195], d_k_M_hat range: [0.8867, 0.9991]
2025-03-11 21:06:41 - Train Iteration 10560: loss: 0.2434, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.5066, 0.9989]
2025-03-11 21:06:42 - Train Iteration 10561: loss: 0.0282, d_k_M range: [0.0002, 0.0030], d_k_M_hat range: [0.8351, 0.9999]
2025-03-11 21:06:42 - Train Iteration 10562: loss: 0.4375, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.3386, 0.9998]
2025-03-11 21:06:43 - Train Iteration 10563: loss: 0.2854, d_k_M range: [0.0005, 0.1609], d_k_M_hat range: [0.6007, 1.0000]
2025-03-11 21:06:43 - Train Iteration 10564: loss: 0.0239, d_k_M range: [0.0001, 0.1544], d_k_M_hat range: [0.9737, 0.9998]
2025-03-11 21:06:44 - Train Iteration 10565: loss: 0.0338, d_k_M range: [0.0004, 0.1834], d_k_M_hat range: [0.9525, 0.9996]
2025-03-11 21:06:44 - Train Iteration 10566: loss: 0.4192, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.3526, 0.9915]
2025-03-11 21:06:44 - Train Iteration 10567: loss: 0.0114, d_k_M range: [0.0000, 0.1057], d_k_M_hat range: [0.9964, 1.0000]
2025-03-11 21:06:45 - Train Iteration 10568: loss: 0.8736, d_k_M range: [0.0000, 0.9343], d_k_M_hat range: [0.9613, 0.9997]
2025-03-11 21:06:45 - Train Iteration 10569: loss: 0.0054, d_k_M range: [0.0000, 0.0065], d_k_M_hat range: [0.9265, 0.9998]
2025-03-11 21:06:46 - Train Iteration 10570: loss: 0.0005, d_k_M range: [0.0000, 0.0157], d_k_M_hat range: [0.9768, 0.9999]
2025-03-11 21:06:46 - Train Iteration 10571: loss: 0.2414, d_k_M range: [0.0000, 0.0610], d_k_M_hat range: [0.5090, 0.9983]
2025-03-11 21:06:46 - Train Iteration 10572: loss: 0.0008, d_k_M range: [0.0001, 0.0161], d_k_M_hat range: [0.9877, 0.9999]
2025-03-11 21:06:47 - Train Iteration 10573: loss: 0.1910, d_k_M range: [0.0000, 0.0328], d_k_M_hat range: [0.5629, 0.9999]
2025-03-11 21:06:47 - Train Iteration 10574: loss: 0.0183, d_k_M range: [0.0012, 0.1333], d_k_M_hat range: [0.9844, 0.9999]
2025-03-11 21:06:48 - Train Iteration 10575: loss: 0.0119, d_k_M range: [0.0002, 0.1072], d_k_M_hat range: [0.9526, 0.9999]
2025-03-11 21:06:48 - Train Iteration 10576: loss: 0.0066, d_k_M range: [0.0000, 0.0792], d_k_M_hat range: [0.9186, 0.9999]
2025-03-11 21:06:49 - Train Iteration 10577: loss: 0.0521, d_k_M range: [0.0016, 0.2226], d_k_M_hat range: [0.9874, 0.9993]
2025-03-11 21:06:49 - Train Iteration 10578: loss: 0.0054, d_k_M range: [0.0001, 0.0109], d_k_M_hat range: [0.9266, 0.9972]
2025-03-11 21:06:49 - Train Iteration 10579: loss: 0.0771, d_k_M range: [0.0001, 0.2745], d_k_M_hat range: [0.9434, 0.9969]
2025-03-11 21:06:50 - Train Iteration 10580: loss: 0.0048, d_k_M range: [0.0000, 0.0482], d_k_M_hat range: [0.9308, 0.9995]
2025-03-11 21:06:50 - Train Iteration 10581: loss: 0.0024, d_k_M range: [0.0000, 0.0113], d_k_M_hat range: [0.9518, 0.9992]
2025-03-11 21:06:51 - Train Iteration 10582: loss: 0.0051, d_k_M range: [0.0001, 0.0590], d_k_M_hat range: [0.9292, 0.9995]
2025-03-11 21:06:51 - Train Iteration 10583: loss: 0.0023, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.9530, 0.9998]
2025-03-11 21:06:52 - Train Iteration 10584: loss: 0.1517, d_k_M range: [0.0000, 0.3885], d_k_M_hat range: [0.7783, 0.9989]
2025-03-11 21:06:52 - Train Iteration 10585: loss: 0.0277, d_k_M range: [0.0000, 0.0943], d_k_M_hat range: [0.9279, 0.9980]
2025-03-11 21:06:53 - Train Iteration 10586: loss: 0.0618, d_k_M range: [0.0000, 0.2447], d_k_M_hat range: [0.8983, 0.9996]
2025-03-11 21:06:53 - Train Iteration 10587: loss: 0.1619, d_k_M range: [0.0000, 0.0943], d_k_M_hat range: [0.5977, 0.9999]
2025-03-11 21:06:54 - Train Iteration 10588: loss: 0.0294, d_k_M range: [0.0000, 0.0901], d_k_M_hat range: [0.8298, 0.9976]
2025-03-11 21:06:54 - Train Iteration 10589: loss: 0.4409, d_k_M range: [0.0000, 0.6636], d_k_M_hat range: [0.9564, 0.9998]
2025-03-11 21:06:55 - Train Iteration 10590: loss: 0.0618, d_k_M range: [0.0000, 0.0238], d_k_M_hat range: [0.7537, 0.9989]
2025-03-11 21:06:55 - Train Iteration 10591: loss: 0.1442, d_k_M range: [0.0007, 0.3783], d_k_M_hat range: [0.9931, 0.9999]
2025-03-11 21:06:55 - Train Iteration 10592: loss: 0.0267, d_k_M range: [0.0000, 0.1474], d_k_M_hat range: [0.8998, 0.9990]
2025-03-11 21:06:56 - Train Iteration 10593: loss: 0.2140, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.5380, 0.9839]
2025-03-11 21:06:56 - Train Iteration 10594: loss: 0.4349, d_k_M range: [0.0000, 0.6595], d_k_M_hat range: [0.9911, 1.0000]
2025-03-11 21:06:57 - Train Iteration 10595: loss: 0.2008, d_k_M range: [0.0000, 0.0106], d_k_M_hat range: [0.5519, 0.9940]
2025-03-11 21:06:57 - Train Iteration 10596: loss: 0.0593, d_k_M range: [0.0000, 0.2419], d_k_M_hat range: [0.9840, 0.9998]
2025-03-11 21:06:58 - Train Iteration 10597: loss: 0.0113, d_k_M range: [0.0000, 0.0223], d_k_M_hat range: [0.8936, 0.9987]
2025-03-11 21:06:58 - Train Iteration 10598: loss: 0.0010, d_k_M range: [0.0000, 0.0269], d_k_M_hat range: [0.9689, 0.9991]
2025-03-11 21:06:59 - Train Iteration 10599: loss: 0.6807, d_k_M range: [0.0000, 0.0275], d_k_M_hat range: [0.1751, 0.9986]
2025-03-11 21:06:59 - Train Iteration 10600: loss: 0.1384, d_k_M range: [0.0001, 0.3719], d_k_M_hat range: [0.9566, 0.9999]
2025-03-11 21:06:59 - Train Iteration 10601: loss: 0.0236, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.8463, 0.9985]
2025-03-11 21:07:00 - Train Iteration 10602: loss: 0.0295, d_k_M range: [0.0001, 0.1593], d_k_M_hat range: [0.8332, 0.9999]
2025-03-11 21:07:00 - Train Iteration 10603: loss: 0.0032, d_k_M range: [0.0000, 0.0556], d_k_M_hat range: [0.9935, 0.9995]
2025-03-11 21:07:01 - Train Iteration 10604: loss: 0.4735, d_k_M range: [0.0041, 0.6816], d_k_M_hat range: [0.9281, 0.9997]
2025-03-11 21:07:01 - Train Iteration 10605: loss: 0.0186, d_k_M range: [0.0017, 0.1350], d_k_M_hat range: [0.9749, 0.9987]
2025-03-11 21:07:01 - Train Iteration 10606: loss: 0.1768, d_k_M range: [0.0000, 0.4204], d_k_M_hat range: [0.8535, 0.9999]
2025-03-11 21:07:02 - Train Iteration 10607: loss: 0.1023, d_k_M range: [0.0000, 0.0437], d_k_M_hat range: [0.6802, 0.9995]
2025-03-11 21:07:02 - Train Iteration 10608: loss: 0.1049, d_k_M range: [0.0016, 0.3086], d_k_M_hat range: [0.9807, 0.9993]
2025-03-11 21:07:03 - Train Iteration 10609: loss: 0.3171, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.4369, 0.9710]
2025-03-11 21:07:03 - Train Iteration 10610: loss: 0.1137, d_k_M range: [0.0004, 0.3372], d_k_M_hat range: [0.9792, 0.9999]
2025-03-11 21:07:04 - Train Iteration 10611: loss: 0.0099, d_k_M range: [0.0000, 0.0345], d_k_M_hat range: [0.9007, 0.9985]
2025-03-11 21:07:04 - Train Iteration 10612: loss: 0.0360, d_k_M range: [0.0000, 0.0958], d_k_M_hat range: [0.8104, 0.9988]
2025-03-11 21:07:05 - Train Iteration 10613: loss: 0.0624, d_k_M range: [0.0000, 0.2032], d_k_M_hat range: [0.7502, 0.9999]
2025-03-11 21:07:05 - Train Iteration 10614: loss: 0.6817, d_k_M range: [0.0001, 0.8244], d_k_M_hat range: [0.9908, 0.9999]
2025-03-11 21:07:06 - Train Iteration 10615: loss: 0.1423, d_k_M range: [0.0000, 0.0528], d_k_M_hat range: [0.6228, 0.9951]
2025-03-11 21:07:06 - Train Iteration 10616: loss: 0.0060, d_k_M range: [0.0003, 0.0534], d_k_M_hat range: [0.9234, 0.9984]
2025-03-11 21:07:06 - Train Iteration 10617: loss: 0.0034, d_k_M range: [0.0000, 0.0576], d_k_M_hat range: [0.9859, 0.9991]
2025-03-11 21:07:07 - Train Iteration 10618: loss: 0.0165, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.8724, 0.9978]
2025-03-11 21:07:07 - Train Iteration 10619: loss: 0.1089, d_k_M range: [0.0001, 0.0048], d_k_M_hat range: [0.6705, 0.9951]
2025-03-11 21:07:08 - Train Iteration 10620: loss: 0.0542, d_k_M range: [0.0018, 0.2326], d_k_M_hat range: [0.9757, 0.9999]
2025-03-11 21:07:08 - Train Iteration 10621: loss: 0.3219, d_k_M range: [0.0004, 0.5667], d_k_M_hat range: [0.9822, 0.9993]
2025-03-11 21:07:08 - Train Iteration 10622: loss: 0.0212, d_k_M range: [0.0003, 0.0059], d_k_M_hat range: [0.8546, 0.9987]
2025-03-11 21:07:09 - Train Iteration 10623: loss: 0.4013, d_k_M range: [0.0007, 0.0411], d_k_M_hat range: [0.3765, 0.9948]
2025-03-11 21:07:09 - Train Iteration 10624: loss: 0.0108, d_k_M range: [0.0000, 0.1035], d_k_M_hat range: [0.9880, 0.9998]
2025-03-11 21:07:10 - Train Iteration 10625: loss: 0.0171, d_k_M range: [0.0001, 0.1169], d_k_M_hat range: [0.9027, 0.9996]
2025-03-11 21:07:10 - Train Iteration 10626: loss: 0.0183, d_k_M range: [0.0000, 0.1222], d_k_M_hat range: [0.8648, 0.9973]
2025-03-11 21:07:11 - Train Iteration 10627: loss: 0.0214, d_k_M range: [0.0000, 0.1365], d_k_M_hat range: [0.9694, 0.9999]
2025-03-11 21:07:11 - Train Iteration 10628: loss: 0.0859, d_k_M range: [0.0000, 0.1727], d_k_M_hat range: [0.7073, 0.9991]
2025-03-11 21:07:11 - Train Iteration 10629: loss: 0.0168, d_k_M range: [0.0000, 0.1180], d_k_M_hat range: [0.9520, 0.9999]
2025-03-11 21:07:12 - Train Iteration 10630: loss: 0.0142, d_k_M range: [0.0000, 0.1143], d_k_M_hat range: [0.9173, 0.9985]
2025-03-11 21:07:12 - Train Iteration 10631: loss: 0.0167, d_k_M range: [0.0000, 0.0073], d_k_M_hat range: [0.8712, 0.9989]
2025-03-11 21:07:13 - Train Iteration 10632: loss: 0.0548, d_k_M range: [0.0000, 0.2329], d_k_M_hat range: [0.8890, 0.9988]
2025-03-11 21:07:13 - Train Iteration 10633: loss: 0.2400, d_k_M range: [0.0000, 0.0314], d_k_M_hat range: [0.5103, 0.9966]
2025-03-11 21:07:14 - Train Iteration 10634: loss: 0.5115, d_k_M range: [0.0002, 0.7151], d_k_M_hat range: [0.9946, 1.0000]
2025-03-11 21:07:14 - Train Iteration 10635: loss: 0.0062, d_k_M range: [0.0001, 0.0082], d_k_M_hat range: [0.9211, 0.9916]
2025-03-11 21:07:14 - Train Iteration 10636: loss: 0.3300, d_k_M range: [0.0001, 0.5655], d_k_M_hat range: [0.8774, 0.9981]
2025-03-11 21:07:15 - Train Iteration 10637: loss: 0.3992, d_k_M range: [0.0000, 0.0454], d_k_M_hat range: [0.3682, 0.9956]
2025-03-11 21:07:15 - Train Iteration 10638: loss: 0.1623, d_k_M range: [0.0003, 0.3995], d_k_M_hat range: [0.9860, 0.9999]
2025-03-11 21:07:16 - Train Iteration 10639: loss: 0.0679, d_k_M range: [0.0002, 0.2604], d_k_M_hat range: [0.9532, 0.9999]
2025-03-11 21:07:16 - Train Iteration 10640: loss: 0.0738, d_k_M range: [0.0000, 0.0080], d_k_M_hat range: [0.7284, 0.9969]
2025-03-11 21:07:17 - Train Iteration 10641: loss: 0.0021, d_k_M range: [0.0006, 0.0138], d_k_M_hat range: [0.9681, 0.9988]
2025-03-11 21:07:17 - Train Iteration 10642: loss: 0.0644, d_k_M range: [0.0011, 0.2506], d_k_M_hat range: [0.9915, 0.9992]
2025-03-11 21:07:18 - Train Iteration 10643: loss: 0.8566, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.0745, 0.9959]
2025-03-11 21:07:18 - Train Iteration 10644: loss: 0.0046, d_k_M range: [0.0001, 0.0678], d_k_M_hat range: [0.9708, 0.9997]
2025-03-11 21:07:18 - Train Iteration 10645: loss: 0.5117, d_k_M range: [0.0018, 0.7133], d_k_M_hat range: [0.9746, 0.9999]
2025-03-11 21:07:19 - Train Iteration 10646: loss: 0.1283, d_k_M range: [0.0001, 0.0468], d_k_M_hat range: [0.6419, 0.9986]
2025-03-11 21:07:19 - Train Iteration 10647: loss: 0.1394, d_k_M range: [0.0000, 0.2274], d_k_M_hat range: [0.6267, 0.9999]
2025-03-11 21:07:20 - Train Iteration 10648: loss: 0.0300, d_k_M range: [0.0000, 0.1719], d_k_M_hat range: [0.9585, 0.9997]
2025-03-11 21:07:20 - Train Iteration 10649: loss: 0.2343, d_k_M range: [0.0000, 0.4204], d_k_M_hat range: [0.5160, 0.9988]
2025-03-11 21:07:21 - Train Iteration 10650: loss: 0.0145, d_k_M range: [0.0000, 0.0143], d_k_M_hat range: [0.8797, 0.9980]
2025-03-11 21:07:21 - Train Iteration 10651: loss: 0.0060, d_k_M range: [0.0000, 0.0596], d_k_M_hat range: [0.9225, 0.9918]
2025-03-11 21:07:22 - Train Iteration 10652: loss: 0.0020, d_k_M range: [0.0000, 0.0111], d_k_M_hat range: [0.9557, 0.9936]
2025-03-11 21:07:22 - Train Iteration 10653: loss: 0.0353, d_k_M range: [0.0001, 0.0729], d_k_M_hat range: [0.8122, 0.9992]
2025-03-11 21:07:22 - Train Iteration 10654: loss: 0.0095, d_k_M range: [0.0001, 0.0974], d_k_M_hat range: [0.9897, 0.9999]
2025-03-11 21:07:23 - Train Iteration 10655: loss: 0.2467, d_k_M range: [0.0000, 0.0363], d_k_M_hat range: [0.5058, 0.9981]
2025-03-11 21:07:23 - Train Iteration 10656: loss: 0.1870, d_k_M range: [0.0000, 0.0171], d_k_M_hat range: [0.5676, 0.9899]
2025-03-11 21:07:24 - Train Iteration 10657: loss: 0.0027, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9530, 0.9991]
2025-03-11 21:07:24 - Train Iteration 10658: loss: 0.0990, d_k_M range: [0.0000, 0.3130], d_k_M_hat range: [0.9092, 0.9988]
2025-03-11 21:07:25 - Train Iteration 10659: loss: 0.6325, d_k_M range: [0.0006, 0.7605], d_k_M_hat range: [0.9652, 0.9998]
2025-03-11 21:07:25 - Train Iteration 10660: loss: 0.0045, d_k_M range: [0.0002, 0.0428], d_k_M_hat range: [0.9616, 0.9982]
2025-03-11 21:07:26 - Train Iteration 10661: loss: 0.0053, d_k_M range: [0.0000, 0.0192], d_k_M_hat range: [0.9281, 0.9969]
2025-03-11 21:07:26 - Train Iteration 10662: loss: 0.0013, d_k_M range: [0.0002, 0.0317], d_k_M_hat range: [0.9740, 0.9999]
2025-03-11 21:07:27 - Train Iteration 10663: loss: 0.0163, d_k_M range: [0.0000, 0.0494], d_k_M_hat range: [0.8851, 0.9987]
2025-03-11 21:07:27 - Train Iteration 10664: loss: 0.0152, d_k_M range: [0.0000, 0.1209], d_k_M_hat range: [0.9680, 0.9997]
2025-03-11 21:07:27 - Train Iteration 10665: loss: 0.0127, d_k_M range: [0.0000, 0.0668], d_k_M_hat range: [0.8891, 0.9968]
2025-03-11 21:07:28 - Train Iteration 10666: loss: 0.9970, d_k_M range: [0.0000, 0.2955], d_k_M_hat range: [0.0015, 0.9997]
2025-03-11 21:07:28 - Train Iteration 10667: loss: 0.0018, d_k_M range: [0.0000, 0.0205], d_k_M_hat range: [0.9577, 0.9999]
2025-03-11 21:07:29 - Train Iteration 10668: loss: 0.0039, d_k_M range: [0.0006, 0.0624], d_k_M_hat range: [0.9606, 0.9999]
2025-03-11 21:07:29 - Train Iteration 10669: loss: 0.0328, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.8189, 0.9980]
2025-03-11 21:07:29 - Train Iteration 10670: loss: 0.2221, d_k_M range: [0.0000, 0.4713], d_k_M_hat range: [0.9247, 1.0000]
2025-03-11 21:07:30 - Train Iteration 10671: loss: 0.3205, d_k_M range: [0.0000, 0.0242], d_k_M_hat range: [0.4339, 0.9976]
2025-03-11 21:07:30 - Train Iteration 10672: loss: 0.0061, d_k_M range: [0.0000, 0.0773], d_k_M_hat range: [0.9929, 0.9997]
2025-03-11 21:07:31 - Train Iteration 10673: loss: 0.0049, d_k_M range: [0.0000, 0.0222], d_k_M_hat range: [0.9322, 0.9997]
2025-03-11 21:07:31 - Train Iteration 10674: loss: 0.0039, d_k_M range: [0.0001, 0.0403], d_k_M_hat range: [0.9390, 0.9999]
2025-03-11 21:07:32 - Train Iteration 10675: loss: 0.1318, d_k_M range: [0.0017, 0.3626], d_k_M_hat range: [0.9915, 1.0000]
2025-03-11 21:07:32 - Train Iteration 10676: loss: 0.0140, d_k_M range: [0.0001, 0.0429], d_k_M_hat range: [0.8838, 0.9996]
2025-03-11 21:07:32 - Train Iteration 10677: loss: 0.4149, d_k_M range: [0.0000, 0.0259], d_k_M_hat range: [0.3560, 0.9993]
2025-03-11 21:07:33 - Train Iteration 10678: loss: 0.0009, d_k_M range: [0.0000, 0.0090], d_k_M_hat range: [0.9699, 1.0000]
2025-03-11 21:07:33 - Train Iteration 10679: loss: 0.0419, d_k_M range: [0.0000, 0.2026], d_k_M_hat range: [0.9291, 0.9980]
2025-03-11 21:07:34 - Train Iteration 10680: loss: 0.0257, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.8398, 0.9993]
2025-03-11 21:07:34 - Train Iteration 10681: loss: 0.8356, d_k_M range: [0.0003, 0.9138], d_k_M_hat range: [0.9934, 1.0000]
2025-03-11 21:07:35 - Train Iteration 10682: loss: 0.0048, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.9321, 0.9987]
2025-03-11 21:07:35 - Train Iteration 10683: loss: 0.8449, d_k_M range: [0.0000, 0.9190], d_k_M_hat range: [0.9920, 0.9998]
2025-03-11 21:07:35 - Train Iteration 10684: loss: 0.0236, d_k_M range: [0.0002, 0.1526], d_k_M_hat range: [0.9475, 0.9990]
2025-03-11 21:07:36 - Train Iteration 10685: loss: 0.0155, d_k_M range: [0.0000, 0.1245], d_k_M_hat range: [0.9216, 1.0000]
2025-03-11 21:07:36 - Train Iteration 10686: loss: 0.0090, d_k_M range: [0.0000, 0.0176], d_k_M_hat range: [0.9062, 0.9997]
2025-03-11 21:07:37 - Train Iteration 10687: loss: 0.0334, d_k_M range: [0.0000, 0.1819], d_k_M_hat range: [0.9873, 0.9990]
2025-03-11 21:07:37 - Train Iteration 10688: loss: 0.1249, d_k_M range: [0.0000, 0.0116], d_k_M_hat range: [0.6471, 0.9986]
2025-03-11 21:07:38 - Train Iteration 10689: loss: 0.5053, d_k_M range: [0.0008, 0.7069], d_k_M_hat range: [0.9939, 0.9998]
2025-03-11 21:07:38 - Train Iteration 10690: loss: 0.2043, d_k_M range: [0.0000, 0.0415], d_k_M_hat range: [0.5485, 0.9998]
2025-03-11 21:07:39 - Train Iteration 10691: loss: 0.3617, d_k_M range: [0.0003, 0.6011], d_k_M_hat range: [0.9951, 1.0000]
2025-03-11 21:07:39 - Train Iteration 10692: loss: 0.0024, d_k_M range: [0.0000, 0.0121], d_k_M_hat range: [0.9510, 0.9992]
2025-03-11 21:07:39 - Train Iteration 10693: loss: 0.3283, d_k_M range: [0.0000, 0.5719], d_k_M_hat range: [0.9751, 0.9999]
2025-03-11 21:07:40 - Train Iteration 10694: loss: 0.0007, d_k_M range: [0.0000, 0.0266], d_k_M_hat range: [0.9730, 0.9995]
2025-03-11 21:07:40 - Train Iteration 10695: loss: 0.0600, d_k_M range: [0.0000, 0.0149], d_k_M_hat range: [0.7554, 0.9970]
2025-03-11 21:07:41 - Train Iteration 10696: loss: 0.0105, d_k_M range: [0.0000, 0.0929], d_k_M_hat range: [0.9298, 0.9977]
2025-03-11 21:07:41 - Train Iteration 10697: loss: 0.0059, d_k_M range: [0.0000, 0.0748], d_k_M_hat range: [0.9846, 0.9997]
2025-03-11 21:07:42 - Train Iteration 10698: loss: 0.0191, d_k_M range: [0.0000, 0.0104], d_k_M_hat range: [0.8619, 0.9997]
2025-03-11 21:07:42 - Train Iteration 10699: loss: 0.0865, d_k_M range: [0.0000, 0.2923], d_k_M_hat range: [0.7979, 0.9990]
2025-03-11 21:07:43 - Train Iteration 10700: loss: 0.0967, d_k_M range: [0.0001, 0.3086], d_k_M_hat range: [0.9583, 1.0000]
2025-03-11 21:07:43 - Train Iteration 10701: loss: 0.2089, d_k_M range: [0.0000, 0.0358], d_k_M_hat range: [0.5430, 0.9996]
2025-03-11 21:07:43 - Train Iteration 10702: loss: 0.0419, d_k_M range: [0.0000, 0.0086], d_k_M_hat range: [0.7972, 0.9999]
2025-03-11 21:07:44 - Train Iteration 10703: loss: 0.0139, d_k_M range: [0.0000, 0.1156], d_k_M_hat range: [0.9962, 1.0000]
2025-03-11 21:07:44 - Train Iteration 10704: loss: 0.0081, d_k_M range: [0.0000, 0.0221], d_k_M_hat range: [0.9102, 0.9994]
2025-03-11 21:07:45 - Train Iteration 10705: loss: 0.0045, d_k_M range: [0.0000, 0.0585], d_k_M_hat range: [0.9580, 0.9990]
2025-03-11 21:07:45 - Train Iteration 10706: loss: 0.0142, d_k_M range: [0.0000, 0.0133], d_k_M_hat range: [0.8807, 0.9997]
2025-03-11 21:07:45 - Train Iteration 10707: loss: 0.1280, d_k_M range: [0.0001, 0.3564], d_k_M_hat range: [0.9635, 0.9992]
2025-03-11 21:07:46 - Train Iteration 10708: loss: 0.0031, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9451, 0.9993]
2025-03-11 21:07:46 - Train Iteration 10709: loss: 0.0334, d_k_M range: [0.0000, 0.1823], d_k_M_hat range: [0.9790, 0.9998]
2025-03-11 21:07:47 - Train Iteration 10710: loss: 0.0172, d_k_M range: [0.0002, 0.1311], d_k_M_hat range: [0.9917, 1.0000]
2025-03-11 21:07:47 - Train Iteration 10711: loss: 0.0166, d_k_M range: [0.0001, 0.0661], d_k_M_hat range: [0.8713, 0.9998]
2025-03-11 21:07:48 - Train Iteration 10712: loss: 0.0032, d_k_M range: [0.0000, 0.0086], d_k_M_hat range: [0.9437, 0.9997]
2025-03-11 21:07:48 - Train Iteration 10713: loss: 0.8655, d_k_M range: [0.0000, 0.1042], d_k_M_hat range: [0.0697, 0.9974]
2025-03-11 21:07:49 - Train Iteration 10714: loss: 0.4317, d_k_M range: [0.0001, 0.6559], d_k_M_hat range: [0.9833, 0.9998]
2025-03-11 21:07:49 - Train Iteration 10715: loss: 0.1119, d_k_M range: [0.0000, 0.3211], d_k_M_hat range: [0.6656, 0.9953]
2025-03-11 21:07:49 - Train Iteration 10716: loss: 0.0345, d_k_M range: [0.0001, 0.0521], d_k_M_hat range: [0.8157, 0.9991]
2025-03-11 21:07:50 - Train Iteration 10717: loss: 0.0374, d_k_M range: [0.0004, 0.1848], d_k_M_hat range: [0.9905, 0.9995]
2025-03-11 21:07:50 - Train Iteration 10718: loss: 0.1222, d_k_M range: [0.0000, 0.1456], d_k_M_hat range: [0.6504, 0.9979]
2025-03-11 21:07:51 - Train Iteration 10719: loss: 0.0321, d_k_M range: [0.0005, 0.1778], d_k_M_hat range: [0.9880, 0.9999]
2025-03-11 21:07:51 - Train Iteration 10720: loss: 0.2251, d_k_M range: [0.0000, 0.0370], d_k_M_hat range: [0.5255, 0.9986]
2025-03-11 21:07:51 - Train Iteration 10721: loss: 0.0312, d_k_M range: [0.0001, 0.1763], d_k_M_hat range: [0.9429, 0.9999]
2025-03-11 21:07:52 - Train Iteration 10722: loss: 0.0793, d_k_M range: [0.0000, 0.0414], d_k_M_hat range: [0.7187, 0.9987]
2025-03-11 21:07:52 - Train Iteration 10723: loss: 0.0239, d_k_M range: [0.0000, 0.1534], d_k_M_hat range: [0.8942, 0.9992]
2025-03-11 21:07:53 - Train Iteration 10724: loss: 0.0586, d_k_M range: [0.0000, 0.2414], d_k_M_hat range: [0.7632, 0.9992]
2025-03-11 21:07:53 - Train Iteration 10725: loss: 0.8672, d_k_M range: [0.0000, 0.0260], d_k_M_hat range: [0.0688, 0.9898]
2025-03-11 21:07:54 - Train Iteration 10726: loss: 0.2279, d_k_M range: [0.0002, 0.4704], d_k_M_hat range: [0.9922, 0.9999]
2025-03-11 21:07:54 - Train Iteration 10727: loss: 0.0159, d_k_M range: [0.0000, 0.0936], d_k_M_hat range: [0.8740, 0.9972]
2025-03-11 21:07:54 - Train Iteration 10728: loss: 0.0025, d_k_M range: [0.0000, 0.0489], d_k_M_hat range: [0.9567, 0.9993]
2025-03-11 21:07:55 - Train Iteration 10729: loss: 0.0148, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.8784, 0.9999]
2025-03-11 21:07:55 - Train Iteration 10730: loss: 0.1037, d_k_M range: [0.0001, 0.3218], d_k_M_hat range: [0.8956, 0.9999]
2025-03-11 21:07:56 - Train Iteration 10731: loss: 0.0120, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.8912, 0.9950]
2025-03-11 21:07:56 - Train Iteration 10732: loss: 0.0251, d_k_M range: [0.0000, 0.1581], d_k_M_hat range: [0.9329, 0.9998]
2025-03-11 21:07:56 - Train Iteration 10733: loss: 0.2419, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.5082, 0.9940]
2025-03-11 21:07:57 - Train Iteration 10734: loss: 0.0445, d_k_M range: [0.0002, 0.0474], d_k_M_hat range: [0.7894, 0.9994]
2025-03-11 21:07:57 - Train Iteration 10735: loss: 0.1087, d_k_M range: [0.0001, 0.3296], d_k_M_hat range: [0.9552, 1.0000]
2025-03-11 21:07:58 - Train Iteration 10736: loss: 0.7540, d_k_M range: [0.0001, 0.8677], d_k_M_hat range: [0.9251, 0.9994]
2025-03-11 21:07:58 - Train Iteration 10737: loss: 0.6250, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.2095, 0.9879]
2025-03-11 21:07:59 - Train Iteration 10738: loss: 0.0005, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.9788, 0.9995]
2025-03-11 21:07:59 - Train Iteration 10739: loss: 0.0055, d_k_M range: [0.0000, 0.0190], d_k_M_hat range: [0.9256, 0.9976]
2025-03-11 21:08:00 - Train Iteration 10740: loss: 0.0147, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.8787, 0.9993]
2025-03-11 21:08:00 - Train Iteration 10741: loss: 0.4866, d_k_M range: [0.0000, 0.6974], d_k_M_hat range: [0.9495, 0.9998]
2025-03-11 21:08:01 - Train Iteration 10742: loss: 0.5106, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.2855, 0.9922]
2025-03-11 21:08:01 - Train Iteration 10743: loss: 0.0121, d_k_M range: [0.0002, 0.1064], d_k_M_hat range: [0.9337, 0.9994]
2025-03-11 21:08:01 - Train Iteration 10744: loss: 0.0858, d_k_M range: [0.0000, 0.2013], d_k_M_hat range: [0.7071, 0.9989]
2025-03-11 21:08:02 - Train Iteration 10745: loss: 0.0719, d_k_M range: [0.0000, 0.2682], d_k_M_hat range: [0.9848, 1.0000]
2025-03-11 21:08:02 - Train Iteration 10746: loss: 0.2056, d_k_M range: [0.0062, 0.4524], d_k_M_hat range: [0.9819, 1.0000]
2025-03-11 21:08:03 - Train Iteration 10747: loss: 0.0442, d_k_M range: [0.0003, 0.2101], d_k_M_hat range: [0.9109, 1.0000]
2025-03-11 21:08:03 - Train Iteration 10748: loss: 0.0778, d_k_M range: [0.0000, 0.2787], d_k_M_hat range: [0.9355, 0.9998]
2025-03-11 21:08:04 - Train Iteration 10749: loss: 0.0505, d_k_M range: [0.0000, 0.0222], d_k_M_hat range: [0.7757, 0.9982]
2025-03-11 21:08:04 - Train Iteration 10750: loss: 0.0685, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.7382, 0.9874]
2025-03-11 21:08:04 - Train Iteration 10751: loss: 0.9691, d_k_M range: [0.0001, 0.9844], d_k_M_hat range: [0.7949, 1.0000]
2025-03-11 21:08:05 - Train Iteration 10752: loss: 0.0282, d_k_M range: [0.0000, 0.0113], d_k_M_hat range: [0.8320, 0.9996]
2025-03-11 21:08:05 - Train Iteration 10753: loss: 0.0043, d_k_M range: [0.0000, 0.0124], d_k_M_hat range: [0.9344, 0.9995]
2025-03-11 21:08:06 - Train Iteration 10754: loss: 0.0317, d_k_M range: [0.0001, 0.0095], d_k_M_hat range: [0.8278, 0.9998]
2025-03-11 21:08:06 - Train Iteration 10755: loss: 0.1231, d_k_M range: [0.0001, 0.0077], d_k_M_hat range: [0.6493, 0.9978]
2025-03-11 21:08:06 - Train Iteration 10756: loss: 0.0007, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.9742, 0.9978]
2025-03-11 21:08:07 - Train Iteration 10757: loss: 0.0320, d_k_M range: [0.0000, 0.0086], d_k_M_hat range: [0.8212, 0.9996]
2025-03-11 21:08:07 - Train Iteration 10758: loss: 0.0034, d_k_M range: [0.0000, 0.0317], d_k_M_hat range: [0.9423, 0.9991]
2025-03-11 21:08:08 - Train Iteration 10759: loss: 0.3462, d_k_M range: [0.0000, 0.5879], d_k_M_hat range: [0.9857, 0.9996]
2025-03-11 21:08:08 - Train Iteration 10760: loss: 0.1827, d_k_M range: [0.0000, 0.0136], d_k_M_hat range: [0.5726, 0.9993]
2025-03-11 21:08:09 - Train Iteration 10761: loss: 0.1593, d_k_M range: [0.0000, 0.0447], d_k_M_hat range: [0.6011, 0.9998]
2025-03-11 21:08:09 - Train Iteration 10762: loss: 0.1319, d_k_M range: [0.0004, 0.3632], d_k_M_hat range: [0.9752, 1.0000]
2025-03-11 21:08:10 - Train Iteration 10763: loss: 0.0037, d_k_M range: [0.0001, 0.0600], d_k_M_hat range: [0.9962, 0.9999]
2025-03-11 21:08:10 - Train Iteration 10764: loss: 0.0240, d_k_M range: [0.0000, 0.0141], d_k_M_hat range: [0.8462, 0.9984]
2025-03-11 21:08:10 - Train Iteration 10765: loss: 0.3267, d_k_M range: [0.0001, 0.0511], d_k_M_hat range: [0.4311, 0.9985]
2025-03-11 21:08:11 - Train Iteration 10766: loss: 0.0257, d_k_M range: [0.0001, 0.1602], d_k_M_hat range: [0.9801, 0.9998]
2025-03-11 21:08:11 - Train Iteration 10767: loss: 0.1435, d_k_M range: [0.0000, 0.0066], d_k_M_hat range: [0.6212, 0.9980]
2025-03-11 21:08:12 - Train Iteration 10768: loss: 0.0831, d_k_M range: [0.0002, 0.2878], d_k_M_hat range: [0.9916, 1.0000]
2025-03-11 21:08:12 - Train Iteration 10769: loss: 0.6488, d_k_M range: [0.0000, 0.0510], d_k_M_hat range: [0.1975, 0.9994]
2025-03-11 21:08:13 - Train Iteration 10770: loss: 0.4763, d_k_M range: [0.0008, 0.6890], d_k_M_hat range: [0.9951, 0.9999]
2025-03-11 21:08:13 - Train Iteration 10771: loss: 0.9946, d_k_M range: [0.0000, 0.0197], d_k_M_hat range: [0.0028, 0.9959]
2025-03-11 21:08:13 - Train Iteration 10772: loss: 0.0015, d_k_M range: [0.0002, 0.0380], d_k_M_hat range: [0.9725, 1.0000]
2025-03-11 21:08:14 - Train Iteration 10773: loss: 0.0593, d_k_M range: [0.0001, 0.1335], d_k_M_hat range: [0.7572, 0.9996]
2025-03-11 21:08:14 - Train Iteration 10774: loss: 0.5982, d_k_M range: [0.0001, 0.7734], d_k_M_hat range: [0.9399, 1.0000]
2025-03-11 21:08:15 - Train Iteration 10775: loss: 0.0101, d_k_M range: [0.0001, 0.0258], d_k_M_hat range: [0.9079, 0.9998]
2025-03-11 21:08:15 - Train Iteration 10776: loss: 0.3466, d_k_M range: [0.0003, 0.5883], d_k_M_hat range: [0.9375, 0.9996]
2025-03-11 21:08:16 - Train Iteration 10777: loss: 0.0293, d_k_M range: [0.0001, 0.0200], d_k_M_hat range: [0.8290, 0.9993]
2025-03-11 21:08:16 - Train Iteration 10778: loss: 0.0061, d_k_M range: [0.0000, 0.0391], d_k_M_hat range: [0.9217, 0.9993]
2025-03-11 21:08:16 - Train Iteration 10779: loss: 0.1969, d_k_M range: [0.0000, 0.4430], d_k_M_hat range: [0.8940, 0.9993]
2025-03-11 21:08:17 - Train Iteration 10780: loss: 0.0494, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.7779, 0.9994]
2025-03-11 21:08:17 - Train Iteration 10781: loss: 0.6349, d_k_M range: [0.0000, 0.7956], d_k_M_hat range: [0.9618, 0.9993]
2025-03-11 21:08:18 - Train Iteration 10782: loss: 0.0012, d_k_M range: [0.0002, 0.0051], d_k_M_hat range: [0.9704, 0.9993]
2025-03-11 21:08:18 - Train Iteration 10783: loss: 0.5037, d_k_M range: [0.0005, 0.7087], d_k_M_hat range: [0.9148, 0.9999]
2025-03-11 21:08:18 - Train Iteration 10784: loss: 0.0061, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.9232, 0.9994]
2025-03-11 21:08:19 - Train Iteration 10785: loss: 0.0036, d_k_M range: [0.0000, 0.0084], d_k_M_hat range: [0.9408, 0.9941]
2025-03-11 21:08:19 - Train Iteration 10786: loss: 0.0006, d_k_M range: [0.0000, 0.0208], d_k_M_hat range: [0.9750, 0.9992]
2025-03-11 21:08:20 - Train Iteration 10787: loss: 0.2025, d_k_M range: [0.0000, 0.0730], d_k_M_hat range: [0.5501, 0.9982]
2025-03-11 21:08:20 - Train Iteration 10788: loss: 0.0278, d_k_M range: [0.0006, 0.1667], d_k_M_hat range: [0.9769, 0.9998]
2025-03-11 21:08:21 - Train Iteration 10789: loss: 0.0095, d_k_M range: [0.0000, 0.0255], d_k_M_hat range: [0.9050, 0.9999]
2025-03-11 21:08:21 - Train Iteration 10790: loss: 0.5794, d_k_M range: [0.0000, 0.7608], d_k_M_hat range: [0.9400, 0.9996]
2025-03-11 21:08:21 - Train Iteration 10791: loss: 0.0161, d_k_M range: [0.0000, 0.0613], d_k_M_hat range: [0.8768, 0.9997]
2025-03-11 21:08:22 - Train Iteration 10792: loss: 0.7065, d_k_M range: [0.0000, 0.8403], d_k_M_hat range: [0.9919, 0.9997]
2025-03-11 21:08:22 - Train Iteration 10793: loss: 0.0415, d_k_M range: [0.0000, 0.0116], d_k_M_hat range: [0.7965, 0.9996]
2025-03-11 21:08:23 - Train Iteration 10794: loss: 0.0030, d_k_M range: [0.0001, 0.0090], d_k_M_hat range: [0.9470, 0.9995]
2025-03-11 21:08:23 - Train Iteration 10795: loss: 0.1022, d_k_M range: [0.0000, 0.3191], d_k_M_hat range: [0.9902, 0.9997]
2025-03-11 21:08:24 - Train Iteration 10796: loss: 0.0345, d_k_M range: [0.0003, 0.1828], d_k_M_hat range: [0.9669, 0.9998]
2025-03-11 21:08:24 - Train Iteration 10797: loss: 0.0688, d_k_M range: [0.0000, 0.0223], d_k_M_hat range: [0.7379, 0.9983]
2025-03-11 21:08:24 - Train Iteration 10798: loss: 0.0289, d_k_M range: [0.0000, 0.1682], d_k_M_hat range: [0.9424, 0.9996]
2025-03-11 21:08:25 - Train Iteration 10799: loss: 0.0058, d_k_M range: [0.0002, 0.0750], d_k_M_hat range: [0.9666, 0.9994]
2025-03-11 21:08:25 - Train Iteration 10800: loss: 0.0128, d_k_M range: [0.0003, 0.0270], d_k_M_hat range: [0.8870, 0.9989]
2025-03-11 21:08:26 - Train Iteration 10801: loss: 0.0533, d_k_M range: [0.0001, 0.1817], d_k_M_hat range: [0.9370, 1.0000]
2025-03-11 21:08:26 - Train Iteration 10802: loss: 0.0014, d_k_M range: [0.0000, 0.0148], d_k_M_hat range: [0.9625, 0.9992]
2025-03-11 21:08:27 - Train Iteration 10803: loss: 0.0028, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9470, 0.9978]
2025-03-11 21:08:27 - Train Iteration 10804: loss: 0.0069, d_k_M range: [0.0003, 0.0829], d_k_M_hat range: [0.9758, 0.9999]
2025-03-11 21:08:28 - Train Iteration 10805: loss: 0.1757, d_k_M range: [0.0003, 0.4187], d_k_M_hat range: [0.9794, 0.9996]
2025-03-11 21:08:28 - Train Iteration 10806: loss: 0.1359, d_k_M range: [0.0000, 0.3573], d_k_M_hat range: [0.8693, 0.9975]
2025-03-11 21:08:28 - Train Iteration 10807: loss: 0.0020, d_k_M range: [0.0000, 0.0089], d_k_M_hat range: [0.9559, 0.9994]
2025-03-11 21:08:29 - Train Iteration 10808: loss: 0.0174, d_k_M range: [0.0001, 0.0461], d_k_M_hat range: [0.9140, 0.9988]
2025-03-11 21:08:29 - Train Iteration 10809: loss: 0.0427, d_k_M range: [0.0001, 0.0162], d_k_M_hat range: [0.7936, 0.9997]
2025-03-11 21:08:30 - Train Iteration 10810: loss: 0.0128, d_k_M range: [0.0000, 0.0986], d_k_M_hat range: [0.9231, 0.9983]
2025-03-11 21:08:30 - Train Iteration 10811: loss: 0.0057, d_k_M range: [0.0000, 0.0153], d_k_M_hat range: [0.9244, 0.9988]
2025-03-11 21:08:31 - Train Iteration 10812: loss: 0.0382, d_k_M range: [0.0000, 0.0109], d_k_M_hat range: [0.8047, 1.0000]
2025-03-11 21:08:31 - Train Iteration 10813: loss: 0.0015, d_k_M range: [0.0000, 0.0215], d_k_M_hat range: [0.9660, 0.9999]
2025-03-11 21:08:32 - Train Iteration 10814: loss: 0.0046, d_k_M range: [0.0000, 0.0505], d_k_M_hat range: [0.9327, 0.9997]
2025-03-11 21:08:32 - Train Iteration 10815: loss: 0.0188, d_k_M range: [0.0001, 0.1371], d_k_M_hat range: [0.9902, 1.0000]
2025-03-11 21:08:32 - Train Iteration 10816: loss: 0.0043, d_k_M range: [0.0000, 0.0543], d_k_M_hat range: [0.9770, 0.9991]
2025-03-11 21:08:33 - Train Iteration 10817: loss: 0.8234, d_k_M range: [0.0000, 0.0155], d_k_M_hat range: [0.0926, 0.9998]
2025-03-11 21:08:33 - Train Iteration 10818: loss: 0.0095, d_k_M range: [0.0000, 0.0316], d_k_M_hat range: [0.9047, 0.9991]
2025-03-11 21:08:34 - Train Iteration 10819: loss: 0.2978, d_k_M range: [0.0000, 0.0143], d_k_M_hat range: [0.4544, 0.9994]
2025-03-11 21:08:34 - Train Iteration 10820: loss: 0.0535, d_k_M range: [0.0000, 0.2308], d_k_M_hat range: [0.9751, 0.9998]
2025-03-11 21:08:35 - Train Iteration 10821: loss: 0.0151, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.8775, 0.9981]
2025-03-11 21:08:35 - Train Iteration 10822: loss: 0.1210, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.6522, 0.9994]
2025-03-11 21:08:35 - Train Iteration 10823: loss: 0.0097, d_k_M range: [0.0000, 0.0980], d_k_M_hat range: [0.9764, 0.9998]
2025-03-11 21:08:36 - Train Iteration 10824: loss: 0.0106, d_k_M range: [0.0000, 0.1015], d_k_M_hat range: [0.9915, 0.9996]
2025-03-11 21:08:36 - Train Iteration 10825: loss: 0.7719, d_k_M range: [0.0000, 0.0334], d_k_M_hat range: [0.1215, 0.9994]
2025-03-11 21:08:37 - Train Iteration 10826: loss: 0.2691, d_k_M range: [0.0000, 0.5176], d_k_M_hat range: [0.9730, 0.9999]
2025-03-11 21:08:37 - Train Iteration 10827: loss: 0.0049, d_k_M range: [0.0001, 0.0365], d_k_M_hat range: [0.9669, 0.9989]
2025-03-11 21:08:37 - Train Iteration 10828: loss: 0.0141, d_k_M range: [0.0004, 0.1164], d_k_M_hat range: [0.8878, 0.9999]
2025-03-11 21:08:38 - Train Iteration 10829: loss: 0.0638, d_k_M range: [0.0000, 0.0228], d_k_M_hat range: [0.7474, 0.9990]
2025-03-11 21:08:38 - Train Iteration 10830: loss: 0.0074, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.9141, 0.9992]
2025-03-11 21:08:39 - Train Iteration 10831: loss: 0.0084, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9103, 0.9981]
2025-03-11 21:08:39 - Train Iteration 10832: loss: 0.0079, d_k_M range: [0.0000, 0.0274], d_k_M_hat range: [0.9385, 0.9984]
2025-03-11 21:08:40 - Train Iteration 10833: loss: 0.0105, d_k_M range: [0.0005, 0.0390], d_k_M_hat range: [0.8987, 0.9996]
2025-03-11 21:08:40 - Train Iteration 10834: loss: 0.0016, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.9603, 0.9996]
2025-03-11 21:08:40 - Train Iteration 10835: loss: 0.0992, d_k_M range: [0.0000, 0.3149], d_k_M_hat range: [0.8492, 0.9999]
2025-03-11 21:08:41 - Train Iteration 10836: loss: 0.0231, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.8480, 0.9902]
2025-03-11 21:08:41 - Train Iteration 10837: loss: 0.0168, d_k_M range: [0.0000, 0.0337], d_k_M_hat range: [0.8853, 0.9998]
2025-03-11 21:08:42 - Train Iteration 10838: loss: 0.8146, d_k_M range: [0.0006, 0.9025], d_k_M_hat range: [0.9877, 1.0000]
2025-03-11 21:08:42 - Train Iteration 10839: loss: 0.0456, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.7863, 0.9989]
2025-03-11 21:08:43 - Train Iteration 10840: loss: 0.0251, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.8416, 0.9967]
2025-03-11 21:08:43 - Train Iteration 10841: loss: 0.0521, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.7721, 0.9982]
2025-03-11 21:08:43 - Train Iteration 10842: loss: 0.0115, d_k_M range: [0.0000, 0.1069], d_k_M_hat range: [0.9421, 0.9997]
2025-03-11 21:08:44 - Train Iteration 10843: loss: 0.2907, d_k_M range: [0.0000, 0.5388], d_k_M_hat range: [0.9866, 0.9998]
2025-03-11 21:08:44 - Train Iteration 10844: loss: 0.3573, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.4022, 0.9957]
2025-03-11 21:08:45 - Train Iteration 10845: loss: 0.0189, d_k_M range: [0.0001, 0.1332], d_k_M_hat range: [0.9650, 0.9996]
2025-03-11 21:08:45 - Train Iteration 10846: loss: 0.0031, d_k_M range: [0.0000, 0.0178], d_k_M_hat range: [0.9444, 0.9984]
2025-03-11 21:08:46 - Train Iteration 10847: loss: 0.0085, d_k_M range: [0.0000, 0.0101], d_k_M_hat range: [0.9093, 0.9995]
2025-03-11 21:08:46 - Train Iteration 10848: loss: 0.3974, d_k_M range: [0.0000, 0.6264], d_k_M_hat range: [0.9753, 0.9983]
2025-03-11 21:08:46 - Train Iteration 10849: loss: 0.1422, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.6229, 0.9705]
2025-03-11 21:08:47 - Train Iteration 10850: loss: 0.0071, d_k_M range: [0.0000, 0.0841], d_k_M_hat range: [0.9960, 0.9996]
2025-03-11 21:08:47 - Train Iteration 10851: loss: 0.1740, d_k_M range: [0.0000, 0.0243], d_k_M_hat range: [0.5828, 0.9998]
2025-03-11 21:08:48 - Train Iteration 10852: loss: 0.3240, d_k_M range: [0.0004, 0.5692], d_k_M_hat range: [0.9823, 1.0000]
2025-03-11 21:08:48 - Train Iteration 10853: loss: 0.0182, d_k_M range: [0.0000, 0.1343], d_k_M_hat range: [0.8736, 0.9994]
2025-03-11 21:08:49 - Train Iteration 10854: loss: 0.0207, d_k_M range: [0.0000, 0.0148], d_k_M_hat range: [0.8560, 1.0000]
2025-03-11 21:08:49 - Train Iteration 10855: loss: 0.8662, d_k_M range: [0.0001, 0.9307], d_k_M_hat range: [0.9684, 0.9999]
2025-03-11 21:08:50 - Train Iteration 10856: loss: 0.0020, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.9554, 0.9997]
2025-03-11 21:08:50 - Train Iteration 10857: loss: 0.0192, d_k_M range: [0.0001, 0.1374], d_k_M_hat range: [0.9059, 0.9995]
2025-03-11 21:08:50 - Train Iteration 10858: loss: 0.0056, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9252, 0.9961]
2025-03-11 21:08:51 - Train Iteration 10859: loss: 0.2518, d_k_M range: [0.0000, 0.5015], d_k_M_hat range: [0.9518, 0.9997]
2025-03-11 21:08:51 - Train Iteration 10860: loss: 0.0872, d_k_M range: [0.0000, 0.0127], d_k_M_hat range: [0.7050, 0.9959]
2025-03-11 21:08:52 - Train Iteration 10861: loss: 0.0027, d_k_M range: [0.0011, 0.0190], d_k_M_hat range: [0.9505, 0.9987]
2025-03-11 21:08:52 - Train Iteration 10862: loss: 0.0038, d_k_M range: [0.0001, 0.0595], d_k_M_hat range: [0.9520, 0.9998]
2025-03-11 21:08:53 - Train Iteration 10863: loss: 0.0101, d_k_M range: [0.0017, 0.0987], d_k_M_hat range: [0.9574, 0.9998]
2025-03-11 21:08:53 - Train Iteration 10864: loss: 0.0068, d_k_M range: [0.0001, 0.0806], d_k_M_hat range: [0.9562, 0.9999]
2025-03-11 21:08:54 - Train Iteration 10865: loss: 0.0197, d_k_M range: [0.0004, 0.0328], d_k_M_hat range: [0.8600, 0.9972]
2025-03-11 21:08:54 - Train Iteration 10866: loss: 0.0017, d_k_M range: [0.0001, 0.0408], d_k_M_hat range: [0.9896, 1.0000]
2025-03-11 21:08:54 - Train Iteration 10867: loss: 0.0073, d_k_M range: [0.0000, 0.0179], d_k_M_hat range: [0.9150, 0.9992]
2025-03-11 21:08:55 - Train Iteration 10868: loss: 0.0022, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9544, 0.9992]
2025-03-11 21:08:55 - Train Iteration 10869: loss: 0.0048, d_k_M range: [0.0000, 0.0688], d_k_M_hat range: [0.9442, 0.9998]
2025-03-11 21:08:56 - Train Iteration 10870: loss: 0.5031, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.2910, 0.9786]
2025-03-11 21:08:56 - Train Iteration 10871: loss: 0.1315, d_k_M range: [0.0037, 0.3623], d_k_M_hat range: [0.9966, 0.9999]
2025-03-11 21:08:57 - Train Iteration 10872: loss: 0.0503, d_k_M range: [0.0000, 0.2228], d_k_M_hat range: [0.9453, 0.9997]
2025-03-11 21:08:57 - Train Iteration 10873: loss: 0.1958, d_k_M range: [0.0000, 0.4415], d_k_M_hat range: [0.9702, 0.9990]
2025-03-11 21:08:57 - Train Iteration 10874: loss: 0.0990, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.6853, 0.9948]
2025-03-11 21:08:58 - Train Iteration 10875: loss: 0.0066, d_k_M range: [0.0006, 0.0797], d_k_M_hat range: [0.9847, 0.9984]
2025-03-11 21:08:58 - Train Iteration 10876: loss: 0.1190, d_k_M range: [0.0000, 0.3434], d_k_M_hat range: [0.8481, 0.9992]
2025-03-11 21:08:59 - Train Iteration 10877: loss: 0.7710, d_k_M range: [0.0000, 0.0227], d_k_M_hat range: [0.1220, 0.9986]
2025-03-11 21:08:59 - Train Iteration 10878: loss: 0.4182, d_k_M range: [0.0003, 0.6442], d_k_M_hat range: [0.9953, 0.9998]
2025-03-11 21:09:00 - Train Iteration 10879: loss: 0.7164, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.1536, 0.9958]
2025-03-11 21:09:00 - Train Iteration 10880: loss: 0.3443, d_k_M range: [0.0002, 0.5865], d_k_M_hat range: [0.9933, 0.9997]
2025-03-11 21:09:01 - Train Iteration 10881: loss: 0.0186, d_k_M range: [0.0000, 0.0458], d_k_M_hat range: [0.9096, 0.9992]
2025-03-11 21:09:01 - Train Iteration 10882: loss: 0.0074, d_k_M range: [0.0000, 0.0716], d_k_M_hat range: [0.9604, 0.9987]
2025-03-11 21:09:01 - Train Iteration 10883: loss: 0.0182, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.8654, 0.9967]
2025-03-11 21:09:02 - Train Iteration 10884: loss: 0.0230, d_k_M range: [0.0000, 0.1506], d_k_M_hat range: [0.9099, 0.9991]
2025-03-11 21:09:02 - Train Iteration 10885: loss: 0.0008, d_k_M range: [0.0002, 0.0129], d_k_M_hat range: [0.9848, 0.9989]
2025-03-11 21:09:03 - Train Iteration 10886: loss: 0.0010, d_k_M range: [0.0000, 0.0314], d_k_M_hat range: [0.9790, 0.9997]
2025-03-11 21:09:03 - Train Iteration 10887: loss: 0.0090, d_k_M range: [0.0000, 0.0239], d_k_M_hat range: [0.9050, 0.9992]
2025-03-11 21:09:04 - Train Iteration 10888: loss: 0.0080, d_k_M range: [0.0000, 0.0863], d_k_M_hat range: [0.9234, 0.9999]
2025-03-11 21:09:04 - Train Iteration 10889: loss: 0.0466, d_k_M range: [0.0000, 0.2148], d_k_M_hat range: [0.9627, 0.9990]
2025-03-11 21:09:04 - Train Iteration 10890: loss: 0.0020, d_k_M range: [0.0000, 0.0101], d_k_M_hat range: [0.9557, 0.9992]
2025-03-11 21:09:05 - Train Iteration 10891: loss: 0.3019, d_k_M range: [0.0001, 0.0218], d_k_M_hat range: [0.4512, 0.9999]
2025-03-11 21:09:05 - Train Iteration 10892: loss: 0.0273, d_k_M range: [0.0000, 0.1076], d_k_M_hat range: [0.8384, 0.9999]
2025-03-11 21:09:06 - Train Iteration 10893: loss: 0.0046, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.9424, 1.0000]
2025-03-11 21:09:06 - Train Iteration 10894: loss: 0.0057, d_k_M range: [0.0000, 0.0065], d_k_M_hat range: [0.9311, 0.9965]
2025-03-11 21:09:06 - Train Iteration 10895: loss: 0.0258, d_k_M range: [0.0000, 0.0375], d_k_M_hat range: [0.8395, 0.9997]
2025-03-11 21:09:07 - Train Iteration 10896: loss: 0.0274, d_k_M range: [0.0000, 0.0567], d_k_M_hat range: [0.8347, 0.9984]
2025-03-11 21:09:07 - Train Iteration 10897: loss: 0.0037, d_k_M range: [0.0001, 0.0184], d_k_M_hat range: [0.9393, 0.9988]
2025-03-11 21:09:08 - Train Iteration 10898: loss: 0.2841, d_k_M range: [0.0000, 0.0105], d_k_M_hat range: [0.4670, 0.9935]
2025-03-11 21:09:08 - Train Iteration 10899: loss: 0.3669, d_k_M range: [0.0009, 0.6041], d_k_M_hat range: [0.9983, 0.9999]
2025-03-11 21:09:09 - Train Iteration 10900: loss: 0.0070, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9162, 0.9903]
2025-03-11 21:09:09 - Train Iteration 10901: loss: 0.8058, d_k_M range: [0.0000, 0.8967], d_k_M_hat range: [0.9841, 0.9998]
2025-03-11 21:09:09 - Train Iteration 10902: loss: 0.0156, d_k_M range: [0.0000, 0.0117], d_k_M_hat range: [0.8761, 0.9994]
2025-03-11 21:09:10 - Train Iteration 10903: loss: 0.0028, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.9499, 0.9999]
2025-03-11 21:09:10 - Train Iteration 10904: loss: 0.0871, d_k_M range: [0.0000, 0.0097], d_k_M_hat range: [0.7050, 0.9996]
2025-03-11 21:09:11 - Train Iteration 10905: loss: 0.0173, d_k_M range: [0.0000, 0.0420], d_k_M_hat range: [0.9104, 0.9998]
2025-03-11 21:09:11 - Train Iteration 10906: loss: 0.0613, d_k_M range: [0.0000, 0.2443], d_k_M_hat range: [0.8679, 0.9999]
2025-03-11 21:09:11 - Train Iteration 10907: loss: 0.0558, d_k_M range: [0.0000, 0.2346], d_k_M_hat range: [0.9322, 0.9985]
2025-03-11 21:09:12 - Train Iteration 10908: loss: 0.0016, d_k_M range: [0.0000, 0.0293], d_k_M_hat range: [0.9839, 0.9999]
2025-03-11 21:09:12 - Train Iteration 10909: loss: 0.0319, d_k_M range: [0.0001, 0.1486], d_k_M_hat range: [0.8216, 0.9997]
2025-03-11 21:09:13 - Train Iteration 10910: loss: 0.1336, d_k_M range: [0.0000, 0.3536], d_k_M_hat range: [0.6669, 0.9994]
2025-03-11 21:09:13 - Train Iteration 10911: loss: 0.7147, d_k_M range: [0.0000, 0.0105], d_k_M_hat range: [0.1546, 0.9988]
2025-03-11 21:09:14 - Train Iteration 10912: loss: 0.1556, d_k_M range: [0.0002, 0.3944], d_k_M_hat range: [0.9950, 1.0000]
2025-03-11 21:09:14 - Train Iteration 10913: loss: 0.0028, d_k_M range: [0.0000, 0.0245], d_k_M_hat range: [0.9473, 0.9994]
2025-03-11 21:09:15 - Train Iteration 10914: loss: 0.3661, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.3949, 0.9972]
2025-03-11 21:09:15 - Train Iteration 10915: loss: 0.0019, d_k_M range: [0.0000, 0.0415], d_k_M_hat range: [0.9805, 1.0000]
2025-03-11 21:09:15 - Train Iteration 10916: loss: 0.0085, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9080, 0.9992]
2025-03-11 21:09:16 - Train Iteration 10917: loss: 0.0011, d_k_M range: [0.0000, 0.0148], d_k_M_hat range: [0.9681, 0.9969]
2025-03-11 21:09:16 - Train Iteration 10918: loss: 0.0001, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9899, 0.9988]
2025-03-11 21:09:17 - Train Iteration 10919: loss: 0.2093, d_k_M range: [0.0000, 0.0056], d_k_M_hat range: [0.5427, 0.9994]
2025-03-11 21:09:17 - Train Iteration 10920: loss: 0.5177, d_k_M range: [0.0000, 0.7193], d_k_M_hat range: [0.9573, 0.9999]
2025-03-11 21:09:18 - Train Iteration 10921: loss: 0.3059, d_k_M range: [0.0000, 0.0343], d_k_M_hat range: [0.4554, 0.9970]
2025-03-11 21:09:18 - Train Iteration 10922: loss: 0.0044, d_k_M range: [0.0001, 0.0034], d_k_M_hat range: [0.9345, 0.9960]
2025-03-11 21:09:18 - Train Iteration 10923: loss: 0.0003, d_k_M range: [0.0002, 0.0171], d_k_M_hat range: [0.9834, 0.9997]
2025-03-11 21:09:19 - Train Iteration 10924: loss: 0.5376, d_k_M range: [0.0001, 0.7330], d_k_M_hat range: [0.9974, 0.9998]
2025-03-11 21:09:19 - Train Iteration 10925: loss: 0.0022, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9533, 0.9991]
2025-03-11 21:09:20 - Train Iteration 10926: loss: 0.0024, d_k_M range: [0.0000, 0.0285], d_k_M_hat range: [0.9513, 0.9998]
2025-03-11 21:09:20 - Train Iteration 10927: loss: 0.0182, d_k_M range: [0.0000, 0.0056], d_k_M_hat range: [0.8651, 0.9992]
2025-03-11 21:09:20 - Train Iteration 10928: loss: 0.8691, d_k_M range: [0.0020, 0.9318], d_k_M_hat range: [0.9990, 1.0000]
2025-03-11 21:09:21 - Train Iteration 10929: loss: 0.0137, d_k_M range: [0.0009, 0.1165], d_k_M_hat range: [0.9593, 0.9998]
2025-03-11 21:09:21 - Train Iteration 10930: loss: 0.0004, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9827, 0.9985]
2025-03-11 21:09:22 - Train Iteration 10931: loss: 0.0007, d_k_M range: [0.0001, 0.0253], d_k_M_hat range: [0.9958, 0.9997]
2025-03-11 21:09:22 - Train Iteration 10932: loss: 0.0101, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.8994, 0.9992]
2025-03-11 21:09:23 - Train Iteration 10933: loss: 0.0008, d_k_M range: [0.0004, 0.0251], d_k_M_hat range: [0.9724, 0.9994]
2025-03-11 21:09:23 - Train Iteration 10934: loss: 0.0035, d_k_M range: [0.0000, 0.0584], d_k_M_hat range: [0.9897, 0.9992]
2025-03-11 21:09:24 - Train Iteration 10935: loss: 0.0353, d_k_M range: [0.0000, 0.1871], d_k_M_hat range: [0.9927, 0.9991]
2025-03-11 21:09:24 - Train Iteration 10936: loss: 0.0370, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.8077, 0.9991]
2025-03-11 21:09:24 - Train Iteration 10937: loss: 0.0300, d_k_M range: [0.0000, 0.1718], d_k_M_hat range: [0.9640, 0.9997]
2025-03-11 21:09:25 - Train Iteration 10938: loss: 0.0114, d_k_M range: [0.0000, 0.1060], d_k_M_hat range: [0.9392, 0.9991]
2025-03-11 21:09:25 - Train Iteration 10939: loss: 0.0121, d_k_M range: [0.0000, 0.0088], d_k_M_hat range: [0.8904, 0.9996]
2025-03-11 21:09:26 - Train Iteration 10940: loss: 0.0076, d_k_M range: [0.0000, 0.0832], d_k_M_hat range: [0.9461, 0.9992]
2025-03-11 21:09:26 - Train Iteration 10941: loss: 0.0361, d_k_M range: [0.0002, 0.1892], d_k_M_hat range: [0.8976, 1.0000]
2025-03-11 21:09:26 - Train Iteration 10942: loss: 0.0048, d_k_M range: [0.0001, 0.0191], d_k_M_hat range: [0.9324, 0.9998]
2025-03-11 21:09:27 - Train Iteration 10943: loss: 0.0024, d_k_M range: [0.0000, 0.0174], d_k_M_hat range: [0.9530, 0.9994]
2025-03-11 21:09:27 - Train Iteration 10944: loss: 0.0051, d_k_M range: [0.0000, 0.0450], d_k_M_hat range: [0.9286, 0.9998]
2025-03-11 21:09:28 - Train Iteration 10945: loss: 0.0030, d_k_M range: [0.0001, 0.0533], d_k_M_hat range: [0.9786, 1.0000]
2025-03-11 21:09:28 - Train Iteration 10946: loss: 0.0011, d_k_M range: [0.0001, 0.0212], d_k_M_hat range: [0.9675, 0.9998]
2025-03-11 21:09:29 - Train Iteration 10947: loss: 0.0371, d_k_M range: [0.0000, 0.0462], d_k_M_hat range: [0.8077, 0.9996]
2025-03-11 21:09:29 - Train Iteration 10948: loss: 0.3070, d_k_M range: [0.0000, 0.5539], d_k_M_hat range: [0.7580, 1.0000]
2025-03-11 21:09:29 - Train Iteration 10949: loss: 0.1106, d_k_M range: [0.0000, 0.0200], d_k_M_hat range: [0.6676, 0.9990]
2025-03-11 21:09:30 - Train Iteration 10950: loss: 0.0273, d_k_M range: [0.0002, 0.1651], d_k_M_hat range: [0.9945, 0.9998]
2025-03-11 21:09:30 - Train Iteration 10951: loss: 0.0104, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.8983, 0.9950]
2025-03-11 21:09:31 - Train Iteration 10952: loss: 0.7485, d_k_M range: [0.0000, 0.8651], d_k_M_hat range: [0.6801, 1.0000]
2025-03-11 21:09:31 - Train Iteration 10953: loss: 0.1449, d_k_M range: [0.0000, 0.1238], d_k_M_hat range: [0.6194, 0.9984]
2025-03-11 21:09:32 - Train Iteration 10954: loss: 0.2581, d_k_M range: [0.0001, 0.4988], d_k_M_hat range: [0.9648, 0.9995]
2025-03-11 21:09:32 - Train Iteration 10955: loss: 0.0282, d_k_M range: [0.0000, 0.0274], d_k_M_hat range: [0.8351, 0.9989]
2025-03-11 21:09:32 - Train Iteration 10956: loss: 0.0392, d_k_M range: [0.0000, 0.0497], d_k_M_hat range: [0.8020, 0.9997]
2025-03-11 21:09:33 - Train Iteration 10957: loss: 0.0002, d_k_M range: [0.0000, 0.0113], d_k_M_hat range: [0.9844, 0.9995]
2025-03-11 21:09:33 - Train Iteration 10958: loss: 0.0023, d_k_M range: [0.0000, 0.0445], d_k_M_hat range: [0.9800, 0.9970]
2025-03-11 21:09:34 - Train Iteration 10959: loss: 0.0010, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9709, 0.9980]
2025-03-11 21:09:34 - Train Iteration 10960: loss: 0.0083, d_k_M range: [0.0000, 0.0196], d_k_M_hat range: [0.9091, 1.0000]
2025-03-11 21:09:35 - Train Iteration 10961: loss: 0.0087, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.9096, 0.9994]
2025-03-11 21:09:35 - Train Iteration 10962: loss: 0.3063, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.4472, 0.9833]
2025-03-11 21:09:36 - Train Iteration 10963: loss: 0.0023, d_k_M range: [0.0000, 0.0091], d_k_M_hat range: [0.9519, 0.9981]
2025-03-11 21:09:36 - Train Iteration 10964: loss: 0.0487, d_k_M range: [0.0000, 0.0132], d_k_M_hat range: [0.7793, 0.9994]
2025-03-11 21:09:36 - Train Iteration 10965: loss: 0.0091, d_k_M range: [0.0000, 0.0942], d_k_M_hat range: [0.9202, 0.9997]
2025-03-11 21:09:37 - Train Iteration 10966: loss: 0.0238, d_k_M range: [0.0000, 0.1541], d_k_M_hat range: [0.9379, 1.0000]
2025-03-11 21:09:37 - Train Iteration 10967: loss: 0.0011, d_k_M range: [0.0002, 0.0236], d_k_M_hat range: [0.9775, 0.9999]
2025-03-11 21:09:38 - Train Iteration 10968: loss: 0.0006, d_k_M range: [0.0000, 0.0112], d_k_M_hat range: [0.9790, 0.9995]
2025-03-11 21:09:38 - Train Iteration 10969: loss: 0.2849, d_k_M range: [0.0000, 0.5337], d_k_M_hat range: [0.9931, 1.0000]
2025-03-11 21:09:39 - Train Iteration 10970: loss: 0.7229, d_k_M range: [0.0000, 0.3897], d_k_M_hat range: [0.1498, 0.9995]
2025-03-11 21:09:39 - Train Iteration 10971: loss: 0.0064, d_k_M range: [0.0000, 0.0100], d_k_M_hat range: [0.9200, 0.9995]
2025-03-11 21:09:39 - Train Iteration 10972: loss: 0.0006, d_k_M range: [0.0002, 0.0205], d_k_M_hat range: [0.9747, 0.9999]
2025-03-11 21:09:40 - Train Iteration 10973: loss: 0.1921, d_k_M range: [0.0000, 0.4362], d_k_M_hat range: [0.9729, 0.9993]
2025-03-11 21:09:40 - Train Iteration 10974: loss: 0.0039, d_k_M range: [0.0000, 0.0529], d_k_M_hat range: [0.9377, 0.9997]
2025-03-11 21:09:41 - Train Iteration 10975: loss: 0.4302, d_k_M range: [0.0004, 0.6559], d_k_M_hat range: [0.9940, 1.0000]
2025-03-11 21:09:41 - Train Iteration 10976: loss: 0.0039, d_k_M range: [0.0000, 0.0622], d_k_M_hat range: [0.9802, 0.9996]
2025-03-11 21:09:42 - Train Iteration 10977: loss: 0.0005, d_k_M range: [0.0000, 0.0201], d_k_M_hat range: [0.9864, 0.9992]
2025-03-11 21:09:42 - Train Iteration 10978: loss: 0.1204, d_k_M range: [0.0000, 0.3452], d_k_M_hat range: [0.8735, 0.9995]
2025-03-11 21:09:43 - Train Iteration 10979: loss: 0.0116, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.8925, 0.9991]
2025-03-11 21:09:43 - Train Iteration 10980: loss: 0.5747, d_k_M range: [0.0000, 0.7581], d_k_M_hat range: [0.9366, 1.0000]
2025-03-11 21:09:43 - Train Iteration 10981: loss: 0.0866, d_k_M range: [0.0000, 0.0088], d_k_M_hat range: [0.7057, 0.9984]
2025-03-11 21:09:44 - Train Iteration 10982: loss: 0.0124, d_k_M range: [0.0002, 0.1051], d_k_M_hat range: [0.8906, 0.9993]
2025-03-11 21:09:44 - Train Iteration 10983: loss: 0.0215, d_k_M range: [0.0000, 0.1440], d_k_M_hat range: [0.9854, 0.9997]
2025-03-11 21:09:45 - Train Iteration 10984: loss: 0.5998, d_k_M range: [0.0000, 0.0069], d_k_M_hat range: [0.2256, 0.9996]
2025-03-11 21:09:45 - Train Iteration 10985: loss: 0.0025, d_k_M range: [0.0000, 0.0489], d_k_M_hat range: [0.9562, 0.9993]
2025-03-11 21:09:46 - Train Iteration 10986: loss: 0.0349, d_k_M range: [0.0000, 0.1786], d_k_M_hat range: [0.9859, 0.9991]
2025-03-11 21:09:46 - Train Iteration 10987: loss: 0.5073, d_k_M range: [0.0000, 0.7120], d_k_M_hat range: [0.8931, 0.9997]
2025-03-11 21:09:46 - Train Iteration 10988: loss: 0.0194, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.8609, 0.9990]
2025-03-11 21:09:47 - Train Iteration 10989: loss: 0.0039, d_k_M range: [0.0000, 0.0335], d_k_M_hat range: [0.9714, 0.9986]
2025-03-11 21:09:47 - Train Iteration 10990: loss: 0.0094, d_k_M range: [0.0001, 0.0935], d_k_M_hat range: [0.9673, 0.9977]
2025-03-11 21:09:48 - Train Iteration 10991: loss: 0.0082, d_k_M range: [0.0004, 0.0902], d_k_M_hat range: [0.9933, 1.0000]
2025-03-11 21:09:48 - Train Iteration 10992: loss: 0.0012, d_k_M range: [0.0016, 0.0134], d_k_M_hat range: [0.9734, 0.9996]
2025-03-11 21:09:49 - Train Iteration 10993: loss: 0.0312, d_k_M range: [0.0002, 0.1765], d_k_M_hat range: [0.9778, 0.9999]
2025-03-11 21:09:49 - Train Iteration 10994: loss: 0.0015, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.9611, 0.9994]
2025-03-11 21:09:49 - Train Iteration 10995: loss: 0.0086, d_k_M range: [0.0000, 0.0155], d_k_M_hat range: [0.9072, 0.9958]
2025-03-11 21:09:50 - Train Iteration 10996: loss: 0.1284, d_k_M range: [0.0000, 0.3490], d_k_M_hat range: [0.9600, 0.9996]
2025-03-11 21:09:50 - Train Iteration 10997: loss: 0.0898, d_k_M range: [0.0000, 0.2349], d_k_M_hat range: [0.7007, 0.9999]
2025-03-11 21:09:51 - Train Iteration 10998: loss: 0.0022, d_k_M range: [0.0001, 0.0096], d_k_M_hat range: [0.9565, 0.9994]
2025-03-11 21:09:51 - Train Iteration 10999: loss: 0.0003, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.9845, 0.9967]
2025-03-11 21:09:52 - Train Iteration 11000: loss: 0.0545, d_k_M range: [0.0001, 0.2293], d_k_M_hat range: [0.9127, 0.9974]
2025-03-11 21:09:52 - Train Iteration 11001: loss: 0.0149, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.8781, 0.9996]
2025-03-11 21:09:52 - Train Iteration 11002: loss: 0.5072, d_k_M range: [0.0001, 0.7105], d_k_M_hat range: [0.9921, 0.9999]
2025-03-11 21:09:53 - Train Iteration 11003: loss: 0.0035, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9412, 0.9999]
2025-03-11 21:09:53 - Train Iteration 11004: loss: 0.0093, d_k_M range: [0.0000, 0.0959], d_k_M_hat range: [0.9441, 0.9997]
2025-03-11 21:09:54 - Train Iteration 11005: loss: 0.0020, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.9556, 0.9979]
2025-03-11 21:09:54 - Train Iteration 11006: loss: 0.0019, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.9567, 0.9992]
2025-03-11 21:09:54 - Train Iteration 11007: loss: 0.0092, d_k_M range: [0.0002, 0.0950], d_k_M_hat range: [0.9635, 0.9992]
2025-03-11 21:09:55 - Train Iteration 11008: loss: 0.4239, d_k_M range: [0.0000, 0.1107], d_k_M_hat range: [0.3490, 0.9991]
2025-03-11 21:09:55 - Train Iteration 11009: loss: 0.0080, d_k_M range: [0.0001, 0.0892], d_k_M_hat range: [0.9955, 0.9998]
2025-03-11 21:09:56 - Train Iteration 11010: loss: 0.4134, d_k_M range: [0.0010, 0.6429], d_k_M_hat range: [0.9107, 0.9999]
2025-03-11 21:09:56 - Train Iteration 11011: loss: 0.1090, d_k_M range: [0.0000, 0.0297], d_k_M_hat range: [0.6698, 0.9984]
2025-03-11 21:09:57 - Train Iteration 11012: loss: 0.0025, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9512, 0.9995]
2025-03-11 21:09:57 - Train Iteration 11013: loss: 0.2982, d_k_M range: [0.0000, 0.5432], d_k_M_hat range: [0.9326, 0.9999]
2025-03-11 21:09:58 - Train Iteration 11014: loss: 0.0106, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.8972, 0.9846]
2025-03-11 21:09:58 - Train Iteration 11015: loss: 0.0099, d_k_M range: [0.0002, 0.0174], d_k_M_hat range: [0.9031, 0.9986]
2025-03-11 21:09:58 - Train Iteration 11016: loss: 0.0063, d_k_M range: [0.0000, 0.0471], d_k_M_hat range: [0.9205, 0.9994]
2025-03-11 21:09:59 - Train Iteration 11017: loss: 0.1860, d_k_M range: [0.0000, 0.4290], d_k_M_hat range: [0.9733, 0.9998]
2025-03-11 21:09:59 - Train Iteration 11018: loss: 0.3084, d_k_M range: [0.0000, 0.0499], d_k_M_hat range: [0.4447, 0.9982]
2025-03-11 21:10:00 - Train Iteration 11019: loss: 0.2491, d_k_M range: [0.0013, 0.4989], d_k_M_hat range: [0.9751, 0.9998]
2025-03-11 21:10:00 - Train Iteration 11020: loss: 0.0299, d_k_M range: [0.0000, 0.0789], d_k_M_hat range: [0.8551, 0.9951]
2025-03-11 21:10:01 - Train Iteration 11021: loss: 0.2135, d_k_M range: [0.0001, 0.4615], d_k_M_hat range: [0.8928, 0.9994]
2025-03-11 21:10:01 - Train Iteration 11022: loss: 0.0146, d_k_M range: [0.0000, 0.0908], d_k_M_hat range: [0.8940, 0.9945]
2025-03-11 21:10:01 - Train Iteration 11023: loss: 0.0352, d_k_M range: [0.0000, 0.0067], d_k_M_hat range: [0.8191, 0.9982]
2025-03-11 21:10:02 - Train Iteration 11024: loss: 0.2714, d_k_M range: [0.0003, 0.5206], d_k_M_hat range: [0.9962, 0.9999]
2025-03-11 21:10:02 - Train Iteration 11025: loss: 0.0258, d_k_M range: [0.0000, 0.0820], d_k_M_hat range: [0.8398, 0.9998]
2025-03-11 21:10:03 - Train Iteration 11026: loss: 0.0048, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.9309, 0.9987]
2025-03-11 21:10:03 - Train Iteration 11027: loss: 0.0005, d_k_M range: [0.0000, 0.0108], d_k_M_hat range: [0.9787, 0.9996]
2025-03-11 21:10:04 - Train Iteration 11028: loss: 0.0270, d_k_M range: [0.0001, 0.0038], d_k_M_hat range: [0.8358, 0.9989]
2025-03-11 21:10:04 - Train Iteration 11029: loss: 0.1832, d_k_M range: [0.0000, 0.0144], d_k_M_hat range: [0.5720, 0.9992]
2025-03-11 21:10:04 - Train Iteration 11030: loss: 0.0036, d_k_M range: [0.0001, 0.0227], d_k_M_hat range: [0.9402, 0.9999]
2025-03-11 21:10:05 - Train Iteration 11031: loss: 0.0058, d_k_M range: [0.0000, 0.0069], d_k_M_hat range: [0.9243, 0.9987]
2025-03-11 21:10:05 - Train Iteration 11032: loss: 0.0169, d_k_M range: [0.0000, 0.0802], d_k_M_hat range: [0.8707, 0.9978]
2025-03-11 21:10:06 - Train Iteration 11033: loss: 0.0118, d_k_M range: [0.0001, 0.1032], d_k_M_hat range: [0.9835, 0.9983]
2025-03-11 21:10:06 - Train Iteration 11034: loss: 0.0082, d_k_M range: [0.0000, 0.0410], d_k_M_hat range: [0.9099, 0.9995]
2025-03-11 21:10:07 - Train Iteration 11035: loss: 0.3067, d_k_M range: [0.0005, 0.5504], d_k_M_hat range: [0.9879, 0.9995]
2025-03-11 21:10:07 - Train Iteration 11036: loss: 0.0769, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.7226, 0.9976]
2025-03-11 21:10:07 - Train Iteration 11037: loss: 0.0706, d_k_M range: [0.0000, 0.0415], d_k_M_hat range: [0.7345, 0.9992]
2025-03-11 21:10:08 - Train Iteration 11038: loss: 0.8487, d_k_M range: [0.0000, 0.9208], d_k_M_hat range: [0.9786, 0.9999]
2025-03-11 21:10:08 - Train Iteration 11039: loss: 0.0088, d_k_M range: [0.0001, 0.0371], d_k_M_hat range: [0.9062, 0.9997]
2025-03-11 21:10:09 - Train Iteration 11040: loss: 0.0381, d_k_M range: [0.0000, 0.0064], d_k_M_hat range: [0.8051, 0.9974]
2025-03-11 21:10:09 - Train Iteration 11041: loss: 0.3972, d_k_M range: [0.0002, 0.0500], d_k_M_hat range: [0.3704, 0.9998]
2025-03-11 21:10:10 - Train Iteration 11042: loss: 0.0060, d_k_M range: [0.0000, 0.0772], d_k_M_hat range: [0.9810, 0.9998]
2025-03-11 21:10:10 - Train Iteration 11043: loss: 0.0013, d_k_M range: [0.0001, 0.0211], d_k_M_hat range: [0.9840, 0.9979]
2025-03-11 21:10:10 - Train Iteration 11044: loss: 0.0268, d_k_M range: [0.0000, 0.1634], d_k_M_hat range: [0.8855, 0.9997]
2025-03-11 21:10:11 - Train Iteration 11045: loss: 0.7376, d_k_M range: [0.0000, 0.8582], d_k_M_hat range: [0.9523, 0.9997]
2025-03-11 21:10:11 - Train Iteration 11046: loss: 0.0565, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.7623, 0.9998]
2025-03-11 21:10:12 - Train Iteration 11047: loss: 0.0164, d_k_M range: [0.0002, 0.1242], d_k_M_hat range: [0.9852, 0.9996]
2025-03-11 21:10:12 - Train Iteration 11048: loss: 0.0159, d_k_M range: [0.0000, 0.0100], d_k_M_hat range: [0.8738, 0.9968]
2025-03-11 21:10:12 - Train Iteration 11049: loss: 0.0032, d_k_M range: [0.0001, 0.0070], d_k_M_hat range: [0.9440, 0.9981]
2025-03-11 21:10:13 - Train Iteration 11050: loss: 0.0685, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.7387, 0.9774]
2025-03-11 21:10:13 - Train Iteration 11051: loss: 0.1538, d_k_M range: [0.0000, 0.3920], d_k_M_hat range: [0.9012, 0.9999]
2025-03-11 21:10:14 - Train Iteration 11052: loss: 0.0047, d_k_M range: [0.0000, 0.0682], d_k_M_hat range: [0.9483, 0.9998]
2025-03-11 21:10:14 - Train Iteration 11053: loss: 0.0030, d_k_M range: [0.0001, 0.0500], d_k_M_hat range: [0.9669, 0.9979]
2025-03-11 21:10:15 - Train Iteration 11054: loss: 0.0089, d_k_M range: [0.0000, 0.0558], d_k_M_hat range: [0.9067, 0.9993]
2025-03-11 21:10:15 - Train Iteration 11055: loss: 0.6712, d_k_M range: [0.0018, 0.8189], d_k_M_hat range: [0.9915, 1.0000]
2025-03-11 21:10:15 - Train Iteration 11056: loss: 0.1242, d_k_M range: [0.0003, 0.3511], d_k_M_hat range: [0.9793, 0.9995]
2025-03-11 21:10:16 - Train Iteration 11057: loss: 0.0546, d_k_M range: [0.0000, 0.0173], d_k_M_hat range: [0.7663, 0.9994]
2025-03-11 21:10:16 - Train Iteration 11058: loss: 0.0198, d_k_M range: [0.0000, 0.1401], d_k_M_hat range: [0.9911, 1.0000]
2025-03-11 21:10:17 - Train Iteration 11059: loss: 0.1552, d_k_M range: [0.0000, 0.3906], d_k_M_hat range: [0.8952, 0.9988]
2025-03-11 21:10:17 - Train Iteration 11060: loss: 0.0145, d_k_M range: [0.0000, 0.1185], d_k_M_hat range: [0.9341, 0.9990]
2025-03-11 21:10:18 - Train Iteration 11061: loss: 0.0034, d_k_M range: [0.0000, 0.0192], d_k_M_hat range: [0.9453, 0.9992]
2025-03-11 21:10:18 - Train Iteration 11062: loss: 0.0102, d_k_M range: [0.0000, 0.0910], d_k_M_hat range: [0.9561, 0.9991]
2025-03-11 21:10:19 - Train Iteration 11063: loss: 0.0065, d_k_M range: [0.0005, 0.0729], d_k_M_hat range: [0.9616, 0.9996]
2025-03-11 21:10:19 - Train Iteration 11064: loss: 0.0630, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.7508, 0.9988]
2025-03-11 21:10:20 - Train Iteration 11065: loss: 0.0093, d_k_M range: [0.0000, 0.0075], d_k_M_hat range: [0.9039, 0.9977]
2025-03-11 21:10:20 - Train Iteration 11066: loss: 0.0037, d_k_M range: [0.0000, 0.0537], d_k_M_hat range: [0.9865, 0.9996]
2025-03-11 21:10:20 - Train Iteration 11067: loss: 0.0163, d_k_M range: [0.0001, 0.1250], d_k_M_hat range: [0.9637, 0.9991]
2025-03-11 21:10:21 - Train Iteration 11068: loss: 0.0057, d_k_M range: [0.0001, 0.0179], d_k_M_hat range: [0.9245, 0.9999]
2025-03-11 21:10:21 - Train Iteration 11069: loss: 0.0155, d_k_M range: [0.0000, 0.0125], d_k_M_hat range: [0.8759, 0.9991]
2025-03-11 21:10:22 - Train Iteration 11070: loss: 0.0008, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9718, 0.9976]
2025-03-11 21:10:22 - Train Iteration 11071: loss: 0.0060, d_k_M range: [0.0001, 0.0281], d_k_M_hat range: [0.9230, 0.9995]
2025-03-11 21:10:22 - Train Iteration 11072: loss: 0.0798, d_k_M range: [0.0000, 0.0092], d_k_M_hat range: [0.7180, 0.9993]
2025-03-11 21:10:23 - Train Iteration 11073: loss: 0.1129, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.6654, 0.9978]
2025-03-11 21:10:23 - Train Iteration 11074: loss: 0.0233, d_k_M range: [0.0001, 0.1512], d_k_M_hat range: [0.9589, 0.9986]
2025-03-11 21:10:24 - Train Iteration 11075: loss: 0.0041, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.9358, 0.9978]
2025-03-11 21:10:24 - Train Iteration 11076: loss: 0.0034, d_k_M range: [0.0000, 0.0542], d_k_M_hat range: [0.9687, 0.9994]
2025-03-11 21:10:24 - Train Iteration 11077: loss: 0.5053, d_k_M range: [0.0002, 0.7107], d_k_M_hat range: [0.9463, 0.9999]
2025-03-11 21:10:25 - Train Iteration 11078: loss: 0.0085, d_k_M range: [0.0001, 0.0133], d_k_M_hat range: [0.9077, 0.9991]
2025-03-11 21:10:25 - Train Iteration 11079: loss: 0.0025, d_k_M range: [0.0001, 0.0134], d_k_M_hat range: [0.9504, 0.9946]
2025-03-11 21:10:25 - Train Iteration 11080: loss: 0.0024, d_k_M range: [0.0000, 0.0487], d_k_M_hat range: [0.9700, 0.9999]
2025-03-11 21:10:26 - Train Iteration 11081: loss: 0.0479, d_k_M range: [0.0000, 0.2179], d_k_M_hat range: [0.8540, 0.9990]
2025-03-11 21:10:26 - Train Iteration 11082: loss: 0.0524, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.7713, 0.9970]
2025-03-11 21:10:27 - Train Iteration 11083: loss: 0.0719, d_k_M range: [0.0000, 0.2678], d_k_M_hat range: [0.8509, 0.9996]
2025-03-11 21:10:27 - Train Iteration 11084: loss: 0.0097, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9014, 0.9975]
2025-03-11 21:10:27 - Train Iteration 11085: loss: 0.0827, d_k_M range: [0.0001, 0.2835], d_k_M_hat range: [0.9242, 0.9989]
2025-03-11 21:10:28 - Train Iteration 11086: loss: 0.0012, d_k_M range: [0.0001, 0.0215], d_k_M_hat range: [0.9675, 0.9999]
2025-03-11 21:10:28 - Train Iteration 11087: loss: 0.9603, d_k_M range: [0.0000, 0.5263], d_k_M_hat range: [0.0201, 0.9994]
2025-03-11 21:10:29 - Train Iteration 11088: loss: 0.0392, d_k_M range: [0.0001, 0.1949], d_k_M_hat range: [0.9200, 0.9999]
2025-03-11 21:10:29 - Train Iteration 11089: loss: 0.0242, d_k_M range: [0.0000, 0.0155], d_k_M_hat range: [0.8445, 0.9996]
2025-03-11 21:10:29 - Train Iteration 11090: loss: 0.0192, d_k_M range: [0.0000, 0.1387], d_k_M_hat range: [0.9855, 1.0000]
2025-03-11 21:10:30 - Train Iteration 11091: loss: 0.0257, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.8406, 0.9979]
2025-03-11 21:10:30 - Train Iteration 11092: loss: 0.0019, d_k_M range: [0.0002, 0.0431], d_k_M_hat range: [0.9825, 0.9995]
2025-03-11 21:10:31 - Train Iteration 11093: loss: 0.0057, d_k_M range: [0.0001, 0.0181], d_k_M_hat range: [0.9248, 0.9994]
2025-03-11 21:10:31 - Train Iteration 11094: loss: 0.0063, d_k_M range: [0.0001, 0.0207], d_k_M_hat range: [0.9213, 0.9999]
2025-03-11 21:10:31 - Train Iteration 11095: loss: 0.2786, d_k_M range: [0.0008, 0.5251], d_k_M_hat range: [0.9908, 1.0000]
2025-03-11 21:10:32 - Train Iteration 11096: loss: 0.0563, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.7627, 0.9990]
2025-03-11 21:10:32 - Train Iteration 11097: loss: 0.0239, d_k_M range: [0.0001, 0.1543], d_k_M_hat range: [0.9531, 1.0000]
2025-03-11 21:10:33 - Train Iteration 11098: loss: 0.0011, d_k_M range: [0.0000, 0.0329], d_k_M_hat range: [0.9719, 1.0000]
2025-03-11 21:10:33 - Train Iteration 11099: loss: 0.1746, d_k_M range: [0.0001, 0.4163], d_k_M_hat range: [0.9799, 1.0000]
2025-03-11 21:10:34 - Train Iteration 11100: loss: 0.0614, d_k_M range: [0.0000, 0.2469], d_k_M_hat range: [0.9838, 0.9999]
2025-03-11 21:10:34 - Train Iteration 11101: loss: 0.0032, d_k_M range: [0.0000, 0.0550], d_k_M_hat range: [0.9763, 0.9997]
2025-03-11 21:10:34 - Train Iteration 11102: loss: 0.0049, d_k_M range: [0.0002, 0.0046], d_k_M_hat range: [0.9300, 0.9983]
2025-03-11 21:10:35 - Train Iteration 11103: loss: 0.0010, d_k_M range: [0.0000, 0.0184], d_k_M_hat range: [0.9692, 0.9998]
2025-03-11 21:10:35 - Train Iteration 11104: loss: 0.0161, d_k_M range: [0.0007, 0.0359], d_k_M_hat range: [0.8917, 0.9998]
2025-03-11 21:10:36 - Train Iteration 11105: loss: 0.0055, d_k_M range: [0.0000, 0.0119], d_k_M_hat range: [0.9266, 0.9997]
2025-03-11 21:10:36 - Train Iteration 11106: loss: 0.0194, d_k_M range: [0.0000, 0.1391], d_k_M_hat range: [0.8782, 1.0000]
2025-03-11 21:10:36 - Train Iteration 11107: loss: 0.0005, d_k_M range: [0.0000, 0.0220], d_k_M_hat range: [0.9901, 0.9999]
2025-03-11 21:10:37 - Train Iteration 11108: loss: 0.1146, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.6615, 0.9920]
2025-03-11 21:10:37 - Train Iteration 11109: loss: 0.0903, d_k_M range: [0.0005, 0.3004], d_k_M_hat range: [0.9398, 0.9999]
2025-03-11 21:10:38 - Train Iteration 11110: loss: 0.0031, d_k_M range: [0.0003, 0.0551], d_k_M_hat range: [0.9931, 1.0000]
2025-03-11 21:10:38 - Train Iteration 11111: loss: 0.0024, d_k_M range: [0.0000, 0.0332], d_k_M_hat range: [0.9514, 0.9997]
2025-03-11 21:10:38 - Train Iteration 11112: loss: 0.2461, d_k_M range: [0.0001, 0.0159], d_k_M_hat range: [0.5199, 0.9999]
2025-03-11 21:10:39 - Train Iteration 11113: loss: 0.4825, d_k_M range: [0.0002, 0.6940], d_k_M_hat range: [0.9976, 0.9996]
2025-03-11 21:10:39 - Train Iteration 11114: loss: 0.0079, d_k_M range: [0.0000, 0.0315], d_k_M_hat range: [0.9426, 0.9972]
2025-03-11 21:10:40 - Train Iteration 11115: loss: 0.0023, d_k_M range: [0.0001, 0.0030], d_k_M_hat range: [0.9522, 0.9994]
2025-03-11 21:10:40 - Train Iteration 11116: loss: 0.0205, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.8569, 0.9993]
2025-03-11 21:10:40 - Train Iteration 11117: loss: 0.0028, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.9582, 0.9946]
2025-03-11 21:10:41 - Train Iteration 11118: loss: 0.1874, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.5672, 0.9991]
2025-03-11 21:10:41 - Train Iteration 11119: loss: 0.0285, d_k_M range: [0.0000, 0.1687], d_k_M_hat range: [0.9391, 0.9999]
2025-03-11 21:10:42 - Train Iteration 11120: loss: 0.0631, d_k_M range: [0.0001, 0.1509], d_k_M_hat range: [0.7489, 0.9998]
2025-03-11 21:10:42 - Train Iteration 11121: loss: 0.8830, d_k_M range: [0.0001, 0.9396], d_k_M_hat range: [0.9858, 0.9999]
2025-03-11 21:10:42 - Train Iteration 11122: loss: 0.0013, d_k_M range: [0.0005, 0.0349], d_k_M_hat range: [0.9876, 0.9994]
2025-03-11 21:10:43 - Train Iteration 11123: loss: 0.0465, d_k_M range: [0.0001, 0.0891], d_k_M_hat range: [0.7844, 0.9998]
2025-03-11 21:10:43 - Train Iteration 11124: loss: 0.0008, d_k_M range: [0.0003, 0.0282], d_k_M_hat range: [0.9953, 0.9998]
2025-03-11 21:10:44 - Train Iteration 11125: loss: 0.0510, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.7743, 0.9997]
2025-03-11 21:10:44 - Train Iteration 11126: loss: 0.3295, d_k_M range: [0.0001, 0.5740], d_k_M_hat range: [0.9526, 1.0000]
2025-03-11 21:10:44 - Train Iteration 11127: loss: 0.0007, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.9824, 0.9987]
2025-03-11 21:10:45 - Train Iteration 11128: loss: 0.0014, d_k_M range: [0.0000, 0.0116], d_k_M_hat range: [0.9674, 0.9990]
2025-03-11 21:10:45 - Train Iteration 11129: loss: 0.0048, d_k_M range: [0.0000, 0.0690], d_k_M_hat range: [0.9757, 0.9998]
2025-03-11 21:10:46 - Train Iteration 11130: loss: 0.0065, d_k_M range: [0.0000, 0.0207], d_k_M_hat range: [0.9196, 0.9979]
2025-03-11 21:10:46 - Train Iteration 11131: loss: 0.0033, d_k_M range: [0.0001, 0.0099], d_k_M_hat range: [0.9479, 0.9992]
2025-03-11 21:10:46 - Train Iteration 11132: loss: 0.1780, d_k_M range: [0.0000, 0.0134], d_k_M_hat range: [0.5797, 0.9994]
2025-03-11 21:10:47 - Train Iteration 11133: loss: 0.0073, d_k_M range: [0.0000, 0.0343], d_k_M_hat range: [0.9180, 0.9997]
2025-03-11 21:10:47 - Train Iteration 11134: loss: 0.0398, d_k_M range: [0.0000, 0.1941], d_k_M_hat range: [0.9579, 0.9991]
2025-03-11 21:10:47 - Train Iteration 11135: loss: 0.0144, d_k_M range: [0.0000, 0.0132], d_k_M_hat range: [0.8800, 0.9995]
2025-03-11 21:10:48 - Train Iteration 11136: loss: 0.0027, d_k_M range: [0.0000, 0.0507], d_k_M_hat range: [0.9896, 0.9994]
2025-03-11 21:10:48 - Train Iteration 11137: loss: 0.0076, d_k_M range: [0.0000, 0.0854], d_k_M_hat range: [0.9785, 0.9997]
2025-03-11 21:10:49 - Train Iteration 11138: loss: 0.0018, d_k_M range: [0.0000, 0.0245], d_k_M_hat range: [0.9579, 0.9988]
2025-03-11 21:10:49 - Train Iteration 11139: loss: 0.5708, d_k_M range: [0.0000, 0.0094], d_k_M_hat range: [0.2446, 0.9973]
2025-03-11 21:10:50 - Train Iteration 11140: loss: 0.0739, d_k_M range: [0.0000, 0.2717], d_k_M_hat range: [0.8727, 0.9998]
2025-03-11 21:10:50 - Train Iteration 11141: loss: 0.0025, d_k_M range: [0.0000, 0.0160], d_k_M_hat range: [0.9498, 0.9985]
2025-03-11 21:10:50 - Train Iteration 11142: loss: 0.2399, d_k_M range: [0.0000, 0.0213], d_k_M_hat range: [0.5102, 0.9991]
2025-03-11 21:10:51 - Train Iteration 11143: loss: 0.0011, d_k_M range: [0.0004, 0.0311], d_k_M_hat range: [0.9920, 0.9998]
2025-03-11 21:10:51 - Train Iteration 11144: loss: 0.0047, d_k_M range: [0.0000, 0.0442], d_k_M_hat range: [0.9759, 0.9999]
2025-03-11 21:10:52 - Train Iteration 11145: loss: 0.0889, d_k_M range: [0.0003, 0.2981], d_k_M_hat range: [0.9973, 1.0000]
2025-03-11 21:10:52 - Train Iteration 11146: loss: 0.0027, d_k_M range: [0.0001, 0.0498], d_k_M_hat range: [0.9590, 0.9985]
2025-03-11 21:10:52 - Train Iteration 11147: loss: 0.0333, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.8176, 0.9928]
2025-03-11 21:10:53 - Train Iteration 11148: loss: 0.0032, d_k_M range: [0.0000, 0.0269], d_k_M_hat range: [0.9702, 0.9997]
2025-03-11 21:10:53 - Train Iteration 11149: loss: 0.0138, d_k_M range: [0.0000, 0.0722], d_k_M_hat range: [0.9546, 0.9989]
2025-03-11 21:10:54 - Train Iteration 11150: loss: 0.0009, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.9693, 0.9985]
2025-03-11 21:10:54 - Train Iteration 11151: loss: 0.0056, d_k_M range: [0.0010, 0.0203], d_k_M_hat range: [0.9377, 0.9999]
2025-03-11 21:10:55 - Train Iteration 11152: loss: 0.2106, d_k_M range: [0.0000, 0.0048], d_k_M_hat range: [0.5420, 0.9985]
2025-03-11 21:10:55 - Train Iteration 11153: loss: 0.1752, d_k_M range: [0.0000, 0.4184], d_k_M_hat range: [0.9786, 0.9999]
2025-03-11 21:10:55 - Train Iteration 11154: loss: 0.0043, d_k_M range: [0.0000, 0.0627], d_k_M_hat range: [0.9741, 0.9988]
2025-03-11 21:10:56 - Train Iteration 11155: loss: 0.0038, d_k_M range: [0.0000, 0.0055], d_k_M_hat range: [0.9419, 0.9999]
2025-03-11 21:10:56 - Train Iteration 11156: loss: 0.0142, d_k_M range: [0.0001, 0.0029], d_k_M_hat range: [0.8811, 0.9981]
2025-03-11 21:10:57 - Train Iteration 11157: loss: 0.3910, d_k_M range: [0.0000, 0.6252], d_k_M_hat range: [0.9677, 0.9999]
2025-03-11 21:10:57 - Train Iteration 11158: loss: 0.0289, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.8301, 0.9927]
2025-03-11 21:10:58 - Train Iteration 11159: loss: 0.0248, d_k_M range: [0.0001, 0.1573], d_k_M_hat range: [0.9918, 0.9999]
2025-03-11 21:10:58 - Train Iteration 11160: loss: 0.0346, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.8140, 0.9994]
2025-03-11 21:10:58 - Train Iteration 11161: loss: 0.0090, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.9055, 0.9999]
2025-03-11 21:10:59 - Train Iteration 11162: loss: 0.0080, d_k_M range: [0.0009, 0.0887], d_k_M_hat range: [0.9650, 0.9996]
2025-03-11 21:10:59 - Train Iteration 11163: loss: 0.0062, d_k_M range: [0.0001, 0.0735], d_k_M_hat range: [0.9214, 0.9997]
2025-03-11 21:11:00 - Train Iteration 11164: loss: 0.0200, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.8606, 0.9993]
2025-03-11 21:11:00 - Train Iteration 11165: loss: 0.0406, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.7986, 0.9984]
2025-03-11 21:11:00 - Train Iteration 11166: loss: 0.0170, d_k_M range: [0.0000, 0.0271], d_k_M_hat range: [0.8699, 0.9994]
2025-03-11 21:11:01 - Train Iteration 11167: loss: 0.0035, d_k_M range: [0.0000, 0.0563], d_k_M_hat range: [0.9724, 0.9988]
2025-03-11 21:11:01 - Train Iteration 11168: loss: 0.0003, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9842, 0.9985]
2025-03-11 21:11:02 - Train Iteration 11169: loss: 0.0004, d_k_M range: [0.0000, 0.0154], d_k_M_hat range: [0.9812, 0.9990]
2025-03-11 21:11:02 - Train Iteration 11170: loss: 0.0086, d_k_M range: [0.0000, 0.0530], d_k_M_hat range: [0.9073, 0.9997]
2025-03-11 21:11:03 - Train Iteration 11171: loss: 0.7861, d_k_M range: [0.0000, 0.1081], d_k_M_hat range: [0.1134, 0.9996]
2025-03-11 21:11:03 - Train Iteration 11172: loss: 0.6160, d_k_M range: [0.0000, 0.7845], d_k_M_hat range: [0.9327, 0.9997]
2025-03-11 21:11:03 - Train Iteration 11173: loss: 0.0039, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9374, 0.9989]
2025-03-11 21:11:04 - Train Iteration 11174: loss: 0.3542, d_k_M range: [0.0003, 0.5947], d_k_M_hat range: [0.9506, 0.9996]
2025-03-11 21:11:04 - Train Iteration 11175: loss: 0.0445, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.7901, 0.9997]
2025-03-11 21:11:04 - Train Iteration 11176: loss: 0.0264, d_k_M range: [0.0000, 0.1519], d_k_M_hat range: [0.8949, 0.9999]
2025-03-11 21:11:05 - Train Iteration 11177: loss: 0.0414, d_k_M range: [0.0000, 0.2002], d_k_M_hat range: [0.8731, 0.9999]
2025-03-11 21:11:05 - Train Iteration 11178: loss: 0.1439, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.6208, 0.9999]
2025-03-11 21:11:06 - Train Iteration 11179: loss: 0.0064, d_k_M range: [0.0000, 0.0800], d_k_M_hat range: [0.9954, 0.9997]
2025-03-11 21:11:06 - Train Iteration 11180: loss: 0.2471, d_k_M range: [0.0000, 0.0149], d_k_M_hat range: [0.5029, 0.9935]
2025-03-11 21:11:07 - Train Iteration 11181: loss: 0.0023, d_k_M range: [0.0000, 0.0482], d_k_M_hat range: [0.9993, 1.0000]
2025-03-11 21:11:07 - Train Iteration 11182: loss: 0.0329, d_k_M range: [0.0002, 0.1811], d_k_M_hat range: [0.9879, 0.9999]
2025-03-11 21:11:08 - Train Iteration 11183: loss: 0.1932, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.5606, 0.9967]
2025-03-11 21:11:08 - Train Iteration 11184: loss: 0.1541, d_k_M range: [0.0000, 0.3863], d_k_M_hat range: [0.9874, 0.9997]
2025-03-11 21:11:09 - Train Iteration 11185: loss: 0.0121, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.8901, 0.9981]
2025-03-11 21:11:09 - Train Iteration 11186: loss: 0.3518, d_k_M range: [0.0000, 0.5931], d_k_M_hat range: [0.9799, 0.9999]
2025-03-11 21:11:10 - Train Iteration 11187: loss: 0.0046, d_k_M range: [0.0000, 0.0383], d_k_M_hat range: [0.9321, 0.9986]
2025-03-11 21:11:10 - Train Iteration 11188: loss: 0.0018, d_k_M range: [0.0002, 0.0209], d_k_M_hat range: [0.9575, 0.9989]
2025-03-11 21:11:10 - Train Iteration 11189: loss: 0.3240, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.4310, 0.9952]
2025-03-11 21:11:11 - Train Iteration 11190: loss: 0.0009, d_k_M range: [0.0000, 0.0090], d_k_M_hat range: [0.9703, 0.9995]
2025-03-11 21:11:11 - Train Iteration 11191: loss: 0.0128, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.8930, 0.9996]
2025-03-11 21:11:12 - Train Iteration 11192: loss: 0.0243, d_k_M range: [0.0024, 0.1557], d_k_M_hat range: [0.9766, 0.9999]
2025-03-11 21:11:12 - Train Iteration 11193: loss: 0.0173, d_k_M range: [0.0000, 0.0230], d_k_M_hat range: [0.8686, 0.9998]
2025-03-11 21:11:13 - Train Iteration 11194: loss: 0.0037, d_k_M range: [0.0006, 0.0582], d_k_M_hat range: [0.9874, 0.9999]
2025-03-11 21:11:13 - Train Iteration 11195: loss: 0.0153, d_k_M range: [0.0002, 0.1238], d_k_M_hat range: [0.9962, 0.9999]
2025-03-11 21:11:13 - Train Iteration 11196: loss: 0.0465, d_k_M range: [0.0001, 0.0220], d_k_M_hat range: [0.7846, 0.9996]
2025-03-11 21:11:14 - Train Iteration 11197: loss: 0.0151, d_k_M range: [0.0000, 0.1220], d_k_M_hat range: [0.9840, 0.9997]
2025-03-11 21:11:14 - Train Iteration 11198: loss: 0.5659, d_k_M range: [0.0000, 0.7515], d_k_M_hat range: [0.9535, 0.9999]
2025-03-11 21:11:15 - Train Iteration 11199: loss: 0.0039, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.9377, 0.9991]
2025-03-11 21:11:15 - Train Iteration 11200: loss: 0.0020, d_k_M range: [0.0000, 0.0255], d_k_M_hat range: [0.9561, 0.9990]
2025-03-11 21:11:16 - Train Iteration 11201: loss: 0.0031, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.9447, 0.9995]
2025-03-11 21:11:16 - Train Iteration 11202: loss: 0.0036, d_k_M range: [0.0000, 0.0593], d_k_M_hat range: [0.9497, 0.9998]
2025-03-11 21:11:17 - Train Iteration 11203: loss: 0.0070, d_k_M range: [0.0000, 0.0069], d_k_M_hat range: [0.9230, 0.9998]
2025-03-11 21:11:17 - Train Iteration 11204: loss: 0.0013, d_k_M range: [0.0000, 0.0066], d_k_M_hat range: [0.9640, 0.9995]
2025-03-11 21:11:17 - Train Iteration 11205: loss: 0.0605, d_k_M range: [0.0000, 0.0203], d_k_M_hat range: [0.7744, 0.9994]
2025-03-11 21:11:18 - Train Iteration 11206: loss: 0.0045, d_k_M range: [0.0001, 0.0648], d_k_M_hat range: [0.9914, 0.9997]
2025-03-11 21:11:18 - Train Iteration 11207: loss: 0.0010, d_k_M range: [0.0000, 0.0169], d_k_M_hat range: [0.9716, 0.9975]
2025-03-11 21:11:19 - Train Iteration 11208: loss: 0.1174, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.6573, 0.9963]
2025-03-11 21:11:19 - Train Iteration 11209: loss: 0.0548, d_k_M range: [0.0002, 0.2327], d_k_M_hat range: [0.9961, 1.0000]
2025-03-11 21:11:20 - Train Iteration 11210: loss: 0.0358, d_k_M range: [0.0001, 0.0176], d_k_M_hat range: [0.8108, 0.9999]
2025-03-11 21:11:20 - Train Iteration 11211: loss: 0.0917, d_k_M range: [0.0000, 0.0563], d_k_M_hat range: [0.6973, 0.9993]
2025-03-11 21:11:21 - Train Iteration 11212: loss: 0.0473, d_k_M range: [0.0001, 0.2172], d_k_M_hat range: [0.9022, 0.9998]
2025-03-11 21:11:21 - Train Iteration 11213: loss: 0.0070, d_k_M range: [0.0001, 0.0129], d_k_M_hat range: [0.9204, 0.9994]
2025-03-11 21:11:22 - Train Iteration 11214: loss: 0.0503, d_k_M range: [0.0000, 0.0274], d_k_M_hat range: [0.7758, 1.0000]
2025-03-11 21:11:22 - Train Iteration 11215: loss: 0.8352, d_k_M range: [0.0000, 0.9132], d_k_M_hat range: [0.9755, 0.9998]
2025-03-11 21:11:22 - Train Iteration 11216: loss: 0.2262, d_k_M range: [0.0000, 0.0192], d_k_M_hat range: [0.5244, 0.9988]
2025-03-11 21:11:23 - Train Iteration 11217: loss: 0.2769, d_k_M range: [0.0004, 0.5256], d_k_M_hat range: [0.9463, 0.9998]
2025-03-11 21:11:23 - Train Iteration 11218: loss: 0.0122, d_k_M range: [0.0000, 0.0932], d_k_M_hat range: [0.8895, 0.9989]
2025-03-11 21:11:24 - Train Iteration 11219: loss: 0.1519, d_k_M range: [0.0000, 0.3839], d_k_M_hat range: [0.9767, 0.9990]
2025-03-11 21:11:24 - Train Iteration 11220: loss: 0.0224, d_k_M range: [0.0000, 0.0121], d_k_M_hat range: [0.8504, 0.9983]
2025-03-11 21:11:24 - Train Iteration 11221: loss: 0.1173, d_k_M range: [0.0000, 0.0087], d_k_M_hat range: [0.6576, 0.9997]
2025-03-11 21:11:25 - Train Iteration 11222: loss: 0.0011, d_k_M range: [0.0003, 0.0328], d_k_M_hat range: [0.9895, 0.9998]
2025-03-11 21:11:25 - Train Iteration 11223: loss: 0.6110, d_k_M range: [0.0000, 0.1472], d_k_M_hat range: [0.2184, 0.9997]
2025-03-11 21:11:26 - Train Iteration 11224: loss: 0.5275, d_k_M range: [0.0000, 0.7260], d_k_M_hat range: [0.4260, 0.9998]
2025-03-11 21:11:26 - Train Iteration 11225: loss: 0.0096, d_k_M range: [0.0000, 0.0525], d_k_M_hat range: [0.9019, 0.9988]
2025-03-11 21:11:27 - Train Iteration 11226: loss: 0.0100, d_k_M range: [0.0000, 0.0116], d_k_M_hat range: [0.9117, 0.9970]
2025-03-11 21:11:27 - Train Iteration 11227: loss: 0.0061, d_k_M range: [0.0001, 0.0751], d_k_M_hat range: [0.9822, 0.9987]
2025-03-11 21:11:27 - Train Iteration 11228: loss: 0.0012, d_k_M range: [0.0000, 0.0154], d_k_M_hat range: [0.9660, 0.9992]
2025-03-11 21:11:28 - Train Iteration 11229: loss: 0.3820, d_k_M range: [0.0000, 0.0276], d_k_M_hat range: [0.3820, 0.9969]
2025-03-11 21:11:28 - Train Iteration 11230: loss: 0.2977, d_k_M range: [0.0000, 0.0105], d_k_M_hat range: [0.4543, 0.9980]
2025-03-11 21:11:29 - Train Iteration 11231: loss: 0.0112, d_k_M range: [0.0000, 0.1042], d_k_M_hat range: [0.9541, 0.9992]
2025-03-11 21:11:29 - Train Iteration 11232: loss: 0.1639, d_k_M range: [0.0000, 0.0437], d_k_M_hat range: [0.5997, 0.9999]
2025-03-11 21:11:29 - Train Iteration 11233: loss: 0.0018, d_k_M range: [0.0000, 0.0410], d_k_M_hat range: [0.9895, 0.9994]
2025-03-11 21:11:30 - Train Iteration 11234: loss: 0.0549, d_k_M range: [0.0001, 0.0189], d_k_M_hat range: [0.7659, 0.9992]
2025-03-11 21:11:30 - Train Iteration 11235: loss: 0.0030, d_k_M range: [0.0000, 0.0056], d_k_M_hat range: [0.9450, 0.9966]
2025-03-11 21:11:31 - Train Iteration 11236: loss: 0.0906, d_k_M range: [0.0000, 0.0092], d_k_M_hat range: [0.6990, 0.9992]
2025-03-11 21:11:31 - Train Iteration 11237: loss: 0.0088, d_k_M range: [0.0002, 0.0933], d_k_M_hat range: [0.9974, 1.0000]
2025-03-11 21:11:31 - Train Iteration 11238: loss: 0.2024, d_k_M range: [0.0000, 0.4494], d_k_M_hat range: [0.9859, 0.9998]
2025-03-11 21:11:32 - Train Iteration 11239: loss: 0.6191, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.2133, 0.9980]
2025-03-11 21:11:32 - Train Iteration 11240: loss: 0.0105, d_k_M range: [0.0001, 0.1024], d_k_M_hat range: [0.9943, 0.9999]
2025-03-11 21:11:33 - Train Iteration 11241: loss: 0.0010, d_k_M range: [0.0000, 0.0298], d_k_M_hat range: [0.9685, 0.9987]
2025-03-11 21:11:33 - Train Iteration 11242: loss: 0.5984, d_k_M range: [0.0003, 0.7725], d_k_M_hat range: [0.9970, 1.0000]
2025-03-11 21:11:33 - Train Iteration 11243: loss: 0.0010, d_k_M range: [0.0000, 0.0298], d_k_M_hat range: [0.9890, 0.9997]
2025-03-11 21:11:34 - Train Iteration 11244: loss: 0.3503, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.4082, 0.9988]
2025-03-11 21:11:34 - Train Iteration 11245: loss: 0.7473, d_k_M range: [0.0002, 0.8644], d_k_M_hat range: [0.9517, 1.0000]
2025-03-11 21:11:35 - Train Iteration 11246: loss: 0.2269, d_k_M range: [0.0000, 0.0379], d_k_M_hat range: [0.5239, 0.9921]
2025-03-11 21:11:35 - Train Iteration 11247: loss: 0.0011, d_k_M range: [0.0000, 0.0244], d_k_M_hat range: [0.9663, 0.9998]
2025-03-11 21:11:36 - Train Iteration 11248: loss: 0.0019, d_k_M range: [0.0000, 0.0393], d_k_M_hat range: [0.9814, 0.9996]
2025-03-11 21:11:36 - Train Iteration 11249: loss: 0.0010, d_k_M range: [0.0001, 0.0021], d_k_M_hat range: [0.9700, 0.9994]
2025-03-11 21:11:37 - Train Iteration 11250: loss: 0.0048, d_k_M range: [0.0000, 0.0338], d_k_M_hat range: [0.9316, 0.9970]
2025-03-11 21:11:37 - Train Iteration 11251: loss: 0.3874, d_k_M range: [0.0000, 0.6206], d_k_M_hat range: [0.9824, 0.9995]
2025-03-11 21:11:37 - Train Iteration 11252: loss: 0.3436, d_k_M range: [0.0000, 0.0379], d_k_M_hat range: [0.4140, 0.9979]
2025-03-11 21:11:38 - Train Iteration 11253: loss: 0.0120, d_k_M range: [0.0000, 0.1094], d_k_M_hat range: [0.9872, 0.9999]
2025-03-11 21:11:38 - Train Iteration 11254: loss: 0.0092, d_k_M range: [0.0000, 0.0286], d_k_M_hat range: [0.9044, 0.9997]
2025-03-11 21:11:39 - Train Iteration 11255: loss: 0.1723, d_k_M range: [0.0000, 0.0089], d_k_M_hat range: [0.5850, 0.9993]
2025-03-11 21:11:39 - Train Iteration 11256: loss: 0.0263, d_k_M range: [0.0014, 0.1615], d_k_M_hat range: [0.9979, 0.9999]
2025-03-11 21:11:39 - Train Iteration 11257: loss: 0.0048, d_k_M range: [0.0000, 0.0661], d_k_M_hat range: [0.9926, 0.9995]
2025-03-11 21:11:40 - Train Iteration 11258: loss: 0.0715, d_k_M range: [0.0000, 0.0105], d_k_M_hat range: [0.7333, 0.9998]
2025-03-11 21:11:40 - Train Iteration 11259: loss: 0.4832, d_k_M range: [0.0000, 0.0488], d_k_M_hat range: [0.3049, 0.9937]
2025-03-11 21:11:41 - Train Iteration 11260: loss: 0.0776, d_k_M range: [0.0001, 0.2784], d_k_M_hat range: [0.9946, 1.0000]
2025-03-11 21:11:41 - Train Iteration 11261: loss: 0.0475, d_k_M range: [0.0000, 0.0150], d_k_M_hat range: [0.7822, 0.9999]
2025-03-11 21:11:41 - Train Iteration 11262: loss: 0.0052, d_k_M range: [0.0002, 0.0409], d_k_M_hat range: [0.9426, 0.9976]
2025-03-11 21:11:42 - Train Iteration 11263: loss: 0.0290, d_k_M range: [0.0001, 0.0371], d_k_M_hat range: [0.8298, 0.9991]
2025-03-11 21:11:42 - Train Iteration 11264: loss: 0.0037, d_k_M range: [0.0001, 0.0124], d_k_M_hat range: [0.9402, 1.0000]
2025-03-11 21:11:43 - Train Iteration 11265: loss: 0.0201, d_k_M range: [0.0001, 0.0126], d_k_M_hat range: [0.8586, 0.9982]
2025-03-11 21:11:43 - Train Iteration 11266: loss: 0.0342, d_k_M range: [0.0000, 0.0095], d_k_M_hat range: [0.8151, 0.9997]
2025-03-11 21:11:44 - Train Iteration 11267: loss: 0.0044, d_k_M range: [0.0000, 0.0610], d_k_M_hat range: [0.9925, 0.9992]
2025-03-11 21:11:44 - Train Iteration 11268: loss: 0.0143, d_k_M range: [0.0000, 0.1182], d_k_M_hat range: [0.9210, 0.9997]
2025-03-11 21:11:44 - Train Iteration 11269: loss: 0.2955, d_k_M range: [0.0000, 0.5435], d_k_M_hat range: [0.9936, 0.9999]
2025-03-11 21:11:45 - Train Iteration 11270: loss: 0.0048, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.9355, 0.9964]
2025-03-11 21:11:45 - Train Iteration 11271: loss: 0.0059, d_k_M range: [0.0000, 0.0097], d_k_M_hat range: [0.9233, 0.9988]
2025-03-11 21:11:46 - Train Iteration 11272: loss: 0.0081, d_k_M range: [0.0001, 0.0669], d_k_M_hat range: [0.9564, 0.9999]
2025-03-11 21:11:46 - Train Iteration 11273: loss: 0.0045, d_k_M range: [0.0000, 0.0592], d_k_M_hat range: [0.9743, 0.9991]
2025-03-11 21:11:47 - Train Iteration 11274: loss: 0.0068, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.9179, 0.9995]
2025-03-11 21:11:47 - Train Iteration 11275: loss: 0.0072, d_k_M range: [0.0000, 0.0814], d_k_M_hat range: [0.9167, 0.9998]
2025-03-11 21:11:48 - Train Iteration 11276: loss: 0.0122, d_k_M range: [0.0000, 0.0108], d_k_M_hat range: [0.8893, 0.9999]
2025-03-11 21:11:48 - Train Iteration 11277: loss: 0.0062, d_k_M range: [0.0000, 0.0198], d_k_M_hat range: [0.9251, 1.0000]
2025-03-11 21:11:48 - Train Iteration 11278: loss: 0.4473, d_k_M range: [0.0000, 0.6686], d_k_M_hat range: [0.9126, 0.9997]
2025-03-11 21:11:49 - Train Iteration 11279: loss: 0.3042, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.4486, 0.9888]
2025-03-11 21:11:49 - Train Iteration 11280: loss: 0.0007, d_k_M range: [0.0000, 0.0142], d_k_M_hat range: [0.9769, 0.9999]
2025-03-11 21:11:50 - Train Iteration 11281: loss: 0.0347, d_k_M range: [0.0007, 0.1851], d_k_M_hat range: [0.9961, 0.9999]
2025-03-11 21:11:50 - Train Iteration 11282: loss: 0.0411, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.7977, 0.9993]
2025-03-11 21:11:51 - Train Iteration 11283: loss: 0.0036, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.9518, 0.9997]
2025-03-11 21:11:51 - Train Iteration 11284: loss: 0.0149, d_k_M range: [0.0000, 0.1217], d_k_M_hat range: [0.9716, 0.9998]
2025-03-11 21:11:51 - Train Iteration 11285: loss: 0.0013, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9649, 1.0000]
2025-03-11 21:11:52 - Train Iteration 11286: loss: 0.2319, d_k_M range: [0.0002, 0.4815], d_k_M_hat range: [0.9908, 1.0000]
2025-03-11 21:11:52 - Train Iteration 11287: loss: 0.8450, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.0808, 0.9919]
2025-03-11 21:11:53 - Train Iteration 11288: loss: 0.1554, d_k_M range: [0.0001, 0.0065], d_k_M_hat range: [0.6058, 0.9991]
2025-03-11 21:11:53 - Train Iteration 11289: loss: 0.3422, d_k_M range: [0.0000, 0.5731], d_k_M_hat range: [0.9687, 0.9991]
2025-03-11 21:11:54 - Train Iteration 11290: loss: 0.0020, d_k_M range: [0.0000, 0.0117], d_k_M_hat range: [0.9562, 0.9979]
2025-03-11 21:11:54 - Train Iteration 11291: loss: 0.0015, d_k_M range: [0.0000, 0.0243], d_k_M_hat range: [0.9715, 0.9997]
2025-03-11 21:11:54 - Train Iteration 11292: loss: 0.0654, d_k_M range: [0.0000, 0.2553], d_k_M_hat range: [0.9531, 0.9995]
2025-03-11 21:11:55 - Train Iteration 11293: loss: 0.0026, d_k_M range: [0.0000, 0.0166], d_k_M_hat range: [0.9494, 0.9987]
2025-03-11 21:11:55 - Train Iteration 11294: loss: 0.0395, d_k_M range: [0.0001, 0.1022], d_k_M_hat range: [0.8021, 0.9956]
2025-03-11 21:11:56 - Train Iteration 11295: loss: 0.0157, d_k_M range: [0.0000, 0.0335], d_k_M_hat range: [0.8745, 0.9997]
2025-03-11 21:11:56 - Train Iteration 11296: loss: 0.0017, d_k_M range: [0.0002, 0.0406], d_k_M_hat range: [0.9759, 0.9998]
2025-03-11 21:11:56 - Train Iteration 11297: loss: 0.3438, d_k_M range: [0.0000, 0.0226], d_k_M_hat range: [0.4138, 0.9993]
2025-03-11 21:11:57 - Train Iteration 11298: loss: 0.8373, d_k_M range: [0.0016, 0.9149], d_k_M_hat range: [0.9959, 1.0000]
2025-03-11 21:11:57 - Train Iteration 11299: loss: 0.0376, d_k_M range: [0.0000, 0.1699], d_k_M_hat range: [0.9759, 0.9998]
2025-03-11 21:11:58 - Train Iteration 11300: loss: 0.0048, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9313, 0.9990]
2025-03-11 21:11:58 - Train Iteration 11301: loss: 0.0091, d_k_M range: [0.0003, 0.0870], d_k_M_hat range: [0.9916, 0.9999]
2025-03-11 21:11:59 - Train Iteration 11302: loss: 0.0550, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.7661, 0.9986]
2025-03-11 21:11:59 - Train Iteration 11303: loss: 0.0954, d_k_M range: [0.0001, 0.3084], d_k_M_hat range: [0.9845, 0.9999]
2025-03-11 21:12:00 - Train Iteration 11304: loss: 0.0862, d_k_M range: [0.0000, 0.0610], d_k_M_hat range: [0.7065, 0.9989]
2025-03-11 21:12:00 - Train Iteration 11305: loss: 0.0017, d_k_M range: [0.0000, 0.0371], d_k_M_hat range: [0.9609, 0.9961]
2025-03-11 21:12:00 - Train Iteration 11306: loss: 0.0046, d_k_M range: [0.0000, 0.0243], d_k_M_hat range: [0.9323, 0.9983]
2025-03-11 21:12:01 - Train Iteration 11307: loss: 0.1108, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.6671, 0.9983]
2025-03-11 21:12:01 - Train Iteration 11308: loss: 0.0041, d_k_M range: [0.0000, 0.0265], d_k_M_hat range: [0.9433, 0.9998]
2025-03-11 21:12:02 - Train Iteration 11309: loss: 0.0004, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.9807, 0.9994]
2025-03-11 21:12:02 - Train Iteration 11310: loss: 0.7710, d_k_M range: [0.0000, 0.0057], d_k_M_hat range: [0.1232, 0.9998]
2025-03-11 21:12:03 - Train Iteration 11311: loss: 0.1845, d_k_M range: [0.0001, 0.4281], d_k_M_hat range: [0.9154, 1.0000]
2025-03-11 21:12:03 - Train Iteration 11312: loss: 0.9157, d_k_M range: [0.0001, 0.9521], d_k_M_hat range: [0.8814, 0.9994]
2025-03-11 21:12:03 - Train Iteration 11313: loss: 0.0008, d_k_M range: [0.0000, 0.0160], d_k_M_hat range: [0.9726, 0.9980]
2025-03-11 21:12:04 - Train Iteration 11314: loss: 0.3209, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.4335, 0.9977]
2025-03-11 21:12:04 - Train Iteration 11315: loss: 0.4232, d_k_M range: [0.0000, 0.6504], d_k_M_hat range: [0.9447, 0.9999]
2025-03-11 21:12:05 - Train Iteration 11316: loss: 0.3253, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.4297, 0.9858]
2025-03-11 21:12:05 - Train Iteration 11317: loss: 0.7993, d_k_M range: [0.0005, 0.8940], d_k_M_hat range: [0.9892, 1.0000]
2025-03-11 21:12:06 - Train Iteration 11318: loss: 0.0811, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.7152, 0.9816]
2025-03-11 21:12:06 - Train Iteration 11319: loss: 0.4773, d_k_M range: [0.0011, 0.6892], d_k_M_hat range: [0.9863, 0.9999]
2025-03-11 21:12:06 - Train Iteration 11320: loss: 0.0393, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.8018, 0.9975]
2025-03-11 21:12:07 - Train Iteration 11321: loss: 0.0617, d_k_M range: [0.0017, 0.2424], d_k_M_hat range: [0.9940, 1.0000]
2025-03-11 21:12:07 - Train Iteration 11322: loss: 0.0721, d_k_M range: [0.0002, 0.2684], d_k_M_hat range: [0.9866, 0.9999]
2025-03-11 21:12:08 - Train Iteration 11323: loss: 0.0093, d_k_M range: [0.0000, 0.0961], d_k_M_hat range: [0.9686, 0.9998]
2025-03-11 21:12:08 - Train Iteration 11324: loss: 0.0015, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.9638, 0.9989]
2025-03-11 21:12:08 - Train Iteration 11325: loss: 0.0006, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9764, 0.9988]
2025-03-11 21:12:09 - Train Iteration 11326: loss: 0.0266, d_k_M range: [0.0000, 0.0427], d_k_M_hat range: [0.8372, 0.9991]
2025-03-11 21:12:09 - Train Iteration 11327: loss: 0.1413, d_k_M range: [0.0000, 0.3753], d_k_M_hat range: [0.9826, 0.9998]
2025-03-11 21:12:10 - Train Iteration 11328: loss: 0.6755, d_k_M range: [0.0000, 0.0735], d_k_M_hat range: [0.1781, 0.9984]
2025-03-11 21:12:10 - Train Iteration 11329: loss: 0.0890, d_k_M range: [0.0001, 0.2952], d_k_M_hat range: [0.9555, 0.9998]
2025-03-11 21:12:10 - Train Iteration 11330: loss: 0.0361, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.8100, 0.9959]
2025-03-11 21:12:11 - Train Iteration 11331: loss: 0.0167, d_k_M range: [0.0000, 0.1078], d_k_M_hat range: [0.8711, 0.9987]
2025-03-11 21:12:11 - Train Iteration 11332: loss: 0.0249, d_k_M range: [0.0000, 0.0224], d_k_M_hat range: [0.8422, 0.9997]
2025-03-11 21:12:12 - Train Iteration 11333: loss: 0.0227, d_k_M range: [0.0000, 0.1475], d_k_M_hat range: [0.9408, 0.9991]
2025-03-11 21:12:12 - Train Iteration 11334: loss: 0.0004, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.9808, 0.9999]
2025-03-11 21:12:13 - Train Iteration 11335: loss: 0.0117, d_k_M range: [0.0000, 0.0948], d_k_M_hat range: [0.8950, 0.9988]
2025-03-11 21:12:13 - Train Iteration 11336: loss: 0.1667, d_k_M range: [0.0001, 0.4052], d_k_M_hat range: [0.9557, 0.9976]
2025-03-11 21:12:13 - Train Iteration 11337: loss: 0.4384, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.3379, 0.9914]
2025-03-11 21:12:14 - Train Iteration 11338: loss: 0.0132, d_k_M range: [0.0000, 0.1146], d_k_M_hat range: [0.9428, 0.9999]
2025-03-11 21:12:14 - Train Iteration 11339: loss: 0.3091, d_k_M range: [0.0000, 0.5558], d_k_M_hat range: [0.9914, 0.9998]
2025-03-11 21:12:15 - Train Iteration 11340: loss: 0.0019, d_k_M range: [0.0001, 0.0068], d_k_M_hat range: [0.9566, 0.9988]
2025-03-11 21:12:15 - Train Iteration 11341: loss: 0.0005, d_k_M range: [0.0000, 0.0197], d_k_M_hat range: [0.9863, 0.9996]
2025-03-11 21:12:15 - Train Iteration 11342: loss: 0.0378, d_k_M range: [0.0000, 0.1941], d_k_M_hat range: [0.9766, 0.9997]
2025-03-11 21:12:16 - Train Iteration 11343: loss: 0.0147, d_k_M range: [0.0000, 0.0056], d_k_M_hat range: [0.8792, 0.9937]
2025-03-11 21:12:16 - Train Iteration 11344: loss: 0.0023, d_k_M range: [0.0000, 0.0078], d_k_M_hat range: [0.9531, 0.9989]
2025-03-11 21:12:17 - Train Iteration 11345: loss: 0.0121, d_k_M range: [0.0000, 0.1088], d_k_M_hat range: [0.9783, 0.9995]
2025-03-11 21:12:17 - Train Iteration 11346: loss: 0.0013, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9641, 0.9987]
2025-03-11 21:12:18 - Train Iteration 11347: loss: 0.0213, d_k_M range: [0.0000, 0.1458], d_k_M_hat range: [0.9578, 0.9999]
2025-03-11 21:12:18 - Train Iteration 11348: loss: 0.0527, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.7704, 0.9978]
2025-03-11 21:12:19 - Train Iteration 11349: loss: 0.0392, d_k_M range: [0.0000, 0.1971], d_k_M_hat range: [0.9980, 0.9999]
2025-03-11 21:12:19 - Train Iteration 11350: loss: 0.0090, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.9053, 0.9997]
2025-03-11 21:12:19 - Train Iteration 11351: loss: 0.5176, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.2840, 0.9973]
2025-03-11 21:12:20 - Train Iteration 11352: loss: 0.0007, d_k_M range: [0.0000, 0.0218], d_k_M_hat range: [0.9783, 0.9996]
2025-03-11 21:12:20 - Train Iteration 11353: loss: 0.0002, d_k_M range: [0.0000, 0.0139], d_k_M_hat range: [0.9936, 1.0000]
2025-03-11 21:12:21 - Train Iteration 11354: loss: 0.0872, d_k_M range: [0.0000, 0.0209], d_k_M_hat range: [0.7061, 0.9991]
2025-03-11 21:12:21 - Train Iteration 11355: loss: 0.0020, d_k_M range: [0.0001, 0.0373], d_k_M_hat range: [0.9559, 0.9998]
2025-03-11 21:12:22 - Train Iteration 11356: loss: 0.0004, d_k_M range: [0.0000, 0.0188], d_k_M_hat range: [0.9895, 0.9999]
2025-03-11 21:12:22 - Train Iteration 11357: loss: 0.0026, d_k_M range: [0.0000, 0.0242], d_k_M_hat range: [0.9493, 0.9999]
2025-03-11 21:12:23 - Train Iteration 11358: loss: 0.2183, d_k_M range: [0.0002, 0.0098], d_k_M_hat range: [0.5361, 0.9999]
2025-03-11 21:12:23 - Train Iteration 11359: loss: 0.0117, d_k_M range: [0.0000, 0.0132], d_k_M_hat range: [0.8958, 0.9990]
2025-03-11 21:12:24 - Train Iteration 11360: loss: 0.0083, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.9112, 1.0000]
2025-03-11 21:12:24 - Train Iteration 11361: loss: 0.0026, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9486, 0.9989]
2025-03-11 21:12:24 - Train Iteration 11362: loss: 0.0142, d_k_M range: [0.0000, 0.0328], d_k_M_hat range: [0.8814, 0.9999]
2025-03-11 21:12:25 - Train Iteration 11363: loss: 0.0157, d_k_M range: [0.0000, 0.1253], d_k_M_hat range: [0.9920, 1.0000]
2025-03-11 21:12:25 - Train Iteration 11364: loss: 0.0025, d_k_M range: [0.0001, 0.0133], d_k_M_hat range: [0.9501, 1.0000]
2025-03-11 21:12:26 - Train Iteration 11365: loss: 0.0083, d_k_M range: [0.0000, 0.0909], d_k_M_hat range: [0.9769, 0.9995]
2025-03-11 21:12:26 - Train Iteration 11366: loss: 0.0867, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.7059, 0.9983]
2025-03-11 21:12:27 - Train Iteration 11367: loss: 0.7839, d_k_M range: [0.0001, 0.1061], d_k_M_hat range: [0.1147, 0.9997]
2025-03-11 21:12:27 - Train Iteration 11368: loss: 0.0855, d_k_M range: [0.0000, 0.2923], d_k_M_hat range: [0.9853, 1.0000]
2025-03-11 21:12:28 - Train Iteration 11369: loss: 0.0159, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.8740, 0.9971]
2025-03-11 21:12:28 - Train Iteration 11370: loss: 0.0084, d_k_M range: [0.0001, 0.0916], d_k_M_hat range: [0.9822, 0.9998]
2025-03-11 21:12:28 - Train Iteration 11371: loss: 0.0026, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9496, 0.9989]
2025-03-11 21:12:29 - Train Iteration 11372: loss: 0.3584, d_k_M range: [0.0000, 0.1232], d_k_M_hat range: [0.4016, 0.9996]
2025-03-11 21:12:29 - Train Iteration 11373: loss: 0.0082, d_k_M range: [0.0001, 0.0704], d_k_M_hat range: [0.9801, 0.9998]
2025-03-11 21:12:30 - Train Iteration 11374: loss: 0.0666, d_k_M range: [0.0000, 0.0125], d_k_M_hat range: [0.7420, 0.9997]
2025-03-11 21:12:30 - Train Iteration 11375: loss: 0.0008, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9720, 0.9986]
2025-03-11 21:12:31 - Train Iteration 11376: loss: 0.1797, d_k_M range: [0.0000, 0.4195], d_k_M_hat range: [0.9526, 0.9994]
2025-03-11 21:12:31 - Train Iteration 11377: loss: 0.0205, d_k_M range: [0.0000, 0.0265], d_k_M_hat range: [0.8570, 0.9998]
2025-03-11 21:12:32 - Train Iteration 11378: loss: 0.4259, d_k_M range: [0.0000, 0.0205], d_k_M_hat range: [0.3474, 0.9996]
2025-03-11 21:12:32 - Train Iteration 11379: loss: 0.0014, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.9632, 0.9994]
2025-03-11 21:12:32 - Train Iteration 11380: loss: 0.0003, d_k_M range: [0.0000, 0.0067], d_k_M_hat range: [0.9897, 0.9997]
2025-03-11 21:12:33 - Train Iteration 11381: loss: 0.0070, d_k_M range: [0.0001, 0.0719], d_k_M_hat range: [0.9651, 0.9996]
2025-03-11 21:12:33 - Train Iteration 11382: loss: 0.0112, d_k_M range: [0.0001, 0.0312], d_k_M_hat range: [0.8944, 0.9969]
2025-03-11 21:12:34 - Train Iteration 11383: loss: 0.0039, d_k_M range: [0.0000, 0.0137], d_k_M_hat range: [0.9375, 0.9998]
2025-03-11 21:12:34 - Train Iteration 11384: loss: 0.0221, d_k_M range: [0.0000, 0.1485], d_k_M_hat range: [0.9264, 0.9999]
2025-03-11 21:12:35 - Train Iteration 11385: loss: 0.0061, d_k_M range: [0.0001, 0.0331], d_k_M_hat range: [0.9359, 0.9918]
2025-03-11 21:12:35 - Train Iteration 11386: loss: 0.0069, d_k_M range: [0.0000, 0.0200], d_k_M_hat range: [0.9169, 0.9999]
2025-03-11 21:12:36 - Train Iteration 11387: loss: 0.0168, d_k_M range: [0.0000, 0.1296], d_k_M_hat range: [0.9918, 1.0000]
2025-03-11 21:12:36 - Train Iteration 11388: loss: 0.0158, d_k_M range: [0.0000, 0.0568], d_k_M_hat range: [0.8745, 0.9969]
2025-03-11 21:12:36 - Train Iteration 11389: loss: 0.0027, d_k_M range: [0.0001, 0.0348], d_k_M_hat range: [0.9483, 1.0000]
2025-03-11 21:12:37 - Train Iteration 11390: loss: 0.3312, d_k_M range: [0.0003, 0.5751], d_k_M_hat range: [0.9945, 0.9999]
2025-03-11 21:12:37 - Train Iteration 11391: loss: 0.0710, d_k_M range: [0.0000, 0.2633], d_k_M_hat range: [0.9804, 0.9982]
2025-03-11 21:12:38 - Train Iteration 11392: loss: 0.2963, d_k_M range: [0.0000, 0.0203], d_k_M_hat range: [0.4557, 0.9982]
2025-03-11 21:12:38 - Train Iteration 11393: loss: 0.0010, d_k_M range: [0.0000, 0.0144], d_k_M_hat range: [0.9711, 0.9993]
2025-03-11 21:12:39 - Train Iteration 11394: loss: 0.0008, d_k_M range: [0.0000, 0.0154], d_k_M_hat range: [0.9722, 0.9997]
2025-03-11 21:12:39 - Train Iteration 11395: loss: 0.0050, d_k_M range: [0.0000, 0.0680], d_k_M_hat range: [0.9387, 0.9991]
2025-03-11 21:12:40 - Train Iteration 11396: loss: 0.0067, d_k_M range: [0.0000, 0.0105], d_k_M_hat range: [0.9184, 0.9996]
2025-03-11 21:12:40 - Train Iteration 11397: loss: 0.2022, d_k_M range: [0.0000, 0.0370], d_k_M_hat range: [0.5503, 0.9965]
2025-03-11 21:12:41 - Train Iteration 11398: loss: 0.0009, d_k_M range: [0.0000, 0.0176], d_k_M_hat range: [0.9714, 0.9980]
2025-03-11 21:12:41 - Train Iteration 11399: loss: 0.0091, d_k_M range: [0.0000, 0.0105], d_k_M_hat range: [0.9057, 0.9994]
2025-03-11 21:12:41 - Train Iteration 11400: loss: 0.8359, d_k_M range: [0.0001, 0.9142], d_k_M_hat range: [0.9114, 0.9999]
2025-03-11 21:12:42 - Train Iteration 11401: loss: 0.0012, d_k_M range: [0.0000, 0.0188], d_k_M_hat range: [0.9649, 0.9981]
2025-03-11 21:12:42 - Train Iteration 11402: loss: 0.0045, d_k_M range: [0.0000, 0.0282], d_k_M_hat range: [0.9435, 0.9994]
2025-03-11 21:12:43 - Train Iteration 11403: loss: 0.0006, d_k_M range: [0.0000, 0.0067], d_k_M_hat range: [0.9783, 0.9988]
2025-03-11 21:12:43 - Train Iteration 11404: loss: 0.0035, d_k_M range: [0.0000, 0.0150], d_k_M_hat range: [0.9466, 0.9990]
2025-03-11 21:12:44 - Train Iteration 11405: loss: 0.0003, d_k_M range: [0.0000, 0.0136], d_k_M_hat range: [0.9906, 0.9995]
2025-03-11 21:12:44 - Train Iteration 11406: loss: 0.0010, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.9687, 0.9994]
2025-03-11 21:12:45 - Train Iteration 11407: loss: 0.0236, d_k_M range: [0.0000, 0.0264], d_k_M_hat range: [0.8463, 0.9996]
2025-03-11 21:12:45 - Train Iteration 11408: loss: 0.0247, d_k_M range: [0.0001, 0.0040], d_k_M_hat range: [0.8447, 0.9999]
2025-03-11 21:12:46 - Train Iteration 11409: loss: 0.0019, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9582, 0.9981]
2025-03-11 21:12:46 - Train Iteration 11410: loss: 0.0182, d_k_M range: [0.0004, 0.1349], d_k_M_hat range: [0.9465, 0.9999]
2025-03-11 21:12:47 - Train Iteration 11411: loss: 0.0051, d_k_M range: [0.0000, 0.0086], d_k_M_hat range: [0.9284, 0.9918]
2025-03-11 21:12:47 - Train Iteration 11412: loss: 0.0195, d_k_M range: [0.0000, 0.1393], d_k_M_hat range: [0.8899, 0.9997]
2025-03-11 21:12:48 - Train Iteration 11413: loss: 0.0001, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.9887, 1.0000]
2025-03-11 21:12:48 - Train Iteration 11414: loss: 0.1637, d_k_M range: [0.0000, 0.0318], d_k_M_hat range: [0.5964, 0.9990]
2025-03-11 21:12:49 - Train Iteration 11415: loss: 0.0017, d_k_M range: [0.0001, 0.0402], d_k_M_hat range: [0.9893, 0.9999]
2025-03-11 21:12:49 - Train Iteration 11416: loss: 0.4091, d_k_M range: [0.0000, 0.6392], d_k_M_hat range: [0.9810, 0.9998]
2025-03-11 21:12:49 - Train Iteration 11417: loss: 0.7340, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.1433, 0.9946]
2025-03-11 21:12:50 - Train Iteration 11418: loss: 0.2057, d_k_M range: [0.0383, 0.4534], d_k_M_hat range: [0.9989, 1.0000]
2025-03-11 21:12:50 - Train Iteration 11419: loss: 0.0036, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.9409, 0.9995]
2025-03-11 21:12:51 - Train Iteration 11420: loss: 0.0021, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9546, 0.9993]
2025-03-11 21:12:51 - Train Iteration 11421: loss: 0.4741, d_k_M range: [0.0000, 0.6885], d_k_M_hat range: [0.9936, 1.0000]
2025-03-11 21:12:52 - Train Iteration 11422: loss: 0.0843, d_k_M range: [0.0000, 0.2900], d_k_M_hat range: [0.8348, 0.9999]
2025-03-11 21:12:52 - Train Iteration 11423: loss: 0.8760, d_k_M range: [0.0000, 0.0265], d_k_M_hat range: [0.0641, 0.9991]
2025-03-11 21:12:52 - Train Iteration 11424: loss: 0.0021, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9542, 0.9991]
2025-03-11 21:12:53 - Train Iteration 11425: loss: 0.0023, d_k_M range: [0.0000, 0.0447], d_k_M_hat range: [0.9520, 0.9998]
2025-03-11 21:12:53 - Train Iteration 11426: loss: 0.0185, d_k_M range: [0.0000, 0.1360], d_k_M_hat range: [0.9784, 0.9999]
2025-03-11 21:12:54 - Train Iteration 11427: loss: 0.5024, d_k_M range: [0.0000, 0.7081], d_k_M_hat range: [0.9866, 0.9995]
2025-03-11 21:12:54 - Train Iteration 11428: loss: 0.0020, d_k_M range: [0.0000, 0.0079], d_k_M_hat range: [0.9558, 0.9994]
2025-03-11 21:12:55 - Train Iteration 11429: loss: 0.0092, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9039, 0.9995]
2025-03-11 21:12:55 - Train Iteration 11430: loss: 0.0210, d_k_M range: [0.0000, 0.1447], d_k_M_hat range: [0.9869, 0.9999]
2025-03-11 21:12:55 - Train Iteration 11431: loss: 0.0042, d_k_M range: [0.0000, 0.0561], d_k_M_hat range: [0.9916, 0.9999]
2025-03-11 21:12:56 - Train Iteration 11432: loss: 0.0974, d_k_M range: [0.0003, 0.3121], d_k_M_hat range: [0.9790, 1.0000]
2025-03-11 21:12:56 - Train Iteration 11433: loss: 0.0028, d_k_M range: [0.0000, 0.0071], d_k_M_hat range: [0.9473, 0.9995]
2025-03-11 21:12:57 - Train Iteration 11434: loss: 0.0693, d_k_M range: [0.0001, 0.0109], d_k_M_hat range: [0.7386, 0.9987]
2025-03-11 21:12:57 - Train Iteration 11435: loss: 0.0113, d_k_M range: [0.0001, 0.1060], d_k_M_hat range: [0.9754, 0.9999]
2025-03-11 21:12:58 - Train Iteration 11436: loss: 0.1645, d_k_M range: [0.0000, 0.0523], d_k_M_hat range: [0.5946, 0.9998]
2025-03-11 21:12:58 - Train Iteration 11437: loss: 0.0807, d_k_M range: [0.0001, 0.2830], d_k_M_hat range: [0.9855, 0.9998]
2025-03-11 21:12:58 - Train Iteration 11438: loss: 0.0015, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9624, 0.9998]
2025-03-11 21:12:59 - Train Iteration 11439: loss: 0.1442, d_k_M range: [0.0000, 0.0380], d_k_M_hat range: [0.6209, 0.9998]
2025-03-11 21:12:59 - Train Iteration 11440: loss: 0.3593, d_k_M range: [0.0000, 0.5990], d_k_M_hat range: [0.5711, 0.9997]
2025-03-11 21:13:00 - Train Iteration 11441: loss: 0.1497, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.6131, 0.9884]
2025-03-11 21:13:00 - Train Iteration 11442: loss: 0.0005, d_k_M range: [0.0000, 0.0096], d_k_M_hat range: [0.9778, 0.9996]
2025-03-11 21:13:01 - Train Iteration 11443: loss: 0.0055, d_k_M range: [0.0000, 0.0581], d_k_M_hat range: [0.9824, 0.9966]
2025-03-11 21:13:01 - Train Iteration 11444: loss: 0.0007, d_k_M range: [0.0000, 0.0219], d_k_M_hat range: [0.9913, 0.9995]
2025-03-11 21:13:01 - Train Iteration 11445: loss: 0.0343, d_k_M range: [0.0003, 0.1849], d_k_M_hat range: [0.9305, 0.9999]
2025-03-11 21:13:02 - Train Iteration 11446: loss: 0.0620, d_k_M range: [0.0000, 0.1265], d_k_M_hat range: [0.7511, 0.9962]
2025-03-11 21:13:02 - Train Iteration 11447: loss: 0.0490, d_k_M range: [0.0066, 0.2203], d_k_M_hat range: [0.9912, 1.0000]
2025-03-11 21:13:03 - Train Iteration 11448: loss: 0.0292, d_k_M range: [0.0004, 0.1708], d_k_M_hat range: [0.9904, 1.0000]
2025-03-11 21:13:03 - Train Iteration 11449: loss: 0.0089, d_k_M range: [0.0000, 0.0212], d_k_M_hat range: [0.9065, 0.9990]
2025-03-11 21:13:04 - Train Iteration 11450: loss: 0.7857, d_k_M range: [0.0001, 0.8860], d_k_M_hat range: [0.9614, 0.9998]
2025-03-11 21:13:04 - Train Iteration 11451: loss: 0.1516, d_k_M range: [0.0000, 0.3884], d_k_M_hat range: [0.9384, 0.9994]
2025-03-11 21:13:05 - Train Iteration 11452: loss: 0.0066, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.9210, 0.9994]
2025-03-11 21:13:05 - Train Iteration 11453: loss: 0.0157, d_k_M range: [0.0000, 0.0352], d_k_M_hat range: [0.8958, 0.9998]
2025-03-11 21:13:06 - Train Iteration 11454: loss: 0.6126, d_k_M range: [0.0000, 0.7826], d_k_M_hat range: [0.7430, 1.0000]
2025-03-11 21:13:06 - Train Iteration 11455: loss: 0.5972, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.2272, 0.9727]
2025-03-11 21:13:06 - Train Iteration 11456: loss: 0.0003, d_k_M range: [0.0003, 0.0055], d_k_M_hat range: [0.9870, 0.9993]
2025-03-11 21:13:07 - Train Iteration 11457: loss: 0.0944, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.6930, 0.9988]
2025-03-11 21:13:07 - Train Iteration 11458: loss: 0.0013, d_k_M range: [0.0000, 0.0344], d_k_M_hat range: [0.9952, 0.9988]
2025-03-11 21:13:08 - Train Iteration 11459: loss: 0.0502, d_k_M range: [0.0000, 0.0170], d_k_M_hat range: [0.7759, 0.9993]
2025-03-11 21:13:08 - Train Iteration 11460: loss: 0.0301, d_k_M range: [0.0000, 0.1735], d_k_M_hat range: [0.9742, 0.9999]
2025-03-11 21:13:09 - Train Iteration 11461: loss: 0.8211, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.0939, 0.9986]
2025-03-11 21:13:09 - Train Iteration 11462: loss: 0.6964, d_k_M range: [0.0000, 0.8334], d_k_M_hat range: [0.9812, 0.9997]
2025-03-11 21:13:09 - Train Iteration 11463: loss: 0.0049, d_k_M range: [0.0000, 0.0679], d_k_M_hat range: [0.9796, 0.9996]
2025-03-11 21:13:10 - Train Iteration 11464: loss: 0.0455, d_k_M range: [0.0001, 0.2118], d_k_M_hat range: [0.8775, 0.9984]
2025-03-11 21:13:10 - Train Iteration 11465: loss: 0.0036, d_k_M range: [0.0001, 0.0049], d_k_M_hat range: [0.9401, 0.9997]
2025-03-11 21:13:11 - Train Iteration 11466: loss: 0.2851, d_k_M range: [0.0004, 0.5336], d_k_M_hat range: [0.9698, 0.9999]
2025-03-11 21:13:11 - Train Iteration 11467: loss: 0.0102, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.8994, 0.9983]
2025-03-11 21:13:11 - Train Iteration 11468: loss: 0.5577, d_k_M range: [0.0000, 0.0112], d_k_M_hat range: [0.2552, 0.9948]
2025-03-11 21:13:12 - Train Iteration 11469: loss: 0.0031, d_k_M range: [0.0002, 0.0538], d_k_M_hat range: [0.9975, 0.9999]
2025-03-11 21:13:12 - Train Iteration 11470: loss: 0.0041, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9356, 0.9984]
2025-03-11 21:13:13 - Train Iteration 11471: loss: 0.0026, d_k_M range: [0.0001, 0.0499], d_k_M_hat range: [0.9625, 0.9999]
2025-03-11 21:13:13 - Train Iteration 11472: loss: 0.0016, d_k_M range: [0.0000, 0.0381], d_k_M_hat range: [0.9850, 0.9989]
2025-03-11 21:13:14 - Train Iteration 11473: loss: 0.8414, d_k_M range: [0.0005, 0.9172], d_k_M_hat range: [0.9732, 0.9999]
2025-03-11 21:13:14 - Train Iteration 11474: loss: 0.0380, d_k_M range: [0.0000, 0.1948], d_k_M_hat range: [0.9488, 0.9999]
2025-03-11 21:13:14 - Train Iteration 11475: loss: 0.0685, d_k_M range: [0.0000, 0.0356], d_k_M_hat range: [0.7388, 0.9876]
2025-03-11 21:13:15 - Train Iteration 11476: loss: 0.0021, d_k_M range: [0.0000, 0.0317], d_k_M_hat range: [0.9549, 0.9997]
2025-03-11 21:13:15 - Train Iteration 11477: loss: 0.5879, d_k_M range: [0.0000, 0.7661], d_k_M_hat range: [0.9860, 0.9999]
2025-03-11 21:13:16 - Train Iteration 11478: loss: 0.0370, d_k_M range: [0.0000, 0.1910], d_k_M_hat range: [0.8713, 0.9990]
2025-03-11 21:13:16 - Train Iteration 11479: loss: 0.0015, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.9612, 0.9994]
2025-03-11 21:13:16 - Train Iteration 11480: loss: 0.0112, d_k_M range: [0.0001, 0.0260], d_k_M_hat range: [0.8945, 0.9994]
2025-03-11 21:13:17 - Train Iteration 11481: loss: 0.0543, d_k_M range: [0.0000, 0.0907], d_k_M_hat range: [0.7669, 0.9998]
2025-03-11 21:13:17 - Train Iteration 11482: loss: 0.0884, d_k_M range: [0.0000, 0.2958], d_k_M_hat range: [0.9773, 0.9986]
2025-03-11 21:13:18 - Train Iteration 11483: loss: 0.0589, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.7576, 0.9939]
2025-03-11 21:13:18 - Train Iteration 11484: loss: 0.0284, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.8315, 0.9996]
2025-03-11 21:13:18 - Train Iteration 11485: loss: 0.0035, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.9412, 0.9997]
2025-03-11 21:13:19 - Train Iteration 11486: loss: 0.0047, d_k_M range: [0.0000, 0.0644], d_k_M_hat range: [0.9775, 0.9995]
2025-03-11 21:13:19 - Train Iteration 11487: loss: 0.0293, d_k_M range: [0.0000, 0.0409], d_k_M_hat range: [0.8290, 0.9997]
2025-03-11 21:13:20 - Train Iteration 11488: loss: 0.0004, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.9802, 0.9999]
2025-03-11 21:13:20 - Train Iteration 11489: loss: 0.4164, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.3547, 0.9906]
2025-03-11 21:13:21 - Train Iteration 11490: loss: 0.7512, d_k_M range: [0.0000, 0.8664], d_k_M_hat range: [0.9617, 1.0000]
2025-03-11 21:13:21 - Train Iteration 11491: loss: 0.0024, d_k_M range: [0.0000, 0.0327], d_k_M_hat range: [0.9837, 0.9995]
2025-03-11 21:13:21 - Train Iteration 11492: loss: 0.0546, d_k_M range: [0.0000, 0.0108], d_k_M_hat range: [0.7672, 1.0000]
2025-03-11 21:13:22 - Train Iteration 11493: loss: 0.0099, d_k_M range: [0.0000, 0.0256], d_k_M_hat range: [0.9003, 0.9991]
2025-03-11 21:13:22 - Train Iteration 11494: loss: 0.0029, d_k_M range: [0.0000, 0.0189], d_k_M_hat range: [0.9460, 0.9997]
2025-03-11 21:13:23 - Train Iteration 11495: loss: 0.1237, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.6484, 0.9985]
2025-03-11 21:13:23 - Train Iteration 11496: loss: 0.0019, d_k_M range: [0.0001, 0.0440], d_k_M_hat range: [0.9771, 0.9999]
2025-03-11 21:13:23 - Train Iteration 11497: loss: 0.4495, d_k_M range: [0.0000, 0.0200], d_k_M_hat range: [0.3296, 1.0000]
2025-03-11 21:13:24 - Train Iteration 11498: loss: 0.1668, d_k_M range: [0.0000, 0.4082], d_k_M_hat range: [0.9898, 0.9999]
2025-03-11 21:13:24 - Train Iteration 11499: loss: 0.0321, d_k_M range: [0.0006, 0.1649], d_k_M_hat range: [0.9573, 0.9998]
2025-03-11 21:13:25 - Train Iteration 11500: loss: 0.0002, d_k_M range: [0.0000, 0.0055], d_k_M_hat range: [0.9871, 0.9986]
2025-03-11 21:13:25 - Train Iteration 11501: loss: 0.5429, d_k_M range: [0.0002, 0.7344], d_k_M_hat range: [0.9739, 0.9994]
2025-03-11 21:13:26 - Train Iteration 11502: loss: 0.1382, d_k_M range: [0.0000, 0.3690], d_k_M_hat range: [0.8996, 0.9991]
2025-03-11 21:13:26 - Train Iteration 11503: loss: 0.6844, d_k_M range: [0.0000, 0.2179], d_k_M_hat range: [0.1728, 0.9984]
2025-03-11 21:13:26 - Train Iteration 11504: loss: 0.0343, d_k_M range: [0.0000, 0.1849], d_k_M_hat range: [0.9939, 0.9996]
2025-03-11 21:13:27 - Train Iteration 11505: loss: 0.4233, d_k_M range: [0.0034, 0.6504], d_k_M_hat range: [0.9840, 0.9999]
2025-03-11 21:13:27 - Train Iteration 11506: loss: 0.0542, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.7671, 0.9988]
2025-03-11 21:13:28 - Train Iteration 11507: loss: 0.0241, d_k_M range: [0.0000, 0.1548], d_k_M_hat range: [0.9895, 0.9996]
2025-03-11 21:13:28 - Train Iteration 11508: loss: 0.0001, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.9903, 0.9987]
2025-03-11 21:13:28 - Train Iteration 11509: loss: 0.0316, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.8232, 0.9994]
2025-03-11 21:13:29 - Train Iteration 11510: loss: 0.2129, d_k_M range: [0.0000, 0.4569], d_k_M_hat range: [0.6865, 0.9996]
2025-03-11 21:13:29 - Train Iteration 11511: loss: 0.0022, d_k_M range: [0.0000, 0.0276], d_k_M_hat range: [0.9761, 0.9994]
2025-03-11 21:13:30 - Train Iteration 11512: loss: 0.1872, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.5673, 0.9991]
2025-03-11 21:13:30 - Train Iteration 11513: loss: 0.1923, d_k_M range: [0.0000, 0.4381], d_k_M_hat range: [0.9925, 0.9999]
2025-03-11 21:13:31 - Train Iteration 11514: loss: 0.0007, d_k_M range: [0.0000, 0.0265], d_k_M_hat range: [0.9874, 1.0000]
2025-03-11 21:13:31 - Train Iteration 11515: loss: 0.0015, d_k_M range: [0.0001, 0.0387], d_k_M_hat range: [0.9866, 0.9998]
2025-03-11 21:13:31 - Train Iteration 11516: loss: 0.0052, d_k_M range: [0.0001, 0.0715], d_k_M_hat range: [0.9960, 0.9999]
2025-03-11 21:13:32 - Train Iteration 11517: loss: 0.0617, d_k_M range: [0.0001, 0.2458], d_k_M_hat range: [0.9782, 0.9994]
2025-03-11 21:13:32 - Train Iteration 11518: loss: 0.2865, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.4648, 0.9975]
2025-03-11 21:13:33 - Train Iteration 11519: loss: 0.0134, d_k_M range: [0.0000, 0.1158], d_k_M_hat range: [0.9861, 0.9999]
2025-03-11 21:13:33 - Train Iteration 11520: loss: 0.0123, d_k_M range: [0.0000, 0.1038], d_k_M_hat range: [0.9291, 0.9993]
2025-03-11 21:13:33 - Train Iteration 11521: loss: 0.0052, d_k_M range: [0.0000, 0.0719], d_k_M_hat range: [0.9723, 0.9997]
2025-03-11 21:13:34 - Train Iteration 11522: loss: 0.0047, d_k_M range: [0.0000, 0.0102], d_k_M_hat range: [0.9315, 0.9991]
2025-03-11 21:13:34 - Train Iteration 11523: loss: 0.0131, d_k_M range: [0.0000, 0.1136], d_k_M_hat range: [0.9618, 0.9999]
2025-03-11 21:13:35 - Train Iteration 11524: loss: 0.8522, d_k_M range: [0.0002, 0.9230], d_k_M_hat range: [0.9853, 0.9999]
2025-03-11 21:13:35 - Train Iteration 11525: loss: 0.0009, d_k_M range: [0.0001, 0.0283], d_k_M_hat range: [0.9890, 0.9999]
2025-03-11 21:13:35 - Train Iteration 11526: loss: 0.0005, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9781, 0.9997]
2025-03-11 21:13:36 - Train Iteration 11527: loss: 0.0004, d_k_M range: [0.0002, 0.0066], d_k_M_hat range: [0.9842, 0.9999]
2025-03-11 21:13:36 - Train Iteration 11528: loss: 0.3019, d_k_M range: [0.0000, 0.0989], d_k_M_hat range: [0.4506, 0.9998]
2025-03-11 21:13:37 - Train Iteration 11529: loss: 0.0045, d_k_M range: [0.0001, 0.0672], d_k_M_hat range: [0.9763, 0.9998]
2025-03-11 21:13:37 - Train Iteration 11530: loss: 0.1712, d_k_M range: [0.0000, 0.2991], d_k_M_hat range: [0.5863, 0.9998]
2025-03-11 21:13:38 - Train Iteration 11531: loss: 0.0048, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9308, 0.9998]
2025-03-11 21:13:38 - Train Iteration 11532: loss: 0.0022, d_k_M range: [0.0000, 0.0326], d_k_M_hat range: [0.9835, 0.9994]
2025-03-11 21:13:38 - Train Iteration 11533: loss: 0.0020, d_k_M range: [0.0000, 0.0397], d_k_M_hat range: [0.9683, 0.9999]
2025-03-11 21:13:39 - Train Iteration 11534: loss: 0.0253, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.8410, 0.9981]
2025-03-11 21:13:39 - Train Iteration 11535: loss: 0.0021, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9545, 0.9973]
2025-03-11 21:13:40 - Train Iteration 11536: loss: 0.0003, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9815, 0.9997]
2025-03-11 21:13:40 - Train Iteration 11537: loss: 0.0005, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9773, 0.9998]
2025-03-11 21:13:40 - Train Iteration 11538: loss: 0.0131, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.8855, 0.9997]
2025-03-11 21:13:41 - Train Iteration 11539: loss: 0.0231, d_k_M range: [0.0000, 0.1207], d_k_M_hat range: [0.8485, 0.9999]
2025-03-11 21:13:41 - Train Iteration 11540: loss: 0.0006, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9764, 1.0000]
2025-03-11 21:13:42 - Train Iteration 11541: loss: 0.1126, d_k_M range: [0.0001, 0.0017], d_k_M_hat range: [0.6647, 0.9990]
2025-03-11 21:13:42 - Train Iteration 11542: loss: 0.0066, d_k_M range: [0.0000, 0.0801], d_k_M_hat range: [0.9235, 0.9998]
2025-03-11 21:13:42 - Train Iteration 11543: loss: 0.0241, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.8447, 0.9987]
2025-03-11 21:13:43 - Train Iteration 11544: loss: 0.2636, d_k_M range: [0.0003, 0.5134], d_k_M_hat range: [0.9823, 1.0000]
2025-03-11 21:13:43 - Train Iteration 11545: loss: 0.0473, d_k_M range: [0.0000, 0.0132], d_k_M_hat range: [0.7824, 0.9994]
2025-03-11 21:13:44 - Train Iteration 11546: loss: 0.3068, d_k_M range: [0.0002, 0.5500], d_k_M_hat range: [0.9961, 1.0000]
2025-03-11 21:13:44 - Train Iteration 11547: loss: 0.1137, d_k_M range: [0.0000, 0.1080], d_k_M_hat range: [0.6628, 0.9992]
2025-03-11 21:13:45 - Train Iteration 11548: loss: 0.0019, d_k_M range: [0.0001, 0.0052], d_k_M_hat range: [0.9579, 0.9998]
2025-03-11 21:13:45 - Train Iteration 11549: loss: 0.0415, d_k_M range: [0.0000, 0.1951], d_k_M_hat range: [0.9618, 0.9998]
2025-03-11 21:13:45 - Train Iteration 11550: loss: 0.1050, d_k_M range: [0.0000, 0.0157], d_k_M_hat range: [0.6761, 0.9984]
2025-03-11 21:13:46 - Train Iteration 11551: loss: 0.0283, d_k_M range: [0.0000, 0.0961], d_k_M_hat range: [0.8319, 0.9995]
2025-03-11 21:13:46 - Train Iteration 11552: loss: 0.0033, d_k_M range: [0.0000, 0.0098], d_k_M_hat range: [0.9429, 0.9999]
2025-03-11 21:13:47 - Train Iteration 11553: loss: 0.0283, d_k_M range: [0.0000, 0.0106], d_k_M_hat range: [0.8320, 0.9977]
2025-03-11 21:13:47 - Train Iteration 11554: loss: 0.0027, d_k_M range: [0.0000, 0.0468], d_k_M_hat range: [0.9860, 0.9976]
2025-03-11 21:13:47 - Train Iteration 11555: loss: 0.0026, d_k_M range: [0.0000, 0.0176], d_k_M_hat range: [0.9496, 0.9998]
2025-03-11 21:13:48 - Train Iteration 11556: loss: 0.0192, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.8615, 0.9992]
2025-03-11 21:13:48 - Train Iteration 11557: loss: 0.0013, d_k_M range: [0.0004, 0.0213], d_k_M_hat range: [0.9685, 0.9997]
2025-03-11 21:13:49 - Train Iteration 11558: loss: 0.0011, d_k_M range: [0.0001, 0.0275], d_k_M_hat range: [0.9676, 0.9998]
2025-03-11 21:13:49 - Train Iteration 11559: loss: 0.8847, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.0594, 0.9950]
2025-03-11 21:13:49 - Train Iteration 11560: loss: 0.8826, d_k_M range: [0.0001, 0.9391], d_k_M_hat range: [0.9620, 0.9997]
2025-03-11 21:13:50 - Train Iteration 11561: loss: 0.0029, d_k_M range: [0.0000, 0.0511], d_k_M_hat range: [0.9831, 0.9998]
2025-03-11 21:13:50 - Train Iteration 11562: loss: 0.0009, d_k_M range: [0.0000, 0.0086], d_k_M_hat range: [0.9700, 0.9995]
2025-03-11 21:13:51 - Train Iteration 11563: loss: 0.1941, d_k_M range: [0.0000, 0.0837], d_k_M_hat range: [0.5594, 0.9998]
2025-03-11 21:13:51 - Train Iteration 11564: loss: 0.0003, d_k_M range: [0.0000, 0.0111], d_k_M_hat range: [0.9838, 0.9998]
2025-03-11 21:13:52 - Train Iteration 11565: loss: 0.0039, d_k_M range: [0.0000, 0.0617], d_k_M_hat range: [0.9808, 0.9993]
2025-03-11 21:13:52 - Train Iteration 11566: loss: 0.0021, d_k_M range: [0.0001, 0.0459], d_k_M_hat range: [0.9867, 0.9996]
2025-03-11 21:13:52 - Train Iteration 11567: loss: 0.0578, d_k_M range: [0.0000, 0.2165], d_k_M_hat range: [0.9410, 0.9997]
2025-03-11 21:13:53 - Train Iteration 11568: loss: 0.0385, d_k_M range: [0.0000, 0.0108], d_k_M_hat range: [0.8052, 0.9995]
2025-03-11 21:13:53 - Train Iteration 11569: loss: 0.0006, d_k_M range: [0.0000, 0.0156], d_k_M_hat range: [0.9773, 0.9997]
2025-03-11 21:13:54 - Train Iteration 11570: loss: 0.0801, d_k_M range: [0.0000, 0.2828], d_k_M_hat range: [0.9844, 1.0000]
2025-03-11 21:13:54 - Train Iteration 11571: loss: 0.0016, d_k_M range: [0.0000, 0.0073], d_k_M_hat range: [0.9608, 0.9999]
2025-03-11 21:13:54 - Train Iteration 11572: loss: 0.0085, d_k_M range: [0.0000, 0.0169], d_k_M_hat range: [0.9077, 0.9998]
2025-03-11 21:13:55 - Train Iteration 11573: loss: 0.1663, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.5924, 0.9999]
2025-03-11 21:13:55 - Train Iteration 11574: loss: 0.0018, d_k_M range: [0.0000, 0.0283], d_k_M_hat range: [0.9596, 0.9996]
2025-03-11 21:13:56 - Train Iteration 11575: loss: 0.0329, d_k_M range: [0.0000, 0.0663], d_k_M_hat range: [0.8248, 0.9996]
2025-03-11 21:13:56 - Train Iteration 11576: loss: 0.0607, d_k_M range: [0.0000, 0.0098], d_k_M_hat range: [0.7537, 0.9998]
2025-03-11 21:13:57 - Train Iteration 11577: loss: 0.0018, d_k_M range: [0.0000, 0.0099], d_k_M_hat range: [0.9588, 0.9999]
2025-03-11 21:13:57 - Train Iteration 11578: loss: 0.0085, d_k_M range: [0.0000, 0.0828], d_k_M_hat range: [0.9269, 0.9998]
2025-03-11 21:13:57 - Train Iteration 11579: loss: 0.0362, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.8102, 0.9965]
2025-03-11 21:13:58 - Train Iteration 11580: loss: 0.0007, d_k_M range: [0.0001, 0.0229], d_k_M_hat range: [0.9860, 1.0000]
2025-03-11 21:13:58 - Train Iteration 11581: loss: 0.4235, d_k_M range: [0.0000, 0.6507], d_k_M_hat range: [0.9905, 0.9999]
2025-03-11 21:13:59 - Train Iteration 11582: loss: 0.0022, d_k_M range: [0.0000, 0.0109], d_k_M_hat range: [0.9540, 0.9998]
2025-03-11 21:13:59 - Train Iteration 11583: loss: 0.0752, d_k_M range: [0.0000, 0.0098], d_k_M_hat range: [0.7259, 0.9997]
2025-03-11 21:13:59 - Train Iteration 11584: loss: 0.2241, d_k_M range: [0.0000, 0.4721], d_k_M_hat range: [0.8778, 0.9989]
2025-03-11 21:14:00 - Train Iteration 11585: loss: 0.0041, d_k_M range: [0.0001, 0.0077], d_k_M_hat range: [0.9363, 0.9950]
2025-03-11 21:14:00 - Train Iteration 11586: loss: 0.0058, d_k_M range: [0.0000, 0.0065], d_k_M_hat range: [0.9235, 0.9989]
2025-03-11 21:14:01 - Train Iteration 11587: loss: 0.8238, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.0924, 0.9972]
2025-03-11 21:14:01 - Train Iteration 11588: loss: 0.0641, d_k_M range: [0.0000, 0.1392], d_k_M_hat range: [0.7547, 1.0000]
2025-03-11 21:14:02 - Train Iteration 11589: loss: 0.0434, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.7921, 0.9999]
2025-03-11 21:14:02 - Train Iteration 11590: loss: 0.0022, d_k_M range: [0.0009, 0.0438], d_k_M_hat range: [0.9872, 0.9999]
2025-03-11 21:14:02 - Train Iteration 11591: loss: 0.1927, d_k_M range: [0.0000, 0.0723], d_k_M_hat range: [0.5614, 1.0000]
2025-03-11 21:14:03 - Train Iteration 11592: loss: 0.0020, d_k_M range: [0.0001, 0.0338], d_k_M_hat range: [0.9551, 1.0000]
2025-03-11 21:14:03 - Train Iteration 11593: loss: 0.0015, d_k_M range: [0.0000, 0.0382], d_k_M_hat range: [0.9774, 0.9999]
2025-03-11 21:14:04 - Train Iteration 11594: loss: 0.2314, d_k_M range: [0.0003, 0.4800], d_k_M_hat range: [0.9850, 0.9998]
2025-03-11 21:14:04 - Train Iteration 11595: loss: 0.0735, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.7290, 0.9982]
2025-03-11 21:14:04 - Train Iteration 11596: loss: 0.1177, d_k_M range: [0.0000, 0.3428], d_k_M_hat range: [0.7630, 0.9999]
2025-03-11 21:14:05 - Train Iteration 11597: loss: 0.0179, d_k_M range: [0.0000, 0.0570], d_k_M_hat range: [0.8661, 0.9994]
2025-03-11 21:14:05 - Train Iteration 11598: loss: 0.0335, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.8170, 0.9992]
2025-03-11 21:14:06 - Train Iteration 11599: loss: 0.0008, d_k_M range: [0.0000, 0.0266], d_k_M_hat range: [0.9837, 0.9998]
2025-03-11 21:14:06 - Train Iteration 11600: loss: 0.0106, d_k_M range: [0.0000, 0.0178], d_k_M_hat range: [0.8971, 0.9990]
2025-03-11 21:14:06 - Train Iteration 11601: loss: 0.0019, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9566, 0.9999]
2025-03-11 21:14:07 - Train Iteration 11602: loss: 0.0854, d_k_M range: [0.0000, 0.2914], d_k_M_hat range: [0.9266, 0.9993]
2025-03-11 21:14:07 - Train Iteration 11603: loss: 0.0010, d_k_M range: [0.0000, 0.0111], d_k_M_hat range: [0.9702, 1.0000]
2025-03-11 21:14:08 - Train Iteration 11604: loss: 0.0063, d_k_M range: [0.0000, 0.0785], d_k_M_hat range: [0.9410, 0.9996]
2025-03-11 21:14:08 - Train Iteration 11605: loss: 0.0254, d_k_M range: [0.0000, 0.0739], d_k_M_hat range: [0.8408, 0.9990]
2025-03-11 21:14:08 - Train Iteration 11606: loss: 0.4861, d_k_M range: [0.0000, 0.6958], d_k_M_hat range: [0.9892, 0.9989]
2025-03-11 21:14:09 - Train Iteration 11607: loss: 0.0003, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9832, 0.9991]
2025-03-11 21:14:09 - Train Iteration 11608: loss: 0.0018, d_k_M range: [0.0003, 0.0318], d_k_M_hat range: [0.9897, 0.9997]
2025-03-11 21:14:10 - Train Iteration 11609: loss: 0.4683, d_k_M range: [0.0000, 0.6843], d_k_M_hat range: [0.9458, 0.9999]
2025-03-11 21:14:10 - Train Iteration 11610: loss: 0.8247, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.0919, 0.9794]
2025-03-11 21:14:11 - Train Iteration 11611: loss: 0.0510, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.7742, 0.9985]
2025-03-11 21:14:11 - Train Iteration 11612: loss: 0.0009, d_k_M range: [0.0001, 0.0077], d_k_M_hat range: [0.9698, 0.9998]
2025-03-11 21:14:11 - Train Iteration 11613: loss: 0.0072, d_k_M range: [0.0002, 0.0795], d_k_M_hat range: [0.9832, 0.9994]
2025-03-11 21:14:12 - Train Iteration 11614: loss: 0.1139, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.6624, 0.9966]
2025-03-11 21:14:12 - Train Iteration 11615: loss: 0.0007, d_k_M range: [0.0005, 0.0272], d_k_M_hat range: [0.9970, 1.0000]
2025-03-11 21:14:13 - Train Iteration 11616: loss: 0.0011, d_k_M range: [0.0000, 0.0304], d_k_M_hat range: [0.9733, 0.9997]
2025-03-11 21:14:13 - Train Iteration 11617: loss: 0.0305, d_k_M range: [0.0001, 0.1738], d_k_M_hat range: [0.9700, 0.9998]
2025-03-11 21:14:13 - Train Iteration 11618: loss: 0.5554, d_k_M range: [0.0000, 0.7445], d_k_M_hat range: [0.9314, 0.9993]
2025-03-11 21:14:14 - Train Iteration 11619: loss: 0.0042, d_k_M range: [0.0001, 0.0195], d_k_M_hat range: [0.9352, 0.9952]
2025-03-11 21:14:14 - Train Iteration 11620: loss: 0.0025, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.9504, 0.9978]
2025-03-11 21:14:15 - Train Iteration 11621: loss: 0.2267, d_k_M range: [0.0001, 0.4760], d_k_M_hat range: [0.9787, 0.9999]
2025-03-11 21:14:15 - Train Iteration 11622: loss: 0.0273, d_k_M range: [0.0000, 0.0296], d_k_M_hat range: [0.8347, 0.9999]
2025-03-11 21:14:16 - Train Iteration 11623: loss: 0.0018, d_k_M range: [0.0000, 0.0148], d_k_M_hat range: [0.9571, 0.9993]
2025-03-11 21:14:16 - Train Iteration 11624: loss: 0.0028, d_k_M range: [0.0000, 0.0095], d_k_M_hat range: [0.9476, 0.9981]
2025-03-11 21:14:16 - Train Iteration 11625: loss: 0.3528, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.4060, 0.9974]
2025-03-11 21:14:17 - Train Iteration 11626: loss: 0.0540, d_k_M range: [0.0000, 0.2318], d_k_M_hat range: [0.9635, 0.9998]
2025-03-11 21:14:17 - Train Iteration 11627: loss: 0.0041, d_k_M range: [0.0000, 0.0303], d_k_M_hat range: [0.9359, 0.9995]
2025-03-11 21:14:18 - Train Iteration 11628: loss: 0.0007, d_k_M range: [0.0000, 0.0265], d_k_M_hat range: [0.9895, 0.9995]
2025-03-11 21:14:18 - Train Iteration 11629: loss: 0.0089, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9057, 0.9956]
2025-03-11 21:14:18 - Train Iteration 11630: loss: 0.1196, d_k_M range: [0.0000, 0.0480], d_k_M_hat range: [0.6543, 0.9996]
2025-03-11 21:14:19 - Train Iteration 11631: loss: 0.1316, d_k_M range: [0.0000, 0.0432], d_k_M_hat range: [0.6372, 0.9999]
2025-03-11 21:14:19 - Train Iteration 11632: loss: 0.5125, d_k_M range: [0.0013, 0.7150], d_k_M_hat range: [0.9954, 0.9998]
2025-03-11 21:14:20 - Train Iteration 11633: loss: 0.0102, d_k_M range: [0.0000, 0.0092], d_k_M_hat range: [0.9000, 0.9969]
2025-03-11 21:14:20 - Train Iteration 11634: loss: 0.0015, d_k_M range: [0.0001, 0.0351], d_k_M_hat range: [0.9612, 0.9984]
2025-03-11 21:14:20 - Train Iteration 11635: loss: 0.0592, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.7567, 0.9961]
2025-03-11 21:14:21 - Train Iteration 11636: loss: 0.7976, d_k_M range: [0.0001, 0.8929], d_k_M_hat range: [0.9968, 0.9998]
2025-03-11 21:14:21 - Train Iteration 11637: loss: 0.0160, d_k_M range: [0.0000, 0.0066], d_k_M_hat range: [0.8737, 0.9975]
2025-03-11 21:14:22 - Train Iteration 11638: loss: 0.0389, d_k_M range: [0.0009, 0.1962], d_k_M_hat range: [0.9940, 1.0000]
2025-03-11 21:14:22 - Train Iteration 11639: loss: 0.0034, d_k_M range: [0.0000, 0.0151], d_k_M_hat range: [0.9420, 0.9999]
2025-03-11 21:14:23 - Train Iteration 11640: loss: 0.0093, d_k_M range: [0.0000, 0.0237], d_k_M_hat range: [0.9037, 0.9979]
2025-03-11 21:14:23 - Train Iteration 11641: loss: 0.1468, d_k_M range: [0.0000, 0.0172], d_k_M_hat range: [0.6172, 0.9989]
2025-03-11 21:14:23 - Train Iteration 11642: loss: 0.0005, d_k_M range: [0.0001, 0.0095], d_k_M_hat range: [0.9809, 0.9996]
2025-03-11 21:14:24 - Train Iteration 11643: loss: 0.0387, d_k_M range: [0.0001, 0.0057], d_k_M_hat range: [0.8034, 0.9987]
2025-03-11 21:14:24 - Train Iteration 11644: loss: 0.0510, d_k_M range: [0.0000, 0.0157], d_k_M_hat range: [0.7743, 0.9994]
2025-03-11 21:14:25 - Train Iteration 11645: loss: 0.0017, d_k_M range: [0.0000, 0.0374], d_k_M_hat range: [0.9590, 0.9994]
2025-03-11 21:14:25 - Train Iteration 11646: loss: 0.0083, d_k_M range: [0.0000, 0.0718], d_k_M_hat range: [0.9626, 0.9873]
2025-03-11 21:14:25 - Train Iteration 11647: loss: 0.0132, d_k_M range: [0.0002, 0.1141], d_k_M_hat range: [0.9842, 0.9999]
2025-03-11 21:14:26 - Train Iteration 11648: loss: 0.0331, d_k_M range: [0.0000, 0.0269], d_k_M_hat range: [0.8230, 0.9994]
2025-03-11 21:14:26 - Train Iteration 11649: loss: 0.0153, d_k_M range: [0.0001, 0.0053], d_k_M_hat range: [0.8763, 0.9998]
2025-03-11 21:14:27 - Train Iteration 11650: loss: 0.0316, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.8228, 0.9969]
2025-03-11 21:14:27 - Train Iteration 11651: loss: 0.3019, d_k_M range: [0.0001, 0.5487], d_k_M_hat range: [0.9751, 0.9999]
2025-03-11 21:14:28 - Train Iteration 11652: loss: 0.0192, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.8613, 0.9996]
2025-03-11 21:14:28 - Train Iteration 11653: loss: 0.9298, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.0358, 0.9990]
2025-03-11 21:14:28 - Train Iteration 11654: loss: 0.0059, d_k_M range: [0.0000, 0.0168], d_k_M_hat range: [0.9230, 0.9985]
2025-03-11 21:14:29 - Train Iteration 11655: loss: 0.1110, d_k_M range: [0.0000, 0.3325], d_k_M_hat range: [0.9718, 0.9998]
2025-03-11 21:14:29 - Train Iteration 11656: loss: 0.0429, d_k_M range: [0.0000, 0.0264], d_k_M_hat range: [0.7939, 0.9989]
2025-03-11 21:14:30 - Train Iteration 11657: loss: 0.0056, d_k_M range: [0.0000, 0.0731], d_k_M_hat range: [0.9680, 0.9991]
2025-03-11 21:14:30 - Train Iteration 11658: loss: 0.0042, d_k_M range: [0.0001, 0.0625], d_k_M_hat range: [0.9952, 0.9991]
2025-03-11 21:14:31 - Train Iteration 11659: loss: 0.0569, d_k_M range: [0.0002, 0.0275], d_k_M_hat range: [0.7616, 0.9997]
2025-03-11 21:14:31 - Train Iteration 11660: loss: 0.0048, d_k_M range: [0.0000, 0.0666], d_k_M_hat range: [0.9320, 0.9991]
2025-03-11 21:14:31 - Train Iteration 11661: loss: 0.0007, d_k_M range: [0.0000, 0.0257], d_k_M_hat range: [0.9866, 0.9998]
2025-03-11 21:14:32 - Train Iteration 11662: loss: 0.0009, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.9694, 0.9998]
2025-03-11 21:14:32 - Train Iteration 11663: loss: 0.0018, d_k_M range: [0.0000, 0.0421], d_k_M_hat range: [0.9591, 0.9996]
2025-03-11 21:14:33 - Train Iteration 11664: loss: 0.0034, d_k_M range: [0.0000, 0.0253], d_k_M_hat range: [0.9416, 0.9997]
2025-03-11 21:14:33 - Train Iteration 11665: loss: 0.0690, d_k_M range: [0.0004, 0.0641], d_k_M_hat range: [0.7916, 0.9987]
2025-03-11 21:14:34 - Train Iteration 11666: loss: 0.0011, d_k_M range: [0.0001, 0.0142], d_k_M_hat range: [0.9700, 0.9995]
2025-03-11 21:14:34 - Train Iteration 11667: loss: 0.0306, d_k_M range: [0.0000, 0.1435], d_k_M_hat range: [0.9685, 0.9986]
2025-03-11 21:14:34 - Train Iteration 11668: loss: 0.0083, d_k_M range: [0.0000, 0.0150], d_k_M_hat range: [0.9091, 0.9999]
2025-03-11 21:14:35 - Train Iteration 11669: loss: 0.0099, d_k_M range: [0.0000, 0.0151], d_k_M_hat range: [0.9030, 0.9995]
2025-03-11 21:14:35 - Train Iteration 11670: loss: 0.0057, d_k_M range: [0.0002, 0.0046], d_k_M_hat range: [0.9254, 0.9995]
2025-03-11 21:14:36 - Train Iteration 11671: loss: 0.0280, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.8328, 0.9988]
2025-03-11 21:14:36 - Train Iteration 11672: loss: 0.0473, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.7826, 0.9990]
2025-03-11 21:14:37 - Train Iteration 11673: loss: 0.0299, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.8282, 0.9998]
2025-03-11 21:14:37 - Train Iteration 11674: loss: 0.0943, d_k_M range: [0.0000, 0.0072], d_k_M_hat range: [0.6929, 0.9995]
2025-03-11 21:14:37 - Train Iteration 11675: loss: 0.0263, d_k_M range: [0.0000, 0.1593], d_k_M_hat range: [0.9481, 0.9999]
2025-03-11 21:14:38 - Train Iteration 11676: loss: 0.0042, d_k_M range: [0.0001, 0.0598], d_k_M_hat range: [0.9666, 0.9981]
2025-03-11 21:14:38 - Train Iteration 11677: loss: 0.0021, d_k_M range: [0.0000, 0.0413], d_k_M_hat range: [0.9957, 0.9995]
2025-03-11 21:14:39 - Train Iteration 11678: loss: 0.1011, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.6820, 0.9972]
2025-03-11 21:14:39 - Train Iteration 11679: loss: 0.0027, d_k_M range: [0.0001, 0.0302], d_k_M_hat range: [0.9484, 1.0000]
2025-03-11 21:14:39 - Train Iteration 11680: loss: 0.0017, d_k_M range: [0.0002, 0.0235], d_k_M_hat range: [0.9600, 0.9991]
2025-03-11 21:14:40 - Train Iteration 11681: loss: 0.0056, d_k_M range: [0.0000, 0.0537], d_k_M_hat range: [0.9253, 0.9998]
2025-03-11 21:14:40 - Train Iteration 11682: loss: 0.0770, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.7225, 0.9980]
2025-03-11 21:14:41 - Train Iteration 11683: loss: 0.1323, d_k_M range: [0.0000, 0.3637], d_k_M_hat range: [0.9869, 1.0000]
2025-03-11 21:14:41 - Train Iteration 11684: loss: 0.0236, d_k_M range: [0.0000, 0.0283], d_k_M_hat range: [0.8592, 0.9996]
2025-03-11 21:14:41 - Train Iteration 11685: loss: 0.3202, d_k_M range: [0.0000, 0.0314], d_k_M_hat range: [0.4656, 0.9981]
2025-03-11 21:14:42 - Train Iteration 11686: loss: 0.0007, d_k_M range: [0.0000, 0.0135], d_k_M_hat range: [0.9751, 0.9994]
2025-03-11 21:14:42 - Train Iteration 11687: loss: 0.0085, d_k_M range: [0.0003, 0.0873], d_k_M_hat range: [0.9663, 0.9999]
2025-03-11 21:14:43 - Train Iteration 11688: loss: 0.3428, d_k_M range: [0.0001, 0.5847], d_k_M_hat range: [0.9871, 0.9992]
2025-03-11 21:14:43 - Train Iteration 11689: loss: 0.0078, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.9124, 0.9991]
2025-03-11 21:14:43 - Train Iteration 11690: loss: 0.0038, d_k_M range: [0.0001, 0.0583], d_k_M_hat range: [0.9677, 0.9990]
2025-03-11 21:14:44 - Train Iteration 11691: loss: 0.0036, d_k_M range: [0.0000, 0.0212], d_k_M_hat range: [0.9402, 0.9978]
2025-03-11 21:14:44 - Train Iteration 11692: loss: 0.0018, d_k_M range: [0.0001, 0.0039], d_k_M_hat range: [0.9590, 0.9980]
2025-03-11 21:14:45 - Train Iteration 11693: loss: 0.0567, d_k_M range: [0.0000, 0.0069], d_k_M_hat range: [0.7624, 0.9993]
2025-03-11 21:14:45 - Train Iteration 11694: loss: 0.0022, d_k_M range: [0.0007, 0.0330], d_k_M_hat range: [0.9538, 1.0000]
2025-03-11 21:14:46 - Train Iteration 11695: loss: 0.0035, d_k_M range: [0.0000, 0.0130], d_k_M_hat range: [0.9434, 0.9997]
2025-03-11 21:14:46 - Train Iteration 11696: loss: 0.0023, d_k_M range: [0.0001, 0.0025], d_k_M_hat range: [0.9546, 0.9996]
2025-03-11 21:14:47 - Train Iteration 11697: loss: 0.3588, d_k_M range: [0.0000, 0.0113], d_k_M_hat range: [0.4010, 0.9995]
2025-03-11 21:14:47 - Train Iteration 11698: loss: 0.0001, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9948, 0.9999]
2025-03-11 21:14:47 - Train Iteration 11699: loss: 0.1100, d_k_M range: [0.0001, 0.0088], d_k_M_hat range: [0.6698, 0.9999]
2025-03-11 21:14:48 - Train Iteration 11700: loss: 0.0730, d_k_M range: [0.0000, 0.2614], d_k_M_hat range: [0.9085, 0.9994]
2025-03-11 21:14:48 - Train Iteration 11701: loss: 0.0110, d_k_M range: [0.0000, 0.1015], d_k_M_hat range: [0.9435, 0.9991]
2025-03-11 21:14:49 - Train Iteration 11702: loss: 0.0550, d_k_M range: [0.0000, 0.2329], d_k_M_hat range: [0.9795, 0.9986]
2025-03-11 21:14:49 - Train Iteration 11703: loss: 0.1471, d_k_M range: [0.0001, 0.3833], d_k_M_hat range: [0.9704, 0.9998]
2025-03-11 21:14:50 - Train Iteration 11704: loss: 0.0219, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.8523, 0.9992]
2025-03-11 21:14:50 - Train Iteration 11705: loss: 0.0777, d_k_M range: [0.0000, 0.0072], d_k_M_hat range: [0.7257, 0.9995]
2025-03-11 21:14:50 - Train Iteration 11706: loss: 0.0024, d_k_M range: [0.0001, 0.0023], d_k_M_hat range: [0.9525, 0.9978]
2025-03-11 21:14:51 - Train Iteration 11707: loss: 0.0018, d_k_M range: [0.0001, 0.0418], d_k_M_hat range: [0.9792, 0.9990]
2025-03-11 21:14:51 - Train Iteration 11708: loss: 0.0002, d_k_M range: [0.0000, 0.0098], d_k_M_hat range: [0.9866, 0.9994]
2025-03-11 21:14:52 - Train Iteration 11709: loss: 0.0695, d_k_M range: [0.0000, 0.2636], d_k_M_hat range: [0.9766, 1.0000]
2025-03-11 21:14:52 - Train Iteration 11710: loss: 0.0498, d_k_M range: [0.0000, 0.0243], d_k_M_hat range: [0.7770, 0.9978]
2025-03-11 21:14:53 - Train Iteration 11711: loss: 0.0173, d_k_M range: [0.0002, 0.1313], d_k_M_hat range: [0.8726, 1.0000]
2025-03-11 21:14:53 - Train Iteration 11712: loss: 0.0057, d_k_M range: [0.0000, 0.0090], d_k_M_hat range: [0.9243, 0.9999]
2025-03-11 21:14:53 - Train Iteration 11713: loss: 0.0007, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.9757, 0.9996]
2025-03-11 21:14:54 - Train Iteration 11714: loss: 0.0162, d_k_M range: [0.0000, 0.0973], d_k_M_hat range: [0.8726, 0.9984]
2025-03-11 21:14:54 - Train Iteration 11715: loss: 0.0017, d_k_M range: [0.0000, 0.0292], d_k_M_hat range: [0.9831, 0.9990]
2025-03-11 21:14:55 - Train Iteration 11716: loss: 0.0595, d_k_M range: [0.0000, 0.1554], d_k_M_hat range: [0.7560, 0.9995]
2025-03-11 21:14:55 - Train Iteration 11717: loss: 0.0034, d_k_M range: [0.0000, 0.0575], d_k_M_hat range: [0.9921, 0.9997]
2025-03-11 21:14:55 - Train Iteration 11718: loss: 0.0125, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.8887, 0.9993]
2025-03-11 21:14:56 - Train Iteration 11719: loss: 0.0534, d_k_M range: [0.0002, 0.2304], d_k_M_hat range: [0.9847, 0.9993]
2025-03-11 21:14:56 - Train Iteration 11720: loss: 0.0199, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.8590, 0.9953]
2025-03-11 21:14:57 - Train Iteration 11721: loss: 0.0012, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9667, 0.9996]
2025-03-11 21:14:57 - Train Iteration 11722: loss: 0.0058, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9254, 0.9981]
2025-03-11 21:14:58 - Train Iteration 11723: loss: 0.0012, d_k_M range: [0.0000, 0.0124], d_k_M_hat range: [0.9661, 0.9961]
2025-03-11 21:14:58 - Train Iteration 11724: loss: 0.1168, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.6582, 0.9985]
2025-03-11 21:14:58 - Train Iteration 11725: loss: 0.0009, d_k_M range: [0.0000, 0.0084], d_k_M_hat range: [0.9703, 0.9997]
2025-03-11 21:14:59 - Train Iteration 11726: loss: 0.5446, d_k_M range: [0.0000, 0.0167], d_k_M_hat range: [0.2621, 0.9987]
2025-03-11 21:14:59 - Train Iteration 11727: loss: 0.0050, d_k_M range: [0.0000, 0.0680], d_k_M_hat range: [0.9603, 1.0000]
2025-03-11 21:15:00 - Train Iteration 11728: loss: 0.1874, d_k_M range: [0.0012, 0.4328], d_k_M_hat range: [0.9732, 0.9999]
2025-03-11 21:15:00 - Train Iteration 11729: loss: 0.0092, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9041, 0.9944]
2025-03-11 21:15:01 - Train Iteration 11730: loss: 0.7839, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.1147, 0.9998]
2025-03-11 21:15:01 - Train Iteration 11731: loss: 0.0338, d_k_M range: [0.0000, 0.0152], d_k_M_hat range: [0.8163, 0.9988]
2025-03-11 21:15:01 - Train Iteration 11732: loss: 0.0031, d_k_M range: [0.0000, 0.0505], d_k_M_hat range: [0.9446, 0.9998]
2025-03-11 21:15:02 - Train Iteration 11733: loss: 0.0033, d_k_M range: [0.0000, 0.0251], d_k_M_hat range: [0.9432, 0.9999]
2025-03-11 21:15:02 - Train Iteration 11734: loss: 0.0436, d_k_M range: [0.0000, 0.2085], d_k_M_hat range: [0.9623, 0.9996]
2025-03-11 21:15:03 - Train Iteration 11735: loss: 0.0704, d_k_M range: [0.0005, 0.1472], d_k_M_hat range: [0.7352, 0.9997]
2025-03-11 21:15:03 - Train Iteration 11736: loss: 0.2223, d_k_M range: [0.0001, 0.4715], d_k_M_hat range: [0.9922, 1.0000]
2025-03-11 21:15:03 - Train Iteration 11737: loss: 0.2487, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.5015, 0.9943]
2025-03-11 21:15:04 - Train Iteration 11738: loss: 0.0035, d_k_M range: [0.0001, 0.0590], d_k_M_hat range: [0.9955, 0.9998]
2025-03-11 21:15:04 - Train Iteration 11739: loss: 0.0007, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9743, 0.9995]
2025-03-11 21:15:05 - Train Iteration 11740: loss: 0.0427, d_k_M range: [0.0001, 0.0463], d_k_M_hat range: [0.7935, 0.9990]
2025-03-11 21:15:05 - Train Iteration 11741: loss: 0.7060, d_k_M range: [0.0131, 0.8391], d_k_M_hat range: [0.9975, 1.0000]
2025-03-11 21:15:05 - Train Iteration 11742: loss: 0.0585, d_k_M range: [0.0000, 0.2381], d_k_M_hat range: [0.9768, 0.9991]
2025-03-11 21:15:06 - Train Iteration 11743: loss: 0.0017, d_k_M range: [0.0002, 0.0124], d_k_M_hat range: [0.9598, 0.9995]
2025-03-11 21:15:06 - Train Iteration 11744: loss: 0.0056, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9253, 0.9998]
2025-03-11 21:15:07 - Train Iteration 11745: loss: 0.3040, d_k_M range: [0.0000, 0.5514], d_k_M_hat range: [0.8515, 1.0000]
2025-03-11 21:15:07 - Train Iteration 11746: loss: 0.0400, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.8002, 0.9991]
2025-03-11 21:15:08 - Train Iteration 11747: loss: 0.0253, d_k_M range: [0.0000, 0.1588], d_k_M_hat range: [0.9843, 0.9999]
2025-03-11 21:15:08 - Train Iteration 11748: loss: 0.0281, d_k_M range: [0.0000, 0.0129], d_k_M_hat range: [0.8325, 0.9981]
2025-03-11 21:15:08 - Train Iteration 11749: loss: 0.1226, d_k_M range: [0.0000, 0.1090], d_k_M_hat range: [0.6499, 0.9985]
2025-03-11 21:15:09 - Train Iteration 11750: loss: 0.0154, d_k_M range: [0.0004, 0.1234], d_k_M_hat range: [0.9955, 0.9999]
2025-03-11 21:15:09 - Train Iteration 11751: loss: 0.0411, d_k_M range: [0.0000, 0.2028], d_k_M_hat range: [0.9067, 0.9999]
2025-03-11 21:15:10 - Train Iteration 11752: loss: 0.2208, d_k_M range: [0.0000, 0.4553], d_k_M_hat range: [0.9290, 0.9975]
2025-03-11 21:15:10 - Train Iteration 11753: loss: 0.0414, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.7966, 0.9974]
2025-03-11 21:15:10 - Train Iteration 11754: loss: 0.5939, d_k_M range: [0.0000, 0.7679], d_k_M_hat range: [0.9569, 0.9999]
2025-03-11 21:15:11 - Train Iteration 11755: loss: 0.0156, d_k_M range: [0.0000, 0.0215], d_k_M_hat range: [0.8749, 0.9995]
2025-03-11 21:15:11 - Train Iteration 11756: loss: 0.0269, d_k_M range: [0.0000, 0.1638], d_k_M_hat range: [0.9563, 0.9999]
2025-03-11 21:15:12 - Train Iteration 11757: loss: 0.0180, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.8657, 0.9989]
2025-03-11 21:15:12 - Train Iteration 11758: loss: 0.0228, d_k_M range: [0.0000, 0.0219], d_k_M_hat range: [0.8508, 0.9998]
2025-03-11 21:15:12 - Train Iteration 11759: loss: 0.0020, d_k_M range: [0.0000, 0.0356], d_k_M_hat range: [0.9671, 0.9997]
2025-03-11 21:15:13 - Train Iteration 11760: loss: 0.0077, d_k_M range: [0.0000, 0.0143], d_k_M_hat range: [0.9121, 0.9992]
2025-03-11 21:15:13 - Train Iteration 11761: loss: 0.0026, d_k_M range: [0.0000, 0.0472], d_k_M_hat range: [0.9651, 0.9982]
2025-03-11 21:15:14 - Train Iteration 11762: loss: 0.0643, d_k_M range: [0.0000, 0.0742], d_k_M_hat range: [0.7465, 0.9983]
2025-03-11 21:15:14 - Train Iteration 11763: loss: 0.0055, d_k_M range: [0.0001, 0.0032], d_k_M_hat range: [0.9258, 0.9998]
2025-03-11 21:15:15 - Train Iteration 11764: loss: 0.4916, d_k_M range: [0.0001, 0.7010], d_k_M_hat range: [0.9363, 0.9998]
2025-03-11 21:15:15 - Train Iteration 11765: loss: 0.8018, d_k_M range: [0.0000, 0.0087], d_k_M_hat range: [0.1046, 0.9908]
2025-03-11 21:15:15 - Train Iteration 11766: loss: 0.0424, d_k_M range: [0.0000, 0.0136], d_k_M_hat range: [0.7946, 0.9995]
2025-03-11 21:15:16 - Train Iteration 11767: loss: 0.0233, d_k_M range: [0.0000, 0.1515], d_k_M_hat range: [0.9348, 0.9999]
2025-03-11 21:15:16 - Train Iteration 11768: loss: 0.0003, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.9817, 0.9995]
2025-03-11 21:15:17 - Train Iteration 11769: loss: 0.0078, d_k_M range: [0.0000, 0.0798], d_k_M_hat range: [0.9774, 0.9981]
2025-03-11 21:15:17 - Train Iteration 11770: loss: 0.0036, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.9404, 0.9958]
2025-03-11 21:15:17 - Train Iteration 11771: loss: 0.0116, d_k_M range: [0.0001, 0.0112], d_k_M_hat range: [0.8938, 0.9994]
2025-03-11 21:15:18 - Train Iteration 11772: loss: 0.5762, d_k_M range: [0.0001, 0.7587], d_k_M_hat range: [0.9755, 0.9999]
2025-03-11 21:15:18 - Train Iteration 11773: loss: 0.0235, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.8470, 0.9968]
2025-03-11 21:15:19 - Train Iteration 11774: loss: 0.1503, d_k_M range: [0.0000, 0.3876], d_k_M_hat range: [0.9721, 0.9999]
2025-03-11 21:15:19 - Train Iteration 11775: loss: 0.0929, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.6953, 0.9993]
2025-03-11 21:15:20 - Train Iteration 11776: loss: 0.0265, d_k_M range: [0.0001, 0.0067], d_k_M_hat range: [0.8427, 0.9997]
2025-03-11 21:15:20 - Train Iteration 11777: loss: 0.0021, d_k_M range: [0.0000, 0.0450], d_k_M_hat range: [0.9739, 0.9991]
2025-03-11 21:15:20 - Train Iteration 11778: loss: 0.0728, d_k_M range: [0.0000, 0.2696], d_k_M_hat range: [0.9629, 0.9997]
2025-03-11 21:15:21 - Train Iteration 11779: loss: 0.0025, d_k_M range: [0.0000, 0.0415], d_k_M_hat range: [0.9900, 0.9994]
2025-03-11 21:15:21 - Train Iteration 11780: loss: 0.2895, d_k_M range: [0.0002, 0.5379], d_k_M_hat range: [0.6568, 0.9999]
2025-03-11 21:15:22 - Train Iteration 11781: loss: 0.3057, d_k_M range: [0.0000, 0.0458], d_k_M_hat range: [0.4929, 0.9937]
2025-03-11 21:15:22 - Train Iteration 11782: loss: 0.1335, d_k_M range: [0.0000, 0.3646], d_k_M_hat range: [0.9766, 0.9994]
2025-03-11 21:15:22 - Train Iteration 11783: loss: 0.2307, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.5197, 0.9977]
2025-03-11 21:15:23 - Train Iteration 11784: loss: 0.3346, d_k_M range: [0.0002, 0.5784], d_k_M_hat range: [0.9989, 0.9999]
2025-03-11 21:15:23 - Train Iteration 11785: loss: 0.0048, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.9312, 0.9994]
2025-03-11 21:15:24 - Train Iteration 11786: loss: 0.0023, d_k_M range: [0.0000, 0.0473], d_k_M_hat range: [0.9797, 0.9999]
2025-03-11 21:15:24 - Train Iteration 11787: loss: 0.0010, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9690, 0.9998]
2025-03-11 21:15:25 - Train Iteration 11788: loss: 0.0040, d_k_M range: [0.0000, 0.0523], d_k_M_hat range: [0.9828, 0.9996]
2025-03-11 21:15:25 - Train Iteration 11789: loss: 0.0862, d_k_M range: [0.0023, 0.2920], d_k_M_hat range: [0.9738, 0.9999]
2025-03-11 21:15:25 - Train Iteration 11790: loss: 0.0123, d_k_M range: [0.0000, 0.1070], d_k_M_hat range: [0.9494, 0.9998]
2025-03-11 21:15:26 - Train Iteration 11791: loss: 0.0022, d_k_M range: [0.0000, 0.0463], d_k_M_hat range: [0.9749, 0.9999]
2025-03-11 21:15:26 - Train Iteration 11792: loss: 0.0651, d_k_M range: [0.0000, 0.2535], d_k_M_hat range: [0.9429, 0.9994]
2025-03-11 21:15:27 - Train Iteration 11793: loss: 0.0108, d_k_M range: [0.0001, 0.0538], d_k_M_hat range: [0.9499, 0.9996]
2025-03-11 21:15:27 - Train Iteration 11794: loss: 0.7443, d_k_M range: [0.0000, 0.8627], d_k_M_hat range: [0.9650, 1.0000]
2025-03-11 21:15:27 - Train Iteration 11795: loss: 0.0104, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.8983, 0.9999]
2025-03-11 21:15:28 - Train Iteration 11796: loss: 0.8429, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.0819, 0.9975]
2025-03-11 21:15:28 - Train Iteration 11797: loss: 0.0005, d_k_M range: [0.0000, 0.0204], d_k_M_hat range: [0.9850, 0.9996]
2025-03-11 21:15:29 - Train Iteration 11798: loss: 0.0016, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9614, 0.9996]
2025-03-11 21:15:29 - Train Iteration 11799: loss: 0.0626, d_k_M range: [0.0000, 0.0632], d_k_M_hat range: [0.7500, 0.9892]
2025-03-11 21:15:29 - Train Iteration 11800: loss: 0.0009, d_k_M range: [0.0000, 0.0298], d_k_M_hat range: [0.9863, 0.9998]
2025-03-11 21:15:30 - Train Iteration 11801: loss: 0.0405, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.7988, 0.9930]
2025-03-11 21:15:30 - Train Iteration 11802: loss: 0.0243, d_k_M range: [0.0000, 0.1552], d_k_M_hat range: [0.9784, 0.9993]
2025-03-11 21:15:31 - Train Iteration 11803: loss: 0.0089, d_k_M range: [0.0002, 0.0878], d_k_M_hat range: [0.9250, 0.9995]
2025-03-11 21:15:31 - Train Iteration 11804: loss: 0.0221, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.8514, 0.9986]
2025-03-11 21:15:31 - Train Iteration 11805: loss: 0.0007, d_k_M range: [0.0001, 0.0046], d_k_M_hat range: [0.9744, 0.9990]
2025-03-11 21:15:32 - Train Iteration 11806: loss: 0.0061, d_k_M range: [0.0000, 0.0262], d_k_M_hat range: [0.9216, 0.9992]
2025-03-11 21:15:32 - Train Iteration 11807: loss: 0.1075, d_k_M range: [0.0000, 0.0209], d_k_M_hat range: [0.6722, 0.9992]
2025-03-11 21:15:33 - Train Iteration 11808: loss: 0.0014, d_k_M range: [0.0000, 0.0378], d_k_M_hat range: [0.9715, 0.9999]
2025-03-11 21:15:33 - Train Iteration 11809: loss: 0.0138, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.8825, 0.9998]
2025-03-11 21:15:34 - Train Iteration 11810: loss: 0.7408, d_k_M range: [0.0000, 0.8581], d_k_M_hat range: [0.9918, 0.9993]
2025-03-11 21:15:34 - Train Iteration 11811: loss: 0.0027, d_k_M range: [0.0000, 0.0351], d_k_M_hat range: [0.9482, 0.9994]
2025-03-11 21:15:34 - Train Iteration 11812: loss: 0.0010, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.9691, 0.9979]
2025-03-11 21:15:35 - Train Iteration 11813: loss: 0.1649, d_k_M range: [0.0000, 0.1196], d_k_M_hat range: [0.5988, 0.9998]
2025-03-11 21:15:35 - Train Iteration 11814: loss: 0.0021, d_k_M range: [0.0000, 0.0442], d_k_M_hat range: [0.9934, 1.0000]
2025-03-11 21:15:36 - Train Iteration 11815: loss: 0.0209, d_k_M range: [0.0000, 0.1433], d_k_M_hat range: [0.9802, 0.9991]
2025-03-11 21:15:36 - Train Iteration 11816: loss: 0.0669, d_k_M range: [0.0002, 0.2581], d_k_M_hat range: [0.9928, 0.9999]
2025-03-11 21:15:36 - Train Iteration 11817: loss: 0.0060, d_k_M range: [0.0003, 0.0736], d_k_M_hat range: [0.9376, 0.9984]
2025-03-11 21:15:37 - Train Iteration 11818: loss: 0.0333, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.8174, 0.9976]
2025-03-11 21:15:37 - Train Iteration 11819: loss: 0.0005, d_k_M range: [0.0002, 0.0147], d_k_M_hat range: [0.9775, 0.9987]
2025-03-11 21:15:38 - Train Iteration 11820: loss: 0.1933, d_k_M range: [0.0003, 0.4383], d_k_M_hat range: [0.9957, 0.9999]
2025-03-11 21:15:38 - Train Iteration 11821: loss: 0.0131, d_k_M range: [0.0000, 0.1143], d_k_M_hat range: [0.9815, 0.9999]
2025-03-11 21:15:38 - Train Iteration 11822: loss: 0.0010, d_k_M range: [0.0000, 0.0298], d_k_M_hat range: [0.9874, 0.9993]
2025-03-11 21:15:39 - Train Iteration 11823: loss: 0.0038, d_k_M range: [0.0000, 0.0290], d_k_M_hat range: [0.9677, 0.9986]
2025-03-11 21:15:39 - Train Iteration 11824: loss: 0.0032, d_k_M range: [0.0001, 0.0515], d_k_M_hat range: [0.9930, 0.9993]
2025-03-11 21:15:40 - Train Iteration 11825: loss: 0.2390, d_k_M range: [0.0000, 0.1006], d_k_M_hat range: [0.5116, 0.9999]
2025-03-11 21:15:40 - Train Iteration 11826: loss: 0.1368, d_k_M range: [0.0001, 0.3693], d_k_M_hat range: [0.9933, 0.9999]
2025-03-11 21:15:41 - Train Iteration 11827: loss: 0.0038, d_k_M range: [0.0000, 0.0117], d_k_M_hat range: [0.9386, 0.9987]
2025-03-11 21:15:41 - Train Iteration 11828: loss: 0.0005, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.9776, 0.9988]
2025-03-11 21:15:41 - Train Iteration 11829: loss: 0.0048, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.9306, 0.9976]
2025-03-11 21:15:42 - Train Iteration 11830: loss: 0.0225, d_k_M range: [0.0000, 0.0130], d_k_M_hat range: [0.8629, 0.9977]
2025-03-11 21:15:42 - Train Iteration 11831: loss: 0.0701, d_k_M range: [0.0002, 0.0144], d_k_M_hat range: [0.7354, 0.9972]
2025-03-11 21:15:43 - Train Iteration 11832: loss: 0.0001, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9904, 0.9996]
2025-03-11 21:15:43 - Train Iteration 11833: loss: 0.0037, d_k_M range: [0.0000, 0.0213], d_k_M_hat range: [0.9607, 0.9998]
2025-03-11 21:15:44 - Train Iteration 11834: loss: 0.0041, d_k_M range: [0.0000, 0.0125], d_k_M_hat range: [0.9360, 0.9998]
2025-03-11 21:15:44 - Train Iteration 11835: loss: 0.0042, d_k_M range: [0.0000, 0.0207], d_k_M_hat range: [0.9353, 0.9999]
2025-03-11 21:15:44 - Train Iteration 11836: loss: 0.0256, d_k_M range: [0.0000, 0.0325], d_k_M_hat range: [0.8404, 0.9983]
2025-03-11 21:15:45 - Train Iteration 11837: loss: 0.0077, d_k_M range: [0.0000, 0.0090], d_k_M_hat range: [0.9211, 0.9976]
2025-03-11 21:15:45 - Train Iteration 11838: loss: 0.3971, d_k_M range: [0.0000, 0.6299], d_k_M_hat range: [0.8744, 0.9997]
2025-03-11 21:15:46 - Train Iteration 11839: loss: 0.0084, d_k_M range: [0.0000, 0.0092], d_k_M_hat range: [0.9087, 0.9977]
2025-03-11 21:15:46 - Train Iteration 11840: loss: 0.0021, d_k_M range: [0.0000, 0.0324], d_k_M_hat range: [0.9738, 0.9995]
2025-03-11 21:15:46 - Train Iteration 11841: loss: 0.1875, d_k_M range: [0.0001, 0.4325], d_k_M_hat range: [0.9965, 0.9997]
2025-03-11 21:15:47 - Train Iteration 11842: loss: 0.0524, d_k_M range: [0.0000, 0.0450], d_k_M_hat range: [0.7722, 0.9991]
2025-03-11 21:15:47 - Train Iteration 11843: loss: 0.0187, d_k_M range: [0.0000, 0.1353], d_k_M_hat range: [0.9960, 0.9998]
2025-03-11 21:15:48 - Train Iteration 11844: loss: 0.0030, d_k_M range: [0.0001, 0.0534], d_k_M_hat range: [0.9899, 0.9999]
2025-03-11 21:15:48 - Train Iteration 11845: loss: 0.0056, d_k_M range: [0.0000, 0.0301], d_k_M_hat range: [0.9255, 0.9967]
2025-03-11 21:15:48 - Train Iteration 11846: loss: 0.0344, d_k_M range: [0.0000, 0.1739], d_k_M_hat range: [0.9585, 0.9966]
2025-03-11 21:15:49 - Train Iteration 11847: loss: 0.0107, d_k_M range: [0.0000, 0.0498], d_k_M_hat range: [0.8967, 0.9997]
2025-03-11 21:15:49 - Train Iteration 11848: loss: 0.0021, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9540, 0.9997]
2025-03-11 21:15:50 - Train Iteration 11849: loss: 0.0241, d_k_M range: [0.0000, 0.1517], d_k_M_hat range: [0.9735, 0.9999]
2025-03-11 21:15:50 - Train Iteration 11850: loss: 0.0017, d_k_M range: [0.0000, 0.0135], d_k_M_hat range: [0.9652, 0.9996]
2025-03-11 21:15:50 - Train Iteration 11851: loss: 0.0216, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.8531, 0.9997]
2025-03-11 21:15:51 - Train Iteration 11852: loss: 0.0021, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9546, 0.9978]
2025-03-11 21:15:51 - Train Iteration 11853: loss: 0.0002, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.9845, 0.9997]
2025-03-11 21:15:52 - Train Iteration 11854: loss: 0.0004, d_k_M range: [0.0000, 0.0119], d_k_M_hat range: [0.9806, 0.9997]
2025-03-11 21:15:52 - Train Iteration 11855: loss: 0.0032, d_k_M range: [0.0000, 0.0537], d_k_M_hat range: [0.9832, 0.9993]
2025-03-11 21:15:53 - Train Iteration 11856: loss: 0.0120, d_k_M range: [0.0000, 0.1063], d_k_M_hat range: [0.9230, 0.9999]
2025-03-11 21:15:53 - Train Iteration 11857: loss: 0.0073, d_k_M range: [0.0000, 0.0128], d_k_M_hat range: [0.9148, 0.9997]
2025-03-11 21:15:53 - Train Iteration 11858: loss: 0.0004, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.9798, 0.9993]
2025-03-11 21:15:54 - Train Iteration 11859: loss: 0.0001, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9921, 0.9990]
2025-03-11 21:15:54 - Train Iteration 11860: loss: 0.0011, d_k_M range: [0.0000, 0.0236], d_k_M_hat range: [0.9678, 0.9999]
2025-03-11 21:15:55 - Train Iteration 11861: loss: 0.0032, d_k_M range: [0.0008, 0.0563], d_k_M_hat range: [0.9942, 0.9998]
2025-03-11 21:15:55 - Train Iteration 11862: loss: 0.0084, d_k_M range: [0.0000, 0.0393], d_k_M_hat range: [0.9476, 0.9979]
2025-03-11 21:15:55 - Train Iteration 11863: loss: 0.0057, d_k_M range: [0.0000, 0.0078], d_k_M_hat range: [0.9274, 1.0000]
2025-03-11 21:15:56 - Train Iteration 11864: loss: 0.0013, d_k_M range: [0.0000, 0.0108], d_k_M_hat range: [0.9754, 0.9997]
2025-03-11 21:15:56 - Train Iteration 11865: loss: 0.1964, d_k_M range: [0.0000, 0.4424], d_k_M_hat range: [0.9806, 0.9998]
2025-03-11 21:15:57 - Train Iteration 11866: loss: 0.0103, d_k_M range: [0.0002, 0.0308], d_k_M_hat range: [0.8997, 0.9988]
2025-03-11 21:15:57 - Train Iteration 11867: loss: 0.0806, d_k_M range: [0.0004, 0.0102], d_k_M_hat range: [0.7263, 0.9991]
2025-03-11 21:15:57 - Train Iteration 11868: loss: 0.1265, d_k_M range: [0.0002, 0.3556], d_k_M_hat range: [0.9923, 1.0000]
2025-03-11 21:15:58 - Train Iteration 11869: loss: 0.0141, d_k_M range: [0.0002, 0.0368], d_k_M_hat range: [0.8816, 0.9994]
2025-03-11 21:15:58 - Train Iteration 11870: loss: 0.0024, d_k_M range: [0.0002, 0.0464], d_k_M_hat range: [0.9711, 0.9999]
2025-03-11 21:15:59 - Train Iteration 11871: loss: 0.0432, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.7922, 0.9990]
2025-03-11 21:15:59 - Train Iteration 11872: loss: 0.0552, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.7651, 0.9983]
2025-03-11 21:15:59 - Train Iteration 11873: loss: 0.0520, d_k_M range: [0.0000, 0.0089], d_k_M_hat range: [0.7720, 0.9993]
2025-03-11 21:16:00 - Train Iteration 11874: loss: 0.3288, d_k_M range: [0.0000, 0.5663], d_k_M_hat range: [0.9751, 0.9997]
2025-03-11 21:16:00 - Train Iteration 11875: loss: 0.0684, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.7385, 0.9998]
2025-03-11 21:16:01 - Train Iteration 11876: loss: 0.0017, d_k_M range: [0.0002, 0.0192], d_k_M_hat range: [0.9595, 0.9997]
2025-03-11 21:16:01 - Train Iteration 11877: loss: 0.0056, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.9256, 0.9999]
2025-03-11 21:16:02 - Train Iteration 11878: loss: 0.0084, d_k_M range: [0.0000, 0.0911], d_k_M_hat range: [0.9662, 0.9999]
2025-03-11 21:16:02 - Train Iteration 11879: loss: 0.0003, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.9815, 0.9990]
2025-03-11 21:16:02 - Train Iteration 11880: loss: 0.2555, d_k_M range: [0.0000, 0.0109], d_k_M_hat range: [0.4945, 0.9995]
2025-03-11 21:16:03 - Train Iteration 11881: loss: 0.0169, d_k_M range: [0.0001, 0.1299], d_k_M_hat range: [0.9890, 0.9997]
2025-03-11 21:16:03 - Train Iteration 11882: loss: 0.0010, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9689, 0.9992]
2025-03-11 21:16:04 - Train Iteration 11883: loss: 0.4323, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.3425, 0.9993]
2025-03-11 21:16:04 - Train Iteration 11884: loss: 0.0099, d_k_M range: [0.0000, 0.0990], d_k_M_hat range: [0.9485, 0.9998]
2025-03-11 21:16:05 - Train Iteration 11885: loss: 0.0040, d_k_M range: [0.0000, 0.0156], d_k_M_hat range: [0.9368, 0.9999]
2025-03-11 21:16:05 - Train Iteration 11886: loss: 0.2460, d_k_M range: [0.0000, 0.0141], d_k_M_hat range: [0.5040, 0.9997]
2025-03-11 21:16:05 - Train Iteration 11887: loss: 0.0009, d_k_M range: [0.0000, 0.0295], d_k_M_hat range: [0.9798, 0.9999]
2025-03-11 21:16:06 - Train Iteration 11888: loss: 0.2308, d_k_M range: [0.0007, 0.4792], d_k_M_hat range: [0.9901, 1.0000]
2025-03-11 21:16:06 - Train Iteration 11889: loss: 0.0187, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.8633, 0.9978]
2025-03-11 21:16:07 - Train Iteration 11890: loss: 0.0129, d_k_M range: [0.0000, 0.1094], d_k_M_hat range: [0.9230, 0.9998]
2025-03-11 21:16:07 - Train Iteration 11891: loss: 0.0085, d_k_M range: [0.0004, 0.0298], d_k_M_hat range: [0.9080, 0.9998]
2025-03-11 21:16:07 - Train Iteration 11892: loss: 0.0559, d_k_M range: [0.0000, 0.2361], d_k_M_hat range: [0.9377, 0.9998]
2025-03-11 21:16:08 - Train Iteration 11893: loss: 0.0271, d_k_M range: [0.0000, 0.0176], d_k_M_hat range: [0.8355, 0.9998]
2025-03-11 21:16:08 - Train Iteration 11894: loss: 0.0020, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.9554, 0.9994]
2025-03-11 21:16:09 - Train Iteration 11895: loss: 0.0054, d_k_M range: [0.0001, 0.0721], d_k_M_hat range: [0.9907, 0.9995]
2025-03-11 21:16:09 - Train Iteration 11896: loss: 0.0070, d_k_M range: [0.0000, 0.0832], d_k_M_hat range: [0.9847, 0.9996]
2025-03-11 21:16:10 - Train Iteration 11897: loss: 0.0003, d_k_M range: [0.0000, 0.0140], d_k_M_hat range: [0.9827, 0.9997]
2025-03-11 21:16:10 - Train Iteration 11898: loss: 0.0007, d_k_M range: [0.0000, 0.0252], d_k_M_hat range: [0.9897, 0.9999]
2025-03-11 21:16:10 - Train Iteration 11899: loss: 0.7840, d_k_M range: [0.0000, 0.0048], d_k_M_hat range: [0.1145, 0.9811]
2025-03-11 21:16:11 - Train Iteration 11900: loss: 0.0038, d_k_M range: [0.0002, 0.0617], d_k_M_hat range: [0.9835, 0.9999]
2025-03-11 21:16:11 - Train Iteration 11901: loss: 0.0716, d_k_M range: [0.0000, 0.0685], d_k_M_hat range: [0.7338, 0.9999]
2025-03-11 21:16:12 - Train Iteration 11902: loss: 0.1844, d_k_M range: [0.0000, 0.4291], d_k_M_hat range: [0.8343, 0.9997]
2025-03-11 21:16:12 - Train Iteration 11903: loss: 0.0671, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.7409, 0.9935]
2025-03-11 21:16:12 - Train Iteration 11904: loss: 0.0912, d_k_M range: [0.0000, 0.0135], d_k_M_hat range: [0.6982, 0.9989]
2025-03-11 21:16:13 - Train Iteration 11905: loss: 0.6676, d_k_M range: [0.0001, 0.8171], d_k_M_hat range: [0.9816, 1.0000]
2025-03-11 21:16:13 - Train Iteration 11906: loss: 0.0996, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.6845, 0.9997]
2025-03-11 21:16:14 - Train Iteration 11907: loss: 0.1656, d_k_M range: [0.0000, 0.1438], d_k_M_hat range: [0.5930, 0.9999]
2025-03-11 21:16:14 - Train Iteration 11908: loss: 0.0996, d_k_M range: [0.0004, 0.3155], d_k_M_hat range: [0.9970, 1.0000]
2025-03-11 21:16:15 - Train Iteration 11909: loss: 0.0590, d_k_M range: [0.0000, 0.0577], d_k_M_hat range: [0.7570, 0.9996]
2025-03-11 21:16:15 - Train Iteration 11910: loss: 0.0475, d_k_M range: [0.0001, 0.0073], d_k_M_hat range: [0.7822, 0.9997]
2025-03-11 21:16:15 - Train Iteration 11911: loss: 0.0046, d_k_M range: [0.0002, 0.0143], d_k_M_hat range: [0.9326, 0.9996]
2025-03-11 21:16:16 - Train Iteration 11912: loss: 0.0729, d_k_M range: [0.0000, 0.2687], d_k_M_hat range: [0.9058, 0.9995]
2025-03-11 21:16:16 - Train Iteration 11913: loss: 0.1081, d_k_M range: [0.0000, 0.3286], d_k_M_hat range: [0.9864, 0.9997]
2025-03-11 21:16:17 - Train Iteration 11914: loss: 0.0173, d_k_M range: [0.0000, 0.0137], d_k_M_hat range: [0.8687, 0.9994]
2025-03-11 21:16:17 - Train Iteration 11915: loss: 0.5259, d_k_M range: [0.0000, 0.0433], d_k_M_hat range: [0.2748, 0.9974]
2025-03-11 21:16:17 - Train Iteration 11916: loss: 0.9684, d_k_M range: [0.0024, 0.9841], d_k_M_hat range: [0.9998, 1.0000]
2025-03-11 21:16:18 - Train Iteration 11917: loss: 0.0720, d_k_M range: [0.0000, 0.2682], d_k_M_hat range: [0.9947, 0.9999]
2025-03-11 21:16:18 - Train Iteration 11918: loss: 0.0028, d_k_M range: [0.0001, 0.0455], d_k_M_hat range: [0.9472, 0.9998]
2025-03-11 21:16:19 - Train Iteration 11919: loss: 0.0093, d_k_M range: [0.0000, 0.0946], d_k_M_hat range: [0.9879, 0.9996]
2025-03-11 21:16:19 - Train Iteration 11920: loss: 0.0001, d_k_M range: [0.0000, 0.0065], d_k_M_hat range: [0.9889, 0.9997]
2025-03-11 21:16:20 - Train Iteration 11921: loss: 0.1013, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.6818, 0.9990]
2025-03-11 21:16:20 - Train Iteration 11922: loss: 0.2917, d_k_M range: [0.0000, 0.5399], d_k_M_hat range: [0.9752, 1.0000]
2025-03-11 21:16:20 - Train Iteration 11923: loss: 0.0136, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.8839, 0.9997]
2025-03-11 21:16:21 - Train Iteration 11924: loss: 0.0456, d_k_M range: [0.0000, 0.2119], d_k_M_hat range: [0.9796, 1.0000]
2025-03-11 21:16:21 - Train Iteration 11925: loss: 0.0003, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9842, 0.9998]
2025-03-11 21:16:22 - Train Iteration 11926: loss: 0.1601, d_k_M range: [0.0002, 0.3999], d_k_M_hat range: [0.9658, 0.9997]
2025-03-11 21:16:22 - Train Iteration 11927: loss: 0.0148, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.8783, 0.9995]
2025-03-11 21:16:23 - Train Iteration 11928: loss: 0.0321, d_k_M range: [0.0000, 0.0330], d_k_M_hat range: [0.8209, 0.9995]
2025-03-11 21:16:23 - Train Iteration 11929: loss: 0.0004, d_k_M range: [0.0001, 0.0021], d_k_M_hat range: [0.9808, 0.9998]
2025-03-11 21:16:23 - Train Iteration 11930: loss: 0.0349, d_k_M range: [0.0001, 0.0088], d_k_M_hat range: [0.8221, 0.9994]
2025-03-11 21:16:24 - Train Iteration 11931: loss: 0.0010, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9692, 0.9991]
2025-03-11 21:16:24 - Train Iteration 11932: loss: 0.9639, d_k_M range: [0.0000, 0.0301], d_k_M_hat range: [0.0185, 0.9997]
2025-03-11 21:16:25 - Train Iteration 11933: loss: 0.0003, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.9822, 0.9999]
2025-03-11 21:16:25 - Train Iteration 11934: loss: 0.0241, d_k_M range: [0.0001, 0.0133], d_k_M_hat range: [0.8451, 0.9994]
2025-03-11 21:16:26 - Train Iteration 11935: loss: 0.0095, d_k_M range: [0.0000, 0.0960], d_k_M_hat range: [0.9924, 1.0000]
2025-03-11 21:16:26 - Train Iteration 11936: loss: 0.0034, d_k_M range: [0.0001, 0.0169], d_k_M_hat range: [0.9486, 0.9998]
2025-03-11 21:16:26 - Train Iteration 11937: loss: 0.0008, d_k_M range: [0.0000, 0.0229], d_k_M_hat range: [0.9815, 0.9990]
2025-03-11 21:16:27 - Train Iteration 11938: loss: 0.0005, d_k_M range: [0.0000, 0.0150], d_k_M_hat range: [0.9781, 1.0000]
2025-03-11 21:16:27 - Train Iteration 11939: loss: 0.0041, d_k_M range: [0.0001, 0.0102], d_k_M_hat range: [0.9383, 0.9992]
2025-03-11 21:16:28 - Train Iteration 11940: loss: 0.0015, d_k_M range: [0.0003, 0.0207], d_k_M_hat range: [0.9618, 0.9998]
2025-03-11 21:16:28 - Train Iteration 11941: loss: 0.8775, d_k_M range: [0.0000, 0.0596], d_k_M_hat range: [0.1229, 0.9979]
2025-03-11 21:16:28 - Train Iteration 11942: loss: 0.0055, d_k_M range: [0.0001, 0.0083], d_k_M_hat range: [0.9262, 0.9997]
2025-03-11 21:16:29 - Train Iteration 11943: loss: 0.0540, d_k_M range: [0.0000, 0.0772], d_k_M_hat range: [0.8449, 0.9999]
2025-03-11 21:16:29 - Train Iteration 11944: loss: 0.4150, d_k_M range: [0.0000, 0.6441], d_k_M_hat range: [0.9754, 0.9999]
2025-03-11 21:16:30 - Train Iteration 11945: loss: 0.3719, d_k_M range: [0.0001, 0.0487], d_k_M_hat range: [0.3905, 0.9987]
2025-03-11 21:16:30 - Train Iteration 11946: loss: 0.0073, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9145, 0.9999]
2025-03-11 21:16:31 - Train Iteration 11947: loss: 0.4061, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.3627, 0.9992]
2025-03-11 21:16:31 - Train Iteration 11948: loss: 0.4688, d_k_M range: [0.0001, 0.6820], d_k_M_hat range: [0.9849, 0.9999]
2025-03-11 21:16:31 - Train Iteration 11949: loss: 0.0083, d_k_M range: [0.0000, 0.0810], d_k_M_hat range: [0.9090, 0.9994]
2025-03-11 21:16:32 - Train Iteration 11950: loss: 0.0715, d_k_M range: [0.0000, 0.2119], d_k_M_hat range: [0.8571, 0.9985]
2025-03-11 21:16:32 - Train Iteration 11951: loss: 0.0007, d_k_M range: [0.0000, 0.0087], d_k_M_hat range: [0.9744, 0.9998]
2025-03-11 21:16:33 - Train Iteration 11952: loss: 0.0023, d_k_M range: [0.0000, 0.0481], d_k_M_hat range: [0.9907, 0.9998]
2025-03-11 21:16:33 - Train Iteration 11953: loss: 0.3880, d_k_M range: [0.0000, 0.6227], d_k_M_hat range: [0.9735, 0.9998]
2025-03-11 21:16:33 - Train Iteration 11954: loss: 0.0090, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.9053, 0.9862]
2025-03-11 21:16:34 - Train Iteration 11955: loss: 0.0641, d_k_M range: [0.0000, 0.0142], d_k_M_hat range: [0.7480, 0.9994]
2025-03-11 21:16:34 - Train Iteration 11956: loss: 0.0027, d_k_M range: [0.0000, 0.0508], d_k_M_hat range: [0.9643, 0.9992]
2025-03-11 21:16:35 - Train Iteration 11957: loss: 0.0021, d_k_M range: [0.0000, 0.0151], d_k_M_hat range: [0.9539, 0.9995]
2025-03-11 21:16:35 - Train Iteration 11958: loss: 0.0025, d_k_M range: [0.0001, 0.0463], d_k_M_hat range: [0.9734, 0.9997]
2025-03-11 21:16:36 - Train Iteration 11959: loss: 0.7596, d_k_M range: [0.0000, 0.8693], d_k_M_hat range: [0.3261, 0.9989]
2025-03-11 21:16:36 - Train Iteration 11960: loss: 0.3445, d_k_M range: [0.0000, 0.5777], d_k_M_hat range: [0.9715, 0.9994]
2025-03-11 21:16:36 - Train Iteration 11961: loss: 0.0542, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.7672, 0.9997]
2025-03-11 21:16:37 - Train Iteration 11962: loss: 0.0116, d_k_M range: [0.0003, 0.1077], d_k_M_hat range: [0.9967, 1.0000]
2025-03-11 21:16:37 - Train Iteration 11963: loss: 0.0033, d_k_M range: [0.0002, 0.0290], d_k_M_hat range: [0.9448, 0.9999]
2025-03-11 21:16:38 - Train Iteration 11964: loss: 0.6158, d_k_M range: [0.0002, 0.7844], d_k_M_hat range: [0.9697, 0.9999]
2025-03-11 21:16:38 - Train Iteration 11965: loss: 0.1503, d_k_M range: [0.0000, 0.0286], d_k_M_hat range: [0.6125, 0.9995]
2025-03-11 21:16:38 - Train Iteration 11966: loss: 0.0755, d_k_M range: [0.0000, 0.2747], d_k_M_hat range: [0.9196, 1.0000]
2025-03-11 21:16:39 - Train Iteration 11967: loss: 0.0547, d_k_M range: [0.0000, 0.0806], d_k_M_hat range: [0.7714, 0.9993]
2025-03-11 21:16:39 - Train Iteration 11968: loss: 0.1631, d_k_M range: [0.0012, 0.4037], d_k_M_hat range: [0.9958, 0.9999]
2025-03-11 21:16:40 - Train Iteration 11969: loss: 0.0103, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.8986, 0.9992]
2025-03-11 21:16:40 - Train Iteration 11970: loss: 0.0106, d_k_M range: [0.0001, 0.0970], d_k_M_hat range: [0.9833, 0.9999]
2025-03-11 21:16:41 - Train Iteration 11971: loss: 0.0096, d_k_M range: [0.0000, 0.0944], d_k_M_hat range: [0.9773, 0.9992]
2025-03-11 21:16:41 - Train Iteration 11972: loss: 0.0002, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.9862, 0.9997]
2025-03-11 21:16:42 - Train Iteration 11973: loss: 0.0005, d_k_M range: [0.0000, 0.0219], d_k_M_hat range: [0.9869, 0.9994]
2025-03-11 21:16:42 - Train Iteration 11974: loss: 0.0319, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.8213, 0.9920]
2025-03-11 21:16:42 - Train Iteration 11975: loss: 0.0443, d_k_M range: [0.0000, 0.2096], d_k_M_hat range: [0.9175, 0.9996]
2025-03-11 21:16:43 - Train Iteration 11976: loss: 0.0265, d_k_M range: [0.0000, 0.1028], d_k_M_hat range: [0.8379, 0.9997]
2025-03-11 21:16:43 - Train Iteration 11977: loss: 0.0244, d_k_M range: [0.0001, 0.1507], d_k_M_hat range: [0.9643, 0.9996]
2025-03-11 21:16:44 - Train Iteration 11978: loss: 0.0053, d_k_M range: [0.0001, 0.0680], d_k_M_hat range: [0.9666, 0.9998]
2025-03-11 21:16:44 - Train Iteration 11979: loss: 0.0005, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9800, 0.9987]
2025-03-11 21:16:45 - Train Iteration 11980: loss: 0.0076, d_k_M range: [0.0001, 0.0856], d_k_M_hat range: [0.9933, 0.9985]
2025-03-11 21:16:45 - Train Iteration 11981: loss: 0.0193, d_k_M range: [0.0002, 0.1386], d_k_M_hat range: [0.9962, 0.9998]
2025-03-11 21:16:45 - Train Iteration 11982: loss: 0.0026, d_k_M range: [0.0000, 0.0503], d_k_M_hat range: [0.9800, 0.9997]
2025-03-11 21:16:46 - Train Iteration 11983: loss: 0.0390, d_k_M range: [0.0002, 0.1932], d_k_M_hat range: [0.9925, 0.9994]
2025-03-11 21:16:46 - Train Iteration 11984: loss: 0.0259, d_k_M range: [0.0000, 0.1600], d_k_M_hat range: [0.9740, 0.9996]
2025-03-11 21:16:47 - Train Iteration 11985: loss: 0.0033, d_k_M range: [0.0001, 0.0083], d_k_M_hat range: [0.9424, 0.9985]
2025-03-11 21:16:47 - Train Iteration 11986: loss: 0.0061, d_k_M range: [0.0001, 0.0770], d_k_M_hat range: [0.9723, 0.9988]
2025-03-11 21:16:48 - Train Iteration 11987: loss: 0.0019, d_k_M range: [0.0001, 0.0133], d_k_M_hat range: [0.9564, 0.9977]
2025-03-11 21:16:48 - Train Iteration 11988: loss: 0.1252, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.6462, 0.9998]
2025-03-11 21:16:48 - Train Iteration 11989: loss: 0.6198, d_k_M range: [0.0002, 0.7864], d_k_M_hat range: [0.9964, 0.9997]
2025-03-11 21:16:49 - Train Iteration 11990: loss: 0.0553, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.7648, 0.9984]
2025-03-11 21:16:49 - Train Iteration 11991: loss: 0.0033, d_k_M range: [0.0000, 0.0149], d_k_M_hat range: [0.9429, 0.9993]
2025-03-11 21:16:50 - Train Iteration 11992: loss: 0.0296, d_k_M range: [0.0000, 0.0739], d_k_M_hat range: [0.8560, 0.9990]
2025-03-11 21:16:50 - Train Iteration 11993: loss: 0.0010, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9696, 0.9994]
2025-03-11 21:16:51 - Train Iteration 11994: loss: 0.0005, d_k_M range: [0.0000, 0.0057], d_k_M_hat range: [0.9770, 0.9992]
2025-03-11 21:16:51 - Train Iteration 11995: loss: 0.0155, d_k_M range: [0.0001, 0.1229], d_k_M_hat range: [0.9714, 0.9983]
2025-03-11 21:16:51 - Train Iteration 11996: loss: 0.0008, d_k_M range: [0.0001, 0.0167], d_k_M_hat range: [0.9762, 0.9991]
2025-03-11 21:16:52 - Train Iteration 11997: loss: 0.2111, d_k_M range: [0.0000, 0.4591], d_k_M_hat range: [0.9766, 0.9998]
2025-03-11 21:16:52 - Train Iteration 11998: loss: 0.0005, d_k_M range: [0.0000, 0.0195], d_k_M_hat range: [0.9873, 0.9996]
2025-03-11 21:16:53 - Train Iteration 11999: loss: 0.2538, d_k_M range: [0.0000, 0.5032], d_k_M_hat range: [0.9878, 1.0000]
2025-03-11 21:16:53 - Train Iteration 12000: loss: 0.0347, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.8139, 0.9993]
2025-03-11 21:16:54 - Train Iteration 12001: loss: 0.0033, d_k_M range: [0.0000, 0.0276], d_k_M_hat range: [0.9427, 0.9996]
2025-03-11 21:16:54 - Train Iteration 12002: loss: 0.8906, d_k_M range: [0.0001, 0.9435], d_k_M_hat range: [0.9972, 0.9999]
2025-03-11 21:16:55 - Train Iteration 12003: loss: 0.0020, d_k_M range: [0.0001, 0.0438], d_k_M_hat range: [0.9923, 0.9998]
2025-03-11 21:16:55 - Train Iteration 12004: loss: 0.0259, d_k_M range: [0.0000, 0.1610], d_k_M_hat range: [0.9840, 1.0000]
2025-03-11 21:16:55 - Train Iteration 12005: loss: 0.0041, d_k_M range: [0.0000, 0.0630], d_k_M_hat range: [0.9905, 0.9992]
2025-03-11 21:16:56 - Train Iteration 12006: loss: 0.0012, d_k_M range: [0.0002, 0.0067], d_k_M_hat range: [0.9656, 0.9999]
2025-03-11 21:16:56 - Train Iteration 12007: loss: 0.0027, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.9483, 0.9932]
2025-03-11 21:16:57 - Train Iteration 12008: loss: 0.0059, d_k_M range: [0.0000, 0.0749], d_k_M_hat range: [0.9927, 0.9999]
2025-03-11 21:16:57 - Train Iteration 12009: loss: 0.0189, d_k_M range: [0.0001, 0.1362], d_k_M_hat range: [0.9935, 0.9999]
2025-03-11 21:16:58 - Train Iteration 12010: loss: 0.0055, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9256, 0.9994]
2025-03-11 21:16:58 - Train Iteration 12011: loss: 0.7240, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.1491, 0.9883]
2025-03-11 21:16:59 - Train Iteration 12012: loss: 0.0231, d_k_M range: [0.0000, 0.1503], d_k_M_hat range: [0.9231, 0.9998]
2025-03-11 21:16:59 - Train Iteration 12013: loss: 0.0027, d_k_M range: [0.0001, 0.0520], d_k_M_hat range: [0.9906, 0.9999]
2025-03-11 21:17:00 - Train Iteration 12014: loss: 0.0001, d_k_M range: [0.0000, 0.0086], d_k_M_hat range: [0.9915, 0.9995]
2025-03-11 21:17:00 - Train Iteration 12015: loss: 0.0118, d_k_M range: [0.0001, 0.1084], d_k_M_hat range: [0.9835, 1.0000]
2025-03-11 21:17:00 - Train Iteration 12016: loss: 0.0007, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9741, 0.9981]
2025-03-11 21:17:01 - Train Iteration 12017: loss: 0.0170, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.8698, 0.9979]
2025-03-11 21:17:01 - Train Iteration 12018: loss: 0.4394, d_k_M range: [0.0000, 0.6601], d_k_M_hat range: [0.9839, 0.9994]
2025-03-11 21:17:02 - Train Iteration 12019: loss: 0.0841, d_k_M range: [0.0000, 0.0137], d_k_M_hat range: [0.7100, 0.9935]
2025-03-11 21:17:02 - Train Iteration 12020: loss: 0.0013, d_k_M range: [0.0001, 0.0012], d_k_M_hat range: [0.9650, 0.9998]
2025-03-11 21:17:02 - Train Iteration 12021: loss: 0.0235, d_k_M range: [0.0000, 0.1428], d_k_M_hat range: [0.9895, 0.9995]
2025-03-11 21:17:03 - Train Iteration 12022: loss: 0.0056, d_k_M range: [0.0000, 0.0748], d_k_M_hat range: [0.9848, 1.0000]
2025-03-11 21:17:03 - Train Iteration 12023: loss: 0.8494, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.0784, 0.9946]
2025-03-11 21:17:04 - Train Iteration 12024: loss: 0.0078, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.9118, 0.9985]
2025-03-11 21:17:04 - Train Iteration 12025: loss: 0.0057, d_k_M range: [0.0000, 0.0735], d_k_M_hat range: [0.9759, 0.9998]
2025-03-11 21:17:05 - Train Iteration 12026: loss: 0.3238, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.4310, 0.9944]
2025-03-11 21:17:05 - Train Iteration 12027: loss: 0.8074, d_k_M range: [0.0005, 0.8985], d_k_M_hat range: [0.9990, 1.0000]
2025-03-11 21:17:05 - Train Iteration 12028: loss: 0.7195, d_k_M range: [0.0000, 0.8461], d_k_M_hat range: [0.9243, 0.9998]
2025-03-11 21:17:06 - Train Iteration 12029: loss: 0.1000, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.6839, 0.9993]
2025-03-11 21:17:06 - Train Iteration 12030: loss: 0.0775, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.7219, 0.9959]
2025-03-11 21:17:07 - Train Iteration 12031: loss: 0.0141, d_k_M range: [0.0000, 0.0150], d_k_M_hat range: [0.8813, 0.9985]
2025-03-11 21:17:07 - Train Iteration 12032: loss: 0.0041, d_k_M range: [0.0002, 0.0567], d_k_M_hat range: [0.9794, 0.9983]
2025-03-11 21:17:07 - Train Iteration 12033: loss: 0.5144, d_k_M range: [0.0000, 0.7171], d_k_M_hat range: [0.9568, 0.9999]
2025-03-11 21:17:08 - Train Iteration 12034: loss: 0.5256, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.2751, 0.9733]
2025-03-11 21:17:08 - Train Iteration 12035: loss: 0.4322, d_k_M range: [0.0002, 0.6558], d_k_M_hat range: [0.9873, 0.9999]
2025-03-11 21:17:09 - Train Iteration 12036: loss: 0.0002, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9880, 0.9978]
2025-03-11 21:17:09 - Train Iteration 12037: loss: 0.0031, d_k_M range: [0.0000, 0.0121], d_k_M_hat range: [0.9443, 0.9997]
2025-03-11 21:17:10 - Train Iteration 12038: loss: 0.3176, d_k_M range: [0.0000, 0.5596], d_k_M_hat range: [0.9665, 0.9998]
2025-03-11 21:17:10 - Train Iteration 12039: loss: 0.0310, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.8239, 0.9952]
2025-03-11 21:17:10 - Train Iteration 12040: loss: 0.1926, d_k_M range: [0.0003, 0.4384], d_k_M_hat range: [0.9791, 0.9998]
2025-03-11 21:17:11 - Train Iteration 12041: loss: 0.0011, d_k_M range: [0.0000, 0.0219], d_k_M_hat range: [0.9668, 0.9998]
2025-03-11 21:17:11 - Train Iteration 12042: loss: 0.0123, d_k_M range: [0.0000, 0.0162], d_k_M_hat range: [0.9052, 0.9982]
2025-03-11 21:17:12 - Train Iteration 12043: loss: 0.0458, d_k_M range: [0.0001, 0.2139], d_k_M_hat range: [0.9862, 0.9999]
2025-03-11 21:17:12 - Train Iteration 12044: loss: 0.0019, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.9560, 0.9990]
2025-03-11 21:17:12 - Train Iteration 12045: loss: 0.0179, d_k_M range: [0.0000, 0.1285], d_k_M_hat range: [0.9908, 0.9984]
2025-03-11 21:17:13 - Train Iteration 12046: loss: 0.0021, d_k_M range: [0.0001, 0.0101], d_k_M_hat range: [0.9618, 0.9976]
2025-03-11 21:17:13 - Train Iteration 12047: loss: 0.0027, d_k_M range: [0.0001, 0.0245], d_k_M_hat range: [0.9506, 0.9998]
2025-03-11 21:17:14 - Train Iteration 12048: loss: 0.0150, d_k_M range: [0.0000, 0.1179], d_k_M_hat range: [0.9837, 0.9999]
2025-03-11 21:17:14 - Train Iteration 12049: loss: 0.0083, d_k_M range: [0.0001, 0.0052], d_k_M_hat range: [0.9090, 0.9996]
2025-03-11 21:17:15 - Train Iteration 12050: loss: 0.0263, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.8381, 0.9999]
2025-03-11 21:17:15 - Train Iteration 12051: loss: 0.0062, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9217, 0.9989]
2025-03-11 21:17:16 - Train Iteration 12052: loss: 0.0027, d_k_M range: [0.0001, 0.0029], d_k_M_hat range: [0.9478, 0.9972]
2025-03-11 21:17:16 - Train Iteration 12053: loss: 0.0036, d_k_M range: [0.0000, 0.0113], d_k_M_hat range: [0.9406, 0.9996]
2025-03-11 21:17:16 - Train Iteration 12054: loss: 0.0095, d_k_M range: [0.0001, 0.0971], d_k_M_hat range: [0.9514, 0.9999]
2025-03-11 21:17:17 - Train Iteration 12055: loss: 0.0271, d_k_M range: [0.0000, 0.1641], d_k_M_hat range: [0.9829, 0.9994]
2025-03-11 21:17:17 - Train Iteration 12056: loss: 0.0242, d_k_M range: [0.0000, 0.0192], d_k_M_hat range: [0.8443, 0.9994]
2025-03-11 21:17:18 - Train Iteration 12057: loss: 0.0444, d_k_M range: [0.0000, 0.0725], d_k_M_hat range: [0.7893, 0.9990]
2025-03-11 21:17:18 - Train Iteration 12058: loss: 0.0005, d_k_M range: [0.0000, 0.0135], d_k_M_hat range: [0.9886, 0.9990]
2025-03-11 21:17:19 - Train Iteration 12059: loss: 0.0540, d_k_M range: [0.0000, 0.0169], d_k_M_hat range: [0.7676, 0.9996]
2025-03-11 21:17:19 - Train Iteration 12060: loss: 0.0017, d_k_M range: [0.0000, 0.0407], d_k_M_hat range: [0.9830, 0.9998]
2025-03-11 21:17:20 - Train Iteration 12061: loss: 0.0019, d_k_M range: [0.0000, 0.0184], d_k_M_hat range: [0.9571, 0.9998]
2025-03-11 21:17:20 - Train Iteration 12062: loss: 0.0004, d_k_M range: [0.0000, 0.0206], d_k_M_hat range: [0.9956, 1.0000]
2025-03-11 21:17:20 - Train Iteration 12063: loss: 0.0318, d_k_M range: [0.0000, 0.0724], d_k_M_hat range: [0.8217, 0.9999]
2025-03-11 21:17:21 - Train Iteration 12064: loss: 0.0045, d_k_M range: [0.0000, 0.0645], d_k_M_hat range: [0.9659, 0.9996]
2025-03-11 21:17:21 - Train Iteration 12065: loss: 0.0000, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9936, 0.9996]
2025-03-11 21:17:22 - Train Iteration 12066: loss: 0.4985, d_k_M range: [0.0000, 0.7026], d_k_M_hat range: [0.9613, 0.9996]
2025-03-11 21:17:22 - Train Iteration 12067: loss: 0.0835, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.7110, 0.9909]
2025-03-11 21:17:23 - Train Iteration 12068: loss: 0.0030, d_k_M range: [0.0002, 0.0541], d_k_M_hat range: [0.9893, 0.9999]
2025-03-11 21:17:23 - Train Iteration 12069: loss: 0.0131, d_k_M range: [0.0000, 0.0370], d_k_M_hat range: [0.8857, 0.9989]
2025-03-11 21:17:23 - Train Iteration 12070: loss: 0.0186, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.8638, 0.9980]
2025-03-11 21:17:24 - Train Iteration 12071: loss: 0.0158, d_k_M range: [0.0000, 0.0089], d_k_M_hat range: [0.8743, 0.9982]
2025-03-11 21:17:24 - Train Iteration 12072: loss: 0.4205, d_k_M range: [0.0000, 0.6476], d_k_M_hat range: [0.9661, 0.9993]
2025-03-11 21:17:25 - Train Iteration 12073: loss: 0.0031, d_k_M range: [0.0003, 0.0188], d_k_M_hat range: [0.9446, 0.9995]
2025-03-11 21:17:25 - Train Iteration 12074: loss: 0.0025, d_k_M range: [0.0003, 0.0475], d_k_M_hat range: [0.9820, 0.9998]
2025-03-11 21:17:26 - Train Iteration 12075: loss: 0.0016, d_k_M range: [0.0000, 0.0137], d_k_M_hat range: [0.9686, 0.9998]
2025-03-11 21:17:26 - Train Iteration 12076: loss: 0.0011, d_k_M range: [0.0000, 0.0126], d_k_M_hat range: [0.9720, 0.9995]
2025-03-11 21:17:26 - Train Iteration 12077: loss: 0.0040, d_k_M range: [0.0000, 0.0550], d_k_M_hat range: [0.9741, 0.9979]
2025-03-11 21:17:27 - Train Iteration 12078: loss: 0.0018, d_k_M range: [0.0000, 0.0354], d_k_M_hat range: [0.9615, 0.9978]
2025-03-11 21:17:27 - Train Iteration 12079: loss: 0.3216, d_k_M range: [0.0000, 0.5635], d_k_M_hat range: [0.8768, 0.9971]
2025-03-11 21:17:28 - Train Iteration 12080: loss: 0.0007, d_k_M range: [0.0003, 0.0167], d_k_M_hat range: [0.9827, 0.9982]
2025-03-11 21:17:28 - Train Iteration 12081: loss: 0.0037, d_k_M range: [0.0000, 0.0526], d_k_M_hat range: [0.9804, 0.9990]
2025-03-11 21:17:28 - Train Iteration 12082: loss: 0.0023, d_k_M range: [0.0004, 0.0044], d_k_M_hat range: [0.9558, 0.9998]
2025-03-11 21:17:29 - Train Iteration 12083: loss: 0.0416, d_k_M range: [0.0000, 0.0174], d_k_M_hat range: [0.7967, 0.9999]
2025-03-11 21:17:29 - Train Iteration 12084: loss: 0.0039, d_k_M range: [0.0001, 0.0620], d_k_M_hat range: [0.9954, 0.9999]
2025-03-11 21:17:30 - Train Iteration 12085: loss: 0.1051, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.6757, 0.9992]
2025-03-11 21:17:30 - Train Iteration 12086: loss: 0.0003, d_k_M range: [0.0000, 0.0147], d_k_M_hat range: [0.9827, 0.9997]
2025-03-11 21:17:31 - Train Iteration 12087: loss: 0.5061, d_k_M range: [0.0000, 0.1957], d_k_M_hat range: [0.2886, 0.9991]
2025-03-11 21:17:31 - Train Iteration 12088: loss: 0.2205, d_k_M range: [0.0000, 0.4686], d_k_M_hat range: [0.9716, 0.9998]
2025-03-11 21:17:32 - Train Iteration 12089: loss: 0.0021, d_k_M range: [0.0000, 0.0113], d_k_M_hat range: [0.9544, 0.9998]
2025-03-11 21:17:32 - Train Iteration 12090: loss: 0.0169, d_k_M range: [0.0027, 0.1293], d_k_M_hat range: [0.9869, 0.9994]
2025-03-11 21:17:33 - Train Iteration 12091: loss: 0.0568, d_k_M range: [0.0004, 0.2380], d_k_M_hat range: [0.9942, 0.9997]
2025-03-11 21:17:33 - Train Iteration 12092: loss: 0.0080, d_k_M range: [0.0000, 0.0125], d_k_M_hat range: [0.9105, 0.9997]
2025-03-11 21:17:33 - Train Iteration 12093: loss: 0.0358, d_k_M range: [0.0002, 0.1889], d_k_M_hat range: [0.9714, 0.9996]
2025-03-11 21:17:34 - Train Iteration 12094: loss: 0.0013, d_k_M range: [0.0000, 0.0352], d_k_M_hat range: [0.9737, 0.9999]
2025-03-11 21:17:34 - Train Iteration 12095: loss: 0.0853, d_k_M range: [0.0000, 0.2744], d_k_M_hat range: [0.9801, 0.9998]
2025-03-11 21:17:35 - Train Iteration 12096: loss: 0.0044, d_k_M range: [0.0000, 0.0070], d_k_M_hat range: [0.9341, 0.9965]
2025-03-11 21:17:35 - Train Iteration 12097: loss: 0.0011, d_k_M range: [0.0000, 0.0218], d_k_M_hat range: [0.9733, 0.9999]
2025-03-11 21:17:36 - Train Iteration 12098: loss: 0.0039, d_k_M range: [0.0001, 0.0623], d_k_M_hat range: [0.9616, 0.9999]
2025-03-11 21:17:36 - Train Iteration 12099: loss: 0.0496, d_k_M range: [0.0001, 0.0228], d_k_M_hat range: [0.7775, 0.9992]
2025-03-11 21:17:36 - Train Iteration 12100: loss: 0.1279, d_k_M range: [0.0001, 0.0172], d_k_M_hat range: [0.6424, 0.9999]
2025-03-11 21:17:37 - Train Iteration 12101: loss: 0.3176, d_k_M range: [0.0004, 0.5633], d_k_M_hat range: [0.9990, 1.0000]
2025-03-11 21:17:37 - Train Iteration 12102: loss: 0.0531, d_k_M range: [0.0000, 0.0207], d_k_M_hat range: [0.7703, 0.9982]
2025-03-11 21:17:38 - Train Iteration 12103: loss: 0.0446, d_k_M range: [0.0000, 0.2104], d_k_M_hat range: [0.9841, 0.9999]
2025-03-11 21:17:38 - Train Iteration 12104: loss: 0.0008, d_k_M range: [0.0000, 0.0190], d_k_M_hat range: [0.9710, 0.9998]
2025-03-11 21:17:38 - Train Iteration 12105: loss: 0.0109, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.8957, 0.9995]
2025-03-11 21:17:39 - Train Iteration 12106: loss: 0.5856, d_k_M range: [0.0000, 0.7616], d_k_M_hat range: [0.9964, 1.0000]
2025-03-11 21:17:39 - Train Iteration 12107: loss: 0.0916, d_k_M range: [0.0000, 0.0372], d_k_M_hat range: [0.6978, 0.9997]
2025-03-11 21:17:40 - Train Iteration 12108: loss: 0.0141, d_k_M range: [0.0003, 0.0275], d_k_M_hat range: [0.8819, 0.9999]
2025-03-11 21:17:40 - Train Iteration 12109: loss: 0.0091, d_k_M range: [0.0001, 0.0012], d_k_M_hat range: [0.9046, 0.9997]
2025-03-11 21:17:41 - Train Iteration 12110: loss: 0.0031, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9443, 0.9995]
2025-03-11 21:17:41 - Train Iteration 12111: loss: 0.0004, d_k_M range: [0.0002, 0.0167], d_k_M_hat range: [0.9833, 0.9999]
2025-03-11 21:17:41 - Train Iteration 12112: loss: 0.0242, d_k_M range: [0.0000, 0.1550], d_k_M_hat range: [0.9980, 1.0000]
2025-03-11 21:17:42 - Train Iteration 12113: loss: 0.0020, d_k_M range: [0.0000, 0.0441], d_k_M_hat range: [0.9792, 0.9997]
2025-03-11 21:17:42 - Train Iteration 12114: loss: 0.0015, d_k_M range: [0.0000, 0.0379], d_k_M_hat range: [0.9781, 0.9996]
2025-03-11 21:17:43 - Train Iteration 12115: loss: 0.0013, d_k_M range: [0.0000, 0.0362], d_k_M_hat range: [0.9633, 0.9999]
2025-03-11 21:17:43 - Train Iteration 12116: loss: 0.0188, d_k_M range: [0.0001, 0.1359], d_k_M_hat range: [0.9966, 0.9999]
2025-03-11 21:17:43 - Train Iteration 12117: loss: 0.2074, d_k_M range: [0.0000, 0.0144], d_k_M_hat range: [0.5446, 0.9993]
2025-03-11 21:17:44 - Train Iteration 12118: loss: 0.0023, d_k_M range: [0.0001, 0.0411], d_k_M_hat range: [0.9927, 0.9999]
2025-03-11 21:17:44 - Train Iteration 12119: loss: 0.1288, d_k_M range: [0.0000, 0.3567], d_k_M_hat range: [0.9817, 0.9994]
2025-03-11 21:17:45 - Train Iteration 12120: loss: 0.0254, d_k_M range: [0.0001, 0.0277], d_k_M_hat range: [0.8443, 0.9992]
2025-03-11 21:17:45 - Train Iteration 12121: loss: 0.0005, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9781, 0.9998]
2025-03-11 21:17:45 - Train Iteration 12122: loss: 0.0001, d_k_M range: [0.0000, 0.0084], d_k_M_hat range: [0.9950, 0.9999]
2025-03-11 21:17:46 - Train Iteration 12123: loss: 0.0723, d_k_M range: [0.0000, 0.2668], d_k_M_hat range: [0.9807, 0.9995]
2025-03-11 21:17:46 - Train Iteration 12124: loss: 0.0012, d_k_M range: [0.0000, 0.0100], d_k_M_hat range: [0.9659, 0.9999]
2025-03-11 21:17:47 - Train Iteration 12125: loss: 0.0008, d_k_M range: [0.0001, 0.0020], d_k_M_hat range: [0.9712, 0.9996]
2025-03-11 21:17:47 - Train Iteration 12126: loss: 0.0208, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.8559, 0.9990]
2025-03-11 21:17:48 - Train Iteration 12127: loss: 0.3188, d_k_M range: [0.0001, 0.5589], d_k_M_hat range: [0.9664, 0.9998]
2025-03-11 21:17:48 - Train Iteration 12128: loss: 0.0009, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.9733, 0.9991]
2025-03-11 21:17:48 - Train Iteration 12129: loss: 0.0004, d_k_M range: [0.0000, 0.0124], d_k_M_hat range: [0.9801, 0.9999]
2025-03-11 21:17:49 - Train Iteration 12130: loss: 0.3650, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.4003, 1.0000]
2025-03-11 21:17:49 - Train Iteration 12131: loss: 0.0029, d_k_M range: [0.0000, 0.0185], d_k_M_hat range: [0.9645, 0.9972]
2025-03-11 21:17:50 - Train Iteration 12132: loss: 0.0009, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9708, 0.9999]
2025-03-11 21:17:50 - Train Iteration 12133: loss: 0.0031, d_k_M range: [0.0002, 0.0554], d_k_M_hat range: [0.9607, 0.9999]
2025-03-11 21:17:50 - Train Iteration 12134: loss: 0.0003, d_k_M range: [0.0002, 0.0097], d_k_M_hat range: [0.9874, 0.9992]
2025-03-11 21:17:51 - Train Iteration 12135: loss: 0.0004, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.9813, 1.0000]
2025-03-11 21:17:51 - Train Iteration 12136: loss: 0.0007, d_k_M range: [0.0001, 0.0199], d_k_M_hat range: [0.9843, 0.9999]
2025-03-11 21:17:52 - Train Iteration 12137: loss: 0.0037, d_k_M range: [0.0000, 0.0604], d_k_M_hat range: [0.9865, 1.0000]
2025-03-11 21:17:52 - Train Iteration 12138: loss: 0.0106, d_k_M range: [0.0000, 0.1029], d_k_M_hat range: [0.9708, 0.9999]
2025-03-11 21:17:52 - Train Iteration 12139: loss: 0.0006, d_k_M range: [0.0000, 0.0197], d_k_M_hat range: [0.9745, 0.9991]
2025-03-11 21:17:53 - Train Iteration 12140: loss: 0.0002, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.9852, 0.9993]
2025-03-11 21:17:53 - Train Iteration 12141: loss: 0.0830, d_k_M range: [0.0000, 0.2876], d_k_M_hat range: [0.9722, 0.9996]
2025-03-11 21:17:54 - Train Iteration 12142: loss: 0.0006, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9753, 0.9973]
2025-03-11 21:17:54 - Train Iteration 12143: loss: 0.9806, d_k_M range: [0.0000, 0.0083], d_k_M_hat range: [0.0098, 0.9978]
2025-03-11 21:17:54 - Train Iteration 12144: loss: 0.0107, d_k_M range: [0.0012, 0.1007], d_k_M_hat range: [0.9796, 0.9997]
2025-03-11 21:17:55 - Train Iteration 12145: loss: 0.0018, d_k_M range: [0.0000, 0.0084], d_k_M_hat range: [0.9601, 0.9972]
2025-03-11 21:17:55 - Train Iteration 12146: loss: 0.0003, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9826, 0.9999]
2025-03-11 21:17:55 - Train Iteration 12147: loss: 0.0007, d_k_M range: [0.0003, 0.0122], d_k_M_hat range: [0.9769, 0.9996]
2025-03-11 21:17:56 - Train Iteration 12148: loss: 0.0056, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.9280, 0.9984]
2025-03-11 21:17:56 - Train Iteration 12149: loss: 0.0008, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.9727, 0.9978]
2025-03-11 21:17:57 - Train Iteration 12150: loss: 0.2533, d_k_M range: [0.0000, 0.5029], d_k_M_hat range: [0.8276, 0.9996]
2025-03-11 21:17:57 - Train Iteration 12151: loss: 0.0395, d_k_M range: [0.0001, 0.1976], d_k_M_hat range: [0.9723, 0.9999]
2025-03-11 21:17:57 - Train Iteration 12152: loss: 0.0763, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.7240, 0.9994]
2025-03-11 21:17:58 - Train Iteration 12153: loss: 0.0617, d_k_M range: [0.0000, 0.2393], d_k_M_hat range: [0.9849, 0.9994]
2025-03-11 21:17:58 - Train Iteration 12154: loss: 0.0100, d_k_M range: [0.0000, 0.0385], d_k_M_hat range: [0.8998, 0.9999]
2025-03-11 21:17:59 - Train Iteration 12155: loss: 0.0834, d_k_M range: [0.0000, 0.2878], d_k_M_hat range: [0.9768, 0.9997]
2025-03-11 21:17:59 - Train Iteration 12156: loss: 0.0833, d_k_M range: [0.0000, 0.0965], d_k_M_hat range: [0.7162, 0.9998]
2025-03-11 21:18:00 - Train Iteration 12157: loss: 0.0335, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.8178, 0.9977]
2025-03-11 21:18:00 - Train Iteration 12158: loss: 0.2170, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.5342, 0.9994]
2025-03-11 21:18:01 - Train Iteration 12159: loss: 0.0900, d_k_M range: [0.0002, 0.2998], d_k_M_hat range: [0.9928, 1.0000]
2025-03-11 21:18:01 - Train Iteration 12160: loss: 0.0770, d_k_M range: [0.0002, 0.0863], d_k_M_hat range: [0.7226, 0.9997]
2025-03-11 21:18:01 - Train Iteration 12161: loss: 0.0014, d_k_M range: [0.0000, 0.0321], d_k_M_hat range: [0.9838, 0.9993]
2025-03-11 21:18:02 - Train Iteration 12162: loss: 0.0118, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.8912, 0.9967]
2025-03-11 21:18:02 - Train Iteration 12163: loss: 0.0044, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9335, 0.9970]
2025-03-11 21:18:03 - Train Iteration 12164: loss: 0.6503, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.1937, 0.9954]
2025-03-11 21:18:03 - Train Iteration 12165: loss: 0.2234, d_k_M range: [0.0006, 0.4726], d_k_M_hat range: [0.9931, 1.0000]
2025-03-11 21:18:03 - Train Iteration 12166: loss: 0.2834, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.4678, 0.9956]
2025-03-11 21:18:04 - Train Iteration 12167: loss: 0.0075, d_k_M range: [0.0002, 0.0864], d_k_M_hat range: [0.9952, 1.0000]
2025-03-11 21:18:04 - Train Iteration 12168: loss: 0.0141, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.8811, 0.9964]
2025-03-11 21:18:05 - Train Iteration 12169: loss: 0.7270, d_k_M range: [0.0002, 0.8526], d_k_M_hat range: [0.9452, 1.0000]
2025-03-11 21:18:05 - Train Iteration 12170: loss: 0.0026, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9493, 0.9990]
2025-03-11 21:18:06 - Train Iteration 12171: loss: 0.0045, d_k_M range: [0.0000, 0.0669], d_k_M_hat range: [0.9682, 0.9998]
2025-03-11 21:18:06 - Train Iteration 12172: loss: 0.0002, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9861, 1.0000]
2025-03-11 21:18:06 - Train Iteration 12173: loss: 0.0066, d_k_M range: [0.0001, 0.0783], d_k_M_hat range: [0.9266, 0.9999]
2025-03-11 21:18:07 - Train Iteration 12174: loss: 0.0004, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.9799, 0.9992]
2025-03-11 21:18:07 - Train Iteration 12175: loss: 0.0005, d_k_M range: [0.0000, 0.0067], d_k_M_hat range: [0.9852, 0.9993]
2025-03-11 21:18:08 - Train Iteration 12176: loss: 0.0693, d_k_M range: [0.0000, 0.2622], d_k_M_hat range: [0.9837, 1.0000]
2025-03-11 21:18:08 - Train Iteration 12177: loss: 0.0019, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9569, 0.9968]
2025-03-11 21:18:09 - Train Iteration 12178: loss: 0.0020, d_k_M range: [0.0000, 0.0222], d_k_M_hat range: [0.9556, 0.9993]
2025-03-11 21:18:09 - Train Iteration 12179: loss: 0.0422, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.7946, 0.9981]
2025-03-11 21:18:09 - Train Iteration 12180: loss: 0.0027, d_k_M range: [0.0001, 0.0501], d_k_M_hat range: [0.9828, 0.9992]
2025-03-11 21:18:10 - Train Iteration 12181: loss: 0.0017, d_k_M range: [0.0000, 0.0407], d_k_M_hat range: [0.9898, 1.0000]
2025-03-11 21:18:10 - Train Iteration 12182: loss: 0.0011, d_k_M range: [0.0000, 0.0129], d_k_M_hat range: [0.9670, 0.9995]
2025-03-11 21:18:11 - Train Iteration 12183: loss: 0.0006, d_k_M range: [0.0000, 0.0182], d_k_M_hat range: [0.9786, 0.9996]
2025-03-11 21:18:11 - Train Iteration 12184: loss: 0.0033, d_k_M range: [0.0010, 0.0398], d_k_M_hat range: [0.9562, 0.9993]
2025-03-11 21:18:11 - Train Iteration 12185: loss: 0.0132, d_k_M range: [0.0000, 0.0129], d_k_M_hat range: [0.8852, 0.9989]
2025-03-11 21:18:12 - Train Iteration 12186: loss: 0.0008, d_k_M range: [0.0000, 0.0191], d_k_M_hat range: [0.9878, 0.9998]
2025-03-11 21:18:12 - Train Iteration 12187: loss: 0.0004, d_k_M range: [0.0000, 0.0193], d_k_M_hat range: [0.9846, 0.9998]
2025-03-11 21:18:13 - Train Iteration 12188: loss: 0.4116, d_k_M range: [0.0000, 0.6411], d_k_M_hat range: [0.9868, 0.9999]
2025-03-11 21:18:13 - Train Iteration 12189: loss: 0.0138, d_k_M range: [0.0000, 0.0221], d_k_M_hat range: [0.8824, 0.9992]
2025-03-11 21:18:14 - Train Iteration 12190: loss: 0.0591, d_k_M range: [0.0000, 0.0272], d_k_M_hat range: [0.7841, 0.9998]
2025-03-11 21:18:14 - Train Iteration 12191: loss: 0.4298, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.3449, 0.9995]
2025-03-11 21:18:14 - Train Iteration 12192: loss: 0.0852, d_k_M range: [0.0003, 0.2918], d_k_M_hat range: [0.9948, 0.9999]
2025-03-11 21:18:15 - Train Iteration 12193: loss: 0.0055, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9295, 0.9992]
2025-03-11 21:18:15 - Train Iteration 12194: loss: 0.1537, d_k_M range: [0.0003, 0.3920], d_k_M_hat range: [0.9924, 0.9999]
2025-03-11 21:18:15 - Train Iteration 12195: loss: 0.0178, d_k_M range: [0.0001, 0.0094], d_k_M_hat range: [0.8689, 0.9996]
2025-03-11 21:18:16 - Train Iteration 12196: loss: 0.0355, d_k_M range: [0.0000, 0.1845], d_k_M_hat range: [0.9693, 0.9996]
2025-03-11 21:18:16 - Train Iteration 12197: loss: 0.0071, d_k_M range: [0.0003, 0.0799], d_k_M_hat range: [0.9671, 0.9978]
2025-03-11 21:18:17 - Train Iteration 12198: loss: 0.0002, d_k_M range: [0.0000, 0.0119], d_k_M_hat range: [0.9892, 0.9996]
2025-03-11 21:18:17 - Train Iteration 12199: loss: 0.2274, d_k_M range: [0.0000, 0.0117], d_k_M_hat range: [0.5231, 0.9993]
2025-03-11 21:18:17 - Train Iteration 12200: loss: 0.0108, d_k_M range: [0.0000, 0.0988], d_k_M_hat range: [0.9450, 0.9999]
2025-03-11 21:18:18 - Train Iteration 12201: loss: 0.0289, d_k_M range: [0.0000, 0.0159], d_k_M_hat range: [0.8301, 0.9995]
2025-03-11 21:18:18 - Train Iteration 12202: loss: 0.7909, d_k_M range: [0.0000, 0.8891], d_k_M_hat range: [0.8132, 0.9998]
2025-03-11 21:18:18 - Train Iteration 12203: loss: 0.0061, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.9222, 0.9990]
2025-03-11 21:18:19 - Train Iteration 12204: loss: 0.0017, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9592, 0.9955]
2025-03-11 21:18:19 - Train Iteration 12205: loss: 0.0638, d_k_M range: [0.0000, 0.2394], d_k_M_hat range: [0.9831, 0.9996]
2025-03-11 21:18:20 - Train Iteration 12206: loss: 0.0078, d_k_M range: [0.0000, 0.0860], d_k_M_hat range: [0.9651, 0.9992]
2025-03-11 21:18:20 - Train Iteration 12207: loss: 0.0315, d_k_M range: [0.0001, 0.0029], d_k_M_hat range: [0.8237, 0.9997]
2025-03-11 21:18:20 - Train Iteration 12208: loss: 0.0900, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.7000, 0.9982]
2025-03-11 21:18:21 - Train Iteration 12209: loss: 0.0807, d_k_M range: [0.0000, 0.0708], d_k_M_hat range: [0.7159, 0.9996]
2025-03-11 21:18:21 - Train Iteration 12210: loss: 0.0014, d_k_M range: [0.0000, 0.0073], d_k_M_hat range: [0.9623, 0.9992]
2025-03-11 21:18:22 - Train Iteration 12211: loss: 0.0012, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.9659, 0.9999]
2025-03-11 21:18:22 - Train Iteration 12212: loss: 0.0272, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.8355, 0.9997]
2025-03-11 21:18:23 - Train Iteration 12213: loss: 0.0024, d_k_M range: [0.0000, 0.0134], d_k_M_hat range: [0.9512, 0.9974]
2025-03-11 21:18:23 - Train Iteration 12214: loss: 0.0146, d_k_M range: [0.0000, 0.0056], d_k_M_hat range: [0.8794, 0.9998]
2025-03-11 21:18:23 - Train Iteration 12215: loss: 0.0021, d_k_M range: [0.0000, 0.0436], d_k_M_hat range: [0.9639, 0.9993]
2025-03-11 21:18:24 - Train Iteration 12216: loss: 0.0132, d_k_M range: [0.0000, 0.0191], d_k_M_hat range: [0.8852, 0.9992]
2025-03-11 21:18:24 - Train Iteration 12217: loss: 0.1421, d_k_M range: [0.0000, 0.0891], d_k_M_hat range: [0.7121, 0.9995]
2025-03-11 21:18:25 - Train Iteration 12218: loss: 0.0011, d_k_M range: [0.0000, 0.0287], d_k_M_hat range: [0.9830, 0.9997]
2025-03-11 21:18:25 - Train Iteration 12219: loss: 0.0037, d_k_M range: [0.0000, 0.0601], d_k_M_hat range: [0.9856, 0.9993]
2025-03-11 21:18:25 - Train Iteration 12220: loss: 0.0378, d_k_M range: [0.0000, 0.1655], d_k_M_hat range: [0.8055, 0.9992]
2025-03-11 21:18:26 - Train Iteration 12221: loss: 0.0028, d_k_M range: [0.0000, 0.0322], d_k_M_hat range: [0.9481, 0.9994]
2025-03-11 21:18:26 - Train Iteration 12222: loss: 0.0039, d_k_M range: [0.0000, 0.0165], d_k_M_hat range: [0.9372, 0.9999]
2025-03-11 21:18:27 - Train Iteration 12223: loss: 0.0140, d_k_M range: [0.0000, 0.1151], d_k_M_hat range: [0.9066, 0.9991]
2025-03-11 21:18:27 - Train Iteration 12224: loss: 0.0357, d_k_M range: [0.0000, 0.1887], d_k_M_hat range: [0.9588, 0.9999]
2025-03-11 21:18:28 - Train Iteration 12225: loss: 0.0217, d_k_M range: [0.0001, 0.1467], d_k_M_hat range: [0.9922, 0.9995]
2025-03-11 21:18:28 - Train Iteration 12226: loss: 0.0018, d_k_M range: [0.0000, 0.0108], d_k_M_hat range: [0.9572, 0.9984]
2025-03-11 21:18:28 - Train Iteration 12227: loss: 0.2960, d_k_M range: [0.0000, 0.5431], d_k_M_hat range: [0.9536, 0.9995]
2025-03-11 21:18:29 - Train Iteration 12228: loss: 0.0700, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.7355, 0.9964]
2025-03-11 21:18:29 - Train Iteration 12229: loss: 0.0897, d_k_M range: [0.0000, 0.2976], d_k_M_hat range: [0.9841, 0.9999]
2025-03-11 21:18:30 - Train Iteration 12230: loss: 0.0049, d_k_M range: [0.0001, 0.0017], d_k_M_hat range: [0.9304, 0.9968]
2025-03-11 21:18:30 - Train Iteration 12231: loss: 0.0114, d_k_M range: [0.0000, 0.1065], d_k_M_hat range: [0.9921, 0.9999]
2025-03-11 21:18:31 - Train Iteration 12232: loss: 0.3579, d_k_M range: [0.0000, 0.5950], d_k_M_hat range: [0.8244, 0.9997]
2025-03-11 21:18:31 - Train Iteration 12233: loss: 0.0046, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9323, 0.9985]
2025-03-11 21:18:31 - Train Iteration 12234: loss: 0.2218, d_k_M range: [0.0000, 0.0047], d_k_M_hat range: [0.5291, 0.9998]
2025-03-11 21:18:32 - Train Iteration 12235: loss: 0.0023, d_k_M range: [0.0000, 0.0480], d_k_M_hat range: [0.9530, 0.9998]
2025-03-11 21:18:32 - Train Iteration 12236: loss: 0.0632, d_k_M range: [0.0003, 0.2510], d_k_M_hat range: [0.9585, 0.9995]
2025-03-11 21:18:33 - Train Iteration 12237: loss: 0.9840, d_k_M range: [0.0000, 0.0314], d_k_M_hat range: [0.0080, 0.9976]
2025-03-11 21:18:33 - Train Iteration 12238: loss: 0.0075, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9134, 0.9989]
2025-03-11 21:18:33 - Train Iteration 12239: loss: 0.4513, d_k_M range: [0.0000, 0.6701], d_k_M_hat range: [0.9970, 0.9997]
2025-03-11 21:18:34 - Train Iteration 12240: loss: 0.5603, d_k_M range: [0.0000, 0.7485], d_k_M_hat range: [0.7771, 1.0000]
2025-03-11 21:18:34 - Train Iteration 12241: loss: 0.3856, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.3791, 0.9974]
2025-03-11 21:18:35 - Train Iteration 12242: loss: 0.0513, d_k_M range: [0.0001, 0.2258], d_k_M_hat range: [0.9886, 0.9994]
2025-03-11 21:18:35 - Train Iteration 12243: loss: 0.0006, d_k_M range: [0.0000, 0.0252], d_k_M_hat range: [0.9844, 0.9999]
2025-03-11 21:18:35 - Train Iteration 12244: loss: 0.5259, d_k_M range: [0.0000, 0.7241], d_k_M_hat range: [0.9940, 0.9990]
2025-03-11 21:18:36 - Train Iteration 12245: loss: 0.0204, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.8580, 0.9974]
2025-03-11 21:18:36 - Train Iteration 12246: loss: 0.1375, d_k_M range: [0.0008, 0.3704], d_k_M_hat range: [0.9984, 0.9999]
2025-03-11 21:18:37 - Train Iteration 12247: loss: 0.7938, d_k_M range: [0.0000, 0.8906], d_k_M_hat range: [0.9011, 0.9997]
2025-03-11 21:18:37 - Train Iteration 12248: loss: 0.0003, d_k_M range: [0.0000, 0.0169], d_k_M_hat range: [0.9899, 0.9993]
2025-03-11 21:18:38 - Train Iteration 12249: loss: 0.9662, d_k_M range: [0.0000, 0.9827], d_k_M_hat range: [0.9378, 0.9998]
2025-03-11 21:18:38 - Train Iteration 12250: loss: 0.4287, d_k_M range: [0.0000, 0.6544], d_k_M_hat range: [0.9945, 0.9998]
2025-03-11 21:18:38 - Train Iteration 12251: loss: 0.0001, d_k_M range: [0.0001, 0.0066], d_k_M_hat range: [0.9924, 0.9997]
2025-03-11 21:18:39 - Train Iteration 12252: loss: 0.0501, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.7762, 0.9929]
2025-03-11 21:18:39 - Train Iteration 12253: loss: 0.9049, d_k_M range: [0.0000, 0.9509], d_k_M_hat range: [0.9737, 0.9999]
2025-03-11 21:18:40 - Train Iteration 12254: loss: 0.0084, d_k_M range: [0.0000, 0.0888], d_k_M_hat range: [0.9388, 0.9992]
2025-03-11 21:18:40 - Train Iteration 12255: loss: 0.0343, d_k_M range: [0.0000, 0.1844], d_k_M_hat range: [0.9308, 0.9993]
2025-03-11 21:18:41 - Train Iteration 12256: loss: 0.0005, d_k_M range: [0.0000, 0.0073], d_k_M_hat range: [0.9776, 0.9983]
2025-03-11 21:18:41 - Train Iteration 12257: loss: 0.0027, d_k_M range: [0.0000, 0.0509], d_k_M_hat range: [0.9795, 0.9991]
2025-03-11 21:18:41 - Train Iteration 12258: loss: 0.0001, d_k_M range: [0.0003, 0.0055], d_k_M_hat range: [0.9891, 0.9997]
2025-03-11 21:18:42 - Train Iteration 12259: loss: 0.0023, d_k_M range: [0.0001, 0.0246], d_k_M_hat range: [0.9769, 0.9987]
2025-03-11 21:18:42 - Train Iteration 12260: loss: 0.0549, d_k_M range: [0.0000, 0.2340], d_k_M_hat range: [0.9661, 0.9997]
2025-03-11 21:18:43 - Train Iteration 12261: loss: 0.0845, d_k_M range: [0.0000, 0.0449], d_k_M_hat range: [0.7093, 0.9994]
2025-03-11 21:18:43 - Train Iteration 12262: loss: 0.0013, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.9634, 0.9971]
2025-03-11 21:18:43 - Train Iteration 12263: loss: 0.0002, d_k_M range: [0.0001, 0.0060], d_k_M_hat range: [0.9916, 0.9996]
2025-03-11 21:18:44 - Train Iteration 12264: loss: 0.0029, d_k_M range: [0.0000, 0.0507], d_k_M_hat range: [0.9589, 0.9980]
2025-03-11 21:18:44 - Train Iteration 12265: loss: 0.0005, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.9796, 0.9992]
2025-03-11 21:18:45 - Train Iteration 12266: loss: 0.6067, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.2212, 0.9995]
2025-03-11 21:18:45 - Train Iteration 12267: loss: 0.0014, d_k_M range: [0.0000, 0.0055], d_k_M_hat range: [0.9622, 0.9998]
2025-03-11 21:18:45 - Train Iteration 12268: loss: 0.0068, d_k_M range: [0.0000, 0.0817], d_k_M_hat range: [0.9935, 1.0000]
2025-03-11 21:18:46 - Train Iteration 12269: loss: 0.0021, d_k_M range: [0.0000, 0.0129], d_k_M_hat range: [0.9542, 0.9995]
2025-03-11 21:18:46 - Train Iteration 12270: loss: 0.0289, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.8302, 0.9984]
2025-03-11 21:18:47 - Train Iteration 12271: loss: 0.0024, d_k_M range: [0.0000, 0.0464], d_k_M_hat range: [0.9844, 0.9999]
2025-03-11 21:18:47 - Train Iteration 12272: loss: 0.4450, d_k_M range: [0.0000, 0.6652], d_k_M_hat range: [0.9859, 0.9997]
2025-03-11 21:18:48 - Train Iteration 12273: loss: 0.0020, d_k_M range: [0.0002, 0.0200], d_k_M_hat range: [0.9608, 0.9992]
2025-03-11 21:18:48 - Train Iteration 12274: loss: 0.0019, d_k_M range: [0.0000, 0.0258], d_k_M_hat range: [0.9701, 0.9994]
2025-03-11 21:18:48 - Train Iteration 12275: loss: 0.0882, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.7031, 0.9999]
2025-03-11 21:18:49 - Train Iteration 12276: loss: 0.0001, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9946, 0.9998]
2025-03-11 21:18:49 - Train Iteration 12277: loss: 0.0073, d_k_M range: [0.0000, 0.0135], d_k_M_hat range: [0.9233, 0.9999]
2025-03-11 21:18:50 - Train Iteration 12278: loss: 0.0002, d_k_M range: [0.0000, 0.0145], d_k_M_hat range: [0.9947, 0.9998]
2025-03-11 21:18:50 - Train Iteration 12279: loss: 0.0354, d_k_M range: [0.0000, 0.1877], d_k_M_hat range: [0.9074, 0.9994]
2025-03-11 21:18:50 - Train Iteration 12280: loss: 0.0015, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9629, 0.9990]
2025-03-11 21:18:51 - Train Iteration 12281: loss: 0.0261, d_k_M range: [0.0001, 0.1609], d_k_M_hat range: [0.9684, 1.0000]
2025-03-11 21:18:51 - Train Iteration 12282: loss: 0.0042, d_k_M range: [0.0003, 0.0647], d_k_M_hat range: [0.9983, 0.9999]
2025-03-11 21:18:52 - Train Iteration 12283: loss: 0.0033, d_k_M range: [0.0002, 0.0136], d_k_M_hat range: [0.9433, 0.9998]
2025-03-11 21:18:52 - Train Iteration 12284: loss: 0.1033, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.6803, 0.9995]
2025-03-11 21:18:53 - Train Iteration 12285: loss: 0.0008, d_k_M range: [0.0001, 0.0249], d_k_M_hat range: [0.9735, 0.9996]
2025-03-11 21:18:53 - Train Iteration 12286: loss: 0.0044, d_k_M range: [0.0000, 0.0290], d_k_M_hat range: [0.9335, 0.9999]
2025-03-11 21:18:53 - Train Iteration 12287: loss: 0.0289, d_k_M range: [0.0000, 0.1699], d_k_M_hat range: [0.9697, 0.9999]
2025-03-11 21:18:54 - Train Iteration 12288: loss: 0.0277, d_k_M range: [0.0001, 0.1597], d_k_M_hat range: [0.9932, 0.9998]
2025-03-11 21:18:54 - Train Iteration 12289: loss: 0.0509, d_k_M range: [0.0000, 0.2254], d_k_M_hat range: [0.9000, 0.9997]
2025-03-11 21:18:54 - Train Iteration 12290: loss: 0.0018, d_k_M range: [0.0000, 0.0421], d_k_M_hat range: [0.9773, 0.9998]
2025-03-11 21:18:55 - Train Iteration 12291: loss: 0.1712, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.5864, 0.9991]
2025-03-11 21:18:55 - Train Iteration 12292: loss: 0.0148, d_k_M range: [0.0000, 0.1144], d_k_M_hat range: [0.9803, 0.9997]
2025-03-11 21:18:56 - Train Iteration 12293: loss: 0.0004, d_k_M range: [0.0000, 0.0130], d_k_M_hat range: [0.9874, 0.9996]
2025-03-11 21:18:56 - Train Iteration 12294: loss: 0.0588, d_k_M range: [0.0000, 0.2420], d_k_M_hat range: [0.9918, 1.0000]
2025-03-11 21:18:56 - Train Iteration 12295: loss: 0.0051, d_k_M range: [0.0001, 0.0704], d_k_M_hat range: [0.9349, 0.9998]
2025-03-11 21:18:57 - Train Iteration 12296: loss: 0.1754, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.5812, 0.9997]
2025-03-11 21:18:57 - Train Iteration 12297: loss: 0.1760, d_k_M range: [0.0000, 0.4194], d_k_M_hat range: [0.9802, 0.9999]
2025-03-11 21:18:58 - Train Iteration 12298: loss: 0.0991, d_k_M range: [0.0001, 0.0517], d_k_M_hat range: [0.7369, 0.9997]
2025-03-11 21:18:58 - Train Iteration 12299: loss: 0.0800, d_k_M range: [0.0000, 0.2805], d_k_M_hat range: [0.9872, 1.0000]
2025-03-11 21:18:59 - Train Iteration 12300: loss: 0.3590, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.4013, 0.9864]
2025-03-11 21:18:59 - Train Iteration 12301: loss: 0.0093, d_k_M range: [0.0001, 0.0555], d_k_M_hat range: [0.9070, 0.9998]
2025-03-11 21:18:59 - Train Iteration 12302: loss: 0.0031, d_k_M range: [0.0000, 0.0258], d_k_M_hat range: [0.9702, 0.9998]
2025-03-11 21:19:00 - Train Iteration 12303: loss: 0.0958, d_k_M range: [0.0000, 0.1343], d_k_M_hat range: [0.6904, 0.9994]
2025-03-11 21:19:00 - Train Iteration 12304: loss: 0.0040, d_k_M range: [0.0000, 0.0629], d_k_M_hat range: [0.9374, 0.9998]
2025-03-11 21:19:01 - Train Iteration 12305: loss: 0.2699, d_k_M range: [0.0000, 0.0097], d_k_M_hat range: [0.4902, 0.9979]
2025-03-11 21:19:01 - Train Iteration 12306: loss: 0.8640, d_k_M range: [0.0001, 0.9295], d_k_M_hat range: [0.9970, 0.9999]
2025-03-11 21:19:01 - Train Iteration 12307: loss: 0.0040, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9373, 0.9994]
2025-03-11 21:19:02 - Train Iteration 12308: loss: 0.0051, d_k_M range: [0.0000, 0.0667], d_k_M_hat range: [0.9732, 0.9996]
2025-03-11 21:19:02 - Train Iteration 12309: loss: 0.0253, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.8410, 0.9986]
2025-03-11 21:19:03 - Train Iteration 12310: loss: 0.0009, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9705, 0.9992]
2025-03-11 21:19:03 - Train Iteration 12311: loss: 0.0040, d_k_M range: [0.0000, 0.0105], d_k_M_hat range: [0.9365, 0.9994]
2025-03-11 21:19:04 - Train Iteration 12312: loss: 0.0487, d_k_M range: [0.0000, 0.2192], d_k_M_hat range: [0.9074, 0.9999]
2025-03-11 21:19:04 - Train Iteration 12313: loss: 0.0103, d_k_M range: [0.0000, 0.0592], d_k_M_hat range: [0.8987, 0.9983]
2025-03-11 21:19:04 - Train Iteration 12314: loss: 0.0022, d_k_M range: [0.0000, 0.0451], d_k_M_hat range: [0.9717, 0.9987]
2025-03-11 21:19:05 - Train Iteration 12315: loss: 0.2451, d_k_M range: [0.0002, 0.4939], d_k_M_hat range: [0.9073, 0.9997]
2025-03-11 21:19:05 - Train Iteration 12316: loss: 0.0040, d_k_M range: [0.0000, 0.0621], d_k_M_hat range: [0.9511, 0.9997]
2025-03-11 21:19:06 - Train Iteration 12317: loss: 0.0007, d_k_M range: [0.0000, 0.0212], d_k_M_hat range: [0.9771, 0.9990]
2025-03-11 21:19:06 - Train Iteration 12318: loss: 0.0009, d_k_M range: [0.0000, 0.0165], d_k_M_hat range: [0.9868, 0.9997]
2025-03-11 21:19:06 - Train Iteration 12319: loss: 0.0008, d_k_M range: [0.0000, 0.0279], d_k_M_hat range: [0.9924, 0.9999]
2025-03-11 21:19:07 - Train Iteration 12320: loss: 0.0007, d_k_M range: [0.0002, 0.0086], d_k_M_hat range: [0.9738, 0.9999]
2025-03-11 21:19:07 - Train Iteration 12321: loss: 0.0138, d_k_M range: [0.0003, 0.0966], d_k_M_hat range: [0.9687, 0.9994]
2025-03-11 21:19:08 - Train Iteration 12322: loss: 0.3857, d_k_M range: [0.0000, 0.6210], d_k_M_hat range: [0.9664, 1.0000]
2025-03-11 21:19:08 - Train Iteration 12323: loss: 0.4817, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.3060, 0.9999]
2025-03-11 21:19:08 - Train Iteration 12324: loss: 0.8455, d_k_M range: [0.0003, 0.9192], d_k_M_hat range: [0.9980, 1.0000]
2025-03-11 21:19:09 - Train Iteration 12325: loss: 0.0191, d_k_M range: [0.0000, 0.1382], d_k_M_hat range: [0.9539, 0.9999]
2025-03-11 21:19:09 - Train Iteration 12326: loss: 0.0084, d_k_M range: [0.0000, 0.0913], d_k_M_hat range: [0.9394, 0.9997]
2025-03-11 21:19:10 - Train Iteration 12327: loss: 0.1503, d_k_M range: [0.0000, 0.0090], d_k_M_hat range: [0.6124, 0.9977]
2025-03-11 21:19:10 - Train Iteration 12328: loss: 0.0004, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9816, 0.9984]
2025-03-11 21:19:11 - Train Iteration 12329: loss: 0.0003, d_k_M range: [0.0000, 0.0126], d_k_M_hat range: [0.9826, 0.9998]
2025-03-11 21:19:11 - Train Iteration 12330: loss: 0.0012, d_k_M range: [0.0000, 0.0345], d_k_M_hat range: [0.9769, 1.0000]
2025-03-11 21:19:11 - Train Iteration 12331: loss: 0.0006, d_k_M range: [0.0000, 0.0099], d_k_M_hat range: [0.9767, 0.9994]
2025-03-11 21:19:12 - Train Iteration 12332: loss: 0.8688, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.0679, 0.9960]
2025-03-11 21:19:12 - Train Iteration 12333: loss: 0.1065, d_k_M range: [0.0000, 0.0467], d_k_M_hat range: [0.6737, 0.9998]
2025-03-11 21:19:13 - Train Iteration 12334: loss: 0.0027, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.9488, 0.9992]
2025-03-11 21:19:13 - Train Iteration 12335: loss: 0.5038, d_k_M range: [0.0002, 0.7096], d_k_M_hat range: [0.9039, 0.9998]
2025-03-11 21:19:13 - Train Iteration 12336: loss: 0.0012, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9655, 1.0000]
2025-03-11 21:19:14 - Train Iteration 12337: loss: 0.0625, d_k_M range: [0.0000, 0.0238], d_k_M_hat range: [0.7499, 0.9980]
2025-03-11 21:19:14 - Train Iteration 12338: loss: 0.0010, d_k_M range: [0.0000, 0.0160], d_k_M_hat range: [0.9694, 0.9996]
2025-03-11 21:19:15 - Train Iteration 12339: loss: 0.0024, d_k_M range: [0.0000, 0.0277], d_k_M_hat range: [0.9784, 0.9995]
2025-03-11 21:19:15 - Train Iteration 12340: loss: 0.0631, d_k_M range: [0.0001, 0.0035], d_k_M_hat range: [0.7492, 0.9996]
2025-03-11 21:19:16 - Train Iteration 12341: loss: 0.0007, d_k_M range: [0.0000, 0.0097], d_k_M_hat range: [0.9829, 0.9997]
2025-03-11 21:19:16 - Train Iteration 12342: loss: 0.0711, d_k_M range: [0.0001, 0.0618], d_k_M_hat range: [0.7429, 0.9999]
2025-03-11 21:19:16 - Train Iteration 12343: loss: 0.0076, d_k_M range: [0.0005, 0.0867], d_k_M_hat range: [0.9931, 0.9999]
2025-03-11 21:19:17 - Train Iteration 12344: loss: 0.2226, d_k_M range: [0.0000, 0.4648], d_k_M_hat range: [0.9738, 0.9990]
2025-03-11 21:19:17 - Train Iteration 12345: loss: 0.0028, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9473, 0.9991]
2025-03-11 21:19:17 - Train Iteration 12346: loss: 0.0014, d_k_M range: [0.0000, 0.0298], d_k_M_hat range: [0.9732, 0.9968]
2025-03-11 21:19:18 - Train Iteration 12347: loss: 0.0041, d_k_M range: [0.0000, 0.0632], d_k_M_hat range: [0.9728, 0.9995]
2025-03-11 21:19:18 - Train Iteration 12348: loss: 0.0074, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.9144, 0.9993]
2025-03-11 21:19:19 - Train Iteration 12349: loss: 0.0008, d_k_M range: [0.0000, 0.0203], d_k_M_hat range: [0.9897, 0.9992]
2025-03-11 21:19:19 - Train Iteration 12350: loss: 0.2900, d_k_M range: [0.0000, 0.0601], d_k_M_hat range: [0.4616, 0.9999]
2025-03-11 21:19:19 - Train Iteration 12351: loss: 0.1546, d_k_M range: [0.0003, 0.3931], d_k_M_hat range: [0.9967, 0.9999]
2025-03-11 21:19:20 - Train Iteration 12352: loss: 0.0068, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9173, 0.9987]
2025-03-11 21:19:20 - Train Iteration 12353: loss: 0.0036, d_k_M range: [0.0000, 0.0565], d_k_M_hat range: [0.9851, 0.9998]
2025-03-11 21:19:21 - Train Iteration 12354: loss: 0.0381, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.8047, 0.9996]
2025-03-11 21:19:21 - Train Iteration 12355: loss: 0.1125, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.6647, 0.9992]
2025-03-11 21:19:21 - Train Iteration 12356: loss: 0.0025, d_k_M range: [0.0000, 0.0338], d_k_M_hat range: [0.9497, 0.9993]
2025-03-11 21:19:22 - Train Iteration 12357: loss: 0.0136, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.8833, 0.9987]
2025-03-11 21:19:22 - Train Iteration 12358: loss: 0.0847, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.7090, 0.9977]
2025-03-11 21:19:23 - Train Iteration 12359: loss: 0.0187, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.8632, 0.9983]
2025-03-11 21:19:23 - Train Iteration 12360: loss: 0.0069, d_k_M range: [0.0000, 0.0200], d_k_M_hat range: [0.9172, 0.9951]
2025-03-11 21:19:24 - Train Iteration 12361: loss: 0.0228, d_k_M range: [0.0000, 0.0073], d_k_M_hat range: [0.8492, 0.9967]
2025-03-11 21:19:24 - Train Iteration 12362: loss: 0.1145, d_k_M range: [0.0000, 0.3357], d_k_M_hat range: [0.9873, 0.9999]
2025-03-11 21:19:24 - Train Iteration 12363: loss: 0.0032, d_k_M range: [0.0000, 0.0545], d_k_M_hat range: [0.9896, 0.9993]
2025-03-11 21:19:25 - Train Iteration 12364: loss: 0.0418, d_k_M range: [0.0000, 0.2041], d_k_M_hat range: [0.9418, 0.9997]
2025-03-11 21:19:25 - Train Iteration 12365: loss: 0.2911, d_k_M range: [0.0000, 0.1372], d_k_M_hat range: [0.4610, 0.9999]
2025-03-11 21:19:26 - Train Iteration 12366: loss: 0.0489, d_k_M range: [0.0000, 0.0585], d_k_M_hat range: [0.7793, 0.9999]
2025-03-11 21:19:26 - Train Iteration 12367: loss: 0.1352, d_k_M range: [0.0000, 0.3659], d_k_M_hat range: [0.9479, 0.9999]
2025-03-11 21:19:26 - Train Iteration 12368: loss: 0.0004, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9816, 0.9997]
2025-03-11 21:19:27 - Train Iteration 12369: loss: 0.2853, d_k_M range: [0.0000, 0.5334], d_k_M_hat range: [0.8918, 0.9992]
2025-03-11 21:19:27 - Train Iteration 12370: loss: 0.0004, d_k_M range: [0.0000, 0.0131], d_k_M_hat range: [0.9809, 0.9998]
2025-03-11 21:19:28 - Train Iteration 12371: loss: 0.0085, d_k_M range: [0.0001, 0.0915], d_k_M_hat range: [0.9861, 1.0000]
2025-03-11 21:19:28 - Train Iteration 12372: loss: 0.1197, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.6541, 0.9939]
2025-03-11 21:19:29 - Train Iteration 12373: loss: 0.0021, d_k_M range: [0.0000, 0.0235], d_k_M_hat range: [0.9612, 0.9999]
2025-03-11 21:19:29 - Train Iteration 12374: loss: 0.0194, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.8606, 0.9960]
2025-03-11 21:19:29 - Train Iteration 12375: loss: 0.0013, d_k_M range: [0.0000, 0.0361], d_k_M_hat range: [0.9949, 0.9999]
2025-03-11 21:19:30 - Train Iteration 12376: loss: 0.0065, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9193, 0.9932]
2025-03-11 21:19:30 - Train Iteration 12377: loss: 0.0542, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.7673, 0.9999]
2025-03-11 21:19:31 - Train Iteration 12378: loss: 0.0214, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.8537, 0.9997]
2025-03-11 21:19:31 - Train Iteration 12379: loss: 0.0030, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9449, 0.9990]
2025-03-11 21:19:31 - Train Iteration 12380: loss: 0.0231, d_k_M range: [0.0000, 0.0529], d_k_M_hat range: [0.8736, 0.9999]
2025-03-11 21:19:32 - Train Iteration 12381: loss: 0.0143, d_k_M range: [0.0001, 0.0275], d_k_M_hat range: [0.8837, 0.9995]
2025-03-11 21:19:32 - Train Iteration 12382: loss: 0.0005, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9773, 0.9997]
2025-03-11 21:19:33 - Train Iteration 12383: loss: 0.0003, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9839, 1.0000]
2025-03-11 21:19:33 - Train Iteration 12384: loss: 0.0006, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.9770, 0.9993]
2025-03-11 21:19:33 - Train Iteration 12385: loss: 0.0009, d_k_M range: [0.0000, 0.0083], d_k_M_hat range: [0.9699, 1.0000]
2025-03-11 21:19:34 - Train Iteration 12386: loss: 0.0087, d_k_M range: [0.0001, 0.0922], d_k_M_hat range: [0.9882, 0.9997]
2025-03-11 21:19:34 - Train Iteration 12387: loss: 0.0008, d_k_M range: [0.0001, 0.0249], d_k_M_hat range: [0.9714, 0.9995]
2025-03-11 21:19:35 - Train Iteration 12388: loss: 0.0021, d_k_M range: [0.0000, 0.0126], d_k_M_hat range: [0.9549, 0.9996]
2025-03-11 21:19:35 - Train Iteration 12389: loss: 0.5834, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.2362, 0.9961]
2025-03-11 21:19:35 - Train Iteration 12390: loss: 0.5291, d_k_M range: [0.0000, 0.7273], d_k_M_hat range: [0.9162, 1.0000]
2025-03-11 21:19:36 - Train Iteration 12391: loss: 0.2478, d_k_M range: [0.0000, 0.4977], d_k_M_hat range: [0.9524, 0.9999]
2025-03-11 21:19:36 - Train Iteration 12392: loss: 0.0080, d_k_M range: [0.0000, 0.0088], d_k_M_hat range: [0.9108, 0.9985]
2025-03-11 21:19:37 - Train Iteration 12393: loss: 0.0058, d_k_M range: [0.0000, 0.0143], d_k_M_hat range: [0.9243, 0.9999]
2025-03-11 21:19:37 - Train Iteration 12394: loss: 0.0133, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.8849, 0.9997]
2025-03-11 21:19:37 - Train Iteration 12395: loss: 0.0001, d_k_M range: [0.0001, 0.0019], d_k_M_hat range: [0.9919, 1.0000]
2025-03-11 21:19:38 - Train Iteration 12396: loss: 0.0525, d_k_M range: [0.0000, 0.0097], d_k_M_hat range: [0.7710, 0.9996]
2025-03-11 21:19:38 - Train Iteration 12397: loss: 0.0961, d_k_M range: [0.0001, 0.3099], d_k_M_hat range: [0.9841, 1.0000]
2025-03-11 21:19:39 - Train Iteration 12398: loss: 0.0005, d_k_M range: [0.0003, 0.0089], d_k_M_hat range: [0.9859, 0.9995]
2025-03-11 21:19:39 - Train Iteration 12399: loss: 0.2406, d_k_M range: [0.0000, 0.1638], d_k_M_hat range: [0.5095, 0.9973]
2025-03-11 21:19:39 - Train Iteration 12400: loss: 0.0062, d_k_M range: [0.0000, 0.0534], d_k_M_hat range: [0.9211, 0.9999]
2025-03-11 21:19:40 - Train Iteration 12401: loss: 0.0359, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.8113, 0.9982]
2025-03-11 21:19:40 - Train Iteration 12402: loss: 0.0182, d_k_M range: [0.0000, 0.1346], d_k_M_hat range: [0.9939, 0.9997]
2025-03-11 21:19:41 - Train Iteration 12403: loss: 0.0071, d_k_M range: [0.0000, 0.0096], d_k_M_hat range: [0.9158, 0.9999]
2025-03-11 21:19:41 - Train Iteration 12404: loss: 0.0322, d_k_M range: [0.0000, 0.1729], d_k_M_hat range: [0.9756, 0.9999]
2025-03-11 21:19:41 - Train Iteration 12405: loss: 0.0549, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.7658, 0.9999]
2025-03-11 21:19:42 - Train Iteration 12406: loss: 0.4725, d_k_M range: [0.0008, 0.6855], d_k_M_hat range: [0.9901, 0.9999]
2025-03-11 21:19:42 - Train Iteration 12407: loss: 0.0019, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.9567, 0.9998]
2025-03-11 21:19:42 - Train Iteration 12408: loss: 0.0037, d_k_M range: [0.0000, 0.0502], d_k_M_hat range: [0.9413, 0.9999]
2025-03-11 21:19:43 - Train Iteration 12409: loss: 0.0426, d_k_M range: [0.0001, 0.2054], d_k_M_hat range: [0.9473, 0.9993]
2025-03-11 21:19:43 - Train Iteration 12410: loss: 0.0144, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.8802, 0.9977]
2025-03-11 21:19:44 - Train Iteration 12411: loss: 0.0010, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9682, 0.9976]
2025-03-11 21:19:44 - Train Iteration 12412: loss: 0.0001, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9947, 0.9999]
2025-03-11 21:19:45 - Train Iteration 12413: loss: 0.2964, d_k_M range: [0.0001, 0.5444], d_k_M_hat range: [0.9721, 0.9999]
2025-03-11 21:19:45 - Train Iteration 12414: loss: 0.0011, d_k_M range: [0.0000, 0.0172], d_k_M_hat range: [0.9668, 0.9995]
2025-03-11 21:19:46 - Train Iteration 12415: loss: 0.0983, d_k_M range: [0.0000, 0.3126], d_k_M_hat range: [0.9019, 0.9994]
2025-03-11 21:19:46 - Train Iteration 12416: loss: 0.0492, d_k_M range: [0.0001, 0.0328], d_k_M_hat range: [0.7796, 0.9999]
2025-03-11 21:19:46 - Train Iteration 12417: loss: 0.0014, d_k_M range: [0.0002, 0.0367], d_k_M_hat range: [0.9814, 0.9992]
2025-03-11 21:19:47 - Train Iteration 12418: loss: 0.0016, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9615, 0.9994]
2025-03-11 21:19:47 - Train Iteration 12419: loss: 0.0010, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9684, 0.9989]
2025-03-11 21:19:48 - Train Iteration 12420: loss: 0.0017, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9592, 0.9982]
2025-03-11 21:19:48 - Train Iteration 12421: loss: 0.0027, d_k_M range: [0.0001, 0.0022], d_k_M_hat range: [0.9482, 0.9997]
2025-03-11 21:19:48 - Train Iteration 12422: loss: 0.4179, d_k_M range: [0.0000, 0.0083], d_k_M_hat range: [0.3552, 0.9998]
2025-03-11 21:19:49 - Train Iteration 12423: loss: 0.0314, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.8228, 0.9999]
2025-03-11 21:19:49 - Train Iteration 12424: loss: 0.0049, d_k_M range: [0.0000, 0.0695], d_k_M_hat range: [0.9506, 0.9994]
2025-03-11 21:19:50 - Train Iteration 12425: loss: 0.1443, d_k_M range: [0.0000, 0.0695], d_k_M_hat range: [0.6201, 0.9995]
2025-03-11 21:19:50 - Train Iteration 12426: loss: 0.0117, d_k_M range: [0.0000, 0.0125], d_k_M_hat range: [0.8917, 0.9998]
2025-03-11 21:19:51 - Train Iteration 12427: loss: 0.0001, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9961, 0.9995]
2025-03-11 21:19:51 - Train Iteration 12428: loss: 0.0063, d_k_M range: [0.0000, 0.0703], d_k_M_hat range: [0.9205, 0.9997]
2025-03-11 21:19:51 - Train Iteration 12429: loss: 0.0003, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.9866, 0.9984]
2025-03-11 21:19:52 - Train Iteration 12430: loss: 0.0041, d_k_M range: [0.0000, 0.0477], d_k_M_hat range: [0.9357, 0.9995]
2025-03-11 21:19:52 - Train Iteration 12431: loss: 0.0075, d_k_M range: [0.0000, 0.0867], d_k_M_hat range: [0.9425, 1.0000]
2025-03-11 21:19:53 - Train Iteration 12432: loss: 0.0006, d_k_M range: [0.0001, 0.0179], d_k_M_hat range: [0.9750, 1.0000]
2025-03-11 21:19:53 - Train Iteration 12433: loss: 0.0037, d_k_M range: [0.0000, 0.0606], d_k_M_hat range: [0.9689, 0.9999]
2025-03-11 21:19:53 - Train Iteration 12434: loss: 0.0002, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.9879, 0.9996]
2025-03-11 21:19:54 - Train Iteration 12435: loss: 0.0054, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9264, 0.9969]
2025-03-11 21:19:54 - Train Iteration 12436: loss: 0.0326, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.8195, 0.9995]
2025-03-11 21:19:55 - Train Iteration 12437: loss: 0.0158, d_k_M range: [0.0000, 0.1176], d_k_M_hat range: [0.9920, 1.0000]
2025-03-11 21:19:55 - Train Iteration 12438: loss: 0.0069, d_k_M range: [0.0000, 0.0743], d_k_M_hat range: [0.9686, 0.9999]
2025-03-11 21:19:56 - Train Iteration 12439: loss: 0.0678, d_k_M range: [0.0000, 0.0106], d_k_M_hat range: [0.7396, 0.9994]
2025-03-11 21:19:56 - Train Iteration 12440: loss: 0.0030, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.9456, 0.9997]
2025-03-11 21:19:56 - Train Iteration 12441: loss: 0.3288, d_k_M range: [0.0000, 0.5730], d_k_M_hat range: [0.9985, 1.0000]
2025-03-11 21:19:57 - Train Iteration 12442: loss: 0.0006, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.9750, 0.9996]
2025-03-11 21:19:57 - Train Iteration 12443: loss: 0.0406, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.7985, 0.9982]
2025-03-11 21:19:58 - Train Iteration 12444: loss: 0.0016, d_k_M range: [0.0001, 0.0392], d_k_M_hat range: [0.9725, 0.9999]
2025-03-11 21:19:58 - Train Iteration 12445: loss: 0.0081, d_k_M range: [0.0000, 0.0874], d_k_M_hat range: [0.9122, 0.9999]
2025-03-11 21:19:58 - Train Iteration 12446: loss: 0.0040, d_k_M range: [0.0000, 0.0613], d_k_M_hat range: [0.9608, 0.9989]
2025-03-11 21:19:59 - Train Iteration 12447: loss: 0.0001, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.9929, 0.9998]
2025-03-11 21:19:59 - Train Iteration 12448: loss: 0.0004, d_k_M range: [0.0000, 0.0175], d_k_M_hat range: [0.9950, 0.9997]
2025-03-11 21:20:00 - Train Iteration 12449: loss: 0.0870, d_k_M range: [0.0000, 0.2948], d_k_M_hat range: [0.9942, 0.9998]
2025-03-11 21:20:00 - Train Iteration 12450: loss: 0.0117, d_k_M range: [0.0000, 0.0433], d_k_M_hat range: [0.8922, 0.9974]
2025-03-11 21:20:01 - Train Iteration 12451: loss: 0.0637, d_k_M range: [0.0002, 0.2522], d_k_M_hat range: [0.9579, 0.9999]
2025-03-11 21:20:01 - Train Iteration 12452: loss: 0.6050, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.2222, 0.9993]
2025-03-11 21:20:01 - Train Iteration 12453: loss: 0.0019, d_k_M range: [0.0000, 0.0412], d_k_M_hat range: [0.9853, 0.9999]
2025-03-11 21:20:02 - Train Iteration 12454: loss: 0.0032, d_k_M range: [0.0000, 0.0561], d_k_M_hat range: [0.9758, 0.9999]
2025-03-11 21:20:02 - Train Iteration 12455: loss: 0.0001, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.9878, 0.9996]
2025-03-11 21:20:03 - Train Iteration 12456: loss: 0.0057, d_k_M range: [0.0000, 0.0753], d_k_M_hat range: [0.9343, 1.0000]
2025-03-11 21:20:03 - Train Iteration 12457: loss: 0.0270, d_k_M range: [0.0000, 0.1634], d_k_M_hat range: [0.9924, 0.9995]
2025-03-11 21:20:03 - Train Iteration 12458: loss: 0.0145, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.8799, 0.9985]
2025-03-11 21:20:04 - Train Iteration 12459: loss: 0.3912, d_k_M range: [0.0000, 0.6250], d_k_M_hat range: [0.9659, 1.0000]
2025-03-11 21:20:04 - Train Iteration 12460: loss: 0.0211, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.8546, 0.9902]
2025-03-11 21:20:05 - Train Iteration 12461: loss: 0.0009, d_k_M range: [0.0000, 0.0217], d_k_M_hat range: [0.9857, 0.9994]
2025-03-11 21:20:05 - Train Iteration 12462: loss: 0.0165, d_k_M range: [0.0000, 0.0109], d_k_M_hat range: [0.8716, 0.9999]
2025-03-11 21:20:06 - Train Iteration 12463: loss: 0.2467, d_k_M range: [0.0000, 0.4966], d_k_M_hat range: [0.9852, 0.9999]
2025-03-11 21:20:06 - Train Iteration 12464: loss: 0.0260, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.8388, 0.9961]
2025-03-11 21:20:06 - Train Iteration 12465: loss: 0.0032, d_k_M range: [0.0000, 0.0089], d_k_M_hat range: [0.9434, 0.9999]
2025-03-11 21:20:07 - Train Iteration 12466: loss: 0.2828, d_k_M range: [0.0000, 0.5314], d_k_M_hat range: [0.9478, 1.0000]
2025-03-11 21:20:07 - Train Iteration 12467: loss: 0.0013, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.9637, 0.9983]
2025-03-11 21:20:08 - Train Iteration 12468: loss: 0.0045, d_k_M range: [0.0000, 0.0048], d_k_M_hat range: [0.9330, 0.9995]
2025-03-11 21:20:08 - Train Iteration 12469: loss: 0.0191, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.8618, 0.9971]
2025-03-11 21:20:09 - Train Iteration 12470: loss: 0.1548, d_k_M range: [0.0000, 0.0072], d_k_M_hat range: [0.6066, 0.9991]
2025-03-11 21:20:09 - Train Iteration 12471: loss: 0.0012, d_k_M range: [0.0000, 0.0167], d_k_M_hat range: [0.9813, 0.9996]
2025-03-11 21:20:09 - Train Iteration 12472: loss: 0.0012, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.9660, 0.9999]
2025-03-11 21:20:10 - Train Iteration 12473: loss: 0.0486, d_k_M range: [0.0001, 0.2143], d_k_M_hat range: [0.9783, 0.9999]
2025-03-11 21:20:10 - Train Iteration 12474: loss: 0.0044, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.9341, 0.9984]
2025-03-11 21:20:11 - Train Iteration 12475: loss: 0.1809, d_k_M range: [0.0000, 0.4240], d_k_M_hat range: [0.9456, 0.9998]
2025-03-11 21:20:11 - Train Iteration 12476: loss: 0.0125, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.8882, 0.9995]
2025-03-11 21:20:12 - Train Iteration 12477: loss: 0.0206, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.8589, 0.9935]
2025-03-11 21:20:12 - Train Iteration 12478: loss: 0.7666, d_k_M range: [0.0000, 0.8742], d_k_M_hat range: [0.9712, 1.0000]
2025-03-11 21:20:13 - Train Iteration 12479: loss: 0.0091, d_k_M range: [0.0000, 0.0924], d_k_M_hat range: [0.9048, 1.0000]
2025-03-11 21:20:13 - Train Iteration 12480: loss: 0.6097, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.2192, 0.9812]
2025-03-11 21:20:13 - Train Iteration 12481: loss: 0.0977, d_k_M range: [0.0013, 0.3124], d_k_M_hat range: [0.9958, 1.0000]
2025-03-11 21:20:14 - Train Iteration 12482: loss: 0.0001, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9935, 0.9997]
2025-03-11 21:20:14 - Train Iteration 12483: loss: 0.0030, d_k_M range: [0.0000, 0.0511], d_k_M_hat range: [0.9931, 0.9999]
2025-03-11 21:20:15 - Train Iteration 12484: loss: 0.0248, d_k_M range: [0.0001, 0.1571], d_k_M_hat range: [0.9955, 0.9999]
2025-03-11 21:20:15 - Train Iteration 12485: loss: 0.7758, d_k_M range: [0.0000, 0.8808], d_k_M_hat range: [0.9976, 1.0000]
2025-03-11 21:20:15 - Train Iteration 12486: loss: 0.0001, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9931, 0.9992]
2025-03-11 21:20:16 - Train Iteration 12487: loss: 0.0102, d_k_M range: [0.0001, 0.0261], d_k_M_hat range: [0.8991, 0.9995]
2025-03-11 21:20:16 - Train Iteration 12488: loss: 0.0036, d_k_M range: [0.0000, 0.0592], d_k_M_hat range: [0.9830, 0.9993]
2025-03-11 21:20:17 - Train Iteration 12489: loss: 0.0005, d_k_M range: [0.0000, 0.0069], d_k_M_hat range: [0.9783, 0.9998]
2025-03-11 21:20:17 - Train Iteration 12490: loss: 0.0143, d_k_M range: [0.0000, 0.1187], d_k_M_hat range: [0.9870, 1.0000]
2025-03-11 21:20:18 - Train Iteration 12491: loss: 0.0426, d_k_M range: [0.0000, 0.0777], d_k_M_hat range: [0.7940, 0.9984]
2025-03-11 21:20:18 - Train Iteration 12492: loss: 0.0003, d_k_M range: [0.0000, 0.0132], d_k_M_hat range: [0.9840, 1.0000]
2025-03-11 21:20:18 - Train Iteration 12493: loss: 0.0051, d_k_M range: [0.0000, 0.0644], d_k_M_hat range: [0.9399, 0.9993]
2025-03-11 21:20:19 - Train Iteration 12494: loss: 0.0812, d_k_M range: [0.0000, 0.2847], d_k_M_hat range: [0.9894, 0.9998]
2025-03-11 21:20:19 - Train Iteration 12495: loss: 0.0042, d_k_M range: [0.0001, 0.0219], d_k_M_hat range: [0.9573, 0.9999]
2025-03-11 21:20:20 - Train Iteration 12496: loss: 0.0065, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.9206, 0.9998]
2025-03-11 21:20:20 - Train Iteration 12497: loss: 0.2457, d_k_M range: [0.0000, 0.4957], d_k_M_hat range: [0.9924, 0.9999]
2025-03-11 21:20:20 - Train Iteration 12498: loss: 0.0001, d_k_M range: [0.0001, 0.0063], d_k_M_hat range: [0.9973, 0.9998]
2025-03-11 21:20:21 - Train Iteration 12499: loss: 0.0034, d_k_M range: [0.0000, 0.0567], d_k_M_hat range: [0.9884, 0.9985]
2025-03-11 21:20:21 - Train Iteration 12500: loss: 0.0135, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.8858, 0.9985]
2025-03-11 21:20:22 - Train Iteration 12501: loss: 0.0033, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9424, 0.9987]
2025-03-11 21:20:22 - Train Iteration 12502: loss: 0.0134, d_k_M range: [0.0000, 0.0709], d_k_M_hat range: [0.9543, 0.9983]
2025-03-11 21:20:23 - Train Iteration 12503: loss: 0.0174, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.8680, 0.9991]
2025-03-11 21:20:23 - Train Iteration 12504: loss: 0.4542, d_k_M range: [0.0001, 0.6684], d_k_M_hat range: [0.9929, 0.9999]
2025-03-11 21:20:23 - Train Iteration 12505: loss: 0.1114, d_k_M range: [0.0000, 0.1511], d_k_M_hat range: [0.6671, 0.9982]
2025-03-11 21:20:24 - Train Iteration 12506: loss: 0.0001, d_k_M range: [0.0000, 0.0071], d_k_M_hat range: [0.9892, 0.9998]
2025-03-11 21:20:24 - Train Iteration 12507: loss: 0.0034, d_k_M range: [0.0001, 0.0573], d_k_M_hat range: [0.9834, 0.9999]
2025-03-11 21:20:25 - Train Iteration 12508: loss: 0.0010, d_k_M range: [0.0000, 0.0137], d_k_M_hat range: [0.9691, 0.9998]
2025-03-11 21:20:25 - Train Iteration 12509: loss: 0.0127, d_k_M range: [0.0002, 0.1124], d_k_M_hat range: [0.9879, 0.9998]
2025-03-11 21:20:25 - Train Iteration 12510: loss: 0.0003, d_k_M range: [0.0000, 0.0142], d_k_M_hat range: [0.9844, 0.9998]
2025-03-11 21:20:26 - Train Iteration 12511: loss: 0.0030, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.9458, 0.9997]
2025-03-11 21:20:26 - Train Iteration 12512: loss: 0.0087, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9103, 0.9999]
2025-03-11 21:20:27 - Train Iteration 12513: loss: 0.4930, d_k_M range: [0.0001, 0.7018], d_k_M_hat range: [0.9879, 1.0000]
2025-03-11 21:20:27 - Train Iteration 12514: loss: 0.0014, d_k_M range: [0.0000, 0.0343], d_k_M_hat range: [0.9940, 0.9994]
2025-03-11 21:20:28 - Train Iteration 12515: loss: 0.0700, d_k_M range: [0.0002, 0.2646], d_k_M_hat range: [0.9710, 0.9999]
2025-03-11 21:20:28 - Train Iteration 12516: loss: 0.0025, d_k_M range: [0.0000, 0.0124], d_k_M_hat range: [0.9497, 0.9998]
2025-03-11 21:20:29 - Train Iteration 12517: loss: 0.0009, d_k_M range: [0.0000, 0.0288], d_k_M_hat range: [0.9759, 0.9996]
2025-03-11 21:20:29 - Train Iteration 12518: loss: 0.0007, d_k_M range: [0.0000, 0.0235], d_k_M_hat range: [0.9813, 0.9998]
2025-03-11 21:20:29 - Train Iteration 12519: loss: 0.0043, d_k_M range: [0.0000, 0.0189], d_k_M_hat range: [0.9350, 0.9991]
2025-03-11 21:20:30 - Train Iteration 12520: loss: 0.0113, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.8937, 0.9987]
2025-03-11 21:20:30 - Train Iteration 12521: loss: 0.0079, d_k_M range: [0.0000, 0.0133], d_k_M_hat range: [0.9114, 0.9996]
2025-03-11 21:20:31 - Train Iteration 12522: loss: 0.0187, d_k_M range: [0.0000, 0.0088], d_k_M_hat range: [0.8640, 0.9995]
2025-03-11 21:20:31 - Train Iteration 12523: loss: 0.3646, d_k_M range: [0.0000, 0.0313], d_k_M_hat range: [0.3962, 0.9997]
2025-03-11 21:20:32 - Train Iteration 12524: loss: 0.6853, d_k_M range: [0.0004, 0.8271], d_k_M_hat range: [0.9993, 1.0000]
2025-03-11 21:20:32 - Train Iteration 12525: loss: 0.5574, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.2548, 0.9997]
2025-03-11 21:20:32 - Train Iteration 12526: loss: 0.0279, d_k_M range: [0.0000, 0.1662], d_k_M_hat range: [0.9808, 0.9996]
2025-03-11 21:20:33 - Train Iteration 12527: loss: 0.0181, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.8655, 0.9997]
2025-03-11 21:20:33 - Train Iteration 12528: loss: 0.0213, d_k_M range: [0.0001, 0.1440], d_k_M_hat range: [0.9943, 0.9999]
2025-03-11 21:20:33 - Train Iteration 12529: loss: 0.0022, d_k_M range: [0.0000, 0.0258], d_k_M_hat range: [0.9535, 0.9998]
2025-03-11 21:20:34 - Train Iteration 12530: loss: 0.2550, d_k_M range: [0.0005, 0.5049], d_k_M_hat range: [0.9993, 0.9999]
2025-03-11 21:20:34 - Train Iteration 12531: loss: 0.0315, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.8224, 0.9970]
2025-03-11 21:20:35 - Train Iteration 12532: loss: 0.3599, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.4002, 0.9992]
2025-03-11 21:20:35 - Train Iteration 12533: loss: 0.0111, d_k_M range: [0.0000, 0.1033], d_k_M_hat range: [0.9937, 0.9989]
2025-03-11 21:20:35 - Train Iteration 12534: loss: 0.0011, d_k_M range: [0.0000, 0.0301], d_k_M_hat range: [0.9909, 0.9999]
2025-03-11 21:20:36 - Train Iteration 12535: loss: 0.0469, d_k_M range: [0.0000, 0.0745], d_k_M_hat range: [0.7840, 0.9998]
2025-03-11 21:20:36 - Train Iteration 12536: loss: 0.0466, d_k_M range: [0.0000, 0.0263], d_k_M_hat range: [0.7857, 0.9995]
2025-03-11 21:20:37 - Train Iteration 12537: loss: 0.0756, d_k_M range: [0.0000, 0.2736], d_k_M_hat range: [0.9847, 0.9987]
2025-03-11 21:20:37 - Train Iteration 12538: loss: 0.0004, d_k_M range: [0.0000, 0.0196], d_k_M_hat range: [0.9873, 0.9999]
2025-03-11 21:20:38 - Train Iteration 12539: loss: 0.0019, d_k_M range: [0.0001, 0.0410], d_k_M_hat range: [0.9699, 0.9981]
2025-03-11 21:20:38 - Train Iteration 12540: loss: 0.0006, d_k_M range: [0.0000, 0.0072], d_k_M_hat range: [0.9758, 0.9995]
2025-03-11 21:20:38 - Train Iteration 12541: loss: 0.0101, d_k_M range: [0.0000, 0.0202], d_k_M_hat range: [0.8993, 0.9996]
2025-03-11 21:20:39 - Train Iteration 12542: loss: 0.0013, d_k_M range: [0.0000, 0.0200], d_k_M_hat range: [0.9813, 0.9991]
2025-03-11 21:20:39 - Train Iteration 12543: loss: 0.0185, d_k_M range: [0.0001, 0.1335], d_k_M_hat range: [0.9960, 1.0000]
2025-03-11 21:20:40 - Train Iteration 12544: loss: 0.0007, d_k_M range: [0.0000, 0.0048], d_k_M_hat range: [0.9731, 0.9985]
2025-03-11 21:20:40 - Train Iteration 12545: loss: 0.0090, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9054, 0.9993]
2025-03-11 21:20:40 - Train Iteration 12546: loss: 0.0019, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9570, 0.9972]
2025-03-11 21:20:41 - Train Iteration 12547: loss: 0.0002, d_k_M range: [0.0000, 0.0078], d_k_M_hat range: [0.9883, 0.9999]
2025-03-11 21:20:41 - Train Iteration 12548: loss: 0.0711, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.7334, 0.9996]
2025-03-11 21:20:41 - Train Iteration 12549: loss: 0.0098, d_k_M range: [0.0000, 0.0480], d_k_M_hat range: [0.9010, 0.9996]
2025-03-11 21:20:42 - Train Iteration 12550: loss: 0.0015, d_k_M range: [0.0001, 0.0121], d_k_M_hat range: [0.9613, 1.0000]
2025-03-11 21:20:42 - Train Iteration 12551: loss: 0.0020, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.9648, 0.9999]
2025-03-11 21:20:43 - Train Iteration 12552: loss: 0.0015, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9611, 0.9998]
2025-03-11 21:20:43 - Train Iteration 12553: loss: 0.0007, d_k_M range: [0.0000, 0.0174], d_k_M_hat range: [0.9906, 0.9992]
2025-03-11 21:20:43 - Train Iteration 12554: loss: 0.0019, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.9570, 0.9980]
2025-03-11 21:20:44 - Train Iteration 12555: loss: 0.0531, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.7698, 0.9929]
2025-03-11 21:20:44 - Train Iteration 12556: loss: 0.0001, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9916, 0.9997]
2025-03-11 21:20:45 - Train Iteration 12557: loss: 0.0002, d_k_M range: [0.0000, 0.0134], d_k_M_hat range: [0.9888, 0.9998]
2025-03-11 21:20:45 - Train Iteration 12558: loss: 0.0637, d_k_M range: [0.0000, 0.0244], d_k_M_hat range: [0.7486, 0.9992]
2025-03-11 21:20:45 - Train Iteration 12559: loss: 0.0004, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9790, 0.9996]
2025-03-11 21:20:46 - Train Iteration 12560: loss: 0.0175, d_k_M range: [0.0000, 0.0775], d_k_M_hat range: [0.8679, 0.9987]
2025-03-11 21:20:46 - Train Iteration 12561: loss: 0.0016, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9606, 0.9994]
2025-03-11 21:20:47 - Train Iteration 12562: loss: 0.1045, d_k_M range: [0.0000, 0.3222], d_k_M_hat range: [0.9908, 0.9999]
2025-03-11 21:20:47 - Train Iteration 12563: loss: 0.0832, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.7115, 0.9924]
2025-03-11 21:20:47 - Train Iteration 12564: loss: 0.0008, d_k_M range: [0.0000, 0.0275], d_k_M_hat range: [0.9864, 0.9997]
2025-03-11 21:20:48 - Train Iteration 12565: loss: 0.0022, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.9626, 0.9999]
2025-03-11 21:20:48 - Train Iteration 12566: loss: 0.0354, d_k_M range: [0.0000, 0.1866], d_k_M_hat range: [0.9493, 0.9996]
2025-03-11 21:20:49 - Train Iteration 12567: loss: 0.4931, d_k_M range: [0.0000, 0.7022], d_k_M_hat range: [0.9788, 1.0000]
2025-03-11 21:20:49 - Train Iteration 12568: loss: 0.0543, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.7671, 0.9984]
2025-03-11 21:20:50 - Train Iteration 12569: loss: 0.9344, d_k_M range: [0.0000, 0.9659], d_k_M_hat range: [0.9980, 0.9993]
2025-03-11 21:20:50 - Train Iteration 12570: loss: 0.0021, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.9553, 0.9990]
2025-03-11 21:20:50 - Train Iteration 12571: loss: 0.0034, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.9414, 0.9995]
2025-03-11 21:20:51 - Train Iteration 12572: loss: 0.0476, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.7819, 0.9999]
2025-03-11 21:20:51 - Train Iteration 12573: loss: 0.0148, d_k_M range: [0.0009, 0.1063], d_k_M_hat range: [0.9669, 0.9978]
2025-03-11 21:20:52 - Train Iteration 12574: loss: 0.0024, d_k_M range: [0.0000, 0.0223], d_k_M_hat range: [0.9513, 0.9995]
2025-03-11 21:20:52 - Train Iteration 12575: loss: 0.0002, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.9929, 0.9998]
2025-03-11 21:20:52 - Train Iteration 12576: loss: 0.4108, d_k_M range: [0.0000, 0.6408], d_k_M_hat range: [0.9119, 1.0000]
2025-03-11 21:20:53 - Train Iteration 12577: loss: 0.0183, d_k_M range: [0.0000, 0.0309], d_k_M_hat range: [0.8646, 0.9998]
2025-03-11 21:20:53 - Train Iteration 12578: loss: 0.0071, d_k_M range: [0.0000, 0.0831], d_k_M_hat range: [0.9896, 0.9998]
2025-03-11 21:20:54 - Train Iteration 12579: loss: 0.0003, d_k_M range: [0.0000, 0.0150], d_k_M_hat range: [0.9880, 0.9999]
2025-03-11 21:20:54 - Train Iteration 12580: loss: 0.1210, d_k_M range: [0.0000, 0.3457], d_k_M_hat range: [0.8852, 0.9996]
2025-03-11 21:20:54 - Train Iteration 12581: loss: 0.0076, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9132, 0.9992]
2025-03-11 21:20:55 - Train Iteration 12582: loss: 0.0621, d_k_M range: [0.0000, 0.0248], d_k_M_hat range: [0.7509, 0.9996]
2025-03-11 21:20:55 - Train Iteration 12583: loss: 0.0015, d_k_M range: [0.0000, 0.0382], d_k_M_hat range: [0.9967, 1.0000]
2025-03-11 21:20:56 - Train Iteration 12584: loss: 0.2939, d_k_M range: [0.0000, 0.0195], d_k_M_hat range: [0.4579, 0.9999]
2025-03-11 21:20:56 - Train Iteration 12585: loss: 0.1983, d_k_M range: [0.0003, 0.4448], d_k_M_hat range: [0.9915, 1.0000]
2025-03-11 21:20:56 - Train Iteration 12586: loss: 0.0008, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.9712, 0.9982]
2025-03-11 21:20:57 - Train Iteration 12587: loss: 0.0051, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.9284, 0.9995]
2025-03-11 21:20:57 - Train Iteration 12588: loss: 0.3656, d_k_M range: [0.0001, 0.6039], d_k_M_hat range: [0.9561, 0.9999]
2025-03-11 21:20:58 - Train Iteration 12589: loss: 0.2198, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.5312, 0.9969]
2025-03-11 21:20:58 - Train Iteration 12590: loss: 0.5532, d_k_M range: [0.0003, 0.7437], d_k_M_hat range: [0.9886, 0.9999]
2025-03-11 21:20:58 - Train Iteration 12591: loss: 0.2181, d_k_M range: [0.0000, 0.4662], d_k_M_hat range: [0.9682, 1.0000]
2025-03-11 21:20:59 - Train Iteration 12592: loss: 0.0081, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9098, 0.9999]
2025-03-11 21:20:59 - Train Iteration 12593: loss: 0.0004, d_k_M range: [0.0000, 0.0185], d_k_M_hat range: [0.9918, 0.9993]
2025-03-11 21:21:00 - Train Iteration 12594: loss: 0.0010, d_k_M range: [0.0002, 0.0104], d_k_M_hat range: [0.9695, 0.9997]
2025-03-11 21:21:00 - Train Iteration 12595: loss: 0.0323, d_k_M range: [0.0000, 0.0165], d_k_M_hat range: [0.8204, 0.9997]
2025-03-11 21:21:00 - Train Iteration 12596: loss: 0.0030, d_k_M range: [0.0000, 0.0544], d_k_M_hat range: [0.9980, 1.0000]
2025-03-11 21:21:01 - Train Iteration 12597: loss: 0.0024, d_k_M range: [0.0000, 0.0323], d_k_M_hat range: [0.9511, 1.0000]
2025-03-11 21:21:01 - Train Iteration 12598: loss: 0.0150, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.8788, 0.9998]
2025-03-11 21:21:02 - Train Iteration 12599: loss: 0.0029, d_k_M range: [0.0000, 0.0106], d_k_M_hat range: [0.9466, 0.9999]
2025-03-11 21:21:02 - Train Iteration 12600: loss: 0.8510, d_k_M range: [0.0001, 0.9223], d_k_M_hat range: [0.8054, 0.9998]
2025-03-11 21:21:02 - Train Iteration 12601: loss: 0.0203, d_k_M range: [0.0001, 0.0218], d_k_M_hat range: [0.8575, 0.9999]
2025-03-11 21:21:03 - Train Iteration 12602: loss: 0.0375, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.8066, 0.9985]
2025-03-11 21:21:03 - Train Iteration 12603: loss: 0.0003, d_k_M range: [0.0000, 0.0099], d_k_M_hat range: [0.9836, 0.9999]
2025-03-11 21:21:04 - Train Iteration 12604: loss: 0.0069, d_k_M range: [0.0003, 0.0819], d_k_M_hat range: [0.9854, 0.9995]
2025-03-11 21:21:04 - Train Iteration 12605: loss: 0.0002, d_k_M range: [0.0003, 0.0086], d_k_M_hat range: [0.9903, 0.9999]
2025-03-11 21:21:04 - Train Iteration 12606: loss: 0.0358, d_k_M range: [0.0000, 0.0433], d_k_M_hat range: [0.8542, 0.9996]
2025-03-11 21:21:05 - Train Iteration 12607: loss: 0.0612, d_k_M range: [0.0001, 0.2473], d_k_M_hat range: [0.9397, 0.9998]
2025-03-11 21:21:05 - Train Iteration 12608: loss: 0.0001, d_k_M range: [0.0003, 0.0064], d_k_M_hat range: [0.9921, 0.9998]
2025-03-11 21:21:06 - Train Iteration 12609: loss: 0.0005, d_k_M range: [0.0000, 0.0177], d_k_M_hat range: [0.9936, 1.0000]
2025-03-11 21:21:06 - Train Iteration 12610: loss: 0.0096, d_k_M range: [0.0001, 0.0975], d_k_M_hat range: [0.9486, 0.9995]
2025-03-11 21:21:07 - Train Iteration 12611: loss: 0.6699, d_k_M range: [0.0000, 0.8180], d_k_M_hat range: [0.9711, 0.9999]
2025-03-11 21:21:07 - Train Iteration 12612: loss: 0.8857, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.0589, 0.9962]
2025-03-11 21:21:07 - Train Iteration 12613: loss: 0.0099, d_k_M range: [0.0000, 0.0994], d_k_M_hat range: [0.9435, 0.9997]
2025-03-11 21:21:08 - Train Iteration 12614: loss: 0.0025, d_k_M range: [0.0001, 0.0364], d_k_M_hat range: [0.9503, 0.9998]
2025-03-11 21:21:08 - Train Iteration 12615: loss: 0.6120, d_k_M range: [0.0000, 0.7818], d_k_M_hat range: [0.9795, 0.9999]
2025-03-11 21:21:09 - Train Iteration 12616: loss: 0.0029, d_k_M range: [0.0000, 0.0269], d_k_M_hat range: [0.9470, 0.9971]
2025-03-11 21:21:09 - Train Iteration 12617: loss: 0.0247, d_k_M range: [0.0000, 0.0138], d_k_M_hat range: [0.8428, 0.9999]
2025-03-11 21:21:09 - Train Iteration 12618: loss: 0.0062, d_k_M range: [0.0000, 0.0748], d_k_M_hat range: [0.9891, 0.9995]
2025-03-11 21:21:10 - Train Iteration 12619: loss: 0.0136, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.8835, 0.9966]
2025-03-11 21:21:10 - Train Iteration 12620: loss: 0.0136, d_k_M range: [0.0000, 0.0186], d_k_M_hat range: [0.8837, 0.9996]
2025-03-11 21:21:11 - Train Iteration 12621: loss: 0.0075, d_k_M range: [0.0000, 0.0861], d_k_M_hat range: [0.9402, 0.9999]
2025-03-11 21:21:11 - Train Iteration 12622: loss: 0.1768, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.5796, 0.9999]
2025-03-11 21:21:11 - Train Iteration 12623: loss: 0.0032, d_k_M range: [0.0000, 0.0111], d_k_M_hat range: [0.9440, 0.9997]
2025-03-11 21:21:12 - Train Iteration 12624: loss: 0.0003, d_k_M range: [0.0000, 0.0130], d_k_M_hat range: [0.9859, 0.9998]
2025-03-11 21:21:12 - Train Iteration 12625: loss: 0.6376, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.2015, 0.9970]
2025-03-11 21:21:13 - Train Iteration 12626: loss: 0.0574, d_k_M range: [0.0000, 0.0577], d_k_M_hat range: [0.7604, 0.9998]
2025-03-11 21:21:13 - Train Iteration 12627: loss: 0.0012, d_k_M range: [0.0000, 0.0279], d_k_M_hat range: [0.9780, 0.9999]
2025-03-11 21:21:13 - Train Iteration 12628: loss: 0.0009, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.9720, 0.9994]
2025-03-11 21:21:14 - Train Iteration 12629: loss: 0.0023, d_k_M range: [0.0000, 0.0435], d_k_M_hat range: [0.9884, 0.9998]
2025-03-11 21:21:14 - Train Iteration 12630: loss: 0.0134, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.8841, 0.9990]
2025-03-11 21:21:15 - Train Iteration 12631: loss: 0.0008, d_k_M range: [0.0000, 0.0264], d_k_M_hat range: [0.9728, 0.9999]
2025-03-11 21:21:15 - Train Iteration 12632: loss: 0.0008, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9716, 0.9995]
2025-03-11 21:21:15 - Train Iteration 12633: loss: 0.3505, d_k_M range: [0.0000, 0.5918], d_k_M_hat range: [0.9786, 0.9999]
2025-03-11 21:21:16 - Train Iteration 12634: loss: 0.1467, d_k_M range: [0.0000, 0.0628], d_k_M_hat range: [0.6170, 0.9996]
2025-03-11 21:21:16 - Train Iteration 12635: loss: 0.0001, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9908, 0.9997]
2025-03-11 21:21:17 - Train Iteration 12636: loss: 0.0721, d_k_M range: [0.0000, 0.0284], d_k_M_hat range: [0.7599, 0.9995]
2025-03-11 21:21:17 - Train Iteration 12637: loss: 0.0385, d_k_M range: [0.0000, 0.0192], d_k_M_hat range: [0.8041, 0.9999]
2025-03-11 21:21:17 - Train Iteration 12638: loss: 0.0001, d_k_M range: [0.0001, 0.0065], d_k_M_hat range: [0.9941, 0.9996]
2025-03-11 21:21:18 - Train Iteration 12639: loss: 0.0432, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.7922, 0.9986]
2025-03-11 21:21:18 - Train Iteration 12640: loss: 0.9505, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.0252, 0.9925]
2025-03-11 21:21:19 - Train Iteration 12641: loss: 0.0020, d_k_M range: [0.0000, 0.0121], d_k_M_hat range: [0.9677, 0.9986]
2025-03-11 21:21:19 - Train Iteration 12642: loss: 0.0055, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.9259, 0.9977]
2025-03-11 21:21:20 - Train Iteration 12643: loss: 0.0020, d_k_M range: [0.0000, 0.0084], d_k_M_hat range: [0.9589, 1.0000]
2025-03-11 21:21:20 - Train Iteration 12644: loss: 0.0074, d_k_M range: [0.0000, 0.0071], d_k_M_hat range: [0.9146, 0.9999]
2025-03-11 21:21:20 - Train Iteration 12645: loss: 0.0000, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9947, 0.9994]
2025-03-11 21:21:21 - Train Iteration 12646: loss: 0.0159, d_k_M range: [0.0001, 0.1258], d_k_M_hat range: [0.9439, 1.0000]
2025-03-11 21:21:21 - Train Iteration 12647: loss: 0.0003, d_k_M range: [0.0000, 0.0057], d_k_M_hat range: [0.9843, 0.9997]
2025-03-11 21:21:22 - Train Iteration 12648: loss: 0.3038, d_k_M range: [0.0002, 0.5510], d_k_M_hat range: [0.9956, 0.9999]
2025-03-11 21:21:22 - Train Iteration 12649: loss: 0.0005, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9785, 0.9994]
2025-03-11 21:21:22 - Train Iteration 12650: loss: 0.0019, d_k_M range: [0.0003, 0.0227], d_k_M_hat range: [0.9571, 0.9999]
2025-03-11 21:21:23 - Train Iteration 12651: loss: 0.0029, d_k_M range: [0.0000, 0.0292], d_k_M_hat range: [0.9465, 0.9997]
2025-03-11 21:21:23 - Train Iteration 12652: loss: 0.0016, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.9602, 0.9982]
2025-03-11 21:21:24 - Train Iteration 12653: loss: 0.0447, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.7886, 0.9989]
2025-03-11 21:21:24 - Train Iteration 12654: loss: 0.0661, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.7430, 0.9998]
2025-03-11 21:21:24 - Train Iteration 12655: loss: 0.0007, d_k_M range: [0.0000, 0.0250], d_k_M_hat range: [0.9984, 0.9999]
2025-03-11 21:21:25 - Train Iteration 12656: loss: 0.0003, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9824, 0.9998]
2025-03-11 21:21:25 - Train Iteration 12657: loss: 0.0416, d_k_M range: [0.0002, 0.2038], d_k_M_hat range: [0.9825, 0.9998]
2025-03-11 21:21:26 - Train Iteration 12658: loss: 0.0084, d_k_M range: [0.0001, 0.0904], d_k_M_hat range: [0.9653, 0.9999]
2025-03-11 21:21:26 - Train Iteration 12659: loss: 0.1494, d_k_M range: [0.0002, 0.3865], d_k_M_hat range: [0.9590, 0.9999]
2025-03-11 21:21:26 - Train Iteration 12660: loss: 0.0035, d_k_M range: [0.0000, 0.0453], d_k_M_hat range: [0.9574, 0.9997]
2025-03-11 21:21:27 - Train Iteration 12661: loss: 0.7833, d_k_M range: [0.0000, 0.8849], d_k_M_hat range: [0.9692, 0.9999]
2025-03-11 21:21:27 - Train Iteration 12662: loss: 0.0020, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9553, 0.9969]
2025-03-11 21:21:28 - Train Iteration 12663: loss: 0.0011, d_k_M range: [0.0001, 0.0076], d_k_M_hat range: [0.9671, 0.9993]
2025-03-11 21:21:28 - Train Iteration 12664: loss: 0.0230, d_k_M range: [0.0000, 0.0433], d_k_M_hat range: [0.8485, 0.9972]
2025-03-11 21:21:29 - Train Iteration 12665: loss: 0.0482, d_k_M range: [0.0000, 0.2177], d_k_M_hat range: [0.9672, 0.9994]
2025-03-11 21:21:29 - Train Iteration 12666: loss: 0.0065, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9191, 0.9996]
2025-03-11 21:21:29 - Train Iteration 12667: loss: 0.0013, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.9678, 0.9999]
2025-03-11 21:21:30 - Train Iteration 12668: loss: 0.0036, d_k_M range: [0.0000, 0.0293], d_k_M_hat range: [0.9690, 0.9997]
2025-03-11 21:21:30 - Train Iteration 12669: loss: 0.5458, d_k_M range: [0.0000, 0.7387], d_k_M_hat range: [0.9887, 0.9999]
2025-03-11 21:21:31 - Train Iteration 12670: loss: 0.4259, d_k_M range: [0.0000, 0.0335], d_k_M_hat range: [0.3474, 0.9998]
2025-03-11 21:21:31 - Train Iteration 12671: loss: 0.1332, d_k_M range: [0.0000, 0.3648], d_k_M_hat range: [0.9406, 0.9998]
2025-03-11 21:21:31 - Train Iteration 12672: loss: 0.0006, d_k_M range: [0.0000, 0.0180], d_k_M_hat range: [0.9811, 0.9998]
2025-03-11 21:21:32 - Train Iteration 12673: loss: 0.0012, d_k_M range: [0.0000, 0.0172], d_k_M_hat range: [0.9659, 0.9998]
2025-03-11 21:21:32 - Train Iteration 12674: loss: 0.0229, d_k_M range: [0.0000, 0.1510], d_k_M_hat range: [0.9620, 0.9997]
2025-03-11 21:21:33 - Train Iteration 12675: loss: 0.4267, d_k_M range: [0.0000, 0.6495], d_k_M_hat range: [0.9928, 0.9998]
2025-03-11 21:21:33 - Train Iteration 12676: loss: 0.0070, d_k_M range: [0.0000, 0.0344], d_k_M_hat range: [0.9161, 0.9991]
2025-03-11 21:21:33 - Train Iteration 12677: loss: 0.0029, d_k_M range: [0.0000, 0.0303], d_k_M_hat range: [0.9465, 0.9998]
2025-03-11 21:21:34 - Train Iteration 12678: loss: 0.0003, d_k_M range: [0.0000, 0.0089], d_k_M_hat range: [0.9865, 0.9996]
2025-03-11 21:21:34 - Train Iteration 12679: loss: 0.0328, d_k_M range: [0.0001, 0.1806], d_k_M_hat range: [0.9223, 0.9996]
2025-03-11 21:21:34 - Train Iteration 12680: loss: 0.0375, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.8064, 0.9998]
2025-03-11 21:21:35 - Train Iteration 12681: loss: 0.0005, d_k_M range: [0.0001, 0.0023], d_k_M_hat range: [0.9779, 0.9999]
2025-03-11 21:21:35 - Train Iteration 12682: loss: 0.2032, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.5493, 0.9988]
2025-03-11 21:21:36 - Train Iteration 12683: loss: 0.2304, d_k_M range: [0.0009, 0.4799], d_k_M_hat range: [0.9849, 0.9999]
2025-03-11 21:21:36 - Train Iteration 12684: loss: 0.0679, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.7395, 0.9965]
2025-03-11 21:21:36 - Train Iteration 12685: loss: 0.0253, d_k_M range: [0.0000, 0.1561], d_k_M_hat range: [0.9788, 0.9991]
2025-03-11 21:21:37 - Train Iteration 12686: loss: 0.0092, d_k_M range: [0.0000, 0.0307], d_k_M_hat range: [0.9042, 0.9997]
2025-03-11 21:21:37 - Train Iteration 12687: loss: 0.4473, d_k_M range: [0.0001, 0.6688], d_k_M_hat range: [0.9828, 0.9999]
2025-03-11 21:21:38 - Train Iteration 12688: loss: 0.0086, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.9074, 0.9999]
2025-03-11 21:21:38 - Train Iteration 12689: loss: 0.0017, d_k_M range: [0.0000, 0.0382], d_k_M_hat range: [0.9914, 0.9981]
2025-03-11 21:21:39 - Train Iteration 12690: loss: 0.0001, d_k_M range: [0.0000, 0.0070], d_k_M_hat range: [0.9897, 0.9995]
2025-03-11 21:21:39 - Train Iteration 12691: loss: 0.0138, d_k_M range: [0.0000, 0.1085], d_k_M_hat range: [0.8836, 0.9999]
2025-03-11 21:21:39 - Train Iteration 12692: loss: 0.0019, d_k_M range: [0.0000, 0.0375], d_k_M_hat range: [0.9696, 0.9984]
2025-03-11 21:21:40 - Train Iteration 12693: loss: 0.0023, d_k_M range: [0.0006, 0.0245], d_k_M_hat range: [0.9715, 0.9999]
2025-03-11 21:21:40 - Train Iteration 12694: loss: 0.0109, d_k_M range: [0.0000, 0.0087], d_k_M_hat range: [0.8958, 0.9992]
2025-03-11 21:21:41 - Train Iteration 12695: loss: 0.0066, d_k_M range: [0.0000, 0.0275], d_k_M_hat range: [0.9197, 0.9997]
2025-03-11 21:21:41 - Train Iteration 12696: loss: 0.0116, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.8924, 0.9997]
2025-03-11 21:21:42 - Train Iteration 12697: loss: 0.0014, d_k_M range: [0.0000, 0.0247], d_k_M_hat range: [0.9877, 0.9999]
2025-03-11 21:21:42 - Train Iteration 12698: loss: 0.0050, d_k_M range: [0.0000, 0.0141], d_k_M_hat range: [0.9291, 0.9981]
2025-03-11 21:21:42 - Train Iteration 12699: loss: 0.0045, d_k_M range: [0.0000, 0.0652], d_k_M_hat range: [0.9915, 0.9995]
2025-03-11 21:21:43 - Train Iteration 12700: loss: 0.0069, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9174, 0.9989]
2025-03-11 21:21:43 - Train Iteration 12701: loss: 0.0003, d_k_M range: [0.0002, 0.0177], d_k_M_hat range: [0.9825, 0.9999]
2025-03-11 21:21:43 - Train Iteration 12702: loss: 0.2601, d_k_M range: [0.0000, 0.5098], d_k_M_hat range: [0.9733, 0.9998]
2025-03-11 21:21:44 - Train Iteration 12703: loss: 0.8926, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.0552, 0.9971]
2025-03-11 21:21:44 - Train Iteration 12704: loss: 0.0031, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9455, 0.9997]
2025-03-11 21:21:45 - Train Iteration 12705: loss: 0.0001, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.9923, 0.9995]
2025-03-11 21:21:45 - Train Iteration 12706: loss: 0.0033, d_k_M range: [0.0001, 0.0470], d_k_M_hat range: [0.9606, 0.9998]
2025-03-11 21:21:45 - Train Iteration 12707: loss: 0.0034, d_k_M range: [0.0002, 0.0541], d_k_M_hat range: [0.9960, 1.0000]
2025-03-11 21:21:46 - Train Iteration 12708: loss: 0.0007, d_k_M range: [0.0001, 0.0256], d_k_M_hat range: [0.9810, 0.9999]
2025-03-11 21:21:46 - Train Iteration 12709: loss: 0.2086, d_k_M range: [0.0000, 0.0355], d_k_M_hat range: [0.5433, 0.9999]
2025-03-11 21:21:46 - Train Iteration 12710: loss: 0.0034, d_k_M range: [0.0001, 0.0057], d_k_M_hat range: [0.9439, 0.9992]
2025-03-11 21:21:47 - Train Iteration 12711: loss: 0.0005, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.9785, 0.9999]
2025-03-11 21:21:47 - Train Iteration 12712: loss: 0.0001, d_k_M range: [0.0001, 0.0078], d_k_M_hat range: [0.9887, 0.9999]
2025-03-11 21:21:48 - Train Iteration 12713: loss: 0.0028, d_k_M range: [0.0000, 0.0457], d_k_M_hat range: [0.9913, 0.9998]
2025-03-11 21:21:48 - Train Iteration 12714: loss: 0.0002, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.9865, 0.9990]
2025-03-11 21:21:49 - Train Iteration 12715: loss: 0.2880, d_k_M range: [0.0000, 0.5361], d_k_M_hat range: [0.9823, 0.9995]
2025-03-11 21:21:49 - Train Iteration 12716: loss: 0.0032, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9435, 0.9993]
2025-03-11 21:21:49 - Train Iteration 12717: loss: 0.1139, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.6626, 0.9975]
2025-03-11 21:21:50 - Train Iteration 12718: loss: 0.0006, d_k_M range: [0.0000, 0.0250], d_k_M_hat range: [0.9783, 0.9997]
2025-03-11 21:21:50 - Train Iteration 12719: loss: 0.0016, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9605, 0.9994]
2025-03-11 21:21:51 - Train Iteration 12720: loss: 0.0022, d_k_M range: [0.0000, 0.0416], d_k_M_hat range: [0.9898, 0.9998]
2025-03-11 21:21:51 - Train Iteration 12721: loss: 0.0076, d_k_M range: [0.0002, 0.0849], d_k_M_hat range: [0.9898, 1.0000]
2025-03-11 21:21:52 - Train Iteration 12722: loss: 0.0002, d_k_M range: [0.0001, 0.0130], d_k_M_hat range: [0.9927, 1.0000]
2025-03-11 21:21:52 - Train Iteration 12723: loss: 0.0003, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9835, 1.0000]
2025-03-11 21:21:52 - Train Iteration 12724: loss: 0.4827, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.3053, 0.9999]
2025-03-11 21:21:53 - Train Iteration 12725: loss: 0.0066, d_k_M range: [0.0001, 0.0778], d_k_M_hat range: [0.9963, 1.0000]
2025-03-11 21:21:53 - Train Iteration 12726: loss: 0.1320, d_k_M range: [0.0000, 0.3633], d_k_M_hat range: [0.8916, 1.0000]
2025-03-11 21:21:53 - Train Iteration 12727: loss: 0.1088, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.6702, 0.9994]
2025-03-11 21:21:54 - Train Iteration 12728: loss: 0.0225, d_k_M range: [0.0001, 0.1500], d_k_M_hat range: [0.9757, 1.0000]
2025-03-11 21:21:54 - Train Iteration 12729: loss: 0.1750, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.5829, 0.9972]
2025-03-11 21:21:55 - Train Iteration 12730: loss: 0.0005, d_k_M range: [0.0000, 0.0169], d_k_M_hat range: [0.9784, 1.0000]
2025-03-11 21:21:55 - Train Iteration 12731: loss: 0.0009, d_k_M range: [0.0000, 0.0152], d_k_M_hat range: [0.9695, 0.9980]
2025-03-11 21:21:55 - Train Iteration 12732: loss: 0.0015, d_k_M range: [0.0001, 0.0381], d_k_M_hat range: [0.9778, 0.9997]
2025-03-11 21:21:56 - Train Iteration 12733: loss: 0.0009, d_k_M range: [0.0000, 0.0285], d_k_M_hat range: [0.9953, 0.9998]
2025-03-11 21:21:56 - Train Iteration 12734: loss: 0.0015, d_k_M range: [0.0000, 0.0129], d_k_M_hat range: [0.9610, 0.9999]
2025-03-11 21:21:57 - Train Iteration 12735: loss: 0.0008, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.9715, 0.9997]
2025-03-11 21:21:57 - Train Iteration 12736: loss: 0.0038, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.9417, 0.9984]
2025-03-11 21:21:58 - Train Iteration 12737: loss: 0.0005, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.9781, 0.9987]
2025-03-11 21:21:58 - Train Iteration 12738: loss: 0.0068, d_k_M range: [0.0000, 0.0279], d_k_M_hat range: [0.9203, 0.9988]
2025-03-11 21:21:58 - Train Iteration 12739: loss: 0.0574, d_k_M range: [0.0000, 0.2386], d_k_M_hat range: [0.9918, 0.9999]
2025-03-11 21:21:59 - Train Iteration 12740: loss: 0.0006, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9747, 0.9994]
2025-03-11 21:21:59 - Train Iteration 12741: loss: 0.0035, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9409, 0.9997]
2025-03-11 21:21:59 - Train Iteration 12742: loss: 0.0041, d_k_M range: [0.0000, 0.0209], d_k_M_hat range: [0.9435, 1.0000]
2025-03-11 21:22:00 - Train Iteration 12743: loss: 0.0117, d_k_M range: [0.0000, 0.0157], d_k_M_hat range: [0.9075, 0.9994]
2025-03-11 21:22:00 - Train Iteration 12744: loss: 0.0583, d_k_M range: [0.0000, 0.2409], d_k_M_hat range: [0.9929, 1.0000]
2025-03-11 21:22:01 - Train Iteration 12745: loss: 0.0626, d_k_M range: [0.0001, 0.2447], d_k_M_hat range: [0.9940, 0.9998]
2025-03-11 21:22:01 - Train Iteration 12746: loss: 0.2518, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.4983, 0.9999]
2025-03-11 21:22:01 - Train Iteration 12747: loss: 0.4364, d_k_M range: [0.0005, 0.6606], d_k_M_hat range: [0.9971, 1.0000]
2025-03-11 21:22:02 - Train Iteration 12748: loss: 0.0024, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9512, 0.9999]
2025-03-11 21:22:02 - Train Iteration 12749: loss: 0.0011, d_k_M range: [0.0000, 0.0165], d_k_M_hat range: [0.9664, 0.9998]
2025-03-11 21:22:03 - Train Iteration 12750: loss: 0.0531, d_k_M range: [0.0000, 0.2301], d_k_M_hat range: [0.9950, 0.9996]
2025-03-11 21:22:03 - Train Iteration 12751: loss: 0.0014, d_k_M range: [0.0000, 0.0071], d_k_M_hat range: [0.9626, 0.9991]
2025-03-11 21:22:04 - Train Iteration 12752: loss: 0.0007, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.9747, 0.9983]
2025-03-11 21:22:04 - Train Iteration 12753: loss: 0.0002, d_k_M range: [0.0000, 0.0064], d_k_M_hat range: [0.9872, 0.9987]
2025-03-11 21:22:04 - Train Iteration 12754: loss: 0.8646, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.0702, 0.9997]
2025-03-11 21:22:05 - Train Iteration 12755: loss: 0.0008, d_k_M range: [0.0000, 0.0097], d_k_M_hat range: [0.9715, 0.9999]
2025-03-11 21:22:05 - Train Iteration 12756: loss: 0.0005, d_k_M range: [0.0000, 0.0152], d_k_M_hat range: [0.9770, 0.9998]
2025-03-11 21:22:05 - Train Iteration 12757: loss: 0.0002, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9854, 0.9991]
2025-03-11 21:22:06 - Train Iteration 12758: loss: 0.5392, d_k_M range: [0.0000, 0.0086], d_k_M_hat range: [0.2659, 0.9997]
2025-03-11 21:22:06 - Train Iteration 12759: loss: 0.0765, d_k_M range: [0.0000, 0.2740], d_k_M_hat range: [0.9954, 0.9995]
2025-03-11 21:22:07 - Train Iteration 12760: loss: 0.0482, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.7805, 0.9999]
2025-03-11 21:22:07 - Train Iteration 12761: loss: 0.0578, d_k_M range: [0.0000, 0.0212], d_k_M_hat range: [0.7595, 0.9997]
2025-03-11 21:22:07 - Train Iteration 12762: loss: 0.6859, d_k_M range: [0.0000, 0.8282], d_k_M_hat range: [0.9885, 1.0000]
2025-03-11 21:22:08 - Train Iteration 12763: loss: 0.0114, d_k_M range: [0.0002, 0.1064], d_k_M_hat range: [0.9851, 0.9999]
2025-03-11 21:22:08 - Train Iteration 12764: loss: 0.0349, d_k_M range: [0.0000, 0.1867], d_k_M_hat range: [0.9938, 0.9999]
2025-03-11 21:22:09 - Train Iteration 12765: loss: 0.0674, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.7405, 0.9993]
2025-03-11 21:22:09 - Train Iteration 12766: loss: 0.0004, d_k_M range: [0.0000, 0.0182], d_k_M_hat range: [0.9826, 0.9998]
2025-03-11 21:22:10 - Train Iteration 12767: loss: 0.0008, d_k_M range: [0.0000, 0.0267], d_k_M_hat range: [0.9959, 1.0000]
2025-03-11 21:22:10 - Train Iteration 12768: loss: 0.1322, d_k_M range: [0.0000, 0.0267], d_k_M_hat range: [0.6632, 0.9990]
2025-03-11 21:22:10 - Train Iteration 12769: loss: 0.0214, d_k_M range: [0.0002, 0.1385], d_k_M_hat range: [0.9839, 1.0000]
2025-03-11 21:22:11 - Train Iteration 12770: loss: 0.0040, d_k_M range: [0.0000, 0.0270], d_k_M_hat range: [0.9366, 0.9995]
2025-03-11 21:22:11 - Train Iteration 12771: loss: 0.4804, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.3070, 0.9992]
2025-03-11 21:22:12 - Train Iteration 12772: loss: 0.0227, d_k_M range: [0.0000, 0.1497], d_k_M_hat range: [0.9932, 0.9998]
2025-03-11 21:22:12 - Train Iteration 12773: loss: 0.0011, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.9669, 0.9998]
2025-03-11 21:22:12 - Train Iteration 12774: loss: 0.0036, d_k_M range: [0.0003, 0.0148], d_k_M_hat range: [0.9408, 0.9999]
2025-03-11 21:22:13 - Train Iteration 12775: loss: 0.0003, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9833, 0.9997]
2025-03-11 21:22:13 - Train Iteration 12776: loss: 0.5615, d_k_M range: [0.0000, 0.7492], d_k_M_hat range: [0.9849, 0.9999]
2025-03-11 21:22:14 - Train Iteration 12777: loss: 0.0651, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.7451, 0.9952]
2025-03-11 21:22:14 - Train Iteration 12778: loss: 0.0977, d_k_M range: [0.0001, 0.3049], d_k_M_hat range: [0.9917, 1.0000]
2025-03-11 21:22:14 - Train Iteration 12779: loss: 0.6665, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.1836, 0.9936]
2025-03-11 21:22:15 - Train Iteration 12780: loss: 0.5033, d_k_M range: [0.0000, 0.0089], d_k_M_hat range: [0.2906, 0.9976]
2025-03-11 21:22:15 - Train Iteration 12781: loss: 0.0909, d_k_M range: [0.0000, 0.3015], d_k_M_hat range: [0.9948, 1.0000]
2025-03-11 21:22:16 - Train Iteration 12782: loss: 0.5267, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.2746, 0.9997]
2025-03-11 21:22:16 - Train Iteration 12783: loss: 0.1267, d_k_M range: [0.0000, 0.3558], d_k_M_hat range: [0.8644, 0.9999]
2025-03-11 21:22:17 - Train Iteration 12784: loss: 0.4370, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.3390, 0.9995]
2025-03-11 21:22:17 - Train Iteration 12785: loss: 0.0007, d_k_M range: [0.0000, 0.0095], d_k_M_hat range: [0.9836, 0.9998]
2025-03-11 21:22:17 - Train Iteration 12786: loss: 0.0002, d_k_M range: [0.0000, 0.0069], d_k_M_hat range: [0.9895, 0.9998]
2025-03-11 21:22:18 - Train Iteration 12787: loss: 0.0105, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.8979, 0.9965]
2025-03-11 21:22:18 - Train Iteration 12788: loss: 0.0018, d_k_M range: [0.0000, 0.0101], d_k_M_hat range: [0.9610, 0.9995]
2025-03-11 21:22:19 - Train Iteration 12789: loss: 0.3104, d_k_M range: [0.0000, 0.5571], d_k_M_hat range: [0.9889, 0.9999]
2025-03-11 21:22:19 - Train Iteration 12790: loss: 0.0020, d_k_M range: [0.0000, 0.0128], d_k_M_hat range: [0.9548, 0.9995]
2025-03-11 21:22:19 - Train Iteration 12791: loss: 0.0019, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9564, 0.9998]
2025-03-11 21:22:20 - Train Iteration 12792: loss: 0.0088, d_k_M range: [0.0000, 0.0940], d_k_M_hat range: [0.9961, 1.0000]
2025-03-11 21:22:20 - Train Iteration 12793: loss: 0.0411, d_k_M range: [0.0000, 0.1259], d_k_M_hat range: [0.7976, 0.9995]
2025-03-11 21:22:21 - Train Iteration 12794: loss: 0.0068, d_k_M range: [0.0000, 0.0703], d_k_M_hat range: [0.9333, 0.9994]
2025-03-11 21:22:21 - Train Iteration 12795: loss: 0.0053, d_k_M range: [0.0000, 0.0439], d_k_M_hat range: [0.9276, 0.9990]
2025-03-11 21:22:21 - Train Iteration 12796: loss: 0.0102, d_k_M range: [0.0000, 0.0095], d_k_M_hat range: [0.8988, 0.9994]
2025-03-11 21:22:22 - Train Iteration 12797: loss: 0.0396, d_k_M range: [0.0001, 0.1975], d_k_M_hat range: [0.9713, 0.9995]
2025-03-11 21:22:22 - Train Iteration 12798: loss: 0.1290, d_k_M range: [0.0000, 0.0163], d_k_M_hat range: [0.6409, 0.9996]
2025-03-11 21:22:23 - Train Iteration 12799: loss: 0.8077, d_k_M range: [0.0001, 0.8974], d_k_M_hat range: [0.8174, 0.9999]
2025-03-11 21:22:23 - Train Iteration 12800: loss: 0.0715, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.7327, 0.9985]
2025-03-11 21:22:23 - Train Iteration 12801: loss: 0.0018, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.9571, 0.9997]
2025-03-11 21:22:24 - Train Iteration 12802: loss: 0.0003, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.9827, 0.9994]
2025-03-11 21:22:24 - Train Iteration 12803: loss: 0.0279, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.8330, 0.9998]
2025-03-11 21:22:25 - Train Iteration 12804: loss: 0.0089, d_k_M range: [0.0000, 0.0917], d_k_M_hat range: [0.9831, 0.9998]
2025-03-11 21:22:25 - Train Iteration 12805: loss: 0.0003, d_k_M range: [0.0000, 0.0089], d_k_M_hat range: [0.9880, 0.9999]
2025-03-11 21:22:26 - Train Iteration 12806: loss: 0.0959, d_k_M range: [0.0000, 0.0505], d_k_M_hat range: [0.6904, 0.9999]
2025-03-11 21:22:26 - Train Iteration 12807: loss: 0.4817, d_k_M range: [0.0000, 0.6939], d_k_M_hat range: [0.9931, 0.9999]
2025-03-11 21:22:27 - Train Iteration 12808: loss: 0.0556, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.7653, 0.9994]
2025-03-11 21:22:27 - Train Iteration 12809: loss: 0.1750, d_k_M range: [0.0000, 0.0504], d_k_M_hat range: [0.5817, 0.9999]
2025-03-11 21:22:28 - Train Iteration 12810: loss: 0.0005, d_k_M range: [0.0001, 0.0052], d_k_M_hat range: [0.9807, 0.9999]
2025-03-11 21:22:28 - Train Iteration 12811: loss: 0.0003, d_k_M range: [0.0001, 0.0105], d_k_M_hat range: [0.9832, 0.9998]
2025-03-11 21:22:29 - Train Iteration 12812: loss: 0.0005, d_k_M range: [0.0001, 0.0025], d_k_M_hat range: [0.9779, 0.9991]
2025-03-11 21:22:29 - Train Iteration 12813: loss: 0.0107, d_k_M range: [0.0000, 0.0073], d_k_M_hat range: [0.8968, 1.0000]
2025-03-11 21:22:30 - Train Iteration 12814: loss: 0.0220, d_k_M range: [0.0000, 0.1482], d_k_M_hat range: [0.9767, 0.9999]
2025-03-11 21:22:30 - Train Iteration 12815: loss: 0.0014, d_k_M range: [0.0001, 0.0107], d_k_M_hat range: [0.9634, 0.9998]
2025-03-11 21:22:31 - Train Iteration 12816: loss: 0.0372, d_k_M range: [0.0000, 0.0449], d_k_M_hat range: [0.8078, 1.0000]
2025-03-11 21:22:31 - Train Iteration 12817: loss: 0.7503, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.1339, 0.9982]
2025-03-11 21:22:32 - Train Iteration 12818: loss: 0.0002, d_k_M range: [0.0000, 0.0128], d_k_M_hat range: [0.9913, 0.9999]
2025-03-11 21:22:32 - Train Iteration 12819: loss: 0.0202, d_k_M range: [0.0000, 0.1419], d_k_M_hat range: [0.9863, 1.0000]
2025-03-11 21:22:32 - Train Iteration 12820: loss: 0.0092, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.9041, 0.9999]
2025-03-11 21:22:33 - Train Iteration 12821: loss: 0.0034, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.9414, 0.9998]
2025-03-11 21:22:33 - Train Iteration 12822: loss: 0.7245, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.1488, 0.9997]
2025-03-11 21:22:34 - Train Iteration 12823: loss: 0.0056, d_k_M range: [0.0000, 0.0203], d_k_M_hat range: [0.9251, 0.9999]
2025-03-11 21:22:34 - Train Iteration 12824: loss: 0.0023, d_k_M range: [0.0000, 0.0143], d_k_M_hat range: [0.9659, 0.9999]
2025-03-11 21:22:35 - Train Iteration 12825: loss: 0.0004, d_k_M range: [0.0000, 0.0115], d_k_M_hat range: [0.9806, 0.9999]
2025-03-11 21:22:35 - Train Iteration 12826: loss: 0.0005, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9775, 0.9998]
2025-03-11 21:22:36 - Train Iteration 12827: loss: 0.1106, d_k_M range: [0.0000, 0.3301], d_k_M_hat range: [0.9935, 0.9995]
2025-03-11 21:22:36 - Train Iteration 12828: loss: 0.0003, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9858, 0.9998]
2025-03-11 21:22:37 - Train Iteration 12829: loss: 0.0002, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9882, 0.9981]
2025-03-11 21:22:37 - Train Iteration 12830: loss: 0.0020, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9553, 0.9996]
2025-03-11 21:22:37 - Train Iteration 12831: loss: 0.2774, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.4733, 0.9979]
2025-03-11 21:22:38 - Train Iteration 12832: loss: 0.1150, d_k_M range: [0.0001, 0.3386], d_k_M_hat range: [0.9957, 1.0000]
2025-03-11 21:22:38 - Train Iteration 12833: loss: 0.0057, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9243, 0.9989]
2025-03-11 21:22:39 - Train Iteration 12834: loss: 0.0008, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9720, 0.9996]
2025-03-11 21:22:39 - Train Iteration 12835: loss: 0.0212, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.8544, 0.9991]
2025-03-11 21:22:40 - Train Iteration 12836: loss: 0.1765, d_k_M range: [0.0000, 0.4201], d_k_M_hat range: [0.9402, 1.0000]
2025-03-11 21:22:40 - Train Iteration 12837: loss: 0.5338, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.2747, 0.9979]
2025-03-11 21:22:41 - Train Iteration 12838: loss: 0.0001, d_k_M range: [0.0000, 0.0084], d_k_M_hat range: [0.9905, 0.9999]
2025-03-11 21:22:41 - Train Iteration 12839: loss: 0.0017, d_k_M range: [0.0000, 0.0409], d_k_M_hat range: [0.9708, 0.9997]
2025-03-11 21:22:41 - Train Iteration 12840: loss: 0.0035, d_k_M range: [0.0000, 0.0572], d_k_M_hat range: [0.9605, 0.9998]
2025-03-11 21:22:42 - Train Iteration 12841: loss: 0.0546, d_k_M range: [0.0000, 0.0539], d_k_M_hat range: [0.7663, 0.9994]
2025-03-11 21:22:42 - Train Iteration 12842: loss: 0.6658, d_k_M range: [0.0000, 0.8148], d_k_M_hat range: [0.9948, 1.0000]
2025-03-11 21:22:43 - Train Iteration 12843: loss: 0.0206, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.8565, 0.9994]
2025-03-11 21:22:43 - Train Iteration 12844: loss: 0.0019, d_k_M range: [0.0001, 0.0396], d_k_M_hat range: [0.9917, 0.9993]
2025-03-11 21:22:44 - Train Iteration 12845: loss: 0.0101, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.9018, 0.9999]
2025-03-11 21:22:44 - Train Iteration 12846: loss: 0.0002, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9914, 0.9999]
2025-03-11 21:22:45 - Train Iteration 12847: loss: 0.0011, d_k_M range: [0.0000, 0.0101], d_k_M_hat range: [0.9664, 0.9997]
2025-03-11 21:22:45 - Train Iteration 12848: loss: 0.0044, d_k_M range: [0.0000, 0.0509], d_k_M_hat range: [0.9734, 0.9997]
2025-03-11 21:22:45 - Train Iteration 12849: loss: 0.0008, d_k_M range: [0.0001, 0.0199], d_k_M_hat range: [0.9907, 0.9993]
2025-03-11 21:22:46 - Train Iteration 12850: loss: 0.0408, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.7982, 0.9999]
2025-03-11 21:22:46 - Train Iteration 12851: loss: 0.0004, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9795, 0.9996]
2025-03-11 21:22:47 - Train Iteration 12852: loss: 0.0421, d_k_M range: [0.0000, 0.2047], d_k_M_hat range: [0.9308, 0.9998]
2025-03-11 21:22:47 - Train Iteration 12853: loss: 0.0857, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.7073, 0.9997]
2025-03-11 21:22:48 - Train Iteration 12854: loss: 0.2879, d_k_M range: [0.0000, 0.5364], d_k_M_hat range: [0.9787, 0.9999]
2025-03-11 21:22:48 - Train Iteration 12855: loss: 0.0015, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.9614, 0.9979]
2025-03-11 21:22:48 - Train Iteration 12856: loss: 0.0201, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.8582, 0.9982]
2025-03-11 21:22:49 - Train Iteration 12857: loss: 0.0034, d_k_M range: [0.0000, 0.0085], d_k_M_hat range: [0.9414, 0.9998]
2025-03-11 21:22:49 - Train Iteration 12858: loss: 0.0069, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9172, 0.9990]
2025-03-11 21:22:50 - Train Iteration 12859: loss: 0.5076, d_k_M range: [0.0000, 0.7124], d_k_M_hat range: [0.9776, 1.0000]
2025-03-11 21:22:50 - Train Iteration 12860: loss: 0.0139, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.8835, 0.9988]
2025-03-11 21:22:51 - Train Iteration 12861: loss: 0.0057, d_k_M range: [0.0002, 0.0014], d_k_M_hat range: [0.9250, 0.9988]
2025-03-11 21:22:51 - Train Iteration 12862: loss: 0.0001, d_k_M range: [0.0000, 0.0112], d_k_M_hat range: [0.9933, 0.9999]
2025-03-11 21:22:51 - Train Iteration 12863: loss: 0.0003, d_k_M range: [0.0001, 0.0128], d_k_M_hat range: [0.9856, 0.9992]
2025-03-11 21:22:52 - Train Iteration 12864: loss: 0.0384, d_k_M range: [0.0000, 0.1955], d_k_M_hat range: [0.9859, 0.9996]
2025-03-11 21:22:52 - Train Iteration 12865: loss: 0.0082, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.9094, 0.9995]
2025-03-11 21:22:53 - Train Iteration 12866: loss: 0.0639, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.7472, 0.9992]
2025-03-11 21:22:53 - Train Iteration 12867: loss: 0.1968, d_k_M range: [0.0000, 0.0171], d_k_M_hat range: [0.5565, 0.9984]
2025-03-11 21:22:54 - Train Iteration 12868: loss: 0.0002, d_k_M range: [0.0002, 0.0045], d_k_M_hat range: [0.9851, 0.9989]
2025-03-11 21:22:54 - Train Iteration 12869: loss: 0.0009, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.9693, 1.0000]
2025-03-11 21:22:54 - Train Iteration 12870: loss: 0.0012, d_k_M range: [0.0003, 0.0339], d_k_M_hat range: [0.9920, 0.9997]
2025-03-11 21:22:55 - Train Iteration 12871: loss: 0.0022, d_k_M range: [0.0001, 0.0224], d_k_M_hat range: [0.9534, 0.9988]
2025-03-11 21:22:55 - Train Iteration 12872: loss: 0.2229, d_k_M range: [0.0000, 0.4716], d_k_M_hat range: [0.9924, 0.9999]
2025-03-11 21:22:56 - Train Iteration 12873: loss: 0.0407, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.7982, 0.9999]
2025-03-11 21:22:56 - Train Iteration 12874: loss: 0.0025, d_k_M range: [0.0000, 0.0121], d_k_M_hat range: [0.9572, 1.0000]
2025-03-11 21:22:57 - Train Iteration 12875: loss: 0.0019, d_k_M range: [0.0002, 0.0438], d_k_M_hat range: [0.9891, 1.0000]
2025-03-11 21:22:57 - Train Iteration 12876: loss: 0.0197, d_k_M range: [0.0000, 0.0072], d_k_M_hat range: [0.8599, 0.9998]
2025-03-11 21:22:57 - Train Iteration 12877: loss: 0.1379, d_k_M range: [0.0000, 0.1238], d_k_M_hat range: [0.6507, 0.9999]
2025-03-11 21:22:58 - Train Iteration 12878: loss: 0.0005, d_k_M range: [0.0001, 0.0104], d_k_M_hat range: [0.9830, 0.9993]
2025-03-11 21:22:58 - Train Iteration 12879: loss: 0.0264, d_k_M range: [0.0002, 0.1623], d_k_M_hat range: [0.9896, 0.9998]
2025-03-11 21:22:59 - Train Iteration 12880: loss: 0.0644, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.7463, 0.9992]
2025-03-11 21:22:59 - Train Iteration 12881: loss: 0.0151, d_k_M range: [0.0005, 0.1227], d_k_M_hat range: [0.9964, 0.9999]
2025-03-11 21:23:00 - Train Iteration 12882: loss: 0.9723, d_k_M range: [0.0001, 0.9860], d_k_M_hat range: [0.9986, 1.0000]
2025-03-11 21:23:00 - Train Iteration 12883: loss: 0.0175, d_k_M range: [0.0000, 0.1323], d_k_M_hat range: [0.9978, 0.9999]
2025-03-11 21:23:00 - Train Iteration 12884: loss: 0.1489, d_k_M range: [0.0000, 0.0218], d_k_M_hat range: [0.6151, 0.9985]
2025-03-11 21:23:01 - Train Iteration 12885: loss: 0.0002, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9870, 0.9995]
2025-03-11 21:23:01 - Train Iteration 12886: loss: 0.0313, d_k_M range: [0.0001, 0.1763], d_k_M_hat range: [0.9557, 0.9995]
2025-03-11 21:23:02 - Train Iteration 12887: loss: 0.0057, d_k_M range: [0.0000, 0.0383], d_k_M_hat range: [0.9245, 0.9997]
2025-03-11 21:23:02 - Train Iteration 12888: loss: 0.0123, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.8891, 0.9995]
2025-03-11 21:23:03 - Train Iteration 12889: loss: 0.0025, d_k_M range: [0.0002, 0.0486], d_k_M_hat range: [0.9764, 0.9999]
2025-03-11 21:23:03 - Train Iteration 12890: loss: 0.0005, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.9781, 0.9995]
2025-03-11 21:23:03 - Train Iteration 12891: loss: 0.0001, d_k_M range: [0.0000, 0.0100], d_k_M_hat range: [0.9897, 0.9999]
2025-03-11 21:23:04 - Train Iteration 12892: loss: 0.5596, d_k_M range: [0.0000, 0.7480], d_k_M_hat range: [0.9982, 0.9999]
2025-03-11 21:23:04 - Train Iteration 12893: loss: 0.0111, d_k_M range: [0.0000, 0.1049], d_k_M_hat range: [0.9710, 0.9997]
2025-03-11 21:23:05 - Train Iteration 12894: loss: 0.0005, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.9785, 0.9988]
2025-03-11 21:23:05 - Train Iteration 12895: loss: 0.0014, d_k_M range: [0.0000, 0.0179], d_k_M_hat range: [0.9623, 0.9997]
2025-03-11 21:23:06 - Train Iteration 12896: loss: 0.1877, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.5667, 0.9990]
2025-03-11 21:23:06 - Train Iteration 12897: loss: 0.0008, d_k_M range: [0.0000, 0.0258], d_k_M_hat range: [0.9736, 0.9997]
2025-03-11 21:23:07 - Train Iteration 12898: loss: 0.1766, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.5809, 0.9979]
2025-03-11 21:23:07 - Train Iteration 12899: loss: 0.0961, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.6905, 0.9997]
2025-03-11 21:23:08 - Train Iteration 12900: loss: 0.2779, d_k_M range: [0.0000, 0.5272], d_k_M_hat range: [0.9794, 1.0000]
2025-03-11 21:23:08 - Train Iteration 12901: loss: 0.0024, d_k_M range: [0.0000, 0.0469], d_k_M_hat range: [0.9653, 0.9996]
2025-03-11 21:23:09 - Train Iteration 12902: loss: 0.0052, d_k_M range: [0.0000, 0.0104], d_k_M_hat range: [0.9278, 0.9995]
2025-03-11 21:23:09 - Train Iteration 12903: loss: 0.0009, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.9715, 0.9999]
2025-03-11 21:23:10 - Train Iteration 12904: loss: 0.0000, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9948, 0.9999]
2025-03-11 21:23:10 - Train Iteration 12905: loss: 0.0003, d_k_M range: [0.0000, 0.0145], d_k_M_hat range: [0.9955, 0.9999]
2025-03-11 21:23:10 - Train Iteration 12906: loss: 0.0065, d_k_M range: [0.0000, 0.0151], d_k_M_hat range: [0.9196, 0.9990]
2025-03-11 21:23:11 - Train Iteration 12907: loss: 0.0004, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.9822, 0.9996]
2025-03-11 21:23:11 - Train Iteration 12908: loss: 0.0005, d_k_M range: [0.0000, 0.0226], d_k_M_hat range: [0.9903, 1.0000]
2025-03-11 21:23:12 - Train Iteration 12909: loss: 0.0504, d_k_M range: [0.0001, 0.0983], d_k_M_hat range: [0.7782, 0.9997]
2025-03-11 21:23:12 - Train Iteration 12910: loss: 0.0003, d_k_M range: [0.0006, 0.0168], d_k_M_hat range: [0.9886, 0.9993]
2025-03-11 21:23:12 - Train Iteration 12911: loss: 0.0090, d_k_M range: [0.0006, 0.0937], d_k_M_hat range: [0.9977, 1.0000]
2025-03-11 21:23:13 - Train Iteration 12912: loss: 0.0005, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.9792, 0.9997]
2025-03-11 21:23:13 - Train Iteration 12913: loss: 0.1199, d_k_M range: [0.0000, 0.3462], d_k_M_hat range: [0.9927, 1.0000]
2025-03-11 21:23:14 - Train Iteration 12914: loss: 0.0105, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.8990, 0.9980]
2025-03-11 21:23:14 - Train Iteration 12915: loss: 0.0075, d_k_M range: [0.0000, 0.0862], d_k_M_hat range: [0.9362, 0.9997]
2025-03-11 21:23:14 - Train Iteration 12916: loss: 0.0004, d_k_M range: [0.0000, 0.0106], d_k_M_hat range: [0.9812, 0.9997]
2025-03-11 21:23:15 - Train Iteration 12917: loss: 0.1155, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.6602, 0.9993]
2025-03-11 21:23:15 - Train Iteration 12918: loss: 0.7649, d_k_M range: [0.0000, 0.8746], d_k_M_hat range: [0.9857, 1.0000]
2025-03-11 21:23:16 - Train Iteration 12919: loss: 0.9106, d_k_M range: [0.0000, 0.3930], d_k_M_hat range: [0.0458, 0.9994]
2025-03-11 21:23:16 - Train Iteration 12920: loss: 0.1713, d_k_M range: [0.0000, 0.0097], d_k_M_hat range: [0.5862, 0.9998]
2025-03-11 21:23:16 - Train Iteration 12921: loss: 0.6798, d_k_M range: [0.0002, 0.8245], d_k_M_hat range: [0.8914, 1.0000]
2025-03-11 21:23:17 - Train Iteration 12922: loss: 0.0659, d_k_M range: [0.0000, 0.2564], d_k_M_hat range: [0.7433, 0.9996]
2025-03-11 21:23:17 - Train Iteration 12923: loss: 0.0293, d_k_M range: [0.0000, 0.1708], d_k_M_hat range: [0.9778, 0.9998]
2025-03-11 21:23:18 - Train Iteration 12924: loss: 0.0361, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.8099, 0.9993]
2025-03-11 21:23:18 - Train Iteration 12925: loss: 0.0003, d_k_M range: [0.0000, 0.0178], d_k_M_hat range: [0.9950, 0.9999]
2025-03-11 21:23:18 - Train Iteration 12926: loss: 0.0679, d_k_M range: [0.0000, 0.0610], d_k_M_hat range: [0.7394, 0.9987]
2025-03-11 21:23:19 - Train Iteration 12927: loss: 0.0009, d_k_M range: [0.0000, 0.0255], d_k_M_hat range: [0.9754, 0.9993]
2025-03-11 21:23:19 - Train Iteration 12928: loss: 0.0111, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.8947, 0.9983]
2025-03-11 21:23:19 - Train Iteration 12929: loss: 0.0299, d_k_M range: [0.0000, 0.0968], d_k_M_hat range: [0.8272, 0.9971]
2025-03-11 21:23:20 - Train Iteration 12930: loss: 0.0003, d_k_M range: [0.0000, 0.0135], d_k_M_hat range: [0.9954, 0.9997]
2025-03-11 21:23:20 - Train Iteration 12931: loss: 0.0002, d_k_M range: [0.0000, 0.0149], d_k_M_hat range: [0.9879, 0.9998]
2025-03-11 21:23:21 - Train Iteration 12932: loss: 0.0072, d_k_M range: [0.0000, 0.0849], d_k_M_hat range: [0.9918, 0.9999]
2025-03-11 21:23:21 - Train Iteration 12933: loss: 0.0128, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.8871, 0.9999]
2025-03-11 21:23:21 - Train Iteration 12934: loss: 0.0090, d_k_M range: [0.0000, 0.0944], d_k_M_hat range: [0.9654, 0.9998]
2025-03-11 21:23:22 - Train Iteration 12935: loss: 0.0003, d_k_M range: [0.0001, 0.0074], d_k_M_hat range: [0.9839, 1.0000]
2025-03-11 21:23:22 - Train Iteration 12936: loss: 0.0150, d_k_M range: [0.0003, 0.1224], d_k_M_hat range: [0.9974, 0.9999]
2025-03-11 21:23:23 - Train Iteration 12937: loss: 0.1630, d_k_M range: [0.0002, 0.4034], d_k_M_hat range: [0.9874, 0.9998]
2025-03-11 21:23:23 - Train Iteration 12938: loss: 0.0067, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9180, 0.9988]
2025-03-11 21:23:24 - Train Iteration 12939: loss: 0.0046, d_k_M range: [0.0000, 0.0191], d_k_M_hat range: [0.9504, 1.0000]
2025-03-11 21:23:24 - Train Iteration 12940: loss: 0.0465, d_k_M range: [0.0000, 0.2150], d_k_M_hat range: [0.9962, 0.9999]
2025-03-11 21:23:24 - Train Iteration 12941: loss: 0.0001, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.9888, 0.9998]
2025-03-11 21:23:25 - Train Iteration 12942: loss: 0.0011, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.9670, 0.9998]
2025-03-11 21:23:25 - Train Iteration 12943: loss: 0.0075, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9141, 0.9995]
2025-03-11 21:23:25 - Train Iteration 12944: loss: 0.0113, d_k_M range: [0.0000, 0.0714], d_k_M_hat range: [0.8938, 0.9998]
2025-03-11 21:23:26 - Train Iteration 12945: loss: 0.0003, d_k_M range: [0.0001, 0.0016], d_k_M_hat range: [0.9829, 0.9994]
2025-03-11 21:23:26 - Train Iteration 12946: loss: 0.0007, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.9738, 0.9999]
2025-03-11 21:23:27 - Train Iteration 12947: loss: 0.0008, d_k_M range: [0.0000, 0.0269], d_k_M_hat range: [0.9773, 0.9999]
2025-03-11 21:23:27 - Train Iteration 12948: loss: 0.0047, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.9312, 0.9989]
2025-03-11 21:23:27 - Train Iteration 12949: loss: 0.0002, d_k_M range: [0.0000, 0.0094], d_k_M_hat range: [0.9861, 0.9988]
2025-03-11 21:23:28 - Train Iteration 12950: loss: 0.4885, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.3011, 0.9998]
2025-03-11 21:23:28 - Train Iteration 12951: loss: 0.0484, d_k_M range: [0.0001, 0.2200], d_k_M_hat range: [0.9962, 0.9999]
2025-03-11 21:23:29 - Train Iteration 12952: loss: 0.0020, d_k_M range: [0.0001, 0.0128], d_k_M_hat range: [0.9560, 0.9973]
2025-03-11 21:23:29 - Train Iteration 12953: loss: 0.8166, d_k_M range: [0.0000, 0.9034], d_k_M_hat range: [0.9893, 0.9998]
2025-03-11 21:23:30 - Train Iteration 12954: loss: 0.0007, d_k_M range: [0.0000, 0.0069], d_k_M_hat range: [0.9743, 0.9998]
2025-03-11 21:23:30 - Train Iteration 12955: loss: 0.0009, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9693, 0.9987]
2025-03-11 21:23:30 - Train Iteration 12956: loss: 0.0077, d_k_M range: [0.0000, 0.0088], d_k_M_hat range: [0.9122, 0.9998]
2025-03-11 21:23:31 - Train Iteration 12957: loss: 0.0007, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9731, 0.9997]
2025-03-11 21:23:31 - Train Iteration 12958: loss: 0.0008, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9724, 0.9988]
2025-03-11 21:23:32 - Train Iteration 12959: loss: 0.0087, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9069, 0.9996]
2025-03-11 21:23:32 - Train Iteration 12960: loss: 0.1437, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.6209, 0.9949]
2025-03-11 21:23:33 - Train Iteration 12961: loss: 0.1032, d_k_M range: [0.0001, 0.3201], d_k_M_hat range: [0.9752, 0.9998]
2025-03-11 21:23:33 - Train Iteration 12962: loss: 0.5512, d_k_M range: [0.0000, 0.0048], d_k_M_hat range: [0.2577, 0.9986]
2025-03-11 21:23:33 - Train Iteration 12963: loss: 0.0221, d_k_M range: [0.0001, 0.1483], d_k_M_hat range: [0.8779, 0.9998]
2025-03-11 21:23:34 - Train Iteration 12964: loss: 0.0091, d_k_M range: [0.0001, 0.0343], d_k_M_hat range: [0.9389, 0.9992]
2025-03-11 21:23:34 - Train Iteration 12965: loss: 0.1008, d_k_M range: [0.0000, 0.3174], d_k_M_hat range: [0.9876, 0.9999]
2025-03-11 21:23:35 - Train Iteration 12966: loss: 0.2275, d_k_M range: [0.0000, 0.0251], d_k_M_hat range: [0.5242, 0.9979]
2025-03-11 21:23:35 - Train Iteration 12967: loss: 0.0404, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.7991, 0.9988]
2025-03-11 21:23:36 - Train Iteration 12968: loss: 0.2573, d_k_M range: [0.0000, 0.5013], d_k_M_hat range: [0.9912, 0.9997]
2025-03-11 21:23:36 - Train Iteration 12969: loss: 0.1046, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.6765, 0.9988]
2025-03-11 21:23:37 - Train Iteration 12970: loss: 0.0035, d_k_M range: [0.0000, 0.0589], d_k_M_hat range: [0.9781, 1.0000]
2025-03-11 21:23:37 - Train Iteration 12971: loss: 0.0092, d_k_M range: [0.0000, 0.0615], d_k_M_hat range: [0.9657, 0.9996]
2025-03-11 21:23:37 - Train Iteration 12972: loss: 0.0144, d_k_M range: [0.0000, 0.1179], d_k_M_hat range: [0.9891, 1.0000]
2025-03-11 21:23:38 - Train Iteration 12973: loss: 0.0006, d_k_M range: [0.0000, 0.0100], d_k_M_hat range: [0.9754, 0.9998]
2025-03-11 21:23:38 - Train Iteration 12974: loss: 0.0157, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.8746, 0.9975]
2025-03-11 21:23:39 - Train Iteration 12975: loss: 0.0004, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.9796, 0.9998]
2025-03-11 21:23:39 - Train Iteration 12976: loss: 0.0003, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9830, 0.9997]
2025-03-11 21:23:40 - Train Iteration 12977: loss: 0.1063, d_k_M range: [0.0000, 0.1392], d_k_M_hat range: [0.6799, 0.9999]
2025-03-11 21:23:40 - Train Iteration 12978: loss: 0.0262, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.8442, 0.9991]
2025-03-11 21:23:41 - Train Iteration 12979: loss: 0.0790, d_k_M range: [0.0000, 0.2810], d_k_M_hat range: [0.9829, 0.9999]
2025-03-11 21:23:41 - Train Iteration 12980: loss: 0.2321, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.5183, 0.9964]
2025-03-11 21:23:42 - Train Iteration 12981: loss: 0.0179, d_k_M range: [0.0000, 0.1335], d_k_M_hat range: [0.9609, 0.9998]
2025-03-11 21:23:42 - Train Iteration 12982: loss: 0.0131, d_k_M range: [0.0003, 0.1139], d_k_M_hat range: [0.9879, 0.9994]
2025-03-11 21:23:43 - Train Iteration 12983: loss: 0.0051, d_k_M range: [0.0000, 0.0584], d_k_M_hat range: [0.9286, 0.9996]
2025-03-11 21:23:43 - Train Iteration 12984: loss: 0.5711, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.2443, 0.9997]
2025-03-11 21:23:43 - Train Iteration 12985: loss: 0.0043, d_k_M range: [0.0000, 0.0137], d_k_M_hat range: [0.9344, 0.9996]
2025-03-11 21:23:44 - Train Iteration 12986: loss: 0.0274, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.8348, 0.9992]
2025-03-11 21:23:44 - Train Iteration 12987: loss: 0.1196, d_k_M range: [0.0002, 0.3444], d_k_M_hat range: [0.9560, 0.9986]
2025-03-11 21:23:45 - Train Iteration 12988: loss: 0.0586, d_k_M range: [0.0001, 0.2405], d_k_M_hat range: [0.8386, 0.9984]
2025-03-11 21:23:45 - Train Iteration 12989: loss: 0.0323, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.8204, 0.9973]
2025-03-11 21:23:46 - Train Iteration 12990: loss: 0.0045, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9331, 0.9995]
2025-03-11 21:23:46 - Train Iteration 12991: loss: 0.0376, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.8065, 0.9994]
2025-03-11 21:23:47 - Train Iteration 12992: loss: 0.0005, d_k_M range: [0.0000, 0.0196], d_k_M_hat range: [0.9915, 0.9999]
2025-03-11 21:23:47 - Train Iteration 12993: loss: 0.6278, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.2077, 0.9990]
2025-03-11 21:23:47 - Train Iteration 12994: loss: 0.8472, d_k_M range: [0.0000, 0.9203], d_k_M_hat range: [0.9956, 1.0000]
2025-03-11 21:23:48 - Train Iteration 12995: loss: 0.0145, d_k_M range: [0.0002, 0.1020], d_k_M_hat range: [0.9486, 1.0000]
2025-03-11 21:23:48 - Train Iteration 12996: loss: 0.0241, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.8449, 0.9986]
2025-03-11 21:23:49 - Train Iteration 12997: loss: 0.0004, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.9852, 0.9993]
2025-03-11 21:23:49 - Train Iteration 12998: loss: 0.2117, d_k_M range: [0.0000, 0.0098], d_k_M_hat range: [0.5400, 0.9984]
2025-03-11 21:23:50 - Train Iteration 12999: loss: 0.0019, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9570, 1.0000]
2025-03-11 21:23:50 - Train Iteration 13000: loss: 0.0075, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9136, 0.9932]
2025-03-11 21:23:51 - Train Iteration 13001: loss: 0.0831, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.7120, 0.9939]
2025-03-11 21:23:51 - Train Iteration 13002: loss: 0.0002, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.9858, 0.9992]
2025-03-11 21:23:51 - Train Iteration 13003: loss: 0.0001, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9928, 0.9998]
2025-03-11 21:23:52 - Train Iteration 13004: loss: 0.0011, d_k_M range: [0.0000, 0.0328], d_k_M_hat range: [0.9885, 0.9996]
2025-03-11 21:23:52 - Train Iteration 13005: loss: 0.0639, d_k_M range: [0.0000, 0.0124], d_k_M_hat range: [0.7471, 0.9951]
2025-03-11 21:23:53 - Train Iteration 13006: loss: 0.0039, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.9408, 0.9988]
2025-03-11 21:23:53 - Train Iteration 13007: loss: 0.1249, d_k_M range: [0.0000, 0.0104], d_k_M_hat range: [0.6466, 0.9998]
2025-03-11 21:23:54 - Train Iteration 13008: loss: 0.0370, d_k_M range: [0.0000, 0.0413], d_k_M_hat range: [0.8079, 0.9981]
2025-03-11 21:23:54 - Train Iteration 13009: loss: 0.0007, d_k_M range: [0.0000, 0.0134], d_k_M_hat range: [0.9764, 0.9999]
2025-03-11 21:23:55 - Train Iteration 13010: loss: 0.0120, d_k_M range: [0.0000, 0.1090], d_k_M_hat range: [0.9871, 0.9995]
2025-03-11 21:23:55 - Train Iteration 13011: loss: 0.3933, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.3729, 0.9959]
2025-03-11 21:23:56 - Train Iteration 13012: loss: 0.4359, d_k_M range: [0.0000, 0.2216], d_k_M_hat range: [0.3405, 0.9996]
2025-03-11 21:23:56 - Train Iteration 13013: loss: 0.0004, d_k_M range: [0.0003, 0.0183], d_k_M_hat range: [0.9986, 0.9999]
2025-03-11 21:23:57 - Train Iteration 13014: loss: 0.0048, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9310, 0.9969]
2025-03-11 21:23:57 - Train Iteration 13015: loss: 0.0108, d_k_M range: [0.0000, 0.0979], d_k_M_hat range: [0.9822, 0.9998]
2025-03-11 21:23:58 - Train Iteration 13016: loss: 0.0038, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.9392, 0.9997]
2025-03-11 21:23:58 - Train Iteration 13017: loss: 0.4199, d_k_M range: [0.0000, 0.6454], d_k_M_hat range: [0.7209, 1.0000]
2025-03-11 21:23:59 - Train Iteration 13018: loss: 0.3694, d_k_M range: [0.0000, 0.0066], d_k_M_hat range: [0.3923, 0.9992]
2025-03-11 21:23:59 - Train Iteration 13019: loss: 0.3105, d_k_M range: [0.0000, 0.5569], d_k_M_hat range: [0.9778, 0.9999]
2025-03-11 21:24:00 - Train Iteration 13020: loss: 0.4501, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.3291, 0.9996]
2025-03-11 21:24:00 - Train Iteration 13021: loss: 0.0373, d_k_M range: [0.0001, 0.1872], d_k_M_hat range: [0.9253, 0.9996]
2025-03-11 21:24:00 - Train Iteration 13022: loss: 0.0439, d_k_M range: [0.0001, 0.0016], d_k_M_hat range: [0.7920, 0.9999]
2025-03-11 21:24:01 - Train Iteration 13023: loss: 0.0149, d_k_M range: [0.0001, 0.1213], d_k_M_hat range: [0.9945, 0.9999]
2025-03-11 21:24:01 - Train Iteration 13024: loss: 0.0111, d_k_M range: [0.0000, 0.0163], d_k_M_hat range: [0.8968, 0.9995]
2025-03-11 21:24:02 - Train Iteration 13025: loss: 0.0002, d_k_M range: [0.0001, 0.0045], d_k_M_hat range: [0.9855, 0.9998]
2025-03-11 21:24:02 - Train Iteration 13026: loss: 0.0322, d_k_M range: [0.0001, 0.0087], d_k_M_hat range: [0.8226, 0.9998]
2025-03-11 21:24:03 - Train Iteration 13027: loss: 0.6745, d_k_M range: [0.0000, 0.8212], d_k_M_hat range: [0.9508, 1.0000]
2025-03-11 21:24:03 - Train Iteration 13028: loss: 0.0222, d_k_M range: [0.0000, 0.0174], d_k_M_hat range: [0.8511, 0.9990]
2025-03-11 21:24:04 - Train Iteration 13029: loss: 0.0024, d_k_M range: [0.0001, 0.0125], d_k_M_hat range: [0.9510, 0.9998]
2025-03-11 21:24:04 - Train Iteration 13030: loss: 0.0004, d_k_M range: [0.0001, 0.0109], d_k_M_hat range: [0.9796, 1.0000]
2025-03-11 21:24:05 - Train Iteration 13031: loss: 0.0006, d_k_M range: [0.0000, 0.0105], d_k_M_hat range: [0.9784, 0.9998]
2025-03-11 21:24:05 - Train Iteration 13032: loss: 0.0011, d_k_M range: [0.0001, 0.0157], d_k_M_hat range: [0.9673, 0.9999]
2025-03-11 21:24:06 - Train Iteration 13033: loss: 0.0007, d_k_M range: [0.0002, 0.0264], d_k_M_hat range: [0.9887, 0.9999]
2025-03-11 21:24:06 - Train Iteration 13034: loss: 0.0325, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.8200, 0.9985]
2025-03-11 21:24:07 - Train Iteration 13035: loss: 0.5294, d_k_M range: [0.0000, 0.7273], d_k_M_hat range: [0.9905, 1.0000]
2025-03-11 21:24:07 - Train Iteration 13036: loss: 0.0228, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.8490, 0.9988]
2025-03-11 21:24:08 - Train Iteration 13037: loss: 0.0114, d_k_M range: [0.0001, 0.1048], d_k_M_hat range: [0.9950, 0.9999]
2025-03-11 21:24:08 - Train Iteration 13038: loss: 0.0969, d_k_M range: [0.0001, 0.3102], d_k_M_hat range: [0.9939, 0.9996]
2025-03-11 21:24:08 - Train Iteration 13039: loss: 0.0461, d_k_M range: [0.0000, 0.0270], d_k_M_hat range: [0.7864, 0.9997]
2025-03-11 21:24:09 - Train Iteration 13040: loss: 0.0125, d_k_M range: [0.0002, 0.0428], d_k_M_hat range: [0.8883, 0.9998]
2025-03-11 21:24:09 - Train Iteration 13041: loss: 0.0735, d_k_M range: [0.0000, 0.0072], d_k_M_hat range: [0.7288, 0.9994]
2025-03-11 21:24:10 - Train Iteration 13042: loss: 0.0002, d_k_M range: [0.0001, 0.0115], d_k_M_hat range: [0.9941, 0.9997]
2025-03-11 21:24:10 - Train Iteration 13043: loss: 0.0004, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.9801, 1.0000]
2025-03-11 21:24:11 - Train Iteration 13044: loss: 0.0012, d_k_M range: [0.0000, 0.0351], d_k_M_hat range: [0.9883, 1.0000]
2025-03-11 21:24:11 - Train Iteration 13045: loss: 0.0005, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.9768, 0.9997]
2025-03-11 21:24:12 - Train Iteration 13046: loss: 0.0006, d_k_M range: [0.0000, 0.0201], d_k_M_hat range: [0.9762, 0.9998]
2025-03-11 21:24:12 - Train Iteration 13047: loss: 0.0020, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9552, 0.9993]
2025-03-11 21:24:13 - Train Iteration 13048: loss: 0.0051, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.9288, 0.9998]
2025-03-11 21:24:13 - Train Iteration 13049: loss: 0.0015, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9617, 0.9997]
2025-03-11 21:24:13 - Train Iteration 13050: loss: 0.2969, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.4554, 0.9984]
2025-03-11 21:24:14 - Train Iteration 13051: loss: 0.0006, d_k_M range: [0.0000, 0.0165], d_k_M_hat range: [0.9766, 1.0000]
2025-03-11 21:24:14 - Train Iteration 13052: loss: 0.0028, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.9472, 0.9997]
2025-03-11 21:24:15 - Train Iteration 13053: loss: 0.0002, d_k_M range: [0.0001, 0.0079], d_k_M_hat range: [0.9913, 0.9996]
2025-03-11 21:24:15 - Train Iteration 13054: loss: 0.6131, d_k_M range: [0.0000, 0.7830], d_k_M_hat range: [0.9883, 1.0000]
2025-03-11 21:24:16 - Train Iteration 13055: loss: 0.0330, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.8184, 0.9989]
2025-03-11 21:24:16 - Train Iteration 13056: loss: 0.0065, d_k_M range: [0.0000, 0.0802], d_k_M_hat range: [0.9955, 1.0000]
2025-03-11 21:24:17 - Train Iteration 13057: loss: 0.0020, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9581, 0.9999]
2025-03-11 21:24:17 - Train Iteration 13058: loss: 0.0003, d_k_M range: [0.0001, 0.0165], d_k_M_hat range: [0.9968, 0.9999]
2025-03-11 21:24:18 - Train Iteration 13059: loss: 0.0045, d_k_M range: [0.0004, 0.0623], d_k_M_hat range: [0.9504, 0.9999]
2025-03-11 21:24:18 - Train Iteration 13060: loss: 0.0019, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9575, 0.9991]
2025-03-11 21:24:18 - Train Iteration 13061: loss: 0.2231, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.5277, 0.9997]
2025-03-11 21:24:19 - Train Iteration 13062: loss: 0.0002, d_k_M range: [0.0000, 0.0142], d_k_M_hat range: [0.9877, 0.9999]
2025-03-11 21:24:19 - Train Iteration 13063: loss: 0.0464, d_k_M range: [0.0000, 0.2139], d_k_M_hat range: [0.9494, 0.9999]
2025-03-11 21:24:20 - Train Iteration 13064: loss: 0.5765, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.2407, 1.0000]
2025-03-11 21:24:20 - Train Iteration 13065: loss: 0.0001, d_k_M range: [0.0004, 0.0071], d_k_M_hat range: [0.9905, 0.9995]
2025-03-11 21:24:21 - Train Iteration 13066: loss: 0.0006, d_k_M range: [0.0000, 0.0218], d_k_M_hat range: [0.9792, 0.9997]
2025-03-11 21:24:21 - Train Iteration 13067: loss: 0.1561, d_k_M range: [0.0001, 0.3949], d_k_M_hat range: [0.9989, 1.0000]
2025-03-11 21:24:22 - Train Iteration 13068: loss: 0.0324, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.8199, 0.9987]
2025-03-11 21:24:22 - Train Iteration 13069: loss: 0.0001, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9909, 0.9996]
2025-03-11 21:24:23 - Train Iteration 13070: loss: 0.0122, d_k_M range: [0.0001, 0.0067], d_k_M_hat range: [0.8902, 0.9983]
2025-03-11 21:24:23 - Train Iteration 13071: loss: 0.1060, d_k_M range: [0.0000, 0.3221], d_k_M_hat range: [0.9907, 0.9997]
2025-03-11 21:24:24 - Train Iteration 13072: loss: 0.5600, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.2519, 0.9995]
2025-03-11 21:24:24 - Train Iteration 13073: loss: 0.0190, d_k_M range: [0.0002, 0.1357], d_k_M_hat range: [0.9931, 1.0000]
2025-03-11 21:24:25 - Train Iteration 13074: loss: 0.0010, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9680, 0.9999]
2025-03-11 21:24:25 - Train Iteration 13075: loss: 0.0086, d_k_M range: [0.0000, 0.0804], d_k_M_hat range: [0.9713, 1.0000]
2025-03-11 21:24:26 - Train Iteration 13076: loss: 0.0003, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.9871, 0.9983]
2025-03-11 21:24:26 - Train Iteration 13077: loss: 0.0004, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.9790, 0.9977]
2025-03-11 21:24:26 - Train Iteration 13078: loss: 0.0007, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9740, 0.9995]
2025-03-11 21:24:27 - Train Iteration 13079: loss: 0.0001, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.9924, 0.9999]
2025-03-11 21:24:27 - Train Iteration 13080: loss: 0.0511, d_k_M range: [0.0000, 0.2229], d_k_M_hat range: [0.8968, 0.9972]
2025-03-11 21:24:28 - Train Iteration 13081: loss: 0.0086, d_k_M range: [0.0000, 0.0292], d_k_M_hat range: [0.9077, 1.0000]
2025-03-11 21:24:28 - Train Iteration 13082: loss: 0.0002, d_k_M range: [0.0000, 0.0133], d_k_M_hat range: [0.9931, 1.0000]
2025-03-11 21:24:29 - Train Iteration 13083: loss: 0.0003, d_k_M range: [0.0000, 0.0119], d_k_M_hat range: [0.9844, 0.9999]
2025-03-11 21:24:29 - Train Iteration 13084: loss: 0.0417, d_k_M range: [0.0000, 0.2038], d_k_M_hat range: [0.9979, 0.9996]
2025-03-11 21:24:30 - Train Iteration 13085: loss: 0.0044, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.9339, 0.9982]
2025-03-11 21:24:30 - Train Iteration 13086: loss: 0.0011, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9672, 0.9995]
2025-03-11 21:24:31 - Train Iteration 13087: loss: 0.0011, d_k_M range: [0.0000, 0.0092], d_k_M_hat range: [0.9669, 0.9996]
2025-03-11 21:24:31 - Train Iteration 13088: loss: 0.0007, d_k_M range: [0.0000, 0.0247], d_k_M_hat range: [0.9864, 0.9999]
2025-03-11 21:24:32 - Train Iteration 13089: loss: 0.2487, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.5013, 0.9942]
2025-03-11 21:24:32 - Train Iteration 13090: loss: 0.0001, d_k_M range: [0.0000, 0.0083], d_k_M_hat range: [0.9893, 0.9993]
2025-03-11 21:24:32 - Train Iteration 13091: loss: 0.0002, d_k_M range: [0.0000, 0.0112], d_k_M_hat range: [0.9960, 0.9996]
2025-03-11 21:24:33 - Train Iteration 13092: loss: 0.0016, d_k_M range: [0.0000, 0.0399], d_k_M_hat range: [0.9946, 0.9997]
2025-03-11 21:24:33 - Train Iteration 13093: loss: 0.0169, d_k_M range: [0.0001, 0.1213], d_k_M_hat range: [0.9741, 0.9999]
2025-03-11 21:24:34 - Train Iteration 13094: loss: 0.0109, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.8958, 0.9987]
2025-03-11 21:24:34 - Train Iteration 13095: loss: 0.0005, d_k_M range: [0.0001, 0.0057], d_k_M_hat range: [0.9776, 0.9991]
2025-03-11 21:24:35 - Train Iteration 13096: loss: 0.0008, d_k_M range: [0.0001, 0.0195], d_k_M_hat range: [0.9916, 0.9990]
2025-03-11 21:24:35 - Train Iteration 13097: loss: 0.0009, d_k_M range: [0.0000, 0.0254], d_k_M_hat range: [0.9699, 1.0000]
2025-03-11 21:24:36 - Train Iteration 13098: loss: 0.0016, d_k_M range: [0.0000, 0.0374], d_k_M_hat range: [0.9842, 0.9999]
2025-03-11 21:24:36 - Train Iteration 13099: loss: 0.4656, d_k_M range: [0.0000, 0.6808], d_k_M_hat range: [0.9192, 0.9989]
2025-03-11 21:24:36 - Train Iteration 13100: loss: 0.5273, d_k_M range: [0.0000, 0.0048], d_k_M_hat range: [0.2739, 0.9980]
2025-03-11 21:24:37 - Train Iteration 13101: loss: 0.7160, d_k_M range: [0.0001, 0.8462], d_k_M_hat range: [0.9975, 1.0000]
2025-03-11 21:24:37 - Train Iteration 13102: loss: 0.0593, d_k_M range: [0.0001, 0.2433], d_k_M_hat range: [0.9932, 0.9998]
2025-03-11 21:24:38 - Train Iteration 13103: loss: 0.0969, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.6892, 0.9975]
2025-03-11 21:24:38 - Train Iteration 13104: loss: 0.0911, d_k_M range: [0.0000, 0.3017], d_k_M_hat range: [0.9789, 0.9999]
2025-03-11 21:24:39 - Train Iteration 13105: loss: 0.0009, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.9698, 0.9992]
2025-03-11 21:24:39 - Train Iteration 13106: loss: 0.0909, d_k_M range: [0.0000, 0.2930], d_k_M_hat range: [0.9819, 0.9999]
2025-03-11 21:24:40 - Train Iteration 13107: loss: 0.0006, d_k_M range: [0.0000, 0.0225], d_k_M_hat range: [0.9893, 0.9991]
2025-03-11 21:24:40 - Train Iteration 13108: loss: 0.1984, d_k_M range: [0.0000, 0.4453], d_k_M_hat range: [0.9876, 0.9999]
2025-03-11 21:24:41 - Train Iteration 13109: loss: 0.3915, d_k_M range: [0.0000, 0.6255], d_k_M_hat range: [0.9840, 0.9998]
2025-03-11 21:24:41 - Train Iteration 13110: loss: 0.0009, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9702, 0.9985]
2025-03-11 21:24:42 - Train Iteration 13111: loss: 0.0008, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.9765, 0.9985]
2025-03-11 21:24:42 - Train Iteration 13112: loss: 0.0003, d_k_M range: [0.0000, 0.0086], d_k_M_hat range: [0.9824, 0.9993]
2025-03-11 21:24:43 - Train Iteration 13113: loss: 0.4847, d_k_M range: [0.0000, 0.6956], d_k_M_hat range: [0.9980, 1.0000]
2025-03-11 21:24:43 - Train Iteration 13114: loss: 0.0006, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9774, 0.9996]
2025-03-11 21:24:44 - Train Iteration 13115: loss: 0.0003, d_k_M range: [0.0000, 0.0166], d_k_M_hat range: [0.9912, 0.9999]
2025-03-11 21:24:44 - Train Iteration 13116: loss: 0.1392, d_k_M range: [0.0000, 0.1577], d_k_M_hat range: [0.6341, 0.9991]
2025-03-11 21:24:44 - Train Iteration 13117: loss: 0.0103, d_k_M range: [0.0002, 0.1011], d_k_M_hat range: [0.9959, 0.9999]
2025-03-11 21:24:45 - Train Iteration 13118: loss: 0.3717, d_k_M range: [0.0000, 0.6090], d_k_M_hat range: [0.9604, 0.9993]
2025-03-11 21:24:45 - Train Iteration 13119: loss: 0.0395, d_k_M range: [0.0000, 0.1977], d_k_M_hat range: [0.9478, 0.9990]
2025-03-11 21:24:46 - Train Iteration 13120: loss: 0.0074, d_k_M range: [0.0000, 0.0097], d_k_M_hat range: [0.9171, 0.9996]
2025-03-11 21:24:46 - Train Iteration 13121: loss: 0.0007, d_k_M range: [0.0000, 0.0261], d_k_M_hat range: [0.9880, 0.9994]
2025-03-11 21:24:47 - Train Iteration 13122: loss: 0.0009, d_k_M range: [0.0001, 0.0096], d_k_M_hat range: [0.9794, 0.9998]
2025-03-11 21:24:47 - Train Iteration 13123: loss: 0.0023, d_k_M range: [0.0000, 0.0444], d_k_M_hat range: [0.9648, 1.0000]
2025-03-11 21:24:48 - Train Iteration 13124: loss: 0.0469, d_k_M range: [0.0000, 0.2124], d_k_M_hat range: [0.9497, 0.9993]
2025-03-11 21:24:48 - Train Iteration 13125: loss: 0.0001, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9926, 0.9999]
2025-03-11 21:24:49 - Train Iteration 13126: loss: 0.0004, d_k_M range: [0.0000, 0.0190], d_k_M_hat range: [0.9812, 0.9995]
2025-03-11 21:24:49 - Train Iteration 13127: loss: 0.0002, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.9861, 0.9995]
2025-03-11 21:24:50 - Train Iteration 13128: loss: 0.0053, d_k_M range: [0.0001, 0.0696], d_k_M_hat range: [0.9964, 1.0000]
2025-03-11 21:24:50 - Train Iteration 13129: loss: 0.0002, d_k_M range: [0.0000, 0.0124], d_k_M_hat range: [0.9956, 0.9998]
2025-03-11 21:24:51 - Train Iteration 13130: loss: 0.0071, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.9158, 0.9982]
2025-03-11 21:24:51 - Train Iteration 13131: loss: 0.1618, d_k_M range: [0.0002, 0.4023], d_k_M_hat range: [0.9392, 1.0000]
2025-03-11 21:24:51 - Train Iteration 13132: loss: 0.0013, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.9751, 0.9964]
2025-03-11 21:24:52 - Train Iteration 13133: loss: 0.0015, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.9617, 0.9992]
2025-03-11 21:24:52 - Train Iteration 13134: loss: 0.0002, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9866, 0.9999]
2025-03-11 21:24:53 - Train Iteration 13135: loss: 0.0008, d_k_M range: [0.0000, 0.0276], d_k_M_hat range: [0.9852, 0.9999]
2025-03-11 21:24:53 - Train Iteration 13136: loss: 0.0011, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9685, 0.9999]
2025-03-11 21:24:54 - Train Iteration 13137: loss: 0.0033, d_k_M range: [0.0000, 0.0098], d_k_M_hat range: [0.9425, 0.9998]
2025-03-11 21:24:54 - Train Iteration 13138: loss: 0.0017, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9592, 0.9983]
2025-03-11 21:24:55 - Train Iteration 13139: loss: 0.0217, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.8534, 0.9980]
2025-03-11 21:24:55 - Train Iteration 13140: loss: 0.0001, d_k_M range: [0.0002, 0.0066], d_k_M_hat range: [0.9937, 1.0000]
2025-03-11 21:24:56 - Train Iteration 13141: loss: 0.1028, d_k_M range: [0.0000, 0.3202], d_k_M_hat range: [0.9748, 0.9999]
2025-03-11 21:24:56 - Train Iteration 13142: loss: 0.0004, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.9799, 0.9994]
2025-03-11 21:24:57 - Train Iteration 13143: loss: 0.0024, d_k_M range: [0.0000, 0.0078], d_k_M_hat range: [0.9533, 0.9998]
2025-03-11 21:24:57 - Train Iteration 13144: loss: 0.0026, d_k_M range: [0.0001, 0.0348], d_k_M_hat range: [0.9842, 1.0000]
2025-03-11 21:24:58 - Train Iteration 13145: loss: 0.0025, d_k_M range: [0.0000, 0.0209], d_k_M_hat range: [0.9504, 0.9999]
2025-03-11 21:24:58 - Train Iteration 13146: loss: 0.0150, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.8777, 0.9978]
2025-03-11 21:24:58 - Train Iteration 13147: loss: 0.0013, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9657, 0.9993]
2025-03-11 21:24:59 - Train Iteration 13148: loss: 0.0138, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.8827, 0.9981]
2025-03-11 21:24:59 - Train Iteration 13149: loss: 0.0600, d_k_M range: [0.0000, 0.2411], d_k_M_hat range: [0.9950, 0.9998]
2025-03-11 21:25:00 - Train Iteration 13150: loss: 0.0021, d_k_M range: [0.0000, 0.0166], d_k_M_hat range: [0.9547, 0.9999]
2025-03-11 21:25:00 - Train Iteration 13151: loss: 0.0064, d_k_M range: [0.0000, 0.0799], d_k_M_hat range: [0.9957, 1.0000]
2025-03-11 21:25:01 - Train Iteration 13152: loss: 0.0074, d_k_M range: [0.0000, 0.0841], d_k_M_hat range: [0.9658, 0.9997]
2025-03-11 21:25:01 - Train Iteration 13153: loss: 0.0012, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9648, 0.9997]
2025-03-11 21:25:02 - Train Iteration 13154: loss: 0.0013, d_k_M range: [0.0000, 0.0360], d_k_M_hat range: [0.9924, 0.9995]
2025-03-11 21:25:02 - Train Iteration 13155: loss: 0.0026, d_k_M range: [0.0000, 0.0507], d_k_M_hat range: [0.9905, 0.9993]
2025-03-11 21:25:02 - Train Iteration 13156: loss: 0.0397, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.8008, 0.9991]
2025-03-11 21:25:03 - Train Iteration 13157: loss: 0.0002, d_k_M range: [0.0000, 0.0153], d_k_M_hat range: [0.9917, 0.9995]
2025-03-11 21:25:03 - Train Iteration 13158: loss: 0.0016, d_k_M range: [0.0000, 0.0373], d_k_M_hat range: [0.9896, 0.9997]
2025-03-11 21:25:04 - Train Iteration 13159: loss: 0.0046, d_k_M range: [0.0000, 0.0469], d_k_M_hat range: [0.9336, 0.9996]
2025-03-11 21:25:04 - Train Iteration 13160: loss: 0.1567, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.6041, 0.9983]
2025-03-11 21:25:05 - Train Iteration 13161: loss: 0.0111, d_k_M range: [0.0003, 0.1053], d_k_M_hat range: [0.9955, 1.0000]
2025-03-11 21:25:05 - Train Iteration 13162: loss: 0.0159, d_k_M range: [0.0000, 0.0651], d_k_M_hat range: [0.8742, 0.9998]
2025-03-11 21:25:06 - Train Iteration 13163: loss: 0.0023, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.9520, 0.9999]
2025-03-11 21:25:06 - Train Iteration 13164: loss: 0.0019, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9567, 0.9999]
2025-03-11 21:25:07 - Train Iteration 13165: loss: 0.0063, d_k_M range: [0.0000, 0.0070], d_k_M_hat range: [0.9204, 1.0000]
2025-03-11 21:25:07 - Train Iteration 13166: loss: 0.0004, d_k_M range: [0.0000, 0.0097], d_k_M_hat range: [0.9805, 0.9998]
2025-03-11 21:25:07 - Train Iteration 13167: loss: 0.0010, d_k_M range: [0.0000, 0.0140], d_k_M_hat range: [0.9685, 0.9976]
2025-03-11 21:25:08 - Train Iteration 13168: loss: 0.0021, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9540, 0.9989]
2025-03-11 21:25:08 - Train Iteration 13169: loss: 0.0001, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9924, 0.9996]
2025-03-11 21:25:09 - Train Iteration 13170: loss: 0.0014, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9631, 0.9999]
2025-03-11 21:25:09 - Train Iteration 13171: loss: 0.0055, d_k_M range: [0.0000, 0.0106], d_k_M_hat range: [0.9261, 0.9996]
2025-03-11 21:25:10 - Train Iteration 13172: loss: 0.0711, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.7343, 0.9995]
2025-03-11 21:25:10 - Train Iteration 13173: loss: 0.0007, d_k_M range: [0.0001, 0.0190], d_k_M_hat range: [0.9925, 0.9998]
2025-03-11 21:25:10 - Train Iteration 13174: loss: 0.0161, d_k_M range: [0.0000, 0.1261], d_k_M_hat range: [0.9167, 0.9992]
2025-03-11 21:25:11 - Train Iteration 13175: loss: 0.6333, d_k_M range: [0.0000, 0.0784], d_k_M_hat range: [0.2042, 0.9989]
2025-03-11 21:25:11 - Train Iteration 13176: loss: 0.5642, d_k_M range: [0.0000, 0.7509], d_k_M_hat range: [0.9907, 0.9998]
2025-03-11 21:25:12 - Train Iteration 13177: loss: 0.0077, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.9124, 0.9985]
2025-03-11 21:25:12 - Train Iteration 13178: loss: 0.0020, d_k_M range: [0.0000, 0.0446], d_k_M_hat range: [0.9565, 0.9994]
2025-03-11 21:25:13 - Train Iteration 13179: loss: 0.0013, d_k_M range: [0.0000, 0.0096], d_k_M_hat range: [0.9646, 0.9998]
2025-03-11 21:25:13 - Train Iteration 13180: loss: 0.0139, d_k_M range: [0.0000, 0.0441], d_k_M_hat range: [0.9263, 0.9998]
2025-03-11 21:25:13 - Train Iteration 13181: loss: 0.0067, d_k_M range: [0.0000, 0.0816], d_k_M_hat range: [0.9868, 1.0000]
2025-03-11 21:25:14 - Train Iteration 13182: loss: 0.0027, d_k_M range: [0.0000, 0.0509], d_k_M_hat range: [0.9898, 0.9998]
2025-03-11 21:25:14 - Train Iteration 13183: loss: 0.2455, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.5045, 0.9998]
2025-03-11 21:25:15 - Train Iteration 13184: loss: 0.0033, d_k_M range: [0.0000, 0.0458], d_k_M_hat range: [0.9887, 1.0000]
2025-03-11 21:25:15 - Train Iteration 13185: loss: 0.2448, d_k_M range: [0.0000, 0.4946], d_k_M_hat range: [0.9934, 0.9999]
2025-03-11 21:25:16 - Train Iteration 13186: loss: 0.2375, d_k_M range: [0.0000, 0.0131], d_k_M_hat range: [0.5127, 0.9988]
2025-03-11 21:25:16 - Train Iteration 13187: loss: 0.0007, d_k_M range: [0.0001, 0.0167], d_k_M_hat range: [0.9733, 0.9987]
2025-03-11 21:25:17 - Train Iteration 13188: loss: 0.0033, d_k_M range: [0.0000, 0.0129], d_k_M_hat range: [0.9423, 0.9999]
2025-03-11 21:25:17 - Train Iteration 13189: loss: 0.0219, d_k_M range: [0.0000, 0.0593], d_k_M_hat range: [0.8519, 1.0000]
2025-03-11 21:25:18 - Train Iteration 13190: loss: 0.3874, d_k_M range: [0.0001, 0.6224], d_k_M_hat range: [0.9939, 1.0000]
2025-03-11 21:25:18 - Train Iteration 13191: loss: 0.0171, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.8694, 0.9946]
2025-03-11 21:25:18 - Train Iteration 13192: loss: 0.0015, d_k_M range: [0.0000, 0.0384], d_k_M_hat range: [0.9916, 0.9998]
2025-03-11 21:25:19 - Train Iteration 13193: loss: 0.0008, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9728, 0.9993]
2025-03-11 21:25:19 - Train Iteration 13194: loss: 0.0009, d_k_M range: [0.0000, 0.0297], d_k_M_hat range: [0.9759, 0.9998]
2025-03-11 21:25:20 - Train Iteration 13195: loss: 0.0018, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9581, 0.9992]
2025-03-11 21:25:20 - Train Iteration 13196: loss: 0.0315, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.8225, 0.9997]
2025-03-11 21:25:21 - Train Iteration 13197: loss: 0.0793, d_k_M range: [0.0000, 0.2814], d_k_M_hat range: [0.8922, 0.9998]
2025-03-11 21:25:21 - Train Iteration 13198: loss: 0.0005, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.9801, 0.9997]
2025-03-11 21:25:21 - Train Iteration 13199: loss: 0.0039, d_k_M range: [0.0000, 0.0047], d_k_M_hat range: [0.9379, 0.9999]
2025-03-11 21:25:22 - Train Iteration 13200: loss: 0.0094, d_k_M range: [0.0000, 0.0959], d_k_M_hat range: [0.9983, 1.0000]
2025-03-11 21:25:22 - Train Iteration 13201: loss: 0.0132, d_k_M range: [0.0000, 0.1146], d_k_M_hat range: [0.9967, 0.9999]
2025-03-11 21:25:23 - Train Iteration 13202: loss: 0.0001, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.9939, 1.0000]
2025-03-11 21:25:23 - Train Iteration 13203: loss: 0.0180, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.8660, 1.0000]
2025-03-11 21:25:24 - Train Iteration 13204: loss: 0.0862, d_k_M range: [0.0000, 0.2925], d_k_M_hat range: [0.8149, 0.9996]
2025-03-11 21:25:24 - Train Iteration 13205: loss: 0.0509, d_k_M range: [0.0001, 0.2254], d_k_M_hat range: [0.9719, 0.9999]
2025-03-11 21:25:25 - Train Iteration 13206: loss: 0.0083, d_k_M range: [0.0000, 0.0079], d_k_M_hat range: [0.9087, 0.9996]
2025-03-11 21:25:25 - Train Iteration 13207: loss: 0.0128, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.8869, 0.9989]
2025-03-11 21:25:25 - Train Iteration 13208: loss: 0.0015, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9623, 0.9999]
2025-03-11 21:25:26 - Train Iteration 13209: loss: 0.0147, d_k_M range: [0.0000, 0.0513], d_k_M_hat range: [0.8787, 0.9998]
2025-03-11 21:25:26 - Train Iteration 13210: loss: 0.0004, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9804, 0.9987]
2025-03-11 21:25:27 - Train Iteration 13211: loss: 0.4928, d_k_M range: [0.0000, 0.1075], d_k_M_hat range: [0.2981, 0.9993]
2025-03-11 21:25:27 - Train Iteration 13212: loss: 0.0002, d_k_M range: [0.0001, 0.0088], d_k_M_hat range: [0.9914, 0.9994]
2025-03-11 21:25:28 - Train Iteration 13213: loss: 0.1165, d_k_M range: [0.0000, 0.3413], d_k_M_hat range: [0.9450, 1.0000]
2025-03-11 21:25:28 - Train Iteration 13214: loss: 0.0014, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.9625, 0.9980]
2025-03-11 21:25:28 - Train Iteration 13215: loss: 0.1675, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.5908, 0.9997]
2025-03-11 21:25:29 - Train Iteration 13216: loss: 0.0007, d_k_M range: [0.0000, 0.0261], d_k_M_hat range: [0.9962, 0.9999]
2025-03-11 21:25:29 - Train Iteration 13217: loss: 0.0004, d_k_M range: [0.0000, 0.0203], d_k_M_hat range: [0.9885, 0.9997]
2025-03-11 21:25:30 - Train Iteration 13218: loss: 0.0006, d_k_M range: [0.0001, 0.0242], d_k_M_hat range: [0.9893, 0.9996]
2025-03-11 21:25:30 - Train Iteration 13219: loss: 0.6710, d_k_M range: [0.0000, 0.8191], d_k_M_hat range: [0.9640, 1.0000]
2025-03-11 21:25:30 - Train Iteration 13220: loss: 0.4111, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.3588, 0.9979]
2025-03-11 21:25:31 - Train Iteration 13221: loss: 0.0569, d_k_M range: [0.0000, 0.2384], d_k_M_hat range: [0.9990, 0.9999]
2025-03-11 21:25:31 - Train Iteration 13222: loss: 0.0402, d_k_M range: [0.0000, 0.2004], d_k_M_hat range: [0.9900, 0.9999]
2025-03-11 21:25:32 - Train Iteration 13223: loss: 0.0002, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.9877, 0.9998]
2025-03-11 21:25:32 - Train Iteration 13224: loss: 0.0187, d_k_M range: [0.0000, 0.0884], d_k_M_hat range: [0.8634, 1.0000]
2025-03-11 21:25:33 - Train Iteration 13225: loss: 0.3621, d_k_M range: [0.0000, 0.6015], d_k_M_hat range: [0.9826, 0.9999]
2025-03-11 21:25:33 - Train Iteration 13226: loss: 0.0009, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.9694, 0.9989]
2025-03-11 21:25:33 - Train Iteration 13227: loss: 0.0002, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9859, 0.9974]
2025-03-11 21:25:34 - Train Iteration 13228: loss: 0.0027, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9485, 0.9995]
2025-03-11 21:25:34 - Train Iteration 13229: loss: 0.0012, d_k_M range: [0.0000, 0.0333], d_k_M_hat range: [0.9893, 0.9993]
2025-03-11 21:25:35 - Train Iteration 13230: loss: 0.0018, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.9572, 0.9998]
2025-03-11 21:25:35 - Train Iteration 13231: loss: 0.0091, d_k_M range: [0.0000, 0.0373], d_k_M_hat range: [0.9056, 0.9998]
2025-03-11 21:25:36 - Train Iteration 13232: loss: 0.0714, d_k_M range: [0.0000, 0.0070], d_k_M_hat range: [0.7329, 0.9996]
2025-03-11 21:25:36 - Train Iteration 13233: loss: 0.0005, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9783, 1.0000]
2025-03-11 21:25:36 - Train Iteration 13234: loss: 0.0018, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9583, 0.9999]
2025-03-11 21:25:37 - Train Iteration 13235: loss: 0.0699, d_k_M range: [0.0000, 0.2639], d_k_M_hat range: [0.9800, 0.9998]
2025-03-11 21:25:37 - Train Iteration 13236: loss: 0.2646, d_k_M range: [0.0000, 0.5142], d_k_M_hat range: [0.9246, 0.9998]
2025-03-11 21:25:38 - Train Iteration 13237: loss: 0.7511, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.1333, 0.9966]
2025-03-11 21:25:38 - Train Iteration 13238: loss: 0.0344, d_k_M range: [0.0000, 0.1846], d_k_M_hat range: [0.9968, 0.9998]
2025-03-11 21:25:39 - Train Iteration 13239: loss: 0.0004, d_k_M range: [0.0000, 0.0190], d_k_M_hat range: [0.9830, 1.0000]
2025-03-11 21:25:39 - Train Iteration 13240: loss: 0.0260, d_k_M range: [0.0001, 0.1612], d_k_M_hat range: [0.9971, 1.0000]
2025-03-11 21:25:39 - Train Iteration 13241: loss: 0.0146, d_k_M range: [0.0000, 0.1159], d_k_M_hat range: [0.9864, 0.9998]
2025-03-11 21:25:40 - Train Iteration 13242: loss: 0.0064, d_k_M range: [0.0000, 0.0781], d_k_M_hat range: [0.9554, 0.9993]
2025-03-11 21:25:40 - Train Iteration 13243: loss: 0.0015, d_k_M range: [0.0000, 0.0231], d_k_M_hat range: [0.9665, 0.9982]
2025-03-11 21:25:41 - Train Iteration 13244: loss: 0.0003, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9825, 0.9996]
2025-03-11 21:25:41 - Train Iteration 13245: loss: 0.0188, d_k_M range: [0.0000, 0.1370], d_k_M_hat range: [0.9966, 1.0000]
2025-03-11 21:25:42 - Train Iteration 13246: loss: 0.3340, d_k_M range: [0.0001, 0.5773], d_k_M_hat range: [0.9847, 0.9999]
2025-03-11 21:25:42 - Train Iteration 13247: loss: 0.0024, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.9513, 0.9988]
2025-03-11 21:25:42 - Train Iteration 13248: loss: 0.0009, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9728, 0.9999]
2025-03-11 21:25:43 - Train Iteration 13249: loss: 0.0072, d_k_M range: [0.0000, 0.0840], d_k_M_hat range: [0.9642, 0.9989]
2025-03-11 21:25:43 - Train Iteration 13250: loss: 0.0009, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9699, 0.9997]
2025-03-11 21:25:44 - Train Iteration 13251: loss: 0.0983, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.6866, 0.9998]
2025-03-11 21:25:44 - Train Iteration 13252: loss: 0.4518, d_k_M range: [0.0015, 0.6722], d_k_M_hat range: [0.9959, 1.0000]
2025-03-11 21:25:45 - Train Iteration 13253: loss: 0.5402, d_k_M range: [0.0000, 0.7342], d_k_M_hat range: [0.9781, 0.9995]
2025-03-11 21:25:45 - Train Iteration 13254: loss: 0.0026, d_k_M range: [0.0000, 0.0318], d_k_M_hat range: [0.9540, 0.9999]
2025-03-11 21:25:45 - Train Iteration 13255: loss: 0.0037, d_k_M range: [0.0000, 0.0127], d_k_M_hat range: [0.9389, 0.9998]
2025-03-11 21:25:46 - Train Iteration 13256: loss: 0.4096, d_k_M range: [0.0000, 0.0117], d_k_M_hat range: [0.3638, 0.9997]
2025-03-11 21:25:46 - Train Iteration 13257: loss: 0.0008, d_k_M range: [0.0000, 0.0171], d_k_M_hat range: [0.9738, 1.0000]
2025-03-11 21:25:47 - Train Iteration 13258: loss: 0.0013, d_k_M range: [0.0000, 0.0347], d_k_M_hat range: [0.9644, 0.9996]
2025-03-11 21:25:47 - Train Iteration 13259: loss: 0.0281, d_k_M range: [0.0000, 0.0055], d_k_M_hat range: [0.8324, 0.9999]
2025-03-11 21:25:48 - Train Iteration 13260: loss: 0.0071, d_k_M range: [0.0001, 0.0840], d_k_M_hat range: [0.9859, 0.9999]
2025-03-11 21:25:48 - Train Iteration 13261: loss: 0.0157, d_k_M range: [0.0000, 0.1203], d_k_M_hat range: [0.9060, 0.9998]
2025-03-11 21:25:49 - Train Iteration 13262: loss: 0.0292, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.8290, 0.9989]
2025-03-11 21:25:49 - Train Iteration 13263: loss: 0.0003, d_k_M range: [0.0001, 0.0018], d_k_M_hat range: [0.9834, 0.9998]
2025-03-11 21:25:49 - Train Iteration 13264: loss: 0.1031, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.6791, 0.9977]
2025-03-11 21:25:50 - Train Iteration 13265: loss: 0.0020, d_k_M range: [0.0000, 0.0438], d_k_M_hat range: [0.9620, 0.9999]
2025-03-11 21:25:50 - Train Iteration 13266: loss: 0.0022, d_k_M range: [0.0000, 0.0440], d_k_M_hat range: [0.9536, 0.9996]
2025-03-11 21:25:51 - Train Iteration 13267: loss: 0.0025, d_k_M range: [0.0000, 0.0373], d_k_M_hat range: [0.9871, 0.9997]
2025-03-11 21:25:51 - Train Iteration 13268: loss: 0.0001, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.9907, 0.9999]
2025-03-11 21:25:52 - Train Iteration 13269: loss: 0.1771, d_k_M range: [0.0000, 0.4202], d_k_M_hat range: [0.9695, 0.9999]
2025-03-11 21:25:52 - Train Iteration 13270: loss: 0.0014, d_k_M range: [0.0000, 0.0206], d_k_M_hat range: [0.9632, 0.9999]
2025-03-11 21:25:52 - Train Iteration 13271: loss: 0.0013, d_k_M range: [0.0000, 0.0362], d_k_M_hat range: [0.9813, 0.9998]
2025-03-11 21:25:53 - Train Iteration 13272: loss: 0.0004, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9826, 0.9992]
2025-03-11 21:25:53 - Train Iteration 13273: loss: 0.0005, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9786, 0.9997]
2025-03-11 21:25:54 - Train Iteration 13274: loss: 0.0023, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9524, 0.9996]
2025-03-11 21:25:54 - Train Iteration 13275: loss: 0.0003, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.9830, 0.9996]
2025-03-11 21:25:55 - Train Iteration 13276: loss: 0.0038, d_k_M range: [0.0002, 0.0028], d_k_M_hat range: [0.9389, 0.9992]
2025-03-11 21:25:55 - Train Iteration 13277: loss: 0.0011, d_k_M range: [0.0000, 0.0191], d_k_M_hat range: [0.9665, 0.9999]
2025-03-11 21:25:55 - Train Iteration 13278: loss: 0.0070, d_k_M range: [0.0000, 0.0155], d_k_M_hat range: [0.9162, 0.9996]
2025-03-11 21:25:56 - Train Iteration 13279: loss: 0.0043, d_k_M range: [0.0000, 0.0655], d_k_M_hat range: [0.9858, 0.9997]
2025-03-11 21:25:56 - Train Iteration 13280: loss: 0.0019, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9561, 0.9997]
2025-03-11 21:25:57 - Train Iteration 13281: loss: 0.0006, d_k_M range: [0.0000, 0.0205], d_k_M_hat range: [0.9932, 0.9999]
2025-03-11 21:25:57 - Train Iteration 13282: loss: 0.0787, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.7194, 0.9936]
2025-03-11 21:25:58 - Train Iteration 13283: loss: 0.0328, d_k_M range: [0.0003, 0.1807], d_k_M_hat range: [0.9970, 0.9999]
2025-03-11 21:25:58 - Train Iteration 13284: loss: 0.2815, d_k_M range: [0.0000, 0.5306], d_k_M_hat range: [0.9752, 1.0000]
2025-03-11 21:25:58 - Train Iteration 13285: loss: 0.0009, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9695, 0.9989]
2025-03-11 21:25:59 - Train Iteration 13286: loss: 0.8342, d_k_M range: [0.0000, 0.9127], d_k_M_hat range: [0.9755, 0.9994]
2025-03-11 21:25:59 - Train Iteration 13287: loss: 0.0036, d_k_M range: [0.0000, 0.0056], d_k_M_hat range: [0.9404, 0.9995]
2025-03-11 21:26:00 - Train Iteration 13288: loss: 0.0770, d_k_M range: [0.0000, 0.2772], d_k_M_hat range: [0.9848, 0.9997]
2025-03-11 21:26:00 - Train Iteration 13289: loss: 0.0052, d_k_M range: [0.0000, 0.0090], d_k_M_hat range: [0.9279, 0.9982]
2025-03-11 21:26:01 - Train Iteration 13290: loss: 0.1985, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.5546, 0.9997]
2025-03-11 21:26:01 - Train Iteration 13291: loss: 0.0006, d_k_M range: [0.0000, 0.0169], d_k_M_hat range: [0.9762, 0.9998]
2025-03-11 21:26:01 - Train Iteration 13292: loss: 0.2196, d_k_M range: [0.0000, 0.4683], d_k_M_hat range: [0.9893, 0.9999]
2025-03-11 21:26:02 - Train Iteration 13293: loss: 0.0061, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9218, 0.9987]
2025-03-11 21:26:02 - Train Iteration 13294: loss: 0.0038, d_k_M range: [0.0000, 0.0112], d_k_M_hat range: [0.9383, 0.9992]
2025-03-11 21:26:03 - Train Iteration 13295: loss: 0.6489, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.1946, 0.9998]
2025-03-11 21:26:03 - Train Iteration 13296: loss: 0.0068, d_k_M range: [0.0001, 0.0805], d_k_M_hat range: [0.9782, 0.9994]
2025-03-11 21:26:03 - Train Iteration 13297: loss: 0.0004, d_k_M range: [0.0000, 0.0138], d_k_M_hat range: [0.9849, 0.9997]
2025-03-11 21:26:04 - Train Iteration 13298: loss: 0.0032, d_k_M range: [0.0000, 0.0560], d_k_M_hat range: [0.9659, 0.9993]
2025-03-11 21:26:04 - Train Iteration 13299: loss: 0.0002, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9879, 0.9986]
2025-03-11 21:26:05 - Train Iteration 13300: loss: 0.8381, d_k_M range: [0.0000, 0.0429], d_k_M_hat range: [0.0845, 0.9998]
2025-03-11 21:26:05 - Train Iteration 13301: loss: 0.0242, d_k_M range: [0.0001, 0.0060], d_k_M_hat range: [0.8447, 0.9998]
2025-03-11 21:26:06 - Train Iteration 13302: loss: 0.6334, d_k_M range: [0.0001, 0.7957], d_k_M_hat range: [0.9978, 0.9998]
2025-03-11 21:26:06 - Train Iteration 13303: loss: 0.3061, d_k_M range: [0.0000, 0.0067], d_k_M_hat range: [0.4534, 0.9999]
2025-03-11 21:26:07 - Train Iteration 13304: loss: 0.0033, d_k_M range: [0.0002, 0.0559], d_k_M_hat range: [0.9712, 1.0000]
2025-03-11 21:26:07 - Train Iteration 13305: loss: 0.0094, d_k_M range: [0.0000, 0.0699], d_k_M_hat range: [0.9730, 1.0000]
2025-03-11 21:26:08 - Train Iteration 13306: loss: 0.0024, d_k_M range: [0.0001, 0.0493], d_k_M_hat range: [0.9921, 0.9999]
2025-03-11 21:26:08 - Train Iteration 13307: loss: 0.0050, d_k_M range: [0.0000, 0.0707], d_k_M_hat range: [0.9977, 0.9999]
2025-03-11 21:26:08 - Train Iteration 13308: loss: 0.0062, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.9217, 0.9991]
2025-03-11 21:26:09 - Train Iteration 13309: loss: 0.0037, d_k_M range: [0.0000, 0.0214], d_k_M_hat range: [0.9392, 0.9995]
2025-03-11 21:26:09 - Train Iteration 13310: loss: 0.0013, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9714, 0.9996]
2025-03-11 21:26:10 - Train Iteration 13311: loss: 0.0248, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.8424, 0.9998]
2025-03-11 21:26:10 - Train Iteration 13312: loss: 0.0427, d_k_M range: [0.0000, 0.2040], d_k_M_hat range: [0.9231, 0.9995]
2025-03-11 21:26:10 - Train Iteration 13313: loss: 0.0634, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.7483, 0.9997]
2025-03-11 21:26:11 - Train Iteration 13314: loss: 0.0019, d_k_M range: [0.0000, 0.0319], d_k_M_hat range: [0.9563, 0.9999]
2025-03-11 21:26:11 - Train Iteration 13315: loss: 0.0066, d_k_M range: [0.0001, 0.0105], d_k_M_hat range: [0.9189, 0.9992]
2025-03-11 21:26:12 - Train Iteration 13316: loss: 0.0002, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.9883, 0.9995]
2025-03-11 21:26:12 - Train Iteration 13317: loss: 0.5438, d_k_M range: [0.0002, 0.7372], d_k_M_hat range: [0.9628, 0.9999]
2025-03-11 21:26:13 - Train Iteration 13318: loss: 0.0076, d_k_M range: [0.0000, 0.0826], d_k_M_hat range: [0.9613, 0.9973]
2025-03-11 21:26:13 - Train Iteration 13319: loss: 0.0017, d_k_M range: [0.0001, 0.0402], d_k_M_hat range: [0.9896, 0.9997]
2025-03-11 21:26:14 - Train Iteration 13320: loss: 0.0014, d_k_M range: [0.0000, 0.0369], d_k_M_hat range: [0.9764, 0.9998]
2025-03-11 21:26:14 - Train Iteration 13321: loss: 0.0483, d_k_M range: [0.0000, 0.0654], d_k_M_hat range: [0.7820, 0.9983]
2025-03-11 21:26:15 - Train Iteration 13322: loss: 0.0036, d_k_M range: [0.0000, 0.0241], d_k_M_hat range: [0.9447, 1.0000]
2025-03-11 21:26:15 - Train Iteration 13323: loss: 0.0012, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9670, 0.9992]
2025-03-11 21:26:16 - Train Iteration 13324: loss: 0.0002, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9870, 0.9997]
2025-03-11 21:26:16 - Train Iteration 13325: loss: 0.0002, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.9873, 1.0000]
2025-03-11 21:26:17 - Train Iteration 13326: loss: 0.0061, d_k_M range: [0.0000, 0.0741], d_k_M_hat range: [0.9408, 0.9982]
2025-03-11 21:26:17 - Train Iteration 13327: loss: 0.0057, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.9242, 0.9998]
2025-03-11 21:26:17 - Train Iteration 13328: loss: 0.0039, d_k_M range: [0.0000, 0.0621], d_k_M_hat range: [0.9921, 0.9998]
2025-03-11 21:26:18 - Train Iteration 13329: loss: 0.0004, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9792, 0.9981]
2025-03-11 21:26:18 - Train Iteration 13330: loss: 0.0400, d_k_M range: [0.0001, 0.1992], d_k_M_hat range: [0.9714, 1.0000]
2025-03-11 21:26:19 - Train Iteration 13331: loss: 0.0251, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.8417, 0.9997]
2025-03-11 21:26:19 - Train Iteration 13332: loss: 0.0033, d_k_M range: [0.0000, 0.0568], d_k_M_hat range: [0.9523, 0.9994]
2025-03-11 21:26:20 - Train Iteration 13333: loss: 0.1049, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.6762, 0.9990]
2025-03-11 21:26:20 - Train Iteration 13334: loss: 0.0119, d_k_M range: [0.0000, 0.1088], d_k_M_hat range: [0.9965, 0.9999]
2025-03-11 21:26:21 - Train Iteration 13335: loss: 0.0016, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.9632, 0.9998]
2025-03-11 21:26:21 - Train Iteration 13336: loss: 0.0008, d_k_M range: [0.0002, 0.0276], d_k_M_hat range: [0.9916, 0.9999]
2025-03-11 21:26:22 - Train Iteration 13337: loss: 0.0026, d_k_M range: [0.0000, 0.0322], d_k_M_hat range: [0.9493, 0.9996]
2025-03-11 21:26:22 - Train Iteration 13338: loss: 0.0049, d_k_M range: [0.0003, 0.0699], d_k_M_hat range: [0.9892, 0.9998]
2025-03-11 21:26:22 - Train Iteration 13339: loss: 0.0093, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9034, 0.9994]
2025-03-11 21:26:23 - Train Iteration 13340: loss: 0.0002, d_k_M range: [0.0000, 0.0057], d_k_M_hat range: [0.9844, 0.9999]
2025-03-11 21:26:23 - Train Iteration 13341: loss: 0.0027, d_k_M range: [0.0001, 0.0078], d_k_M_hat range: [0.9520, 0.9999]
2025-03-11 21:26:24 - Train Iteration 13342: loss: 0.0019, d_k_M range: [0.0000, 0.0104], d_k_M_hat range: [0.9573, 0.9990]
2025-03-11 21:26:24 - Train Iteration 13343: loss: 0.0028, d_k_M range: [0.0001, 0.0523], d_k_M_hat range: [0.9941, 0.9999]
2025-03-11 21:26:25 - Train Iteration 13344: loss: 0.7933, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.1093, 0.9998]
2025-03-11 21:26:25 - Train Iteration 13345: loss: 0.0016, d_k_M range: [0.0000, 0.0350], d_k_M_hat range: [0.9938, 0.9999]
2025-03-11 21:26:25 - Train Iteration 13346: loss: 0.0062, d_k_M range: [0.0000, 0.0594], d_k_M_hat range: [0.9215, 0.9991]
2025-03-11 21:26:26 - Train Iteration 13347: loss: 0.0020, d_k_M range: [0.0000, 0.0418], d_k_M_hat range: [0.9811, 0.9998]
2025-03-11 21:26:26 - Train Iteration 13348: loss: 0.0576, d_k_M range: [0.0000, 0.1687], d_k_M_hat range: [0.7601, 0.9991]
2025-03-11 21:26:27 - Train Iteration 13349: loss: 0.0001, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.9900, 0.9997]
2025-03-11 21:26:27 - Train Iteration 13350: loss: 0.0017, d_k_M range: [0.0000, 0.0404], d_k_M_hat range: [0.9724, 0.9995]
2025-03-11 21:26:28 - Train Iteration 13351: loss: 0.0005, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9771, 0.9998]
2025-03-11 21:26:28 - Train Iteration 13352: loss: 0.0134, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.8853, 0.9988]
2025-03-11 21:26:28 - Train Iteration 13353: loss: 0.0025, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9500, 0.9998]
2025-03-11 21:26:29 - Train Iteration 13354: loss: 0.0154, d_k_M range: [0.0000, 0.0183], d_k_M_hat range: [0.8759, 0.9996]
2025-03-11 21:26:29 - Train Iteration 13355: loss: 0.0014, d_k_M range: [0.0000, 0.0367], d_k_M_hat range: [0.9811, 0.9997]
2025-03-11 21:26:30 - Train Iteration 13356: loss: 0.0019, d_k_M range: [0.0003, 0.0427], d_k_M_hat range: [0.9726, 0.9994]
2025-03-11 21:26:30 - Train Iteration 13357: loss: 0.4925, d_k_M range: [0.0000, 0.7007], d_k_M_hat range: [0.9903, 0.9995]
2025-03-11 21:26:31 - Train Iteration 13358: loss: 0.0181, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.8666, 0.9990]
2025-03-11 21:26:31 - Train Iteration 13359: loss: 0.0225, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.8499, 0.9992]
2025-03-11 21:26:31 - Train Iteration 13360: loss: 0.0001, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.9936, 1.0000]
2025-03-11 21:26:32 - Train Iteration 13361: loss: 0.0005, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9770, 0.9994]
2025-03-11 21:26:32 - Train Iteration 13362: loss: 0.3098, d_k_M range: [0.0000, 0.3613], d_k_M_hat range: [0.4447, 0.9988]
2025-03-11 21:26:33 - Train Iteration 13363: loss: 0.0194, d_k_M range: [0.0000, 0.1374], d_k_M_hat range: [0.9953, 0.9997]
2025-03-11 21:26:33 - Train Iteration 13364: loss: 0.0593, d_k_M range: [0.0000, 0.2428], d_k_M_hat range: [0.9977, 0.9999]
2025-03-11 21:26:33 - Train Iteration 13365: loss: 0.0002, d_k_M range: [0.0000, 0.0140], d_k_M_hat range: [0.9854, 0.9997]
2025-03-11 21:26:34 - Train Iteration 13366: loss: 0.0005, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.9783, 0.9998]
2025-03-11 21:26:34 - Train Iteration 13367: loss: 0.0005, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9785, 0.9999]
2025-03-11 21:26:35 - Train Iteration 13368: loss: 0.0376, d_k_M range: [0.0000, 0.1887], d_k_M_hat range: [0.9796, 0.9996]
2025-03-11 21:26:35 - Train Iteration 13369: loss: 0.0011, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9693, 0.9991]
2025-03-11 21:26:36 - Train Iteration 13370: loss: 0.6306, d_k_M range: [0.0000, 0.0497], d_k_M_hat range: [0.2059, 0.9981]
2025-03-11 21:26:36 - Train Iteration 13371: loss: 0.0558, d_k_M range: [0.0000, 0.2349], d_k_M_hat range: [0.9940, 0.9998]
2025-03-11 21:26:37 - Train Iteration 13372: loss: 0.0017, d_k_M range: [0.0000, 0.0407], d_k_M_hat range: [0.9595, 0.9998]
2025-03-11 21:26:37 - Train Iteration 13373: loss: 0.0604, d_k_M range: [0.0000, 0.2381], d_k_M_hat range: [0.8565, 0.9999]
2025-03-11 21:26:38 - Train Iteration 13374: loss: 0.0008, d_k_M range: [0.0000, 0.0223], d_k_M_hat range: [0.9939, 0.9998]
2025-03-11 21:26:38 - Train Iteration 13375: loss: 0.0021, d_k_M range: [0.0000, 0.0447], d_k_M_hat range: [0.9934, 0.9999]
2025-03-11 21:26:38 - Train Iteration 13376: loss: 0.0070, d_k_M range: [0.0000, 0.0835], d_k_M_hat range: [0.9938, 0.9999]
2025-03-11 21:26:39 - Train Iteration 13377: loss: 0.0065, d_k_M range: [0.0000, 0.0410], d_k_M_hat range: [0.9194, 0.9996]
2025-03-11 21:26:39 - Train Iteration 13378: loss: 0.0038, d_k_M range: [0.0000, 0.0101], d_k_M_hat range: [0.9390, 0.9997]
2025-03-11 21:26:40 - Train Iteration 13379: loss: 0.0722, d_k_M range: [0.0000, 0.0057], d_k_M_hat range: [0.7365, 0.9995]
2025-03-11 21:26:40 - Train Iteration 13380: loss: 0.0004, d_k_M range: [0.0000, 0.0131], d_k_M_hat range: [0.9888, 0.9995]
2025-03-11 21:26:41 - Train Iteration 13381: loss: 0.0472, d_k_M range: [0.0000, 0.2171], d_k_M_hat range: [0.9743, 0.9999]
2025-03-11 21:26:41 - Train Iteration 13382: loss: 0.0074, d_k_M range: [0.0004, 0.0650], d_k_M_hat range: [0.9147, 0.9996]
2025-03-11 21:26:41 - Train Iteration 13383: loss: 0.0019, d_k_M range: [0.0002, 0.0414], d_k_M_hat range: [0.9892, 0.9999]
2025-03-11 21:26:42 - Train Iteration 13384: loss: 0.0102, d_k_M range: [0.0000, 0.0354], d_k_M_hat range: [0.8992, 0.9995]
2025-03-11 21:26:42 - Train Iteration 13385: loss: 0.0912, d_k_M range: [0.0001, 0.3011], d_k_M_hat range: [0.9881, 0.9994]
2025-03-11 21:26:43 - Train Iteration 13386: loss: 0.0012, d_k_M range: [0.0000, 0.0345], d_k_M_hat range: [0.9810, 0.9996]
2025-03-11 21:26:43 - Train Iteration 13387: loss: 0.0212, d_k_M range: [0.0000, 0.0256], d_k_M_hat range: [0.8545, 0.9999]
2025-03-11 21:26:44 - Train Iteration 13388: loss: 0.0008, d_k_M range: [0.0002, 0.0130], d_k_M_hat range: [0.9787, 0.9999]
2025-03-11 21:26:44 - Train Iteration 13389: loss: 0.2312, d_k_M range: [0.0001, 0.0057], d_k_M_hat range: [0.5197, 0.9996]
2025-03-11 21:26:45 - Train Iteration 13390: loss: 0.0006, d_k_M range: [0.0002, 0.0177], d_k_M_hat range: [0.9808, 0.9999]
2025-03-11 21:26:45 - Train Iteration 13391: loss: 0.0039, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9375, 0.9980]
2025-03-11 21:26:46 - Train Iteration 13392: loss: 0.0130, d_k_M range: [0.0000, 0.0287], d_k_M_hat range: [0.9023, 0.9998]
2025-03-11 21:26:46 - Train Iteration 13393: loss: 0.0046, d_k_M range: [0.0000, 0.0573], d_k_M_hat range: [0.9802, 0.9995]
2025-03-11 21:26:46 - Train Iteration 13394: loss: 0.0395, d_k_M range: [0.0001, 0.1981], d_k_M_hat range: [0.9895, 0.9994]
2025-03-11 21:26:47 - Train Iteration 13395: loss: 0.0004, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9790, 0.9991]
2025-03-11 21:26:47 - Train Iteration 13396: loss: 0.1301, d_k_M range: [0.0000, 0.0625], d_k_M_hat range: [0.6402, 0.9993]
2025-03-11 21:26:48 - Train Iteration 13397: loss: 0.0137, d_k_M range: [0.0000, 0.1112], d_k_M_hat range: [0.9915, 0.9989]
2025-03-11 21:26:48 - Train Iteration 13398: loss: 0.0005, d_k_M range: [0.0002, 0.0193], d_k_M_hat range: [0.9785, 0.9999]
2025-03-11 21:26:49 - Train Iteration 13399: loss: 0.0011, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9694, 0.9995]
2025-03-11 21:26:49 - Train Iteration 13400: loss: 0.0080, d_k_M range: [0.0000, 0.0886], d_k_M_hat range: [0.9950, 0.9999]
2025-03-11 21:26:49 - Train Iteration 13401: loss: 0.0116, d_k_M range: [0.0000, 0.0906], d_k_M_hat range: [0.8924, 0.9998]
2025-03-11 21:26:50 - Train Iteration 13402: loss: 0.0033, d_k_M range: [0.0002, 0.0442], d_k_M_hat range: [0.9744, 0.9990]
2025-03-11 21:26:50 - Train Iteration 13403: loss: 0.0024, d_k_M range: [0.0000, 0.0482], d_k_M_hat range: [0.9918, 0.9999]
2025-03-11 21:26:51 - Train Iteration 13404: loss: 0.0004, d_k_M range: [0.0000, 0.0047], d_k_M_hat range: [0.9796, 0.9997]
2025-03-11 21:26:51 - Train Iteration 13405: loss: 0.0050, d_k_M range: [0.0000, 0.0225], d_k_M_hat range: [0.9324, 0.9999]
2025-03-11 21:26:51 - Train Iteration 13406: loss: 0.0011, d_k_M range: [0.0000, 0.0327], d_k_M_hat range: [0.9875, 0.9997]
2025-03-11 21:26:52 - Train Iteration 13407: loss: 0.0005, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9768, 0.9997]
2025-03-11 21:26:52 - Train Iteration 13408: loss: 0.0080, d_k_M range: [0.0000, 0.0131], d_k_M_hat range: [0.9122, 0.9999]
2025-03-11 21:26:53 - Train Iteration 13409: loss: 0.0021, d_k_M range: [0.0000, 0.0452], d_k_M_hat range: [0.9865, 0.9999]
2025-03-11 21:26:53 - Train Iteration 13410: loss: 0.0109, d_k_M range: [0.0000, 0.1012], d_k_M_hat range: [0.9894, 0.9998]
2025-03-11 21:26:53 - Train Iteration 13411: loss: 0.2213, d_k_M range: [0.0000, 0.4690], d_k_M_hat range: [0.9952, 0.9995]
2025-03-11 21:26:54 - Train Iteration 13412: loss: 0.0062, d_k_M range: [0.0000, 0.0759], d_k_M_hat range: [0.9847, 0.9993]
2025-03-11 21:26:54 - Train Iteration 13413: loss: 0.0005, d_k_M range: [0.0000, 0.0228], d_k_M_hat range: [0.9938, 0.9997]
2025-03-11 21:26:55 - Train Iteration 13414: loss: 0.6131, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.2170, 0.9998]
2025-03-11 21:26:55 - Train Iteration 13415: loss: 0.0276, d_k_M range: [0.0000, 0.1488], d_k_M_hat range: [0.9825, 0.9998]
2025-03-11 21:26:55 - Train Iteration 13416: loss: 0.0015, d_k_M range: [0.0000, 0.0381], d_k_M_hat range: [0.9789, 0.9999]
2025-03-11 21:26:56 - Train Iteration 13417: loss: 0.0074, d_k_M range: [0.0005, 0.0861], d_k_M_hat range: [0.9899, 0.9998]
2025-03-11 21:26:56 - Train Iteration 13418: loss: 0.3483, d_k_M range: [0.0000, 0.0463], d_k_M_hat range: [0.4099, 0.9995]
2025-03-11 21:26:57 - Train Iteration 13419: loss: 0.2321, d_k_M range: [0.0002, 0.4804], d_k_M_hat range: [0.8922, 0.9998]
2025-03-11 21:26:57 - Train Iteration 13420: loss: 0.0008, d_k_M range: [0.0000, 0.0263], d_k_M_hat range: [0.9809, 0.9999]
2025-03-11 21:26:58 - Train Iteration 13421: loss: 0.0181, d_k_M range: [0.0006, 0.1196], d_k_M_hat range: [0.9775, 0.9999]
2025-03-11 21:26:58 - Train Iteration 13422: loss: 0.0042, d_k_M range: [0.0002, 0.0015], d_k_M_hat range: [0.9369, 0.9974]
2025-03-11 21:26:59 - Train Iteration 13423: loss: 0.0001, d_k_M range: [0.0000, 0.0078], d_k_M_hat range: [0.9928, 0.9989]
2025-03-11 21:26:59 - Train Iteration 13424: loss: 0.0004, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9790, 0.9996]
2025-03-11 21:27:00 - Train Iteration 13425: loss: 0.5122, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.2846, 0.9992]
2025-03-11 21:27:00 - Train Iteration 13426: loss: 0.0009, d_k_M range: [0.0000, 0.0244], d_k_M_hat range: [0.9693, 0.9998]
2025-03-11 21:27:01 - Train Iteration 13427: loss: 0.0034, d_k_M range: [0.0000, 0.0095], d_k_M_hat range: [0.9421, 0.9993]
2025-03-11 21:27:01 - Train Iteration 13428: loss: 0.0001, d_k_M range: [0.0000, 0.0086], d_k_M_hat range: [0.9958, 0.9998]
2025-03-11 21:27:01 - Train Iteration 13429: loss: 0.0887, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.7022, 1.0000]
2025-03-11 21:27:02 - Train Iteration 13430: loss: 0.0043, d_k_M range: [0.0000, 0.0652], d_k_M_hat range: [0.9977, 1.0000]
2025-03-11 21:27:02 - Train Iteration 13431: loss: 0.0626, d_k_M range: [0.0000, 0.2502], d_k_M_hat range: [0.9631, 1.0000]
2025-03-11 21:27:03 - Train Iteration 13432: loss: 0.0134, d_k_M range: [0.0003, 0.0908], d_k_M_hat range: [0.9752, 0.9993]
2025-03-11 21:27:03 - Train Iteration 13433: loss: 0.0153, d_k_M range: [0.0000, 0.0199], d_k_M_hat range: [0.8772, 0.9993]
2025-03-11 21:27:04 - Train Iteration 13434: loss: 0.0184, d_k_M range: [0.0000, 0.1342], d_k_M_hat range: [0.9272, 0.9986]
2025-03-11 21:27:04 - Train Iteration 13435: loss: 0.0322, d_k_M range: [0.0000, 0.0229], d_k_M_hat range: [0.8205, 0.9990]
2025-03-11 21:27:04 - Train Iteration 13436: loss: 0.0115, d_k_M range: [0.0000, 0.0737], d_k_M_hat range: [0.8931, 0.9998]
2025-03-11 21:27:05 - Train Iteration 13437: loss: 0.0006, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.9748, 0.9991]
2025-03-11 21:27:05 - Train Iteration 13438: loss: 0.0415, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.7964, 0.9996]
2025-03-11 21:27:06 - Train Iteration 13439: loss: 0.0078, d_k_M range: [0.0000, 0.0855], d_k_M_hat range: [0.9777, 0.9997]
2025-03-11 21:27:06 - Train Iteration 13440: loss: 0.0016, d_k_M range: [0.0000, 0.0065], d_k_M_hat range: [0.9596, 0.9977]
2025-03-11 21:27:07 - Train Iteration 13441: loss: 0.8533, d_k_M range: [0.0000, 0.9237], d_k_M_hat range: [0.9827, 1.0000]
2025-03-11 21:27:07 - Train Iteration 13442: loss: 0.4944, d_k_M range: [0.0000, 0.7029], d_k_M_hat range: [0.9262, 0.9998]
2025-03-11 21:27:08 - Train Iteration 13443: loss: 0.6883, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.1703, 0.9826]
2025-03-11 21:27:08 - Train Iteration 13444: loss: 0.0386, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.8034, 0.9998]
2025-03-11 21:27:09 - Train Iteration 13445: loss: 0.0030, d_k_M range: [0.0000, 0.0162], d_k_M_hat range: [0.9615, 0.9993]
2025-03-11 21:27:09 - Train Iteration 13446: loss: 0.0026, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9486, 0.9998]
2025-03-11 21:27:09 - Train Iteration 13447: loss: 0.0026, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9494, 0.9996]
2025-03-11 21:27:10 - Train Iteration 13448: loss: 0.0970, d_k_M range: [0.0000, 0.0104], d_k_M_hat range: [0.6891, 0.9998]
2025-03-11 21:27:10 - Train Iteration 13449: loss: 0.0027, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9484, 1.0000]
2025-03-11 21:27:11 - Train Iteration 13450: loss: 0.0586, d_k_M range: [0.0001, 0.2418], d_k_M_hat range: [0.9916, 0.9999]
2025-03-11 21:27:11 - Train Iteration 13451: loss: 0.4758, d_k_M range: [0.0000, 0.0624], d_k_M_hat range: [0.3108, 0.9991]
2025-03-11 21:27:12 - Train Iteration 13452: loss: 0.0001, d_k_M range: [0.0002, 0.0033], d_k_M_hat range: [0.9920, 0.9999]
2025-03-11 21:27:12 - Train Iteration 13453: loss: 0.0145, d_k_M range: [0.0004, 0.1193], d_k_M_hat range: [0.9873, 0.9994]
2025-03-11 21:27:12 - Train Iteration 13454: loss: 0.2867, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.4646, 0.9992]
2025-03-11 21:27:13 - Train Iteration 13455: loss: 0.0010, d_k_M range: [0.0001, 0.0190], d_k_M_hat range: [0.9837, 0.9999]
2025-03-11 21:27:13 - Train Iteration 13456: loss: 0.1416, d_k_M range: [0.0000, 0.3759], d_k_M_hat range: [0.9921, 0.9997]
2025-03-11 21:27:14 - Train Iteration 13457: loss: 0.7202, d_k_M range: [0.0000, 0.0127], d_k_M_hat range: [0.1514, 1.0000]
2025-03-11 21:27:14 - Train Iteration 13458: loss: 0.0098, d_k_M range: [0.0000, 0.0989], d_k_M_hat range: [0.9762, 0.9999]
2025-03-11 21:27:14 - Train Iteration 13459: loss: 0.0038, d_k_M range: [0.0000, 0.0605], d_k_M_hat range: [0.9648, 0.9986]
2025-03-11 21:27:15 - Train Iteration 13460: loss: 0.0011, d_k_M range: [0.0000, 0.0087], d_k_M_hat range: [0.9674, 0.9982]
2025-03-11 21:27:15 - Train Iteration 13461: loss: 0.0027, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.9489, 0.9992]
2025-03-11 21:27:16 - Train Iteration 13462: loss: 0.0002, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9862, 0.9988]
2025-03-11 21:27:16 - Train Iteration 13463: loss: 0.0259, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.8390, 0.9997]
2025-03-11 21:27:16 - Train Iteration 13464: loss: 0.0081, d_k_M range: [0.0000, 0.0893], d_k_M_hat range: [0.9982, 0.9999]
2025-03-11 21:27:17 - Train Iteration 13465: loss: 0.0750, d_k_M range: [0.0000, 0.2735], d_k_M_hat range: [0.7783, 0.9998]
2025-03-11 21:27:17 - Train Iteration 13466: loss: 0.0006, d_k_M range: [0.0000, 0.0168], d_k_M_hat range: [0.9763, 0.9997]
2025-03-11 21:27:18 - Train Iteration 13467: loss: 0.0016, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.9606, 0.9985]
2025-03-11 21:27:18 - Train Iteration 13468: loss: 0.0013, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9661, 0.9995]
2025-03-11 21:27:19 - Train Iteration 13469: loss: 0.0005, d_k_M range: [0.0001, 0.0161], d_k_M_hat range: [0.9780, 0.9999]
2025-03-11 21:27:19 - Train Iteration 13470: loss: 0.0019, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9583, 0.9973]
2025-03-11 21:27:20 - Train Iteration 13471: loss: 0.0360, d_k_M range: [0.0000, 0.1830], d_k_M_hat range: [0.9671, 0.9994]
2025-03-11 21:27:20 - Train Iteration 13472: loss: 0.0023, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9525, 0.9988]
2025-03-11 21:27:21 - Train Iteration 13473: loss: 0.0006, d_k_M range: [0.0001, 0.0235], d_k_M_hat range: [0.9914, 0.9999]
2025-03-11 21:27:21 - Train Iteration 13474: loss: 0.0005, d_k_M range: [0.0000, 0.0158], d_k_M_hat range: [0.9774, 0.9991]
2025-03-11 21:27:21 - Train Iteration 13475: loss: 0.0083, d_k_M range: [0.0000, 0.0162], d_k_M_hat range: [0.9252, 0.9993]
2025-03-11 21:27:22 - Train Iteration 13476: loss: 0.0075, d_k_M range: [0.0000, 0.0836], d_k_M_hat range: [0.9669, 0.9996]
2025-03-11 21:27:22 - Train Iteration 13477: loss: 0.0009, d_k_M range: [0.0000, 0.0118], d_k_M_hat range: [0.9731, 0.9976]
2025-03-11 21:27:23 - Train Iteration 13478: loss: 0.0006, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.9763, 0.9988]
2025-03-11 21:27:23 - Train Iteration 13479: loss: 0.0126, d_k_M range: [0.0000, 0.0837], d_k_M_hat range: [0.9713, 0.9995]
2025-03-11 21:27:24 - Train Iteration 13480: loss: 0.0701, d_k_M range: [0.0000, 0.2647], d_k_M_hat range: [0.8730, 1.0000]
2025-03-11 21:27:24 - Train Iteration 13481: loss: 0.0003, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9838, 0.9998]
2025-03-11 21:27:24 - Train Iteration 13482: loss: 0.0001, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.9940, 0.9994]
2025-03-11 21:27:25 - Train Iteration 13483: loss: 0.0023, d_k_M range: [0.0000, 0.0112], d_k_M_hat range: [0.9523, 0.9997]
2025-03-11 21:27:25 - Train Iteration 13484: loss: 0.7183, d_k_M range: [0.0000, 0.8474], d_k_M_hat range: [0.9818, 0.9999]
2025-03-11 21:27:26 - Train Iteration 13485: loss: 0.0610, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.7535, 0.9981]
2025-03-11 21:27:26 - Train Iteration 13486: loss: 0.0020, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9561, 0.9994]
2025-03-11 21:27:27 - Train Iteration 13487: loss: 0.0009, d_k_M range: [0.0000, 0.0291], d_k_M_hat range: [0.9858, 0.9998]
2025-03-11 21:27:27 - Train Iteration 13488: loss: 0.0054, d_k_M range: [0.0000, 0.0729], d_k_M_hat range: [0.9788, 0.9996]
2025-03-11 21:27:28 - Train Iteration 13489: loss: 0.0014, d_k_M range: [0.0000, 0.0371], d_k_M_hat range: [0.9887, 0.9997]
2025-03-11 21:27:28 - Train Iteration 13490: loss: 0.0051, d_k_M range: [0.0000, 0.0704], d_k_M_hat range: [0.9328, 0.9997]
2025-03-11 21:27:29 - Train Iteration 13491: loss: 0.0010, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.9684, 0.9991]
2025-03-11 21:27:29 - Train Iteration 13492: loss: 0.0012, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9659, 0.9992]
2025-03-11 21:27:29 - Train Iteration 13493: loss: 0.0397, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.8006, 0.9964]
2025-03-11 21:27:30 - Train Iteration 13494: loss: 0.1621, d_k_M range: [0.0000, 0.4026], d_k_M_hat range: [0.9958, 0.9999]
2025-03-11 21:27:30 - Train Iteration 13495: loss: 0.0022, d_k_M range: [0.0000, 0.0164], d_k_M_hat range: [0.9531, 0.9995]
2025-03-11 21:27:31 - Train Iteration 13496: loss: 0.0019, d_k_M range: [0.0001, 0.0080], d_k_M_hat range: [0.9569, 0.9997]
2025-03-11 21:27:31 - Train Iteration 13497: loss: 0.0222, d_k_M range: [0.0000, 0.0377], d_k_M_hat range: [0.8519, 0.9997]
2025-03-11 21:27:31 - Train Iteration 13498: loss: 0.0003, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9825, 0.9988]
2025-03-11 21:27:32 - Train Iteration 13499: loss: 0.0081, d_k_M range: [0.0000, 0.0900], d_k_M_hat range: [0.9675, 1.0000]
2025-03-11 21:27:32 - Train Iteration 13500: loss: 0.0005, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9780, 0.9978]
2025-03-11 21:27:33 - Train Iteration 13501: loss: 0.0196, d_k_M range: [0.0000, 0.1375], d_k_M_hat range: [0.9631, 0.9987]
2025-03-11 21:27:33 - Train Iteration 13502: loss: 0.0327, d_k_M range: [0.0002, 0.1801], d_k_M_hat range: [0.9773, 0.9997]
2025-03-11 21:27:34 - Train Iteration 13503: loss: 0.0081, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9124, 0.9979]
2025-03-11 21:27:34 - Train Iteration 13504: loss: 0.0006, d_k_M range: [0.0001, 0.0192], d_k_M_hat range: [0.9797, 0.9998]
2025-03-11 21:27:34 - Train Iteration 13505: loss: 0.0002, d_k_M range: [0.0000, 0.0151], d_k_M_hat range: [0.9953, 0.9999]
2025-03-11 21:27:35 - Train Iteration 13506: loss: 0.0057, d_k_M range: [0.0000, 0.0585], d_k_M_hat range: [0.9832, 0.9992]
2025-03-11 21:27:35 - Train Iteration 13507: loss: 0.0008, d_k_M range: [0.0000, 0.0117], d_k_M_hat range: [0.9715, 0.9998]
2025-03-11 21:27:36 - Train Iteration 13508: loss: 0.0268, d_k_M range: [0.0001, 0.0007], d_k_M_hat range: [0.8363, 0.9998]
2025-03-11 21:27:36 - Train Iteration 13509: loss: 0.0409, d_k_M range: [0.0000, 0.0083], d_k_M_hat range: [0.7978, 0.9998]
2025-03-11 21:27:36 - Train Iteration 13510: loss: 0.2039, d_k_M range: [0.0000, 0.4506], d_k_M_hat range: [0.9837, 0.9997]
2025-03-11 21:27:37 - Train Iteration 13511: loss: 0.0567, d_k_M range: [0.0000, 0.0095], d_k_M_hat range: [0.7620, 0.9998]
2025-03-11 21:27:37 - Train Iteration 13512: loss: 0.0108, d_k_M range: [0.0020, 0.1037], d_k_M_hat range: [0.9689, 0.9999]
2025-03-11 21:27:38 - Train Iteration 13513: loss: 0.0013, d_k_M range: [0.0000, 0.0351], d_k_M_hat range: [0.9943, 0.9998]
2025-03-11 21:27:38 - Train Iteration 13514: loss: 0.0019, d_k_M range: [0.0000, 0.0162], d_k_M_hat range: [0.9571, 0.9986]
2025-03-11 21:27:39 - Train Iteration 13515: loss: 0.0098, d_k_M range: [0.0000, 0.0964], d_k_M_hat range: [0.9651, 0.9999]
2025-03-11 21:27:39 - Train Iteration 13516: loss: 0.4425, d_k_M range: [0.0001, 0.0770], d_k_M_hat range: [0.3349, 1.0000]
2025-03-11 21:27:40 - Train Iteration 13517: loss: 0.0015, d_k_M range: [0.0000, 0.0109], d_k_M_hat range: [0.9728, 0.9989]
2025-03-11 21:27:40 - Train Iteration 13518: loss: 0.0018, d_k_M range: [0.0000, 0.0391], d_k_M_hat range: [0.9581, 0.9996]
2025-03-11 21:27:40 - Train Iteration 13519: loss: 0.0025, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.9496, 0.9997]
2025-03-11 21:27:41 - Train Iteration 13520: loss: 0.0073, d_k_M range: [0.0000, 0.0126], d_k_M_hat range: [0.9149, 0.9997]
2025-03-11 21:27:41 - Train Iteration 13521: loss: 0.0136, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.8833, 0.9991]
2025-03-11 21:27:42 - Train Iteration 13522: loss: 0.0031, d_k_M range: [0.0000, 0.0203], d_k_M_hat range: [0.9440, 0.9994]
2025-03-11 21:27:42 - Train Iteration 13523: loss: 0.0986, d_k_M range: [0.0000, 0.0560], d_k_M_hat range: [0.7419, 1.0000]
2025-03-11 21:27:43 - Train Iteration 13524: loss: 0.0158, d_k_M range: [0.0002, 0.1237], d_k_M_hat range: [0.9836, 0.9999]
2025-03-11 21:27:43 - Train Iteration 13525: loss: 0.0558, d_k_M range: [0.0000, 0.2244], d_k_M_hat range: [0.9714, 0.9995]
2025-03-11 21:27:44 - Train Iteration 13526: loss: 0.0028, d_k_M range: [0.0004, 0.0434], d_k_M_hat range: [0.9484, 0.9998]
2025-03-11 21:27:44 - Train Iteration 13527: loss: 0.0219, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.8545, 0.9999]
2025-03-11 21:27:44 - Train Iteration 13528: loss: 0.0046, d_k_M range: [0.0000, 0.0318], d_k_M_hat range: [0.9320, 0.9998]
2025-03-11 21:27:45 - Train Iteration 13529: loss: 0.0019, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.9587, 0.9993]
2025-03-11 21:27:45 - Train Iteration 13530: loss: 0.0017, d_k_M range: [0.0000, 0.0281], d_k_M_hat range: [0.9684, 0.9995]
2025-03-11 21:27:46 - Train Iteration 13531: loss: 0.1184, d_k_M range: [0.0000, 0.3440], d_k_M_hat range: [0.9967, 1.0000]
2025-03-11 21:27:46 - Train Iteration 13532: loss: 0.0148, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.8784, 0.9989]
2025-03-11 21:27:47 - Train Iteration 13533: loss: 0.0004, d_k_M range: [0.0002, 0.0203], d_k_M_hat range: [0.9979, 1.0000]
2025-03-11 21:27:47 - Train Iteration 13534: loss: 0.0017, d_k_M range: [0.0000, 0.0315], d_k_M_hat range: [0.9861, 0.9984]
2025-03-11 21:27:47 - Train Iteration 13535: loss: 0.0008, d_k_M range: [0.0002, 0.0137], d_k_M_hat range: [0.9723, 1.0000]
2025-03-11 21:27:48 - Train Iteration 13536: loss: 0.0073, d_k_M range: [0.0000, 0.0361], d_k_M_hat range: [0.9148, 0.9999]
2025-03-11 21:27:48 - Train Iteration 13537: loss: 0.0003, d_k_M range: [0.0000, 0.0159], d_k_M_hat range: [0.9943, 0.9998]
2025-03-11 21:27:49 - Train Iteration 13538: loss: 0.0034, d_k_M range: [0.0001, 0.0574], d_k_M_hat range: [0.9932, 0.9996]
2025-03-11 21:27:49 - Train Iteration 13539: loss: 0.0002, d_k_M range: [0.0000, 0.0143], d_k_M_hat range: [0.9880, 0.9999]
2025-03-11 21:27:50 - Train Iteration 13540: loss: 0.0148, d_k_M range: [0.0002, 0.1213], d_k_M_hat range: [0.9966, 0.9999]
2025-03-11 21:27:50 - Train Iteration 13541: loss: 0.0251, d_k_M range: [0.0001, 0.1563], d_k_M_hat range: [0.9521, 0.9992]
2025-03-11 21:27:51 - Train Iteration 13542: loss: 0.0177, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.8729, 0.9990]
2025-03-11 21:27:51 - Train Iteration 13543: loss: 0.0008, d_k_M range: [0.0001, 0.0143], d_k_M_hat range: [0.9865, 0.9994]
2025-03-11 21:27:52 - Train Iteration 13544: loss: 0.0025, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.9498, 0.9992]
2025-03-11 21:27:52 - Train Iteration 13545: loss: 0.0008, d_k_M range: [0.0000, 0.0067], d_k_M_hat range: [0.9724, 0.9999]
2025-03-11 21:27:52 - Train Iteration 13546: loss: 0.0032, d_k_M range: [0.0002, 0.0156], d_k_M_hat range: [0.9441, 0.9999]
2025-03-11 21:27:53 - Train Iteration 13547: loss: 0.1859, d_k_M range: [0.0000, 0.1979], d_k_M_hat range: [0.5689, 1.0000]
2025-03-11 21:27:53 - Train Iteration 13548: loss: 0.9878, d_k_M range: [0.0005, 0.9939], d_k_M_hat range: [0.9923, 1.0000]
2025-03-11 21:27:54 - Train Iteration 13549: loss: 0.0008, d_k_M range: [0.0000, 0.0286], d_k_M_hat range: [0.9978, 0.9999]
2025-03-11 21:27:54 - Train Iteration 13550: loss: 0.0019, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.9563, 0.9997]
2025-03-11 21:27:54 - Train Iteration 13551: loss: 0.0003, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.9840, 0.9998]
2025-03-11 21:27:55 - Train Iteration 13552: loss: 0.0004, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.9803, 0.9999]
2025-03-11 21:27:55 - Train Iteration 13553: loss: 0.0002, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.9887, 0.9991]
2025-03-11 21:27:56 - Train Iteration 13554: loss: 0.0035, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.9407, 0.9992]
2025-03-11 21:27:56 - Train Iteration 13555: loss: 0.0205, d_k_M range: [0.0000, 0.0153], d_k_M_hat range: [0.8723, 0.9999]
2025-03-11 21:27:57 - Train Iteration 13556: loss: 0.8092, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.1004, 0.9999]
2025-03-11 21:27:57 - Train Iteration 13557: loss: 0.0071, d_k_M range: [0.0000, 0.0814], d_k_M_hat range: [0.9903, 0.9996]
2025-03-11 21:27:57 - Train Iteration 13558: loss: 0.0001, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9913, 0.9996]
2025-03-11 21:27:58 - Train Iteration 13559: loss: 0.0287, d_k_M range: [0.0000, 0.1693], d_k_M_hat range: [0.9594, 0.9998]
2025-03-11 21:27:58 - Train Iteration 13560: loss: 0.2546, d_k_M range: [0.0000, 0.1015], d_k_M_hat range: [0.4954, 0.9997]
2025-03-11 21:27:59 - Train Iteration 13561: loss: 0.0326, d_k_M range: [0.0000, 0.1472], d_k_M_hat range: [0.8381, 0.9999]
2025-03-11 21:27:59 - Train Iteration 13562: loss: 0.0006, d_k_M range: [0.0000, 0.0084], d_k_M_hat range: [0.9831, 0.9994]
2025-03-11 21:27:59 - Train Iteration 13563: loss: 0.0395, d_k_M range: [0.0001, 0.0259], d_k_M_hat range: [0.8097, 0.9997]
2025-03-11 21:28:00 - Train Iteration 13564: loss: 0.0013, d_k_M range: [0.0004, 0.0344], d_k_M_hat range: [0.9933, 0.9999]
2025-03-11 21:28:00 - Train Iteration 13565: loss: 0.0159, d_k_M range: [0.0004, 0.1168], d_k_M_hat range: [0.9908, 0.9993]
2025-03-11 21:28:01 - Train Iteration 13566: loss: 0.0027, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9485, 0.9998]
2025-03-11 21:28:01 - Train Iteration 13567: loss: 0.0482, d_k_M range: [0.0000, 0.2160], d_k_M_hat range: [0.9936, 0.9999]
2025-03-11 21:28:02 - Train Iteration 13568: loss: 0.0001, d_k_M range: [0.0000, 0.0084], d_k_M_hat range: [0.9933, 0.9999]
2025-03-11 21:28:02 - Train Iteration 13569: loss: 0.0002, d_k_M range: [0.0000, 0.0132], d_k_M_hat range: [0.9896, 1.0000]
2025-03-11 21:28:03 - Train Iteration 13570: loss: 0.0004, d_k_M range: [0.0000, 0.0064], d_k_M_hat range: [0.9803, 0.9991]
2025-03-11 21:28:03 - Train Iteration 13571: loss: 0.0186, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.8676, 0.9997]
2025-03-11 21:28:04 - Train Iteration 13572: loss: 0.0044, d_k_M range: [0.0002, 0.0664], d_k_M_hat range: [0.9878, 0.9997]
2025-03-11 21:28:04 - Train Iteration 13573: loss: 0.0019, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9573, 0.9997]
2025-03-11 21:28:05 - Train Iteration 13574: loss: 0.0705, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.7344, 0.9997]
2025-03-11 21:28:05 - Train Iteration 13575: loss: 0.0013, d_k_M range: [0.0000, 0.0350], d_k_M_hat range: [0.9979, 0.9997]
2025-03-11 21:28:05 - Train Iteration 13576: loss: 0.0016, d_k_M range: [0.0000, 0.0387], d_k_M_hat range: [0.9938, 0.9999]
2025-03-11 21:28:06 - Train Iteration 13577: loss: 0.3683, d_k_M range: [0.0000, 0.6032], d_k_M_hat range: [0.9945, 0.9990]
2025-03-11 21:28:06 - Train Iteration 13578: loss: 0.0866, d_k_M range: [0.0000, 0.2937], d_k_M_hat range: [0.9922, 1.0000]
2025-03-11 21:28:07 - Train Iteration 13579: loss: 0.0214, d_k_M range: [0.0002, 0.0534], d_k_M_hat range: [0.8548, 0.9986]
2025-03-11 21:28:07 - Train Iteration 13580: loss: 0.0055, d_k_M range: [0.0001, 0.0731], d_k_M_hat range: [0.9876, 1.0000]
2025-03-11 21:28:08 - Train Iteration 13581: loss: 0.0017, d_k_M range: [0.0001, 0.0359], d_k_M_hat range: [0.9816, 0.9985]
2025-03-11 21:28:08 - Train Iteration 13582: loss: 0.0096, d_k_M range: [0.0000, 0.0863], d_k_M_hat range: [0.9647, 1.0000]
2025-03-11 21:28:08 - Train Iteration 13583: loss: 0.0022, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9533, 0.9992]
2025-03-11 21:28:09 - Train Iteration 13584: loss: 0.0002, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9843, 0.9998]
2025-03-11 21:28:09 - Train Iteration 13585: loss: 0.0230, d_k_M range: [0.0000, 0.1340], d_k_M_hat range: [0.8486, 0.9995]
2025-03-11 21:28:10 - Train Iteration 13586: loss: 0.0313, d_k_M range: [0.0000, 0.1759], d_k_M_hat range: [0.9744, 0.9997]
2025-03-11 21:28:10 - Train Iteration 13587: loss: 0.0050, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9294, 0.9996]
2025-03-11 21:28:11 - Train Iteration 13588: loss: 0.0063, d_k_M range: [0.0000, 0.0079], d_k_M_hat range: [0.9209, 0.9990]
2025-03-11 21:28:11 - Train Iteration 13589: loss: 0.0006, d_k_M range: [0.0003, 0.0251], d_k_M_hat range: [0.9873, 0.9999]
2025-03-11 21:28:11 - Train Iteration 13590: loss: 0.0001, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.9880, 0.9997]
2025-03-11 21:28:12 - Train Iteration 13591: loss: 0.0006, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9750, 0.9988]
2025-03-11 21:28:12 - Train Iteration 13592: loss: 0.0052, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.9276, 0.9971]
2025-03-11 21:28:13 - Train Iteration 13593: loss: 0.0012, d_k_M range: [0.0001, 0.0062], d_k_M_hat range: [0.9713, 0.9985]
2025-03-11 21:28:13 - Train Iteration 13594: loss: 0.0163, d_k_M range: [0.0000, 0.0178], d_k_M_hat range: [0.8723, 0.9985]
2025-03-11 21:28:14 - Train Iteration 13595: loss: 0.0003, d_k_M range: [0.0000, 0.0067], d_k_M_hat range: [0.9828, 0.9997]
2025-03-11 21:28:14 - Train Iteration 13596: loss: 0.0088, d_k_M range: [0.0001, 0.0138], d_k_M_hat range: [0.9062, 0.9996]
2025-03-11 21:28:15 - Train Iteration 13597: loss: 0.0100, d_k_M range: [0.0000, 0.0996], d_k_M_hat range: [0.9973, 1.0000]
2025-03-11 21:28:15 - Train Iteration 13598: loss: 0.6988, d_k_M range: [0.0003, 0.8360], d_k_M_hat range: [0.9967, 1.0000]
2025-03-11 21:28:15 - Train Iteration 13599: loss: 0.0148, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.8785, 0.9984]
2025-03-11 21:28:16 - Train Iteration 13600: loss: 0.0007, d_k_M range: [0.0000, 0.0247], d_k_M_hat range: [0.9874, 0.9998]
2025-03-11 21:28:16 - Train Iteration 13601: loss: 0.0007, d_k_M range: [0.0000, 0.0265], d_k_M_hat range: [0.9964, 1.0000]
2025-03-11 21:28:17 - Train Iteration 13602: loss: 0.0018, d_k_M range: [0.0000, 0.0422], d_k_M_hat range: [0.9928, 0.9995]
2025-03-11 21:28:17 - Train Iteration 13603: loss: 0.0008, d_k_M range: [0.0000, 0.0266], d_k_M_hat range: [0.9871, 0.9998]
2025-03-11 21:28:17 - Train Iteration 13604: loss: 0.0310, d_k_M range: [0.0001, 0.1758], d_k_M_hat range: [0.9949, 0.9999]
2025-03-11 21:28:18 - Train Iteration 13605: loss: 0.0028, d_k_M range: [0.0001, 0.0526], d_k_M_hat range: [0.9538, 0.9996]
2025-03-11 21:28:18 - Train Iteration 13606: loss: 0.0015, d_k_M range: [0.0000, 0.0274], d_k_M_hat range: [0.9892, 0.9999]
2025-03-11 21:28:19 - Train Iteration 13607: loss: 0.0020, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9549, 0.9999]
2025-03-11 21:28:19 - Train Iteration 13608: loss: 0.0032, d_k_M range: [0.0001, 0.0041], d_k_M_hat range: [0.9456, 0.9997]
2025-03-11 21:28:19 - Train Iteration 13609: loss: 0.0039, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9378, 0.9996]
2025-03-11 21:28:20 - Train Iteration 13610: loss: 0.1283, d_k_M range: [0.0000, 0.3581], d_k_M_hat range: [0.8861, 0.9999]
2025-03-11 21:28:20 - Train Iteration 13611: loss: 0.0011, d_k_M range: [0.0000, 0.0309], d_k_M_hat range: [0.9673, 0.9996]
2025-03-11 21:28:21 - Train Iteration 13612: loss: 0.1934, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.5602, 0.9994]
2025-03-11 21:28:21 - Train Iteration 13613: loss: 0.9439, d_k_M range: [0.0001, 0.9715], d_k_M_hat range: [0.9977, 1.0000]
2025-03-11 21:28:22 - Train Iteration 13614: loss: 0.4759, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.3101, 0.9999]
2025-03-11 21:28:22 - Train Iteration 13615: loss: 0.0400, d_k_M range: [0.0000, 0.1993], d_k_M_hat range: [0.9959, 0.9995]
2025-03-11 21:28:22 - Train Iteration 13616: loss: 0.0097, d_k_M range: [0.0000, 0.0512], d_k_M_hat range: [0.9527, 0.9991]
2025-03-11 21:28:23 - Train Iteration 13617: loss: 0.0291, d_k_M range: [0.0001, 0.1703], d_k_M_hat range: [0.9059, 0.9999]
2025-03-11 21:28:23 - Train Iteration 13618: loss: 0.0061, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9221, 0.9991]
2025-03-11 21:28:24 - Train Iteration 13619: loss: 0.0005, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9780, 0.9999]
2025-03-11 21:28:24 - Train Iteration 13620: loss: 0.0001, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9931, 0.9998]
2025-03-11 21:28:25 - Train Iteration 13621: loss: 0.0920, d_k_M range: [0.0001, 0.0021], d_k_M_hat range: [0.6973, 0.9999]
2025-03-11 21:28:25 - Train Iteration 13622: loss: 0.0010, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9679, 0.9997]
2025-03-11 21:28:26 - Train Iteration 13623: loss: 0.0063, d_k_M range: [0.0000, 0.0793], d_k_M_hat range: [0.9772, 0.9998]
2025-03-11 21:28:26 - Train Iteration 13624: loss: 0.0016, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.9605, 0.9998]
2025-03-11 21:28:26 - Train Iteration 13625: loss: 0.0053, d_k_M range: [0.0002, 0.0721], d_k_M_hat range: [0.9962, 1.0000]
2025-03-11 21:28:27 - Train Iteration 13626: loss: 0.0071, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.9159, 0.9991]
2025-03-11 21:28:27 - Train Iteration 13627: loss: 0.1421, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.6231, 0.9999]
2025-03-11 21:28:28 - Train Iteration 13628: loss: 0.0001, d_k_M range: [0.0001, 0.0053], d_k_M_hat range: [0.9920, 1.0000]
2025-03-11 21:28:28 - Train Iteration 13629: loss: 0.0000, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.9955, 0.9996]
2025-03-11 21:28:29 - Train Iteration 13630: loss: 0.0003, d_k_M range: [0.0000, 0.0180], d_k_M_hat range: [0.9889, 0.9998]
2025-03-11 21:28:29 - Train Iteration 13631: loss: 0.0716, d_k_M range: [0.0000, 0.2667], d_k_M_hat range: [0.9921, 0.9995]
2025-03-11 21:28:29 - Train Iteration 13632: loss: 0.0140, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.8826, 0.9996]
2025-03-11 21:28:30 - Train Iteration 13633: loss: 0.0128, d_k_M range: [0.0000, 0.0152], d_k_M_hat range: [0.8869, 1.0000]
2025-03-11 21:28:30 - Train Iteration 13634: loss: 0.2795, d_k_M range: [0.0000, 0.5277], d_k_M_hat range: [0.9756, 1.0000]
2025-03-11 21:28:31 - Train Iteration 13635: loss: 0.0055, d_k_M range: [0.0000, 0.0089], d_k_M_hat range: [0.9260, 0.9997]
2025-03-11 21:28:31 - Train Iteration 13636: loss: 0.0860, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.7108, 0.9987]
2025-03-11 21:28:32 - Train Iteration 13637: loss: 0.0001, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9921, 0.9997]
2025-03-11 21:28:32 - Train Iteration 13638: loss: 0.0013, d_k_M range: [0.0000, 0.0353], d_k_M_hat range: [0.9802, 0.9998]
2025-03-11 21:28:33 - Train Iteration 13639: loss: 0.0066, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.9187, 0.9995]
2025-03-11 21:28:33 - Train Iteration 13640: loss: 0.0054, d_k_M range: [0.0001, 0.0092], d_k_M_hat range: [0.9273, 0.9998]
2025-03-11 21:28:34 - Train Iteration 13641: loss: 0.0014, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9624, 0.9994]
2025-03-11 21:28:34 - Train Iteration 13642: loss: 0.0002, d_k_M range: [0.0001, 0.0108], d_k_M_hat range: [0.9887, 1.0000]
2025-03-11 21:28:34 - Train Iteration 13643: loss: 0.0197, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.8595, 0.9995]
2025-03-11 21:28:35 - Train Iteration 13644: loss: 0.0056, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9261, 1.0000]
2025-03-11 21:28:35 - Train Iteration 13645: loss: 0.0093, d_k_M range: [0.0000, 0.0088], d_k_M_hat range: [0.9036, 1.0000]
2025-03-11 21:28:36 - Train Iteration 13646: loss: 0.0017, d_k_M range: [0.0000, 0.0198], d_k_M_hat range: [0.9593, 0.9999]
2025-03-11 21:28:36 - Train Iteration 13647: loss: 0.0027, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9476, 0.9992]
2025-03-11 21:28:36 - Train Iteration 13648: loss: 0.0463, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.7849, 0.9991]
2025-03-11 21:28:37 - Train Iteration 13649: loss: 0.0094, d_k_M range: [0.0000, 0.0950], d_k_M_hat range: [0.9764, 0.9999]
2025-03-11 21:28:37 - Train Iteration 13650: loss: 0.5779, d_k_M range: [0.0000, 0.7541], d_k_M_hat range: [0.9795, 0.9996]
2025-03-11 21:28:38 - Train Iteration 13651: loss: 0.0583, d_k_M range: [0.0000, 0.1102], d_k_M_hat range: [0.8687, 0.9972]
2025-03-11 21:28:38 - Train Iteration 13652: loss: 0.6773, d_k_M range: [0.0000, 0.8217], d_k_M_hat range: [0.9987, 1.0000]
2025-03-11 21:28:39 - Train Iteration 13653: loss: 0.0011, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.9674, 0.9995]
2025-03-11 21:28:39 - Train Iteration 13654: loss: 0.0000, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.9942, 0.9999]
2025-03-11 21:28:39 - Train Iteration 13655: loss: 0.0044, d_k_M range: [0.0000, 0.0135], d_k_M_hat range: [0.9339, 0.9997]
2025-03-11 21:28:40 - Train Iteration 13656: loss: 0.0142, d_k_M range: [0.0001, 0.0037], d_k_M_hat range: [0.8813, 1.0000]
2025-03-11 21:28:40 - Train Iteration 13657: loss: 0.0001, d_k_M range: [0.0000, 0.0064], d_k_M_hat range: [0.9882, 0.9999]
2025-03-11 21:28:41 - Train Iteration 13658: loss: 0.0006, d_k_M range: [0.0001, 0.0130], d_k_M_hat range: [0.9770, 1.0000]
2025-03-11 21:28:41 - Train Iteration 13659: loss: 0.0150, d_k_M range: [0.0001, 0.0729], d_k_M_hat range: [0.9502, 0.9997]
2025-03-11 21:28:41 - Train Iteration 13660: loss: 0.0003, d_k_M range: [0.0000, 0.0070], d_k_M_hat range: [0.9831, 0.9996]
2025-03-11 21:28:42 - Train Iteration 13661: loss: 0.0074, d_k_M range: [0.0000, 0.0840], d_k_M_hat range: [0.9336, 0.9998]
2025-03-11 21:28:42 - Train Iteration 13662: loss: 0.0003, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.9941, 0.9995]
2025-03-11 21:28:43 - Train Iteration 13663: loss: 0.5615, d_k_M range: [0.0000, 0.7492], d_k_M_hat range: [0.9355, 0.9998]
2025-03-11 21:28:43 - Train Iteration 13664: loss: 0.7674, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.1274, 0.9996]
2025-03-11 21:28:44 - Train Iteration 13665: loss: 0.0188, d_k_M range: [0.0000, 0.1344], d_k_M_hat range: [0.9433, 0.9995]
2025-03-11 21:28:44 - Train Iteration 13666: loss: 0.0014, d_k_M range: [0.0000, 0.0287], d_k_M_hat range: [0.9631, 0.9999]
2025-03-11 21:28:45 - Train Iteration 13667: loss: 0.0194, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.8608, 0.9995]
2025-03-11 21:28:45 - Train Iteration 13668: loss: 0.0003, d_k_M range: [0.0001, 0.0070], d_k_M_hat range: [0.9837, 0.9996]
2025-03-11 21:28:45 - Train Iteration 13669: loss: 0.0053, d_k_M range: [0.0000, 0.0065], d_k_M_hat range: [0.9285, 0.9990]
2025-03-11 21:28:46 - Train Iteration 13670: loss: 0.0104, d_k_M range: [0.0000, 0.0104], d_k_M_hat range: [0.8984, 0.9998]
2025-03-11 21:28:46 - Train Iteration 13671: loss: 0.0000, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.9973, 0.9993]
2025-03-11 21:28:47 - Train Iteration 13672: loss: 0.0002, d_k_M range: [0.0001, 0.0144], d_k_M_hat range: [0.9920, 0.9998]
2025-03-11 21:28:47 - Train Iteration 13673: loss: 0.8620, d_k_M range: [0.0000, 0.9283], d_k_M_hat range: [0.9913, 0.9998]
2025-03-11 21:28:48 - Train Iteration 13674: loss: 0.0007, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9735, 0.9994]
2025-03-11 21:28:48 - Train Iteration 13675: loss: 0.0041, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.9364, 0.9999]
2025-03-11 21:28:49 - Train Iteration 13676: loss: 0.0093, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.9036, 0.9980]
2025-03-11 21:28:49 - Train Iteration 13677: loss: 0.0010, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.9758, 0.9994]
2025-03-11 21:28:49 - Train Iteration 13678: loss: 0.0007, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9733, 0.9996]
2025-03-11 21:28:50 - Train Iteration 13679: loss: 0.0019, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.9572, 0.9999]
2025-03-11 21:28:50 - Train Iteration 13680: loss: 0.0000, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.9950, 0.9994]
2025-03-11 21:28:51 - Train Iteration 13681: loss: 0.0015, d_k_M range: [0.0000, 0.0147], d_k_M_hat range: [0.9762, 0.9990]
2025-03-11 21:28:51 - Train Iteration 13682: loss: 0.2411, d_k_M range: [0.0001, 0.4904], d_k_M_hat range: [0.9976, 1.0000]
2025-03-11 21:28:52 - Train Iteration 13683: loss: 0.0551, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.7654, 0.9992]
2025-03-11 21:28:52 - Train Iteration 13684: loss: 0.0041, d_k_M range: [0.0000, 0.0170], d_k_M_hat range: [0.9357, 0.9998]
2025-03-11 21:28:52 - Train Iteration 13685: loss: 0.0004, d_k_M range: [0.0000, 0.0180], d_k_M_hat range: [0.9892, 0.9996]
2025-03-11 21:28:53 - Train Iteration 13686: loss: 0.1110, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.6668, 0.9996]
2025-03-11 21:28:53 - Train Iteration 13687: loss: 0.0016, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.9602, 0.9998]
2025-03-11 21:28:54 - Train Iteration 13688: loss: 0.0069, d_k_M range: [0.0000, 0.0438], d_k_M_hat range: [0.9573, 0.9994]
2025-03-11 21:28:54 - Train Iteration 13689: loss: 0.2208, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.5302, 0.9995]
2025-03-11 21:28:55 - Train Iteration 13690: loss: 0.8477, d_k_M range: [0.0006, 0.9207], d_k_M_hat range: [0.9994, 1.0000]
2025-03-11 21:28:55 - Train Iteration 13691: loss: 0.0001, d_k_M range: [0.0001, 0.0061], d_k_M_hat range: [0.9918, 1.0000]
2025-03-11 21:28:55 - Train Iteration 13692: loss: 0.0002, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9877, 0.9991]
2025-03-11 21:28:56 - Train Iteration 13693: loss: 0.1316, d_k_M range: [0.0000, 0.0733], d_k_M_hat range: [0.6372, 0.9999]
2025-03-11 21:28:56 - Train Iteration 13694: loss: 0.0003, d_k_M range: [0.0000, 0.0139], d_k_M_hat range: [0.9869, 1.0000]
2025-03-11 21:28:57 - Train Iteration 13695: loss: 0.0054, d_k_M range: [0.0000, 0.0696], d_k_M_hat range: [0.9950, 0.9999]
2025-03-11 21:28:57 - Train Iteration 13696: loss: 0.0006, d_k_M range: [0.0000, 0.0122], d_k_M_hat range: [0.9770, 1.0000]
2025-03-11 21:28:58 - Train Iteration 13697: loss: 0.0029, d_k_M range: [0.0000, 0.0520], d_k_M_hat range: [0.9816, 0.9999]
2025-03-11 21:28:58 - Train Iteration 13698: loss: 0.0013, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.9672, 0.9998]
2025-03-11 21:28:58 - Train Iteration 13699: loss: 0.0320, d_k_M range: [0.0000, 0.1784], d_k_M_hat range: [0.9379, 0.9995]
2025-03-11 21:28:59 - Train Iteration 13700: loss: 0.0001, d_k_M range: [0.0000, 0.0108], d_k_M_hat range: [0.9897, 0.9997]
2025-03-11 21:28:59 - Train Iteration 13701: loss: 0.0075, d_k_M range: [0.0000, 0.0428], d_k_M_hat range: [0.9137, 0.9982]
2025-03-11 21:29:00 - Train Iteration 13702: loss: 0.0022, d_k_M range: [0.0000, 0.0424], d_k_M_hat range: [0.9532, 0.9990]
2025-03-11 21:29:00 - Train Iteration 13703: loss: 0.0004, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.9813, 0.9998]
2025-03-11 21:29:00 - Train Iteration 13704: loss: 0.0047, d_k_M range: [0.0001, 0.0669], d_k_M_hat range: [0.9786, 0.9998]
2025-03-11 21:29:01 - Train Iteration 13705: loss: 0.0097, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.9040, 0.9999]
2025-03-11 21:29:01 - Train Iteration 13706: loss: 0.0001, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9941, 1.0000]
2025-03-11 21:29:02 - Train Iteration 13707: loss: 0.0009, d_k_M range: [0.0000, 0.0093], d_k_M_hat range: [0.9787, 0.9999]
2025-03-11 21:29:02 - Train Iteration 13708: loss: 0.0046, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9349, 0.9998]
2025-03-11 21:29:03 - Train Iteration 13709: loss: 0.0425, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.7939, 0.9994]
2025-03-11 21:29:03 - Train Iteration 13710: loss: 0.0006, d_k_M range: [0.0000, 0.0230], d_k_M_hat range: [0.9974, 0.9999]
2025-03-11 21:29:03 - Train Iteration 13711: loss: 0.0945, d_k_M range: [0.0001, 0.1240], d_k_M_hat range: [0.7694, 0.9999]
2025-03-11 21:29:04 - Train Iteration 13712: loss: 0.3469, d_k_M range: [0.0000, 0.5873], d_k_M_hat range: [0.9881, 0.9998]
2025-03-11 21:29:04 - Train Iteration 13713: loss: 0.0374, d_k_M range: [0.0000, 0.0112], d_k_M_hat range: [0.8089, 0.9997]
2025-03-11 21:29:05 - Train Iteration 13714: loss: 0.0939, d_k_M range: [0.0000, 0.0796], d_k_M_hat range: [0.6936, 0.9998]
2025-03-11 21:29:05 - Train Iteration 13715: loss: 0.0026, d_k_M range: [0.0001, 0.0045], d_k_M_hat range: [0.9500, 0.9998]
2025-03-11 21:29:06 - Train Iteration 13716: loss: 0.6846, d_k_M range: [0.0000, 0.8274], d_k_M_hat range: [0.9674, 1.0000]
2025-03-11 21:29:06 - Train Iteration 13717: loss: 0.0007, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.9730, 0.9986]
2025-03-11 21:29:07 - Train Iteration 13718: loss: 0.0517, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.7726, 0.9986]
2025-03-11 21:29:07 - Train Iteration 13719: loss: 0.6775, d_k_M range: [0.0000, 0.8217], d_k_M_hat range: [0.9748, 0.9999]
2025-03-11 21:29:08 - Train Iteration 13720: loss: 0.0271, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.8353, 0.9993]
2025-03-11 21:29:08 - Train Iteration 13721: loss: 0.0054, d_k_M range: [0.0002, 0.0729], d_k_M_hat range: [0.9951, 0.9999]
2025-03-11 21:29:09 - Train Iteration 13722: loss: 0.0021, d_k_M range: [0.0001, 0.0054], d_k_M_hat range: [0.9552, 0.9994]
2025-03-11 21:29:09 - Train Iteration 13723: loss: 0.0059, d_k_M range: [0.0000, 0.0104], d_k_M_hat range: [0.9233, 0.9996]
2025-03-11 21:29:09 - Train Iteration 13724: loss: 0.0005, d_k_M range: [0.0000, 0.0220], d_k_M_hat range: [0.9936, 0.9999]
2025-03-11 21:29:10 - Train Iteration 13725: loss: 0.2830, d_k_M range: [0.0000, 0.5319], d_k_M_hat range: [0.9552, 0.9999]
2025-03-11 21:29:10 - Train Iteration 13726: loss: 0.0066, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9188, 0.9985]
2025-03-11 21:29:11 - Train Iteration 13727: loss: 0.1444, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.6201, 0.9999]
2025-03-11 21:29:11 - Train Iteration 13728: loss: 0.0025, d_k_M range: [0.0000, 0.0480], d_k_M_hat range: [0.9792, 0.9996]
2025-03-11 21:29:12 - Train Iteration 13729: loss: 0.0004, d_k_M range: [0.0000, 0.0154], d_k_M_hat range: [0.9854, 0.9989]
2025-03-11 21:29:12 - Train Iteration 13730: loss: 0.0027, d_k_M range: [0.0000, 0.0494], d_k_M_hat range: [0.9479, 0.9982]
2025-03-11 21:29:13 - Train Iteration 13731: loss: 0.0418, d_k_M range: [0.0000, 0.2042], d_k_M_hat range: [0.9013, 0.9999]
2025-03-11 21:29:13 - Train Iteration 13732: loss: 0.0223, d_k_M range: [0.0000, 0.1320], d_k_M_hat range: [0.9806, 0.9997]
2025-03-11 21:29:13 - Train Iteration 13733: loss: 0.0002, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9870, 0.9989]
2025-03-11 21:29:14 - Train Iteration 13734: loss: 0.0192, d_k_M range: [0.0000, 0.0065], d_k_M_hat range: [0.8615, 0.9996]
2025-03-11 21:29:14 - Train Iteration 13735: loss: 0.4905, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.2998, 0.9995]
2025-03-11 21:29:15 - Train Iteration 13736: loss: 0.0544, d_k_M range: [0.0002, 0.0659], d_k_M_hat range: [0.7673, 0.9993]
2025-03-11 21:29:15 - Train Iteration 13737: loss: 0.9293, d_k_M range: [0.0000, 0.0224], d_k_M_hat range: [0.0360, 0.9999]
2025-03-11 21:29:16 - Train Iteration 13738: loss: 0.0495, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.7776, 0.9981]
2025-03-11 21:29:16 - Train Iteration 13739: loss: 0.1338, d_k_M range: [0.0000, 0.3658], d_k_M_hat range: [0.9706, 1.0000]
2025-03-11 21:29:17 - Train Iteration 13740: loss: 0.0145, d_k_M range: [0.0000, 0.0185], d_k_M_hat range: [0.8795, 0.9998]
2025-03-11 21:29:17 - Train Iteration 13741: loss: 0.0014, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9628, 0.9999]
2025-03-11 21:29:18 - Train Iteration 13742: loss: 0.0024, d_k_M range: [0.0001, 0.0055], d_k_M_hat range: [0.9516, 0.9996]
2025-03-11 21:29:18 - Train Iteration 13743: loss: 0.0019, d_k_M range: [0.0000, 0.0239], d_k_M_hat range: [0.9566, 0.9999]
2025-03-11 21:29:18 - Train Iteration 13744: loss: 0.0013, d_k_M range: [0.0001, 0.0266], d_k_M_hat range: [0.9894, 0.9999]
2025-03-11 21:29:19 - Train Iteration 13745: loss: 0.0041, d_k_M range: [0.0000, 0.0135], d_k_M_hat range: [0.9364, 1.0000]
2025-03-11 21:29:19 - Train Iteration 13746: loss: 0.4580, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.3233, 1.0000]
2025-03-11 21:29:20 - Train Iteration 13747: loss: 0.0066, d_k_M range: [0.0005, 0.0811], d_k_M_hat range: [0.9962, 1.0000]
2025-03-11 21:29:20 - Train Iteration 13748: loss: 0.0015, d_k_M range: [0.0001, 0.0381], d_k_M_hat range: [0.9922, 1.0000]
2025-03-11 21:29:21 - Train Iteration 13749: loss: 0.0074, d_k_M range: [0.0000, 0.0315], d_k_M_hat range: [0.9149, 0.9995]
2025-03-11 21:29:21 - Train Iteration 13750: loss: 0.0056, d_k_M range: [0.0002, 0.0109], d_k_M_hat range: [0.9252, 0.9992]
2025-03-11 21:29:22 - Train Iteration 13751: loss: 0.0035, d_k_M range: [0.0000, 0.0112], d_k_M_hat range: [0.9413, 1.0000]
2025-03-11 21:29:22 - Train Iteration 13752: loss: 0.8009, d_k_M range: [0.0001, 0.8949], d_k_M_hat range: [0.9994, 1.0000]
2025-03-11 21:29:22 - Train Iteration 13753: loss: 0.0175, d_k_M range: [0.0000, 0.0605], d_k_M_hat range: [0.8687, 0.9998]
2025-03-11 21:29:23 - Train Iteration 13754: loss: 0.0004, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.9898, 0.9999]
2025-03-11 21:29:23 - Train Iteration 13755: loss: 0.0316, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.8224, 0.9986]
2025-03-11 21:29:24 - Train Iteration 13756: loss: 0.0099, d_k_M range: [0.0000, 0.0989], d_k_M_hat range: [0.9929, 0.9999]
2025-03-11 21:29:24 - Train Iteration 13757: loss: 0.0030, d_k_M range: [0.0000, 0.0531], d_k_M_hat range: [0.9811, 0.9994]
2025-03-11 21:29:25 - Train Iteration 13758: loss: 0.0106, d_k_M range: [0.0003, 0.1024], d_k_M_hat range: [0.9671, 0.9996]
2025-03-11 21:29:25 - Train Iteration 13759: loss: 0.1020, d_k_M range: [0.0000, 0.3192], d_k_M_hat range: [0.9753, 0.9999]
2025-03-11 21:29:25 - Train Iteration 13760: loss: 0.0036, d_k_M range: [0.0000, 0.0113], d_k_M_hat range: [0.9399, 0.9997]
2025-03-11 21:29:26 - Train Iteration 13761: loss: 0.0203, d_k_M range: [0.0000, 0.0090], d_k_M_hat range: [0.8576, 0.9996]
2025-03-11 21:29:26 - Train Iteration 13762: loss: 0.0848, d_k_M range: [0.0000, 0.2873], d_k_M_hat range: [0.9955, 0.9998]
2025-03-11 21:29:27 - Train Iteration 13763: loss: 0.0024, d_k_M range: [0.0001, 0.0213], d_k_M_hat range: [0.9515, 0.9999]
2025-03-11 21:29:27 - Train Iteration 13764: loss: 0.0080, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.9104, 0.9993]
2025-03-11 21:29:28 - Train Iteration 13765: loss: 0.0001, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.9895, 0.9994]
2025-03-11 21:29:28 - Train Iteration 13766: loss: 0.0041, d_k_M range: [0.0000, 0.0638], d_k_M_hat range: [0.9894, 1.0000]
2025-03-11 21:29:29 - Train Iteration 13767: loss: 0.0142, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.8809, 0.9996]
2025-03-11 21:29:29 - Train Iteration 13768: loss: 0.0331, d_k_M range: [0.0000, 0.1370], d_k_M_hat range: [0.8179, 0.9990]
2025-03-11 21:29:30 - Train Iteration 13769: loss: 0.0000, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9953, 0.9999]
2025-03-11 21:29:30 - Train Iteration 13770: loss: 0.0022, d_k_M range: [0.0000, 0.0372], d_k_M_hat range: [0.9640, 1.0000]
2025-03-11 21:29:30 - Train Iteration 13771: loss: 0.0004, d_k_M range: [0.0000, 0.0091], d_k_M_hat range: [0.9892, 1.0000]
2025-03-11 21:29:31 - Train Iteration 13772: loss: 0.0108, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.8961, 0.9997]
2025-03-11 21:29:31 - Train Iteration 13773: loss: 0.0020, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9557, 0.9998]
2025-03-11 21:29:32 - Train Iteration 13774: loss: 0.0110, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.8952, 0.9997]
2025-03-11 21:29:32 - Train Iteration 13775: loss: 0.0013, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9642, 0.9997]
2025-03-11 21:29:33 - Train Iteration 13776: loss: 0.0004, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.9862, 0.9997]
2025-03-11 21:29:33 - Train Iteration 13777: loss: 0.1758, d_k_M range: [0.0000, 0.4192], d_k_M_hat range: [0.6050, 0.9999]
2025-03-11 21:29:33 - Train Iteration 13778: loss: 0.0010, d_k_M range: [0.0000, 0.0207], d_k_M_hat range: [0.9686, 0.9998]
2025-03-11 21:29:34 - Train Iteration 13779: loss: 0.0029, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.9459, 0.9999]
2025-03-11 21:29:34 - Train Iteration 13780: loss: 0.0081, d_k_M range: [0.0000, 0.0892], d_k_M_hat range: [0.9690, 0.9995]
2025-03-11 21:29:35 - Train Iteration 13781: loss: 0.0070, d_k_M range: [0.0000, 0.0827], d_k_M_hat range: [0.9950, 1.0000]
2025-03-11 21:29:35 - Train Iteration 13782: loss: 0.3721, d_k_M range: [0.0001, 0.6100], d_k_M_hat range: [0.9833, 1.0000]
2025-03-11 21:29:36 - Train Iteration 13783: loss: 0.3388, d_k_M range: [0.0000, 0.0690], d_k_M_hat range: [0.4179, 0.9998]
2025-03-11 21:29:36 - Train Iteration 13784: loss: 0.0060, d_k_M range: [0.0000, 0.0765], d_k_M_hat range: [0.9826, 1.0000]
2025-03-11 21:29:37 - Train Iteration 13785: loss: 0.0005, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9769, 0.9997]
2025-03-11 21:29:37 - Train Iteration 13786: loss: 0.0085, d_k_M range: [0.0001, 0.0906], d_k_M_hat range: [0.9981, 1.0000]
2025-03-11 21:29:37 - Train Iteration 13787: loss: 0.0001, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.9985, 1.0000]
2025-03-11 21:29:38 - Train Iteration 13788: loss: 0.0035, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9431, 0.9993]
2025-03-11 21:29:38 - Train Iteration 13789: loss: 0.0002, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9853, 0.9985]
2025-03-11 21:29:39 - Train Iteration 13790: loss: 0.0008, d_k_M range: [0.0000, 0.0280], d_k_M_hat range: [0.9879, 0.9998]
2025-03-11 21:29:39 - Train Iteration 13791: loss: 0.0025, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9498, 1.0000]
2025-03-11 21:29:40 - Train Iteration 13792: loss: 0.0667, d_k_M range: [0.0001, 0.2573], d_k_M_hat range: [0.9754, 1.0000]
2025-03-11 21:29:40 - Train Iteration 13793: loss: 0.1649, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.5939, 0.9997]
2025-03-11 21:29:41 - Train Iteration 13794: loss: 0.1377, d_k_M range: [0.0000, 0.3706], d_k_M_hat range: [0.9851, 0.9999]
2025-03-11 21:29:41 - Train Iteration 13795: loss: 0.5766, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.2408, 0.9997]
2025-03-11 21:29:42 - Train Iteration 13796: loss: 0.0025, d_k_M range: [0.0001, 0.0501], d_k_M_hat range: [0.9792, 1.0000]
2025-03-11 21:29:42 - Train Iteration 13797: loss: 0.3737, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.3887, 0.9986]
2025-03-11 21:29:43 - Train Iteration 13798: loss: 0.0001, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9921, 0.9999]
2025-03-11 21:29:43 - Train Iteration 13799: loss: 0.1237, d_k_M range: [0.0000, 0.0975], d_k_M_hat range: [0.7458, 1.0000]
2025-03-11 21:29:43 - Train Iteration 13800: loss: 0.0924, d_k_M range: [0.0000, 0.3038], d_k_M_hat range: [0.9863, 0.9999]
2025-03-11 21:29:44 - Train Iteration 13801: loss: 0.0002, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9866, 0.9997]
2025-03-11 21:29:44 - Train Iteration 13802: loss: 0.0056, d_k_M range: [0.0000, 0.0750], d_k_M_hat range: [0.9941, 1.0000]
2025-03-11 21:29:45 - Train Iteration 13803: loss: 0.0122, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.8894, 0.9997]
2025-03-11 21:29:45 - Train Iteration 13804: loss: 0.0138, d_k_M range: [0.0000, 0.0091], d_k_M_hat range: [0.8824, 0.9985]
2025-03-11 21:29:45 - Train Iteration 13805: loss: 0.0060, d_k_M range: [0.0000, 0.0724], d_k_M_hat range: [0.9537, 0.9993]
2025-03-11 21:29:46 - Train Iteration 13806: loss: 0.0027, d_k_M range: [0.0000, 0.0518], d_k_M_hat range: [0.9931, 1.0000]
2025-03-11 21:29:46 - Train Iteration 13807: loss: 0.0013, d_k_M range: [0.0001, 0.0139], d_k_M_hat range: [0.9673, 1.0000]
2025-03-11 21:29:47 - Train Iteration 13808: loss: 0.0006, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.9769, 1.0000]
2025-03-11 21:29:47 - Train Iteration 13809: loss: 0.0000, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9934, 0.9997]
2025-03-11 21:29:48 - Train Iteration 13810: loss: 0.0010, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9695, 0.9998]
2025-03-11 21:29:48 - Train Iteration 13811: loss: 0.0063, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9214, 0.9988]
2025-03-11 21:29:48 - Train Iteration 13812: loss: 0.1814, d_k_M range: [0.0000, 0.4256], d_k_M_hat range: [0.6435, 0.9999]
2025-03-11 21:29:49 - Train Iteration 13813: loss: 0.0014, d_k_M range: [0.0000, 0.0361], d_k_M_hat range: [0.9875, 0.9992]
2025-03-11 21:29:49 - Train Iteration 13814: loss: 0.0094, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.9029, 0.9987]
2025-03-11 21:29:50 - Train Iteration 13815: loss: 0.0008, d_k_M range: [0.0000, 0.0062], d_k_M_hat range: [0.9714, 0.9997]
2025-03-11 21:29:50 - Train Iteration 13816: loss: 0.3426, d_k_M range: [0.0000, 0.0327], d_k_M_hat range: [0.4147, 0.9994]
2025-03-11 21:29:51 - Train Iteration 13817: loss: 0.0063, d_k_M range: [0.0000, 0.0494], d_k_M_hat range: [0.9699, 0.9995]
2025-03-11 21:29:51 - Train Iteration 13818: loss: 0.6731, d_k_M range: [0.0000, 0.0117], d_k_M_hat range: [0.1796, 1.0000]
2025-03-11 21:29:52 - Train Iteration 13819: loss: 0.0019, d_k_M range: [0.0000, 0.0436], d_k_M_hat range: [0.9923, 0.9999]
2025-03-11 21:29:52 - Train Iteration 13820: loss: 0.0258, d_k_M range: [0.0000, 0.0461], d_k_M_hat range: [0.8401, 0.9997]
2025-03-11 21:29:53 - Train Iteration 13821: loss: 0.0017, d_k_M range: [0.0000, 0.0379], d_k_M_hat range: [0.9824, 0.9998]
2025-03-11 21:29:53 - Train Iteration 13822: loss: 0.0166, d_k_M range: [0.0000, 0.1279], d_k_M_hat range: [0.9711, 0.9995]
2025-03-11 21:29:54 - Train Iteration 13823: loss: 0.0010, d_k_M range: [0.0000, 0.0271], d_k_M_hat range: [0.9687, 0.9999]
2025-03-11 21:29:54 - Train Iteration 13824: loss: 0.0798, d_k_M range: [0.0000, 0.2816], d_k_M_hat range: [0.9310, 0.9991]
2025-03-11 21:29:55 - Train Iteration 13825: loss: 0.0031, d_k_M range: [0.0000, 0.0511], d_k_M_hat range: [0.9951, 0.9997]
2025-03-11 21:29:55 - Train Iteration 13826: loss: 0.0950, d_k_M range: [0.0000, 0.3050], d_k_M_hat range: [0.9691, 0.9999]
2025-03-11 21:29:55 - Train Iteration 13827: loss: 0.0290, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.8298, 0.9990]
2025-03-11 21:29:56 - Train Iteration 13828: loss: 0.5719, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.2438, 0.9997]
2025-03-11 21:29:56 - Train Iteration 13829: loss: 0.0584, d_k_M range: [0.0000, 0.2417], d_k_M_hat range: [0.9956, 1.0000]
2025-03-11 21:29:57 - Train Iteration 13830: loss: 0.0078, d_k_M range: [0.0000, 0.0855], d_k_M_hat range: [0.9693, 0.9978]
2025-03-11 21:29:57 - Train Iteration 13831: loss: 0.0100, d_k_M range: [0.0000, 0.0085], d_k_M_hat range: [0.9003, 1.0000]
2025-03-11 21:29:58 - Train Iteration 13832: loss: 0.0513, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.7740, 0.9993]
2025-03-11 21:29:58 - Train Iteration 13833: loss: 0.0030, d_k_M range: [0.0000, 0.0543], d_k_M_hat range: [0.9507, 0.9999]
2025-03-11 21:29:59 - Train Iteration 13834: loss: 0.0671, d_k_M range: [0.0000, 0.2589], d_k_M_hat range: [0.9926, 0.9999]
2025-03-11 21:29:59 - Train Iteration 13835: loss: 0.0002, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9854, 0.9999]
2025-03-11 21:30:00 - Train Iteration 13836: loss: 0.0005, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.9773, 0.9999]
2025-03-11 21:30:00 - Train Iteration 13837: loss: 0.0027, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9492, 0.9984]
2025-03-11 21:30:00 - Train Iteration 13838: loss: 0.0289, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.8301, 0.9994]
2025-03-11 21:30:01 - Train Iteration 13839: loss: 0.0636, d_k_M range: [0.0000, 0.2508], d_k_M_hat range: [0.9761, 1.0000]
2025-03-11 21:30:01 - Train Iteration 13840: loss: 0.0003, d_k_M range: [0.0000, 0.0184], d_k_M_hat range: [0.9897, 0.9999]
2025-03-11 21:30:02 - Train Iteration 13841: loss: 0.0226, d_k_M range: [0.0000, 0.0055], d_k_M_hat range: [0.8498, 0.9994]
2025-03-11 21:30:02 - Train Iteration 13842: loss: 0.0019, d_k_M range: [0.0000, 0.0430], d_k_M_hat range: [0.9826, 0.9993]
2025-03-11 21:30:03 - Train Iteration 13843: loss: 0.0993, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.6849, 0.9985]
2025-03-11 21:30:03 - Train Iteration 13844: loss: 0.0785, d_k_M range: [0.0000, 0.2794], d_k_M_hat range: [0.9979, 0.9999]
2025-03-11 21:30:04 - Train Iteration 13845: loss: 0.0009, d_k_M range: [0.0000, 0.0298], d_k_M_hat range: [0.9845, 0.9998]
2025-03-11 21:30:04 - Train Iteration 13846: loss: 0.0023, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.9526, 0.9999]
2025-03-11 21:30:04 - Train Iteration 13847: loss: 0.0007, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9731, 0.9997]
2025-03-11 21:30:05 - Train Iteration 13848: loss: 0.0195, d_k_M range: [0.0000, 0.0125], d_k_M_hat range: [0.8729, 0.9994]
2025-03-11 21:30:05 - Train Iteration 13849: loss: 0.0027, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.9483, 0.9999]
2025-03-11 21:30:06 - Train Iteration 13850: loss: 0.2252, d_k_M range: [0.0006, 0.4745], d_k_M_hat range: [0.9381, 0.9999]
2025-03-11 21:30:06 - Train Iteration 13851: loss: 0.6931, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.1675, 0.9983]
2025-03-11 21:30:07 - Train Iteration 13852: loss: 0.0037, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9390, 0.9998]
2025-03-11 21:30:07 - Train Iteration 13853: loss: 0.0003, d_k_M range: [0.0000, 0.0131], d_k_M_hat range: [0.9965, 0.9996]
2025-03-11 21:30:07 - Train Iteration 13854: loss: 0.7133, d_k_M range: [0.0000, 0.1849], d_k_M_hat range: [0.1627, 1.0000]
2025-03-11 21:30:08 - Train Iteration 13855: loss: 0.0322, d_k_M range: [0.0000, 0.1778], d_k_M_hat range: [0.9870, 0.9999]
2025-03-11 21:30:08 - Train Iteration 13856: loss: 0.0007, d_k_M range: [0.0000, 0.0087], d_k_M_hat range: [0.9742, 0.9996]
2025-03-11 21:30:09 - Train Iteration 13857: loss: 0.1477, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.6157, 0.9904]
2025-03-11 21:30:09 - Train Iteration 13858: loss: 0.0119, d_k_M range: [0.0001, 0.1092], d_k_M_hat range: [0.9759, 0.9999]
2025-03-11 21:30:10 - Train Iteration 13859: loss: 0.0010, d_k_M range: [0.0000, 0.0296], d_k_M_hat range: [0.9856, 1.0000]
2025-03-11 21:30:10 - Train Iteration 13860: loss: 0.0001, d_k_M range: [0.0000, 0.0092], d_k_M_hat range: [0.9967, 0.9998]
2025-03-11 21:30:10 - Train Iteration 13861: loss: 0.5102, d_k_M range: [0.0001, 0.7123], d_k_M_hat range: [0.9955, 0.9998]
2025-03-11 21:30:11 - Train Iteration 13862: loss: 0.0002, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.9842, 0.9991]
2025-03-11 21:30:11 - Train Iteration 13863: loss: 0.0014, d_k_M range: [0.0000, 0.0281], d_k_M_hat range: [0.9641, 0.9997]
2025-03-11 21:30:12 - Train Iteration 13864: loss: 0.0581, d_k_M range: [0.0000, 0.0056], d_k_M_hat range: [0.7590, 0.9992]
2025-03-11 21:30:12 - Train Iteration 13865: loss: 0.0305, d_k_M range: [0.0000, 0.1738], d_k_M_hat range: [0.9791, 0.9999]
2025-03-11 21:30:13 - Train Iteration 13866: loss: 0.1464, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.6174, 0.9998]
2025-03-11 21:30:13 - Train Iteration 13867: loss: 0.0009, d_k_M range: [0.0000, 0.0299], d_k_M_hat range: [0.9925, 0.9999]
2025-03-11 21:30:14 - Train Iteration 13868: loss: 0.0010, d_k_M range: [0.0000, 0.0135], d_k_M_hat range: [0.9820, 0.9999]
2025-03-11 21:30:14 - Train Iteration 13869: loss: 0.0019, d_k_M range: [0.0000, 0.0101], d_k_M_hat range: [0.9563, 1.0000]
2025-03-11 21:30:15 - Train Iteration 13870: loss: 0.0029, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.9460, 0.9994]
2025-03-11 21:30:15 - Train Iteration 13871: loss: 0.0083, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.9091, 0.9964]
2025-03-11 21:30:16 - Train Iteration 13872: loss: 0.0001, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9920, 0.9997]
2025-03-11 21:30:16 - Train Iteration 13873: loss: 0.0511, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.7739, 0.9996]
2025-03-11 21:30:17 - Train Iteration 13874: loss: 0.0030, d_k_M range: [0.0000, 0.0300], d_k_M_hat range: [0.9752, 0.9997]
2025-03-11 21:30:17 - Train Iteration 13875: loss: 0.1641, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.5949, 0.9999]
2025-03-11 21:30:17 - Train Iteration 13876: loss: 0.0009, d_k_M range: [0.0000, 0.0292], d_k_M_hat range: [0.9965, 1.0000]
2025-03-11 21:30:18 - Train Iteration 13877: loss: 0.0002, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.9864, 0.9994]
2025-03-11 21:30:18 - Train Iteration 13878: loss: 0.6956, d_k_M range: [0.0000, 0.8340], d_k_M_hat range: [0.9996, 0.9999]
2025-03-11 21:30:19 - Train Iteration 13879: loss: 0.0012, d_k_M range: [0.0001, 0.0052], d_k_M_hat range: [0.9705, 0.9999]
2025-03-11 21:30:19 - Train Iteration 13880: loss: 0.0019, d_k_M range: [0.0000, 0.0428], d_k_M_hat range: [0.9843, 0.9995]
2025-03-11 21:30:20 - Train Iteration 13881: loss: 0.0049, d_k_M range: [0.0000, 0.0255], d_k_M_hat range: [0.9300, 0.9999]
2025-03-11 21:30:20 - Train Iteration 13882: loss: 0.0131, d_k_M range: [0.0000, 0.1139], d_k_M_hat range: [0.9887, 0.9998]
2025-03-11 21:30:21 - Train Iteration 13883: loss: 0.0000, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9944, 0.9999]
2025-03-11 21:30:21 - Train Iteration 13884: loss: 0.0034, d_k_M range: [0.0000, 0.0057], d_k_M_hat range: [0.9416, 0.9999]
2025-03-11 21:30:22 - Train Iteration 13885: loss: 0.0098, d_k_M range: [0.0000, 0.0991], d_k_M_hat range: [0.9840, 1.0000]
2025-03-11 21:30:22 - Train Iteration 13886: loss: 0.0006, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.9796, 0.9992]
2025-03-11 21:30:22 - Train Iteration 13887: loss: 0.0088, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.9060, 0.9993]
2025-03-11 21:30:23 - Train Iteration 13888: loss: 0.0003, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9874, 0.9998]
2025-03-11 21:30:23 - Train Iteration 13889: loss: 0.4864, d_k_M range: [0.0000, 0.6972], d_k_M_hat range: [0.9887, 0.9998]
2025-03-11 21:30:24 - Train Iteration 13890: loss: 0.0086, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9075, 0.9997]
2025-03-11 21:30:24 - Train Iteration 13891: loss: 0.0001, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9904, 0.9999]
2025-03-11 21:30:25 - Train Iteration 13892: loss: 0.0005, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9771, 0.9999]
2025-03-11 21:30:25 - Train Iteration 13893: loss: 0.0008, d_k_M range: [0.0000, 0.0128], d_k_M_hat range: [0.9725, 0.9995]
2025-03-11 21:30:25 - Train Iteration 13894: loss: 0.0002, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.9932, 1.0000]
2025-03-11 21:30:26 - Train Iteration 13895: loss: 0.0175, d_k_M range: [0.0000, 0.1296], d_k_M_hat range: [0.9944, 0.9998]
2025-03-11 21:30:26 - Train Iteration 13896: loss: 0.0325, d_k_M range: [0.0000, 0.1754], d_k_M_hat range: [0.9861, 0.9997]
2025-03-11 21:30:27 - Train Iteration 13897: loss: 0.0002, d_k_M range: [0.0001, 0.0098], d_k_M_hat range: [0.9864, 0.9998]
2025-03-11 21:30:27 - Train Iteration 13898: loss: 0.1455, d_k_M range: [0.0000, 0.0070], d_k_M_hat range: [0.6188, 0.9996]
2025-03-11 21:30:28 - Train Iteration 13899: loss: 0.0012, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.9654, 0.9998]
2025-03-11 21:30:28 - Train Iteration 13900: loss: 0.0717, d_k_M range: [0.0000, 0.2641], d_k_M_hat range: [0.9922, 0.9996]
2025-03-11 21:30:28 - Train Iteration 13901: loss: 0.0144, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.8802, 0.9997]
2025-03-11 21:30:29 - Train Iteration 13902: loss: 0.1815, d_k_M range: [0.0000, 0.0047], d_k_M_hat range: [0.5739, 0.9977]
2025-03-11 21:30:29 - Train Iteration 13903: loss: 0.5166, d_k_M range: [0.0000, 0.7187], d_k_M_hat range: [0.9567, 0.9999]
2025-03-11 21:30:30 - Train Iteration 13904: loss: 0.0001, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9904, 0.9996]
2025-03-11 21:30:30 - Train Iteration 13905: loss: 0.0969, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.6887, 0.9953]
2025-03-11 21:30:31 - Train Iteration 13906: loss: 0.5413, d_k_M range: [0.0000, 0.0452], d_k_M_hat range: [0.2642, 0.9999]
2025-03-11 21:30:31 - Train Iteration 13907: loss: 0.0004, d_k_M range: [0.0002, 0.0196], d_k_M_hat range: [0.9972, 0.9999]
2025-03-11 21:30:31 - Train Iteration 13908: loss: 0.0038, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.9425, 0.9985]
2025-03-11 21:30:32 - Train Iteration 13909: loss: 0.1586, d_k_M range: [0.0000, 0.3963], d_k_M_hat range: [0.9960, 0.9995]
2025-03-11 21:30:32 - Train Iteration 13910: loss: 0.0009, d_k_M range: [0.0000, 0.0241], d_k_M_hat range: [0.9852, 0.9981]
2025-03-11 21:30:33 - Train Iteration 13911: loss: 0.0003, d_k_M range: [0.0000, 0.0113], d_k_M_hat range: [0.9932, 0.9998]
2025-03-11 21:30:33 - Train Iteration 13912: loss: 0.0062, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.9212, 0.9981]
2025-03-11 21:30:34 - Train Iteration 13913: loss: 0.0002, d_k_M range: [0.0000, 0.0126], d_k_M_hat range: [0.9899, 0.9999]
2025-03-11 21:30:34 - Train Iteration 13914: loss: 0.0001, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.9932, 1.0000]
2025-03-11 21:30:35 - Train Iteration 13915: loss: 0.0007, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9742, 1.0000]
2025-03-11 21:30:35 - Train Iteration 13916: loss: 0.0105, d_k_M range: [0.0000, 0.0179], d_k_M_hat range: [0.8982, 0.9991]
2025-03-11 21:30:36 - Train Iteration 13917: loss: 0.0006, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9760, 0.9994]
2025-03-11 21:30:36 - Train Iteration 13918: loss: 0.0016, d_k_M range: [0.0000, 0.0393], d_k_M_hat range: [0.9755, 0.9999]
2025-03-11 21:30:37 - Train Iteration 13919: loss: 0.0008, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.9709, 0.9999]
2025-03-11 21:30:37 - Train Iteration 13920: loss: 0.0012, d_k_M range: [0.0000, 0.0342], d_k_M_hat range: [0.9947, 0.9997]
2025-03-11 21:30:38 - Train Iteration 13921: loss: 0.0920, d_k_M range: [0.0000, 0.3030], d_k_M_hat range: [0.9942, 0.9998]
2025-03-11 21:30:38 - Train Iteration 13922: loss: 0.0304, d_k_M range: [0.0000, 0.1741], d_k_M_hat range: [0.9432, 0.9998]
2025-03-11 21:30:38 - Train Iteration 13923: loss: 0.0042, d_k_M range: [0.0000, 0.0224], d_k_M_hat range: [0.9354, 0.9989]
2025-03-11 21:30:39 - Train Iteration 13924: loss: 0.0038, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.9384, 0.9999]
2025-03-11 21:30:39 - Train Iteration 13925: loss: 0.0005, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.9786, 0.9998]
2025-03-11 21:30:40 - Train Iteration 13926: loss: 0.0007, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9736, 0.9976]
2025-03-11 21:30:40 - Train Iteration 13927: loss: 0.1004, d_k_M range: [0.0001, 0.3164], d_k_M_hat range: [0.9899, 0.9996]
2025-03-11 21:30:41 - Train Iteration 13928: loss: 0.0040, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9368, 0.9998]
2025-03-11 21:30:41 - Train Iteration 13929: loss: 0.0147, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.8786, 0.9986]
2025-03-11 21:30:42 - Train Iteration 13930: loss: 0.0045, d_k_M range: [0.0000, 0.0640], d_k_M_hat range: [0.9621, 0.9999]
2025-03-11 21:30:42 - Train Iteration 13931: loss: 0.0014, d_k_M range: [0.0001, 0.0360], d_k_M_hat range: [0.9956, 0.9999]
2025-03-11 21:30:43 - Train Iteration 13932: loss: 0.3074, d_k_M range: [0.0000, 0.5544], d_k_M_hat range: [0.9807, 0.9999]
2025-03-11 21:30:43 - Train Iteration 13933: loss: 0.0002, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9851, 0.9996]
2025-03-11 21:30:44 - Train Iteration 13934: loss: 0.0001, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9938, 0.9998]
2025-03-11 21:30:44 - Train Iteration 13935: loss: 0.0002, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9884, 1.0000]
2025-03-11 21:30:44 - Train Iteration 13936: loss: 0.0080, d_k_M range: [0.0000, 0.0067], d_k_M_hat range: [0.9105, 0.9989]
2025-03-11 21:30:45 - Train Iteration 13937: loss: 0.0347, d_k_M range: [0.0000, 0.0183], d_k_M_hat range: [0.8137, 0.9994]
2025-03-11 21:30:45 - Train Iteration 13938: loss: 0.0010, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.9690, 0.9999]
2025-03-11 21:30:46 - Train Iteration 13939: loss: 0.0778, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.7266, 0.9959]
2025-03-11 21:30:46 - Train Iteration 13940: loss: 0.0795, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.7181, 0.9998]
2025-03-11 21:30:47 - Train Iteration 13941: loss: 0.0688, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.7378, 0.9993]
2025-03-11 21:30:47 - Train Iteration 13942: loss: 0.0003, d_k_M range: [0.0000, 0.0162], d_k_M_hat range: [0.9967, 0.9999]
2025-03-11 21:30:47 - Train Iteration 13943: loss: 0.0569, d_k_M range: [0.0000, 0.2373], d_k_M_hat range: [0.9947, 0.9999]
2025-03-11 21:30:48 - Train Iteration 13944: loss: 0.0001, d_k_M range: [0.0001, 0.0094], d_k_M_hat range: [0.9893, 0.9999]
2025-03-11 21:30:48 - Train Iteration 13945: loss: 0.0001, d_k_M range: [0.0000, 0.0090], d_k_M_hat range: [0.9950, 1.0000]
2025-03-11 21:30:49 - Train Iteration 13946: loss: 0.0005, d_k_M range: [0.0000, 0.0127], d_k_M_hat range: [0.9778, 0.9994]
2025-03-11 21:30:49 - Train Iteration 13947: loss: 0.0019, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9564, 0.9988]
2025-03-11 21:30:50 - Train Iteration 13948: loss: 0.0001, d_k_M range: [0.0000, 0.0072], d_k_M_hat range: [0.9957, 0.9997]
2025-03-11 21:30:50 - Train Iteration 13949: loss: 0.0001, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9911, 0.9997]
2025-03-11 21:30:50 - Train Iteration 13950: loss: 0.0077, d_k_M range: [0.0000, 0.0877], d_k_M_hat range: [0.9945, 0.9999]
2025-03-11 21:30:51 - Train Iteration 13951: loss: 0.0087, d_k_M range: [0.0000, 0.0907], d_k_M_hat range: [0.9940, 0.9999]
2025-03-11 21:30:51 - Train Iteration 13952: loss: 0.0231, d_k_M range: [0.0000, 0.0186], d_k_M_hat range: [0.8481, 0.9998]
2025-03-11 21:30:52 - Train Iteration 13953: loss: 0.0005, d_k_M range: [0.0000, 0.0221], d_k_M_hat range: [0.9923, 0.9999]
2025-03-11 21:30:52 - Train Iteration 13954: loss: 0.0008, d_k_M range: [0.0000, 0.0271], d_k_M_hat range: [0.9926, 0.9999]
2025-03-11 21:30:53 - Train Iteration 13955: loss: 0.0011, d_k_M range: [0.0001, 0.0047], d_k_M_hat range: [0.9669, 0.9998]
2025-03-11 21:30:53 - Train Iteration 13956: loss: 0.0003, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.9861, 0.9989]
2025-03-11 21:30:53 - Train Iteration 13957: loss: 0.0002, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9853, 0.9998]
2025-03-11 21:30:54 - Train Iteration 13958: loss: 0.0003, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9833, 0.9996]
2025-03-11 21:30:54 - Train Iteration 13959: loss: 0.0495, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.7776, 0.9998]
2025-03-11 21:30:55 - Train Iteration 13960: loss: 0.0004, d_k_M range: [0.0000, 0.0073], d_k_M_hat range: [0.9807, 0.9999]
2025-03-11 21:30:55 - Train Iteration 13961: loss: 0.1364, d_k_M range: [0.0000, 0.3682], d_k_M_hat range: [0.9588, 0.9999]
2025-03-11 21:30:56 - Train Iteration 13962: loss: 0.0009, d_k_M range: [0.0000, 0.0086], d_k_M_hat range: [0.9708, 0.9999]
2025-03-11 21:30:56 - Train Iteration 13963: loss: 0.0000, d_k_M range: [0.0002, 0.0053], d_k_M_hat range: [0.9956, 0.9994]
2025-03-11 21:30:57 - Train Iteration 13964: loss: 0.0001, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9927, 0.9997]
2025-03-11 21:30:57 - Train Iteration 13965: loss: 0.0199, d_k_M range: [0.0000, 0.0236], d_k_M_hat range: [0.8591, 0.9992]
2025-03-11 21:30:58 - Train Iteration 13966: loss: 0.0027, d_k_M range: [0.0000, 0.0480], d_k_M_hat range: [0.9477, 0.9997]
2025-03-11 21:30:58 - Train Iteration 13967: loss: 0.0020, d_k_M range: [0.0000, 0.0445], d_k_M_hat range: [0.9957, 0.9999]
2025-03-11 21:30:59 - Train Iteration 13968: loss: 0.0010, d_k_M range: [0.0000, 0.0224], d_k_M_hat range: [0.9776, 0.9999]
2025-03-11 21:30:59 - Train Iteration 13969: loss: 0.0341, d_k_M range: [0.0000, 0.1820], d_k_M_hat range: [0.9916, 0.9997]
2025-03-11 21:30:59 - Train Iteration 13970: loss: 0.0035, d_k_M range: [0.0000, 0.0590], d_k_M_hat range: [0.9851, 0.9998]
2025-03-11 21:31:00 - Train Iteration 13971: loss: 0.0037, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9388, 0.9998]
2025-03-11 21:31:00 - Train Iteration 13972: loss: 0.0002, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9854, 0.9999]
2025-03-11 21:31:01 - Train Iteration 13973: loss: 0.7329, d_k_M range: [0.0000, 0.8560], d_k_M_hat range: [0.9456, 0.9999]
2025-03-11 21:31:01 - Train Iteration 13974: loss: 0.0121, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.8898, 0.9984]
2025-03-11 21:31:02 - Train Iteration 13975: loss: 0.7419, d_k_M range: [0.0004, 0.8611], d_k_M_hat range: [0.9997, 1.0000]
2025-03-11 21:31:02 - Train Iteration 13976: loss: 0.0003, d_k_M range: [0.0000, 0.0175], d_k_M_hat range: [0.9913, 0.9999]
2025-03-11 21:31:03 - Train Iteration 13977: loss: 0.2185, d_k_M range: [0.0000, 0.4674], d_k_M_hat range: [0.9951, 1.0000]
2025-03-11 21:31:03 - Train Iteration 13978: loss: 0.7071, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.1592, 0.9990]
2025-03-11 21:31:04 - Train Iteration 13979: loss: 0.0113, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.8938, 0.9992]
2025-03-11 21:31:04 - Train Iteration 13980: loss: 0.0394, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.8015, 0.9999]
2025-03-11 21:31:04 - Train Iteration 13981: loss: 0.0001, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.9924, 0.9999]
2025-03-11 21:31:05 - Train Iteration 13982: loss: 0.0020, d_k_M range: [0.0000, 0.0095], d_k_M_hat range: [0.9569, 0.9999]
2025-03-11 21:31:05 - Train Iteration 13983: loss: 0.6343, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.2036, 0.9998]
2025-03-11 21:31:06 - Train Iteration 13984: loss: 0.0141, d_k_M range: [0.0004, 0.1160], d_k_M_hat range: [0.9849, 1.0000]
2025-03-11 21:31:06 - Train Iteration 13985: loss: 0.0044, d_k_M range: [0.0000, 0.0664], d_k_M_hat range: [0.9947, 1.0000]
2025-03-11 21:31:07 - Train Iteration 13986: loss: 0.3892, d_k_M range: [0.0000, 0.6235], d_k_M_hat range: [0.9965, 0.9996]
2025-03-11 21:31:07 - Train Iteration 13987: loss: 0.0061, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9219, 0.9999]
2025-03-11 21:31:07 - Train Iteration 13988: loss: 0.0008, d_k_M range: [0.0001, 0.0037], d_k_M_hat range: [0.9712, 0.9999]
2025-03-11 21:31:08 - Train Iteration 13989: loss: 0.0037, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9391, 0.9965]
2025-03-11 21:31:08 - Train Iteration 13990: loss: 0.5498, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.2586, 0.9998]
2025-03-11 21:31:09 - Train Iteration 13991: loss: 0.8094, d_k_M range: [0.0000, 0.8996], d_k_M_hat range: [0.9933, 0.9999]
2025-03-11 21:31:09 - Train Iteration 13992: loss: 0.0000, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9950, 0.9998]
2025-03-11 21:31:10 - Train Iteration 13993: loss: 0.9021, d_k_M range: [0.0000, 0.0294], d_k_M_hat range: [0.0502, 0.9998]
2025-03-11 21:31:10 - Train Iteration 13994: loss: 0.0288, d_k_M range: [0.0000, 0.1696], d_k_M_hat range: [0.9795, 1.0000]
2025-03-11 21:31:11 - Train Iteration 13995: loss: 0.0062, d_k_M range: [0.0001, 0.0777], d_k_M_hat range: [0.9821, 0.9996]
2025-03-11 21:31:11 - Train Iteration 13996: loss: 0.1298, d_k_M range: [0.0000, 0.3600], d_k_M_hat range: [0.9959, 0.9999]
2025-03-11 21:31:11 - Train Iteration 13997: loss: 0.0013, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9653, 0.9992]
2025-03-11 21:31:12 - Train Iteration 13998: loss: 0.0035, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9415, 0.9993]
2025-03-11 21:31:12 - Train Iteration 13999: loss: 0.0027, d_k_M range: [0.0000, 0.0154], d_k_M_hat range: [0.9478, 0.9994]
2025-03-11 21:31:13 - Train Iteration 14000: loss: 0.0021, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9557, 0.9996]
2025-03-11 21:31:13 - Train Iteration 14001: loss: 0.6965, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.1654, 0.9990]
2025-03-11 21:31:14 - Train Iteration 14002: loss: 0.0004, d_k_M range: [0.0000, 0.0175], d_k_M_hat range: [0.9807, 0.9999]
2025-03-11 21:31:14 - Train Iteration 14003: loss: 0.0003, d_k_M range: [0.0000, 0.0141], d_k_M_hat range: [0.9944, 0.9997]
2025-03-11 21:31:15 - Train Iteration 14004: loss: 0.0085, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9076, 0.9997]
2025-03-11 21:31:15 - Train Iteration 14005: loss: 0.0505, d_k_M range: [0.0000, 0.0320], d_k_M_hat range: [0.7829, 0.9999]
2025-03-11 21:31:16 - Train Iteration 14006: loss: 0.0004, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.9807, 0.9997]
2025-03-11 21:31:16 - Train Iteration 14007: loss: 0.0028, d_k_M range: [0.0000, 0.0513], d_k_M_hat range: [0.9696, 1.0000]
2025-03-11 21:31:16 - Train Iteration 14008: loss: 0.0037, d_k_M range: [0.0000, 0.0180], d_k_M_hat range: [0.9394, 0.9998]
2025-03-11 21:31:17 - Train Iteration 14009: loss: 0.0002, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9843, 0.9988]
2025-03-11 21:31:17 - Train Iteration 14010: loss: 0.1162, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.6591, 0.9963]
2025-03-11 21:31:18 - Train Iteration 14011: loss: 0.0002, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.9878, 0.9999]
2025-03-11 21:31:18 - Train Iteration 14012: loss: 0.0172, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.8696, 0.9996]
2025-03-11 21:31:19 - Train Iteration 14013: loss: 0.0000, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9958, 1.0000]
2025-03-11 21:31:19 - Train Iteration 14014: loss: 0.9456, d_k_M range: [0.0000, 0.9724], d_k_M_hat range: [0.9998, 1.0000]
2025-03-11 21:31:20 - Train Iteration 14015: loss: 0.4067, d_k_M range: [0.0000, 0.6174], d_k_M_hat range: [0.9797, 0.9998]
2025-03-11 21:31:20 - Train Iteration 14016: loss: 0.0155, d_k_M range: [0.0000, 0.0065], d_k_M_hat range: [0.8755, 0.9999]
2025-03-11 21:31:21 - Train Iteration 14017: loss: 0.0019, d_k_M range: [0.0000, 0.0423], d_k_M_hat range: [0.9665, 0.9997]
2025-03-11 21:31:21 - Train Iteration 14018: loss: 0.0001, d_k_M range: [0.0000, 0.0078], d_k_M_hat range: [0.9909, 0.9996]
2025-03-11 21:31:22 - Train Iteration 14019: loss: 0.0008, d_k_M range: [0.0001, 0.0263], d_k_M_hat range: [0.9844, 1.0000]
2025-03-11 21:31:22 - Train Iteration 14020: loss: 0.0126, d_k_M range: [0.0000, 0.1114], d_k_M_hat range: [0.9949, 0.9997]
2025-03-11 21:31:22 - Train Iteration 14021: loss: 0.0000, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9932, 0.9997]
2025-03-11 21:31:23 - Train Iteration 14022: loss: 0.0036, d_k_M range: [0.0000, 0.0250], d_k_M_hat range: [0.9401, 0.9996]
2025-03-11 21:31:23 - Train Iteration 14023: loss: 0.0001, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9915, 0.9997]
2025-03-11 21:31:24 - Train Iteration 14024: loss: 0.0000, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9940, 0.9998]
2025-03-11 21:31:24 - Train Iteration 14025: loss: 0.0000, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.9974, 1.0000]
2025-03-11 21:31:25 - Train Iteration 14026: loss: 0.0390, d_k_M range: [0.0000, 0.1964], d_k_M_hat range: [0.9949, 1.0000]
2025-03-11 21:31:25 - Train Iteration 14027: loss: 0.0170, d_k_M range: [0.0000, 0.1302], d_k_M_hat range: [0.9915, 1.0000]
2025-03-11 21:31:26 - Train Iteration 14028: loss: 0.0009, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.9701, 0.9999]
2025-03-11 21:31:26 - Train Iteration 14029: loss: 0.0077, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.9122, 0.9983]
2025-03-11 21:31:26 - Train Iteration 14030: loss: 0.0039, d_k_M range: [0.0000, 0.0608], d_k_M_hat range: [0.9864, 0.9994]
2025-03-11 21:31:27 - Train Iteration 14031: loss: 0.0002, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9872, 0.9999]
2025-03-11 21:31:27 - Train Iteration 14032: loss: 0.0007, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9767, 0.9990]
2025-03-11 21:31:28 - Train Iteration 14033: loss: 0.6044, d_k_M range: [0.0000, 0.7751], d_k_M_hat range: [0.9845, 0.9999]
2025-03-11 21:31:28 - Train Iteration 14034: loss: 0.0223, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.8505, 0.9976]
2025-03-11 21:31:29 - Train Iteration 14035: loss: 0.0101, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.8993, 0.9991]
2025-03-11 21:31:29 - Train Iteration 14036: loss: 0.0073, d_k_M range: [0.0000, 0.0852], d_k_M_hat range: [0.9637, 0.9998]
2025-03-11 21:31:29 - Train Iteration 14037: loss: 0.0017, d_k_M range: [0.0000, 0.0171], d_k_M_hat range: [0.9762, 0.9999]
2025-03-11 21:31:30 - Train Iteration 14038: loss: 0.0271, d_k_M range: [0.0001, 0.1645], d_k_M_hat range: [0.9684, 0.9999]
2025-03-11 21:31:30 - Train Iteration 14039: loss: 0.0007, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9731, 0.9994]
2025-03-11 21:31:31 - Train Iteration 14040: loss: 0.0091, d_k_M range: [0.0000, 0.0085], d_k_M_hat range: [0.9049, 0.9999]
2025-03-11 21:31:31 - Train Iteration 14041: loss: 0.0023, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9517, 0.9996]
2025-03-11 21:31:32 - Train Iteration 14042: loss: 0.0002, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9851, 0.9994]
2025-03-11 21:31:32 - Train Iteration 14043: loss: 0.0061, d_k_M range: [0.0000, 0.0748], d_k_M_hat range: [0.9965, 0.9997]
2025-03-11 21:31:33 - Train Iteration 14044: loss: 0.0009, d_k_M range: [0.0000, 0.0290], d_k_M_hat range: [0.9873, 0.9995]
2025-03-11 21:31:33 - Train Iteration 14045: loss: 0.5272, d_k_M range: [0.0000, 0.7260], d_k_M_hat range: [0.7260, 1.0000]
2025-03-11 21:31:33 - Train Iteration 14046: loss: 0.0152, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.8769, 0.9991]
2025-03-11 21:31:34 - Train Iteration 14047: loss: 0.0013, d_k_M range: [0.0000, 0.0339], d_k_M_hat range: [0.9978, 1.0000]
2025-03-11 21:31:34 - Train Iteration 14048: loss: 0.1463, d_k_M range: [0.0000, 0.3745], d_k_M_hat range: [0.8958, 0.9999]
2025-03-11 21:31:35 - Train Iteration 14049: loss: 0.0154, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.8759, 0.9989]
2025-03-11 21:31:35 - Train Iteration 14050: loss: 0.0004, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9805, 0.9997]
2025-03-11 21:31:35 - Train Iteration 14051: loss: 0.0404, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.7998, 0.9996]
2025-03-11 21:31:36 - Train Iteration 14052: loss: 0.0012, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9655, 0.9995]
2025-03-11 21:31:36 - Train Iteration 14053: loss: 0.0346, d_k_M range: [0.0000, 0.0230], d_k_M_hat range: [0.8139, 0.9998]
2025-03-11 21:31:37 - Train Iteration 14054: loss: 0.0003, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9816, 0.9998]
2025-03-11 21:31:37 - Train Iteration 14055: loss: 0.0535, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.7693, 0.9997]
2025-03-11 21:31:38 - Train Iteration 14056: loss: 0.0001, d_k_M range: [0.0000, 0.0090], d_k_M_hat range: [0.9940, 0.9999]
2025-03-11 21:31:38 - Train Iteration 14057: loss: 0.0011, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9672, 1.0000]
2025-03-11 21:31:39 - Train Iteration 14058: loss: 0.0002, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9844, 0.9994]
2025-03-11 21:31:39 - Train Iteration 14059: loss: 0.0030, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9457, 0.9996]
2025-03-11 21:31:40 - Train Iteration 14060: loss: 0.0116, d_k_M range: [0.0000, 0.0121], d_k_M_hat range: [0.8925, 0.9991]
2025-03-11 21:31:40 - Train Iteration 14061: loss: 0.0008, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.9728, 0.9998]
2025-03-11 21:31:41 - Train Iteration 14062: loss: 0.0115, d_k_M range: [0.0002, 0.1069], d_k_M_hat range: [0.9868, 0.9999]
2025-03-11 21:31:41 - Train Iteration 14063: loss: 0.1978, d_k_M range: [0.0000, 0.4448], d_k_M_hat range: [0.9900, 1.0000]
2025-03-11 21:31:42 - Train Iteration 14064: loss: 0.0009, d_k_M range: [0.0000, 0.0196], d_k_M_hat range: [0.9693, 0.9991]
2025-03-11 21:31:42 - Train Iteration 14065: loss: 0.4616, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.3206, 0.9995]
2025-03-11 21:31:42 - Train Iteration 14066: loss: 0.0002, d_k_M range: [0.0000, 0.0109], d_k_M_hat range: [0.9911, 0.9997]
2025-03-11 21:31:43 - Train Iteration 14067: loss: 0.0017, d_k_M range: [0.0000, 0.0070], d_k_M_hat range: [0.9609, 0.9996]
2025-03-11 21:31:43 - Train Iteration 14068: loss: 0.0084, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9086, 1.0000]
2025-03-11 21:31:44 - Train Iteration 14069: loss: 0.0097, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9017, 0.9996]
2025-03-11 21:31:44 - Train Iteration 14070: loss: 0.0002, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.9875, 0.9994]
2025-03-11 21:31:45 - Train Iteration 14071: loss: 0.0001, d_k_M range: [0.0000, 0.0057], d_k_M_hat range: [0.9888, 0.9998]
2025-03-11 21:31:45 - Train Iteration 14072: loss: 0.0023, d_k_M range: [0.0000, 0.0430], d_k_M_hat range: [0.9954, 1.0000]
2025-03-11 21:31:46 - Train Iteration 14073: loss: 0.0002, d_k_M range: [0.0000, 0.0056], d_k_M_hat range: [0.9857, 0.9997]
2025-03-11 21:31:46 - Train Iteration 14074: loss: 0.0010, d_k_M range: [0.0000, 0.0309], d_k_M_hat range: [0.9924, 0.9998]
2025-03-11 21:31:46 - Train Iteration 14075: loss: 0.0017, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.9626, 0.9998]
2025-03-11 21:31:47 - Train Iteration 14076: loss: 0.0007, d_k_M range: [0.0000, 0.0131], d_k_M_hat range: [0.9798, 0.9994]
2025-03-11 21:31:47 - Train Iteration 14077: loss: 0.0522, d_k_M range: [0.0001, 0.2284], d_k_M_hat range: [0.9957, 1.0000]
2025-03-11 21:31:48 - Train Iteration 14078: loss: 0.0162, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.8731, 1.0000]
2025-03-11 21:31:48 - Train Iteration 14079: loss: 0.0083, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9088, 1.0000]
2025-03-11 21:31:49 - Train Iteration 14080: loss: 0.7325, d_k_M range: [0.0000, 0.8558], d_k_M_hat range: [0.9850, 0.9999]
2025-03-11 21:31:49 - Train Iteration 14081: loss: 0.0248, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.8426, 0.9999]
2025-03-11 21:31:49 - Train Iteration 14082: loss: 0.0003, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9819, 0.9999]
2025-03-11 21:31:50 - Train Iteration 14083: loss: 0.0012, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9654, 0.9989]
2025-03-11 21:31:50 - Train Iteration 14084: loss: 0.0008, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.9722, 0.9997]
2025-03-11 21:31:51 - Train Iteration 14085: loss: 0.3231, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.4316, 0.9992]
2025-03-11 21:31:51 - Train Iteration 14086: loss: 0.0005, d_k_M range: [0.0000, 0.0225], d_k_M_hat range: [0.9776, 1.0000]
2025-03-11 21:31:52 - Train Iteration 14087: loss: 0.0005, d_k_M range: [0.0001, 0.0030], d_k_M_hat range: [0.9782, 0.9992]
2025-03-11 21:31:52 - Train Iteration 14088: loss: 0.0976, d_k_M range: [0.0000, 0.3122], d_k_M_hat range: [0.9977, 0.9999]
2025-03-11 21:31:53 - Train Iteration 14089: loss: 0.0508, d_k_M range: [0.0000, 0.2229], d_k_M_hat range: [0.9708, 0.9993]
2025-03-11 21:31:53 - Train Iteration 14090: loss: 0.0090, d_k_M range: [0.0000, 0.0233], d_k_M_hat range: [0.9053, 0.9998]
2025-03-11 21:31:54 - Train Iteration 14091: loss: 0.6901, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.1700, 0.9976]
2025-03-11 21:31:54 - Train Iteration 14092: loss: 0.0005, d_k_M range: [0.0000, 0.0217], d_k_M_hat range: [0.9978, 0.9999]
2025-03-11 21:31:54 - Train Iteration 14093: loss: 0.0004, d_k_M range: [0.0001, 0.0190], d_k_M_hat range: [0.9828, 1.0000]
2025-03-11 21:31:55 - Train Iteration 14094: loss: 0.0163, d_k_M range: [0.0000, 0.1036], d_k_M_hat range: [0.8726, 0.9998]
2025-03-11 21:31:55 - Train Iteration 14095: loss: 0.0008, d_k_M range: [0.0000, 0.0278], d_k_M_hat range: [0.9918, 0.9999]
2025-03-11 21:31:56 - Train Iteration 14096: loss: 0.0000, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9934, 0.9999]
2025-03-11 21:31:56 - Train Iteration 14097: loss: 0.0000, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9956, 0.9998]
2025-03-11 21:31:57 - Train Iteration 14098: loss: 0.0001, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.9927, 0.9998]
2025-03-11 21:31:57 - Train Iteration 14099: loss: 0.0020, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9554, 1.0000]
2025-03-11 21:31:58 - Train Iteration 14100: loss: 0.0000, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.9980, 0.9999]
2025-03-11 21:31:58 - Train Iteration 14101: loss: 0.0033, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9429, 0.9991]
2025-03-11 21:31:59 - Train Iteration 14102: loss: 0.0759, d_k_M range: [0.0001, 0.2746], d_k_M_hat range: [0.9939, 0.9999]
2025-03-11 21:31:59 - Train Iteration 14103: loss: 0.0001, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9878, 0.9999]
2025-03-11 21:32:00 - Train Iteration 14104: loss: 0.0233, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.8479, 0.9992]
2025-03-11 21:32:00 - Train Iteration 14105: loss: 0.0022, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9528, 0.9996]
2025-03-11 21:32:00 - Train Iteration 14106: loss: 0.0001, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9929, 0.9999]
2025-03-11 21:32:01 - Train Iteration 14107: loss: 0.0307, d_k_M range: [0.0000, 0.1708], d_k_M_hat range: [0.9477, 0.9993]
2025-03-11 21:32:01 - Train Iteration 14108: loss: 0.0018, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.9584, 0.9981]
2025-03-11 21:32:02 - Train Iteration 14109: loss: 0.0094, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9032, 0.9983]
2025-03-11 21:32:02 - Train Iteration 14110: loss: 0.0002, d_k_M range: [0.0000, 0.0132], d_k_M_hat range: [0.9910, 1.0000]
2025-03-11 21:32:03 - Train Iteration 14111: loss: 0.0080, d_k_M range: [0.0000, 0.0892], d_k_M_hat range: [0.9829, 0.9999]
2025-03-11 21:32:03 - Train Iteration 14112: loss: 0.0314, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.8229, 0.9991]
2025-03-11 21:32:04 - Train Iteration 14113: loss: 0.3116, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.4447, 0.9992]
2025-03-11 21:32:04 - Train Iteration 14114: loss: 0.0209, d_k_M range: [0.0000, 0.0488], d_k_M_hat range: [0.8555, 0.9999]
2025-03-11 21:32:04 - Train Iteration 14115: loss: 0.0841, d_k_M range: [0.0000, 0.0135], d_k_M_hat range: [0.7101, 0.9995]
2025-03-11 21:32:05 - Train Iteration 14116: loss: 0.0015, d_k_M range: [0.0000, 0.0358], d_k_M_hat range: [0.9666, 0.9998]
2025-03-11 21:32:05 - Train Iteration 14117: loss: 0.0025, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9504, 0.9999]
2025-03-11 21:32:06 - Train Iteration 14118: loss: 0.0002, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9866, 1.0000]
2025-03-11 21:32:06 - Train Iteration 14119: loss: 0.0260, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.8388, 0.9999]
2025-03-11 21:32:07 - Train Iteration 14120: loss: 0.0301, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.8266, 0.9996]
2025-03-11 21:32:07 - Train Iteration 14121: loss: 0.0002, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.9872, 0.9997]
2025-03-11 21:32:07 - Train Iteration 14122: loss: 0.0013, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9647, 0.9997]
2025-03-11 21:32:08 - Train Iteration 14123: loss: 0.0041, d_k_M range: [0.0000, 0.0631], d_k_M_hat range: [0.9984, 0.9998]
2025-03-11 21:32:08 - Train Iteration 14124: loss: 0.0022, d_k_M range: [0.0000, 0.0462], d_k_M_hat range: [0.9948, 0.9999]
2025-03-11 21:32:09 - Train Iteration 14125: loss: 0.0090, d_k_M range: [0.0000, 0.0940], d_k_M_hat range: [0.9873, 1.0000]
2025-03-11 21:32:09 - Train Iteration 14126: loss: 0.0026, d_k_M range: [0.0000, 0.0497], d_k_M_hat range: [0.9973, 0.9999]
2025-03-11 21:32:10 - Train Iteration 14127: loss: 0.0001, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9902, 0.9998]
2025-03-11 21:32:10 - Train Iteration 14128: loss: 0.0473, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.7825, 0.9993]
2025-03-11 21:32:11 - Train Iteration 14129: loss: 0.0136, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.8836, 0.9999]
2025-03-11 21:32:11 - Train Iteration 14130: loss: 0.0000, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9970, 0.9994]
2025-03-11 21:32:12 - Train Iteration 14131: loss: 0.1293, d_k_M range: [0.0001, 0.1340], d_k_M_hat range: [0.6406, 1.0000]
2025-03-11 21:32:12 - Train Iteration 14132: loss: 0.4116, d_k_M range: [0.0000, 0.6415], d_k_M_hat range: [0.9780, 1.0000]
2025-03-11 21:32:12 - Train Iteration 14133: loss: 0.0186, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.8638, 0.9994]
2025-03-11 21:32:13 - Train Iteration 14134: loss: 0.0236, d_k_M range: [0.0000, 0.1531], d_k_M_hat range: [0.9710, 0.9998]
2025-03-11 21:32:13 - Train Iteration 14135: loss: 0.0000, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.9935, 0.9998]
2025-03-11 21:32:14 - Train Iteration 14136: loss: 0.0008, d_k_M range: [0.0000, 0.0274], d_k_M_hat range: [0.9729, 0.9998]
2025-03-11 21:32:14 - Train Iteration 14137: loss: 0.0194, d_k_M range: [0.0001, 0.1388], d_k_M_hat range: [0.9948, 0.9999]
2025-03-11 21:32:15 - Train Iteration 14138: loss: 0.0004, d_k_M range: [0.0000, 0.0157], d_k_M_hat range: [0.9952, 0.9999]
2025-03-11 21:32:15 - Train Iteration 14139: loss: 0.0016, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.9604, 0.9999]
2025-03-11 21:32:16 - Train Iteration 14140: loss: 0.0001, d_k_M range: [0.0000, 0.0121], d_k_M_hat range: [0.9958, 0.9999]
2025-03-11 21:32:16 - Train Iteration 14141: loss: 0.0029, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.9458, 0.9999]
2025-03-11 21:32:16 - Train Iteration 14142: loss: 0.0183, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.8646, 0.9998]
2025-03-11 21:32:17 - Train Iteration 14143: loss: 0.0008, d_k_M range: [0.0001, 0.0269], d_k_M_hat range: [0.9849, 0.9998]
2025-03-11 21:32:17 - Train Iteration 14144: loss: 0.0246, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.8432, 1.0000]
2025-03-11 21:32:18 - Train Iteration 14145: loss: 0.0001, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9887, 1.0000]
2025-03-11 21:32:18 - Train Iteration 14146: loss: 0.0002, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9857, 0.9998]
2025-03-11 21:32:18 - Train Iteration 14147: loss: 0.1338, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.6343, 0.9996]
2025-03-11 21:32:19 - Train Iteration 14148: loss: 0.0014, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9633, 0.9993]
2025-03-11 21:32:19 - Train Iteration 14149: loss: 0.0001, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.9913, 0.9998]
2025-03-11 21:32:20 - Train Iteration 14150: loss: 0.0077, d_k_M range: [0.0000, 0.0803], d_k_M_hat range: [0.9556, 0.9999]
2025-03-11 21:32:20 - Train Iteration 14151: loss: 0.0802, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.7169, 0.9996]
2025-03-11 21:32:21 - Train Iteration 14152: loss: 0.0202, d_k_M range: [0.0000, 0.0278], d_k_M_hat range: [0.8577, 0.9997]
2025-03-11 21:32:21 - Train Iteration 14153: loss: 0.0165, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.8716, 0.9992]
2025-03-11 21:32:22 - Train Iteration 14154: loss: 0.8205, d_k_M range: [0.0000, 0.9053], d_k_M_hat range: [0.9944, 1.0000]
2025-03-11 21:32:22 - Train Iteration 14155: loss: 0.0060, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.9223, 0.9996]
2025-03-11 21:32:23 - Train Iteration 14156: loss: 0.0030, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9454, 0.9998]
2025-03-11 21:32:23 - Train Iteration 14157: loss: 0.0011, d_k_M range: [0.0000, 0.0137], d_k_M_hat range: [0.9668, 0.9999]
2025-03-11 21:32:24 - Train Iteration 14158: loss: 0.0060, d_k_M range: [0.0000, 0.0259], d_k_M_hat range: [0.9224, 0.9996]
2025-03-11 21:32:24 - Train Iteration 14159: loss: 0.0162, d_k_M range: [0.0001, 0.0015], d_k_M_hat range: [0.8729, 0.9991]
2025-03-11 21:32:25 - Train Iteration 14160: loss: 0.0022, d_k_M range: [0.0001, 0.0466], d_k_M_hat range: [0.9801, 1.0000]
2025-03-11 21:32:25 - Train Iteration 14161: loss: 0.0008, d_k_M range: [0.0000, 0.0284], d_k_M_hat range: [0.9862, 0.9997]
2025-03-11 21:32:26 - Train Iteration 14162: loss: 0.0017, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9587, 0.9988]
2025-03-11 21:32:26 - Train Iteration 14163: loss: 0.0000, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9948, 0.9995]
2025-03-11 21:32:26 - Train Iteration 14164: loss: 0.0005, d_k_M range: [0.0003, 0.0163], d_k_M_hat range: [0.9939, 1.0000]
2025-03-11 21:32:27 - Train Iteration 14165: loss: 0.0256, d_k_M range: [0.0002, 0.1580], d_k_M_hat range: [0.9948, 0.9999]
2025-03-11 21:32:27 - Train Iteration 14166: loss: 0.5507, d_k_M range: [0.0000, 0.7421], d_k_M_hat range: [0.9991, 1.0000]
2025-03-11 21:32:28 - Train Iteration 14167: loss: 0.0008, d_k_M range: [0.0000, 0.0126], d_k_M_hat range: [0.9717, 0.9994]
2025-03-11 21:32:28 - Train Iteration 14168: loss: 0.0027, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.9479, 0.9999]
2025-03-11 21:32:29 - Train Iteration 14169: loss: 0.0001, d_k_M range: [0.0000, 0.0101], d_k_M_hat range: [0.9959, 0.9999]
2025-03-11 21:32:29 - Train Iteration 14170: loss: 0.0016, d_k_M range: [0.0001, 0.0375], d_k_M_hat range: [0.9954, 0.9998]
2025-03-11 21:32:29 - Train Iteration 14171: loss: 0.0145, d_k_M range: [0.0000, 0.0127], d_k_M_hat range: [0.8795, 0.9993]
2025-03-11 21:32:30 - Train Iteration 14172: loss: 0.0005, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9767, 0.9997]
2025-03-11 21:32:30 - Train Iteration 14173: loss: 0.0027, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9483, 0.9997]
2025-03-11 21:32:31 - Train Iteration 14174: loss: 0.0013, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9636, 0.9999]
2025-03-11 21:32:31 - Train Iteration 14175: loss: 0.4177, d_k_M range: [0.0000, 0.4657], d_k_M_hat range: [0.3537, 0.9997]
2025-03-11 21:32:32 - Train Iteration 14176: loss: 0.0043, d_k_M range: [0.0000, 0.0653], d_k_M_hat range: [0.9908, 0.9999]
2025-03-11 21:32:32 - Train Iteration 14177: loss: 0.0076, d_k_M range: [0.0000, 0.0873], d_k_M_hat range: [0.9910, 0.9999]
2025-03-11 21:32:33 - Train Iteration 14178: loss: 0.0023, d_k_M range: [0.0001, 0.0045], d_k_M_hat range: [0.9518, 0.9998]
2025-03-11 21:32:33 - Train Iteration 14179: loss: 0.0020, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9548, 0.9999]
2025-03-11 21:32:33 - Train Iteration 14180: loss: 0.0001, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.9879, 0.9990]
2025-03-11 21:32:34 - Train Iteration 14181: loss: 0.0900, d_k_M range: [0.0000, 0.2959], d_k_M_hat range: [0.9865, 0.9999]
2025-03-11 21:32:34 - Train Iteration 14182: loss: 0.0006, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9762, 0.9993]
2025-03-11 21:32:35 - Train Iteration 14183: loss: 0.0052, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9282, 0.9999]
2025-03-11 21:32:35 - Train Iteration 14184: loss: 0.0004, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.9818, 0.9995]
2025-03-11 21:32:36 - Train Iteration 14185: loss: 0.0030, d_k_M range: [0.0001, 0.0542], d_k_M_hat range: [0.9604, 0.9996]
2025-03-11 21:32:36 - Train Iteration 14186: loss: 0.0107, d_k_M range: [0.0000, 0.0339], d_k_M_hat range: [0.8978, 0.9999]
2025-03-11 21:32:36 - Train Iteration 14187: loss: 0.0141, d_k_M range: [0.0000, 0.0166], d_k_M_hat range: [0.8849, 0.9996]
2025-03-11 21:32:37 - Train Iteration 14188: loss: 0.0041, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9357, 1.0000]
2025-03-11 21:32:37 - Train Iteration 14189: loss: 0.0001, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9923, 0.9998]
2025-03-11 21:32:38 - Train Iteration 14190: loss: 0.0047, d_k_M range: [0.0000, 0.0218], d_k_M_hat range: [0.9312, 0.9996]
2025-03-11 21:32:38 - Train Iteration 14191: loss: 0.0868, d_k_M range: [0.0001, 0.2898], d_k_M_hat range: [0.9548, 0.9997]
2025-03-11 21:32:39 - Train Iteration 14192: loss: 0.1005, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.6829, 0.9999]
2025-03-11 21:32:39 - Train Iteration 14193: loss: 0.0004, d_k_M range: [0.0000, 0.0200], d_k_M_hat range: [0.9944, 0.9996]
2025-03-11 21:32:40 - Train Iteration 14194: loss: 0.0004, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9799, 0.9994]
2025-03-11 21:32:40 - Train Iteration 14195: loss: 0.0030, d_k_M range: [0.0000, 0.0116], d_k_M_hat range: [0.9456, 1.0000]
2025-03-11 21:32:41 - Train Iteration 14196: loss: 0.1603, d_k_M range: [0.0000, 0.3988], d_k_M_hat range: [0.9850, 0.9997]
2025-03-11 21:32:41 - Train Iteration 14197: loss: 0.9043, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.0491, 0.9989]
2025-03-11 21:32:42 - Train Iteration 14198: loss: 0.1314, d_k_M range: [0.0000, 0.0155], d_k_M_hat range: [0.6375, 0.9994]
2025-03-11 21:32:42 - Train Iteration 14199: loss: 0.0019, d_k_M range: [0.0000, 0.0431], d_k_M_hat range: [0.9977, 0.9999]
2025-03-11 21:32:43 - Train Iteration 14200: loss: 0.0003, d_k_M range: [0.0001, 0.0040], d_k_M_hat range: [0.9865, 0.9998]
2025-03-11 21:32:43 - Train Iteration 14201: loss: 0.0006, d_k_M range: [0.0000, 0.0136], d_k_M_hat range: [0.9751, 0.9997]
2025-03-11 21:32:43 - Train Iteration 14202: loss: 0.0009, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9740, 0.9997]
2025-03-11 21:32:44 - Train Iteration 14203: loss: 0.0001, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.9933, 0.9992]
2025-03-11 21:32:44 - Train Iteration 14204: loss: 0.0001, d_k_M range: [0.0002, 0.0101], d_k_M_hat range: [0.9951, 0.9997]
2025-03-11 21:32:45 - Train Iteration 14205: loss: 0.0009, d_k_M range: [0.0000, 0.0184], d_k_M_hat range: [0.9892, 0.9998]
2025-03-11 21:32:45 - Train Iteration 14206: loss: 0.0001, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9936, 1.0000]
2025-03-11 21:32:46 - Train Iteration 14207: loss: 0.0023, d_k_M range: [0.0000, 0.0432], d_k_M_hat range: [0.9523, 1.0000]
2025-03-11 21:32:46 - Train Iteration 14208: loss: 0.0008, d_k_M range: [0.0000, 0.0275], d_k_M_hat range: [0.9796, 0.9997]
2025-03-11 21:32:47 - Train Iteration 14209: loss: 0.0003, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9842, 0.9999]
2025-03-11 21:32:47 - Train Iteration 14210: loss: 0.1739, d_k_M range: [0.0000, 0.4165], d_k_M_hat range: [0.9934, 0.9999]
2025-03-11 21:32:48 - Train Iteration 14211: loss: 0.0002, d_k_M range: [0.0000, 0.0133], d_k_M_hat range: [0.9912, 0.9999]
2025-03-11 21:32:48 - Train Iteration 14212: loss: 0.0001, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9928, 0.9997]
2025-03-11 21:32:48 - Train Iteration 14213: loss: 0.0103, d_k_M range: [0.0000, 0.1014], d_k_M_hat range: [0.9988, 1.0000]
2025-03-11 21:32:49 - Train Iteration 14214: loss: 0.0007, d_k_M range: [0.0000, 0.0172], d_k_M_hat range: [0.9827, 0.9995]
2025-03-11 21:32:49 - Train Iteration 14215: loss: 0.0221, d_k_M range: [0.0000, 0.1486], d_k_M_hat range: [0.9973, 0.9999]
2025-03-11 21:32:50 - Train Iteration 14216: loss: 0.0083, d_k_M range: [0.0000, 0.0901], d_k_M_hat range: [0.9923, 0.9997]
2025-03-11 21:32:50 - Train Iteration 14217: loss: 0.0002, d_k_M range: [0.0000, 0.0138], d_k_M_hat range: [0.9897, 1.0000]
2025-03-11 21:32:51 - Train Iteration 14218: loss: 0.0122, d_k_M range: [0.0001, 0.1104], d_k_M_hat range: [0.9972, 0.9999]
2025-03-11 21:32:51 - Train Iteration 14219: loss: 0.0028, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.9467, 0.9998]
2025-03-11 21:32:52 - Train Iteration 14220: loss: 0.0049, d_k_M range: [0.0000, 0.0137], d_k_M_hat range: [0.9301, 0.9997]
2025-03-11 21:32:52 - Train Iteration 14221: loss: 0.0010, d_k_M range: [0.0000, 0.0090], d_k_M_hat range: [0.9691, 0.9994]
2025-03-11 21:32:52 - Train Iteration 14222: loss: 0.0186, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.8638, 0.9998]
2025-03-11 21:32:53 - Train Iteration 14223: loss: 0.0017, d_k_M range: [0.0000, 0.0415], d_k_M_hat range: [0.9932, 0.9998]
2025-03-11 21:32:53 - Train Iteration 14224: loss: 0.0003, d_k_M range: [0.0001, 0.0167], d_k_M_hat range: [0.9974, 0.9999]
2025-03-11 21:32:54 - Train Iteration 14225: loss: 0.0002, d_k_M range: [0.0000, 0.0131], d_k_M_hat range: [0.9942, 0.9998]
2025-03-11 21:32:54 - Train Iteration 14226: loss: 0.5548, d_k_M range: [0.0000, 0.7448], d_k_M_hat range: [0.9101, 0.9999]
2025-03-11 21:32:55 - Train Iteration 14227: loss: 0.0044, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.9377, 0.9993]
2025-03-11 21:32:55 - Train Iteration 14228: loss: 0.0001, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9926, 0.9998]
2025-03-11 21:32:55 - Train Iteration 14229: loss: 0.9668, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.0167, 0.9996]
2025-03-11 21:32:56 - Train Iteration 14230: loss: 0.0028, d_k_M range: [0.0000, 0.0526], d_k_M_hat range: [0.9784, 1.0000]
2025-03-11 21:32:56 - Train Iteration 14231: loss: 0.0033, d_k_M range: [0.0001, 0.0575], d_k_M_hat range: [0.9968, 0.9999]
2025-03-11 21:32:57 - Train Iteration 14232: loss: 0.0013, d_k_M range: [0.0000, 0.0352], d_k_M_hat range: [0.9924, 0.9996]
2025-03-11 21:32:57 - Train Iteration 14233: loss: 0.0003, d_k_M range: [0.0000, 0.0056], d_k_M_hat range: [0.9876, 0.9995]
2025-03-11 21:32:58 - Train Iteration 14234: loss: 0.0025, d_k_M range: [0.0001, 0.0289], d_k_M_hat range: [0.9500, 0.9999]
2025-03-11 21:32:58 - Train Iteration 14235: loss: 0.0056, d_k_M range: [0.0000, 0.0749], d_k_M_hat range: [0.9509, 1.0000]
2025-03-11 21:32:58 - Train Iteration 14236: loss: 0.0666, d_k_M range: [0.0000, 0.0994], d_k_M_hat range: [0.7420, 0.9995]
2025-03-11 21:32:59 - Train Iteration 14237: loss: 0.0149, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.8782, 0.9999]
2025-03-11 21:32:59 - Train Iteration 14238: loss: 0.0254, d_k_M range: [0.0000, 0.1594], d_k_M_hat range: [0.9923, 1.0000]
2025-03-11 21:33:00 - Train Iteration 14239: loss: 0.0031, d_k_M range: [0.0000, 0.0100], d_k_M_hat range: [0.9440, 0.9999]
2025-03-11 21:33:00 - Train Iteration 14240: loss: 0.0995, d_k_M range: [0.0000, 0.0145], d_k_M_hat range: [0.6846, 0.9999]
2025-03-11 21:33:01 - Train Iteration 14241: loss: 0.0912, d_k_M range: [0.0000, 0.3013], d_k_M_hat range: [0.9965, 1.0000]
2025-03-11 21:33:01 - Train Iteration 14242: loss: 0.0022, d_k_M range: [0.0000, 0.0459], d_k_M_hat range: [0.9964, 0.9998]
2025-03-11 21:33:02 - Train Iteration 14243: loss: 0.0043, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9354, 0.9996]
2025-03-11 21:33:02 - Train Iteration 14244: loss: 0.0087, d_k_M range: [0.0000, 0.0928], d_k_M_hat range: [0.9607, 0.9996]
2025-03-11 21:33:03 - Train Iteration 14245: loss: 0.0004, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9829, 0.9987]
2025-03-11 21:33:03 - Train Iteration 14246: loss: 0.0002, d_k_M range: [0.0000, 0.0109], d_k_M_hat range: [0.9912, 1.0000]
2025-03-11 21:33:04 - Train Iteration 14247: loss: 0.0544, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.7667, 0.9996]
2025-03-11 21:33:04 - Train Iteration 14248: loss: 0.0075, d_k_M range: [0.0001, 0.0862], d_k_M_hat range: [0.9713, 1.0000]
2025-03-11 21:33:05 - Train Iteration 14249: loss: 0.0001, d_k_M range: [0.0000, 0.0098], d_k_M_hat range: [0.9909, 0.9998]
2025-03-11 21:33:05 - Train Iteration 14250: loss: 0.0006, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.9750, 0.9998]
2025-03-11 21:33:05 - Train Iteration 14251: loss: 0.0712, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.7334, 0.9977]
2025-03-11 21:33:06 - Train Iteration 14252: loss: 0.0123, d_k_M range: [0.0000, 0.1107], d_k_M_hat range: [0.9947, 0.9998]
2025-03-11 21:33:06 - Train Iteration 14253: loss: 0.0007, d_k_M range: [0.0000, 0.0264], d_k_M_hat range: [0.9939, 0.9999]
2025-03-11 21:33:07 - Train Iteration 14254: loss: 0.0024, d_k_M range: [0.0000, 0.0265], d_k_M_hat range: [0.9553, 0.9999]
2025-03-11 21:33:07 - Train Iteration 14255: loss: 0.0031, d_k_M range: [0.0000, 0.0224], d_k_M_hat range: [0.9440, 0.9993]
2025-03-11 21:33:08 - Train Iteration 14256: loss: 0.0574, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.7604, 0.9990]
2025-03-11 21:33:08 - Train Iteration 14257: loss: 0.0052, d_k_M range: [0.0000, 0.0722], d_k_M_hat range: [0.9939, 1.0000]
2025-03-11 21:33:09 - Train Iteration 14258: loss: 0.0002, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.9916, 0.9999]
2025-03-11 21:33:09 - Train Iteration 14259: loss: 0.0012, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9651, 0.9998]
2025-03-11 21:33:09 - Train Iteration 14260: loss: 0.0102, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9004, 0.9994]
2025-03-11 21:33:10 - Train Iteration 14261: loss: 0.2156, d_k_M range: [0.0000, 0.0881], d_k_M_hat range: [0.5357, 0.9998]
2025-03-11 21:33:10 - Train Iteration 14262: loss: 0.0676, d_k_M range: [0.0000, 0.2572], d_k_M_hat range: [0.9892, 0.9999]
2025-03-11 21:33:11 - Train Iteration 14263: loss: 0.0131, d_k_M range: [0.0001, 0.1144], d_k_M_hat range: [0.9931, 0.9999]
2025-03-11 21:33:11 - Train Iteration 14264: loss: 0.0099, d_k_M range: [0.0000, 0.0925], d_k_M_hat range: [0.9931, 0.9997]
2025-03-11 21:33:12 - Train Iteration 14265: loss: 0.0168, d_k_M range: [0.0000, 0.1291], d_k_M_hat range: [0.9945, 0.9999]
2025-03-11 21:33:12 - Train Iteration 14266: loss: 0.0002, d_k_M range: [0.0000, 0.0146], d_k_M_hat range: [0.9950, 1.0000]
2025-03-11 21:33:13 - Train Iteration 14267: loss: 0.0315, d_k_M range: [0.0000, 0.1773], d_k_M_hat range: [0.9748, 1.0000]
2025-03-11 21:33:13 - Train Iteration 14268: loss: 0.0169, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.8700, 1.0000]
2025-03-11 21:33:13 - Train Iteration 14269: loss: 0.0009, d_k_M range: [0.0000, 0.0108], d_k_M_hat range: [0.9696, 0.9998]
2025-03-11 21:33:14 - Train Iteration 14270: loss: 0.0002, d_k_M range: [0.0000, 0.0101], d_k_M_hat range: [0.9947, 0.9999]
2025-03-11 21:33:14 - Train Iteration 14271: loss: 0.0635, d_k_M range: [0.0000, 0.1293], d_k_M_hat range: [0.7481, 1.0000]
2025-03-11 21:33:15 - Train Iteration 14272: loss: 0.0523, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.7714, 0.9991]
2025-03-11 21:33:15 - Train Iteration 14273: loss: 0.0013, d_k_M range: [0.0000, 0.0108], d_k_M_hat range: [0.9636, 0.9991]
2025-03-11 21:33:16 - Train Iteration 14274: loss: 0.0002, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9867, 0.9995]
2025-03-11 21:33:16 - Train Iteration 14275: loss: 0.0038, d_k_M range: [0.0000, 0.0047], d_k_M_hat range: [0.9388, 0.9998]
2025-03-11 21:33:17 - Train Iteration 14276: loss: 0.0006, d_k_M range: [0.0000, 0.0130], d_k_M_hat range: [0.9777, 0.9998]
2025-03-11 21:33:17 - Train Iteration 14277: loss: 0.0004, d_k_M range: [0.0000, 0.0142], d_k_M_hat range: [0.9799, 0.9999]
2025-03-11 21:33:18 - Train Iteration 14278: loss: 0.0009, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9706, 0.9933]
2025-03-11 21:33:18 - Train Iteration 14279: loss: 0.0001, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.9940, 1.0000]
2025-03-11 21:33:18 - Train Iteration 14280: loss: 0.3427, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.4151, 0.9989]
2025-03-11 21:33:19 - Train Iteration 14281: loss: 0.0126, d_k_M range: [0.0002, 0.1122], d_k_M_hat range: [0.9731, 1.0000]
2025-03-11 21:33:19 - Train Iteration 14282: loss: 0.1993, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.5536, 0.9983]
2025-03-11 21:33:20 - Train Iteration 14283: loss: 0.2817, d_k_M range: [0.0001, 0.5307], d_k_M_hat range: [0.9619, 1.0000]
2025-03-11 21:33:20 - Train Iteration 14284: loss: 0.0335, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.8171, 0.9982]
2025-03-11 21:33:21 - Train Iteration 14285: loss: 0.0006, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9752, 0.9997]
2025-03-11 21:33:21 - Train Iteration 14286: loss: 0.0018, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9576, 0.9996]
2025-03-11 21:33:22 - Train Iteration 14287: loss: 0.0001, d_k_M range: [0.0000, 0.0107], d_k_M_hat range: [0.9935, 0.9999]
2025-03-11 21:33:22 - Train Iteration 14288: loss: 0.0002, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9858, 0.9998]
2025-03-11 21:33:23 - Train Iteration 14289: loss: 0.0247, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.8431, 0.9993]
2025-03-11 21:33:23 - Train Iteration 14290: loss: 0.0001, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9940, 0.9998]
2025-03-11 21:33:24 - Train Iteration 14291: loss: 0.0006, d_k_M range: [0.0000, 0.0250], d_k_M_hat range: [0.9981, 0.9999]
2025-03-11 21:33:24 - Train Iteration 14292: loss: 0.0124, d_k_M range: [0.0000, 0.0830], d_k_M_hat range: [0.8887, 0.9999]
2025-03-11 21:33:24 - Train Iteration 14293: loss: 0.0014, d_k_M range: [0.0000, 0.0069], d_k_M_hat range: [0.9630, 0.9991]
2025-03-11 21:33:25 - Train Iteration 14294: loss: 0.0003, d_k_M range: [0.0000, 0.0139], d_k_M_hat range: [0.9836, 0.9996]
2025-03-11 21:33:25 - Train Iteration 14295: loss: 0.0026, d_k_M range: [0.0001, 0.0103], d_k_M_hat range: [0.9492, 0.9987]
2025-03-11 21:33:26 - Train Iteration 14296: loss: 0.4831, d_k_M range: [0.0000, 0.6951], d_k_M_hat range: [0.9977, 1.0000]
2025-03-11 21:33:26 - Train Iteration 14297: loss: 0.0002, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9854, 0.9992]
2025-03-11 21:33:27 - Train Iteration 14298: loss: 0.0002, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9871, 0.9998]
2025-03-11 21:33:27 - Train Iteration 14299: loss: 0.0002, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.9913, 0.9999]
2025-03-11 21:33:27 - Train Iteration 14300: loss: 0.0068, d_k_M range: [0.0000, 0.0119], d_k_M_hat range: [0.9178, 0.9995]
2025-03-11 21:33:28 - Train Iteration 14301: loss: 0.2105, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.5412, 0.9990]
2025-03-11 21:33:28 - Train Iteration 14302: loss: 0.0001, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.9921, 0.9995]
2025-03-11 21:33:29 - Train Iteration 14303: loss: 0.0072, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9152, 0.9996]
2025-03-11 21:33:29 - Train Iteration 14304: loss: 0.0004, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.9803, 0.9994]
2025-03-11 21:33:30 - Train Iteration 14305: loss: 0.0044, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9333, 0.9997]
2025-03-11 21:33:30 - Train Iteration 14306: loss: 0.0015, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.9620, 0.9997]
2025-03-11 21:33:31 - Train Iteration 14307: loss: 0.0014, d_k_M range: [0.0000, 0.0087], d_k_M_hat range: [0.9633, 1.0000]
2025-03-11 21:33:31 - Train Iteration 14308: loss: 0.0008, d_k_M range: [0.0000, 0.0126], d_k_M_hat range: [0.9720, 0.9993]
2025-03-11 21:33:31 - Train Iteration 14309: loss: 0.1949, d_k_M range: [0.0000, 0.0301], d_k_M_hat range: [0.5586, 0.9999]
2025-03-11 21:33:32 - Train Iteration 14310: loss: 0.0013, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9635, 0.9998]
2025-03-11 21:33:32 - Train Iteration 14311: loss: 0.0032, d_k_M range: [0.0000, 0.0516], d_k_M_hat range: [0.9524, 0.9999]
2025-03-11 21:33:33 - Train Iteration 14312: loss: 0.0016, d_k_M range: [0.0000, 0.0080], d_k_M_hat range: [0.9606, 0.9997]
2025-03-11 21:33:33 - Train Iteration 14313: loss: 0.1308, d_k_M range: [0.0001, 0.3610], d_k_M_hat range: [0.9767, 1.0000]
2025-03-11 21:33:33 - Train Iteration 14314: loss: 0.2051, d_k_M range: [0.0001, 0.4358], d_k_M_hat range: [0.9790, 0.9999]
2025-03-11 21:33:34 - Train Iteration 14315: loss: 0.0073, d_k_M range: [0.0000, 0.0327], d_k_M_hat range: [0.9144, 0.9999]
2025-03-11 21:33:34 - Train Iteration 14316: loss: 0.0003, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.9898, 0.9998]
2025-03-11 21:33:35 - Train Iteration 14317: loss: 0.0150, d_k_M range: [0.0001, 0.1225], d_k_M_hat range: [0.9878, 0.9999]
2025-03-11 21:33:35 - Train Iteration 14318: loss: 0.0002, d_k_M range: [0.0000, 0.0116], d_k_M_hat range: [0.9954, 0.9997]
2025-03-11 21:33:36 - Train Iteration 14319: loss: 0.0022, d_k_M range: [0.0000, 0.0471], d_k_M_hat range: [0.9955, 1.0000]
2025-03-11 21:33:36 - Train Iteration 14320: loss: 0.0124, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.8887, 0.9989]
2025-03-11 21:33:37 - Train Iteration 14321: loss: 0.0008, d_k_M range: [0.0001, 0.0287], d_k_M_hat range: [0.9907, 0.9999]
2025-03-11 21:33:37 - Train Iteration 14322: loss: 0.0916, d_k_M range: [0.0003, 0.3026], d_k_M_hat range: [0.9988, 1.0000]
2025-03-11 21:33:37 - Train Iteration 14323: loss: 0.0000, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9943, 0.9993]
2025-03-11 21:33:38 - Train Iteration 14324: loss: 0.0013, d_k_M range: [0.0000, 0.0348], d_k_M_hat range: [0.9959, 0.9999]
2025-03-11 21:33:38 - Train Iteration 14325: loss: 0.0002, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9872, 0.9998]
2025-03-11 21:33:39 - Train Iteration 14326: loss: 0.0255, d_k_M range: [0.0000, 0.1593], d_k_M_hat range: [0.8558, 1.0000]
2025-03-11 21:33:39 - Train Iteration 14327: loss: 0.0009, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9708, 0.9998]
2025-03-11 21:33:39 - Train Iteration 14328: loss: 0.0029, d_k_M range: [0.0000, 0.0206], d_k_M_hat range: [0.9461, 0.9997]
2025-03-11 21:33:40 - Train Iteration 14329: loss: 0.0016, d_k_M range: [0.0000, 0.0327], d_k_M_hat range: [0.9599, 0.9993]
2025-03-11 21:33:40 - Train Iteration 14330: loss: 0.0009, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9706, 0.9998]
2025-03-11 21:33:41 - Train Iteration 14331: loss: 0.0164, d_k_M range: [0.0000, 0.1279], d_k_M_hat range: [0.9786, 1.0000]
2025-03-11 21:33:41 - Train Iteration 14332: loss: 0.1254, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.6459, 1.0000]
2025-03-11 21:33:42 - Train Iteration 14333: loss: 0.0053, d_k_M range: [0.0002, 0.0714], d_k_M_hat range: [0.9956, 0.9998]
2025-03-11 21:33:42 - Train Iteration 14334: loss: 0.0004, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.9806, 0.9998]
2025-03-11 21:33:43 - Train Iteration 14335: loss: 0.0011, d_k_M range: [0.0000, 0.0334], d_k_M_hat range: [0.9899, 1.0000]
2025-03-11 21:33:43 - Train Iteration 14336: loss: 0.0002, d_k_M range: [0.0000, 0.0112], d_k_M_hat range: [0.9898, 0.9999]
2025-03-11 21:33:44 - Train Iteration 14337: loss: 0.0010, d_k_M range: [0.0000, 0.0313], d_k_M_hat range: [0.9927, 0.9998]
2025-03-11 21:33:44 - Train Iteration 14338: loss: 0.0964, d_k_M range: [0.0000, 0.0238], d_k_M_hat range: [0.6933, 0.9995]
2025-03-11 21:33:45 - Train Iteration 14339: loss: 0.2974, d_k_M range: [0.0000, 0.1269], d_k_M_hat range: [0.4547, 1.0000]
2025-03-11 21:33:45 - Train Iteration 14340: loss: 0.0197, d_k_M range: [0.0001, 0.1389], d_k_M_hat range: [0.9984, 1.0000]
2025-03-11 21:33:45 - Train Iteration 14341: loss: 0.0048, d_k_M range: [0.0000, 0.0690], d_k_M_hat range: [0.9982, 1.0000]
2025-03-11 21:33:46 - Train Iteration 14342: loss: 0.0038, d_k_M range: [0.0000, 0.0128], d_k_M_hat range: [0.9412, 0.9998]
2025-03-11 21:33:46 - Train Iteration 14343: loss: 0.0803, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.7172, 0.9995]
2025-03-11 21:33:47 - Train Iteration 14344: loss: 0.0015, d_k_M range: [0.0000, 0.0094], d_k_M_hat range: [0.9616, 0.9999]
2025-03-11 21:33:47 - Train Iteration 14345: loss: 0.0007, d_k_M range: [0.0000, 0.0126], d_k_M_hat range: [0.9729, 0.9995]
2025-03-11 21:33:48 - Train Iteration 14346: loss: 0.0021, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9546, 0.9991]
2025-03-11 21:33:48 - Train Iteration 14347: loss: 0.0243, d_k_M range: [0.0000, 0.1558], d_k_M_hat range: [0.9905, 1.0000]
2025-03-11 21:33:49 - Train Iteration 14348: loss: 0.0060, d_k_M range: [0.0001, 0.0772], d_k_M_hat range: [0.9971, 1.0000]
2025-03-11 21:33:49 - Train Iteration 14349: loss: 0.0004, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9806, 0.9999]
2025-03-11 21:33:50 - Train Iteration 14350: loss: 0.0003, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.9821, 0.9987]
2025-03-11 21:33:50 - Train Iteration 14351: loss: 0.0000, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9965, 1.0000]
2025-03-11 21:33:50 - Train Iteration 14352: loss: 0.0030, d_k_M range: [0.0001, 0.0435], d_k_M_hat range: [0.9451, 0.9998]
2025-03-11 21:33:51 - Train Iteration 14353: loss: 0.0165, d_k_M range: [0.0000, 0.1281], d_k_M_hat range: [0.9914, 1.0000]
2025-03-11 21:33:51 - Train Iteration 14354: loss: 0.0020, d_k_M range: [0.0000, 0.0438], d_k_M_hat range: [0.9895, 0.9993]
2025-03-11 21:33:52 - Train Iteration 14355: loss: 0.0009, d_k_M range: [0.0000, 0.0278], d_k_M_hat range: [0.9980, 0.9997]
2025-03-11 21:33:52 - Train Iteration 14356: loss: 0.9018, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.0504, 0.9996]
2025-03-11 21:33:53 - Train Iteration 14357: loss: 0.0084, d_k_M range: [0.0000, 0.0912], d_k_M_hat range: [0.9926, 0.9998]
2025-03-11 21:33:53 - Train Iteration 14358: loss: 0.0005, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.9776, 0.9988]
2025-03-11 21:33:54 - Train Iteration 14359: loss: 0.0036, d_k_M range: [0.0000, 0.0105], d_k_M_hat range: [0.9403, 0.9995]
2025-03-11 21:33:54 - Train Iteration 14360: loss: 0.0129, d_k_M range: [0.0000, 0.1135], d_k_M_hat range: [0.9940, 0.9999]
2025-03-11 21:33:55 - Train Iteration 14361: loss: 0.0004, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.9792, 0.9997]
2025-03-11 21:33:55 - Train Iteration 14362: loss: 0.0004, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9799, 0.9999]
2025-03-11 21:33:55 - Train Iteration 14363: loss: 0.0061, d_k_M range: [0.0000, 0.0780], d_k_M_hat range: [0.9524, 0.9997]
2025-03-11 21:33:56 - Train Iteration 14364: loss: 0.1102, d_k_M range: [0.0000, 0.3319], d_k_M_hat range: [0.9924, 1.0000]
2025-03-11 21:33:56 - Train Iteration 14365: loss: 0.0338, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.8162, 0.9978]
2025-03-11 21:33:57 - Train Iteration 14366: loss: 0.0008, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9712, 0.9997]
2025-03-11 21:33:57 - Train Iteration 14367: loss: 0.1422, d_k_M range: [0.0000, 0.3771], d_k_M_hat range: [0.9989, 1.0000]
2025-03-11 21:33:58 - Train Iteration 14368: loss: 0.0005, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9771, 0.9998]
2025-03-11 21:33:58 - Train Iteration 14369: loss: 0.0020, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.9550, 0.9999]
2025-03-11 21:33:59 - Train Iteration 14370: loss: 0.0003, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9840, 0.9999]
2025-03-11 21:33:59 - Train Iteration 14371: loss: 0.0008, d_k_M range: [0.0000, 0.0277], d_k_M_hat range: [0.9934, 0.9994]
2025-03-11 21:33:59 - Train Iteration 14372: loss: 0.0011, d_k_M range: [0.0000, 0.0072], d_k_M_hat range: [0.9666, 0.9996]
2025-03-11 21:34:00 - Train Iteration 14373: loss: 0.0027, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.9481, 0.9995]
2025-03-11 21:34:00 - Train Iteration 14374: loss: 0.0062, d_k_M range: [0.0000, 0.0175], d_k_M_hat range: [0.9245, 0.9998]
2025-03-11 21:34:01 - Train Iteration 14375: loss: 0.3935, d_k_M range: [0.0000, 0.6271], d_k_M_hat range: [0.9602, 0.9999]
2025-03-11 21:34:01 - Train Iteration 14376: loss: 0.0088, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9064, 0.9996]
2025-03-11 21:34:02 - Train Iteration 14377: loss: 0.0051, d_k_M range: [0.0000, 0.0709], d_k_M_hat range: [0.9958, 1.0000]
2025-03-11 21:34:02 - Train Iteration 14378: loss: 0.0458, d_k_M range: [0.0000, 0.2134], d_k_M_hat range: [0.9988, 1.0000]
2025-03-11 21:34:03 - Train Iteration 14379: loss: 0.0004, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9799, 0.9999]
2025-03-11 21:34:03 - Train Iteration 14380: loss: 0.0037, d_k_M range: [0.0000, 0.0608], d_k_M_hat range: [0.9937, 1.0000]
2025-03-11 21:34:03 - Train Iteration 14381: loss: 0.0056, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9250, 0.9996]
2025-03-11 21:34:04 - Train Iteration 14382: loss: 0.0356, d_k_M range: [0.0000, 0.1879], d_k_M_hat range: [0.8824, 0.9993]
2025-03-11 21:34:04 - Train Iteration 14383: loss: 0.0000, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.9946, 0.9998]
2025-03-11 21:34:05 - Train Iteration 14384: loss: 0.1166, d_k_M range: [0.0000, 0.3413], d_k_M_hat range: [0.9244, 0.9999]
2025-03-11 21:34:05 - Train Iteration 14385: loss: 0.0611, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.7528, 0.9966]
2025-03-11 21:34:06 - Train Iteration 14386: loss: 0.0058, d_k_M range: [0.0000, 0.0129], d_k_M_hat range: [0.9238, 0.9995]
2025-03-11 21:34:06 - Train Iteration 14387: loss: 0.0001, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9923, 0.9999]
2025-03-11 21:34:07 - Train Iteration 14388: loss: 0.0001, d_k_M range: [0.0000, 0.0105], d_k_M_hat range: [0.9968, 0.9999]
2025-03-11 21:34:07 - Train Iteration 14389: loss: 0.0372, d_k_M range: [0.0000, 0.0283], d_k_M_hat range: [0.8086, 1.0000]
2025-03-11 21:34:07 - Train Iteration 14390: loss: 0.0001, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9884, 0.9999]
2025-03-11 21:34:08 - Train Iteration 14391: loss: 0.0006, d_k_M range: [0.0000, 0.0225], d_k_M_hat range: [0.9860, 0.9997]
2025-03-11 21:34:08 - Train Iteration 14392: loss: 0.0196, d_k_M range: [0.0000, 0.0115], d_k_M_hat range: [0.8608, 0.9996]
2025-03-11 21:34:09 - Train Iteration 14393: loss: 0.0019, d_k_M range: [0.0001, 0.0078], d_k_M_hat range: [0.9566, 0.9999]
2025-03-11 21:34:09 - Train Iteration 14394: loss: 0.0001, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9903, 0.9999]
2025-03-11 21:34:10 - Train Iteration 14395: loss: 0.3849, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.3796, 0.9993]
2025-03-11 21:34:10 - Train Iteration 14396: loss: 0.0024, d_k_M range: [0.0002, 0.0491], d_k_M_hat range: [0.9968, 0.9999]
2025-03-11 21:34:11 - Train Iteration 14397: loss: 0.0001, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9910, 0.9998]
2025-03-11 21:34:11 - Train Iteration 14398: loss: 0.0446, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.7889, 0.9999]
2025-03-11 21:34:11 - Train Iteration 14399: loss: 0.0001, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.9916, 0.9998]
2025-03-11 21:34:12 - Train Iteration 14400: loss: 0.2896, d_k_M range: [0.0000, 0.5378], d_k_M_hat range: [0.9826, 0.9999]
2025-03-11 21:34:12 - Train Iteration 14401: loss: 0.7456, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.1365, 0.9999]
2025-03-11 21:34:13 - Train Iteration 14402: loss: 0.5316, d_k_M range: [0.0000, 0.7291], d_k_M_hat range: [0.9997, 1.0000]
2025-03-11 21:34:13 - Train Iteration 14403: loss: 0.0089, d_k_M range: [0.0000, 0.0072], d_k_M_hat range: [0.9059, 0.9999]
2025-03-11 21:34:14 - Train Iteration 14404: loss: 0.0029, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9460, 0.9993]
2025-03-11 21:34:14 - Train Iteration 14405: loss: 0.0028, d_k_M range: [0.0002, 0.0079], d_k_M_hat range: [0.9549, 1.0000]
2025-03-11 21:34:14 - Train Iteration 14406: loss: 0.1384, d_k_M range: [0.0002, 0.3712], d_k_M_hat range: [0.9856, 0.9996]
2025-03-11 21:34:15 - Train Iteration 14407: loss: 0.0299, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.8273, 0.9986]
2025-03-11 21:34:15 - Train Iteration 14408: loss: 0.0303, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.8261, 0.9986]
2025-03-11 21:34:16 - Train Iteration 14409: loss: 0.0011, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9684, 0.9990]
2025-03-11 21:34:16 - Train Iteration 14410: loss: 0.0126, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.8876, 0.9999]
2025-03-11 21:34:17 - Train Iteration 14411: loss: 0.0089, d_k_M range: [0.0001, 0.0044], d_k_M_hat range: [0.9059, 0.9997]
2025-03-11 21:34:17 - Train Iteration 14412: loss: 0.0001, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9904, 0.9994]
2025-03-11 21:34:18 - Train Iteration 14413: loss: 0.0014, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9627, 0.9999]
2025-03-11 21:34:18 - Train Iteration 14414: loss: 0.0056, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.9250, 0.9997]
2025-03-11 21:34:18 - Train Iteration 14415: loss: 0.0008, d_k_M range: [0.0000, 0.0288], d_k_M_hat range: [0.9893, 1.0000]
2025-03-11 21:34:19 - Train Iteration 14416: loss: 0.0015, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.9647, 0.9999]
2025-03-11 21:34:19 - Train Iteration 14417: loss: 0.0933, d_k_M range: [0.0000, 0.3054], d_k_M_hat range: [0.9891, 0.9999]
2025-03-11 21:34:20 - Train Iteration 14418: loss: 0.0104, d_k_M range: [0.0000, 0.0164], d_k_M_hat range: [0.8994, 0.9998]
2025-03-11 21:34:20 - Train Iteration 14419: loss: 0.0594, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.7563, 0.9999]
2025-03-11 21:34:21 - Train Iteration 14420: loss: 0.0058, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.9243, 0.9997]
2025-03-11 21:34:21 - Train Iteration 14421: loss: 0.0066, d_k_M range: [0.0000, 0.0803], d_k_M_hat range: [0.9297, 0.9997]
2025-03-11 21:34:21 - Train Iteration 14422: loss: 0.0039, d_k_M range: [0.0000, 0.0625], d_k_M_hat range: [0.9941, 0.9999]
2025-03-11 21:34:22 - Train Iteration 14423: loss: 0.0058, d_k_M range: [0.0000, 0.0762], d_k_M_hat range: [0.9874, 1.0000]
2025-03-11 21:34:22 - Train Iteration 14424: loss: 0.0163, d_k_M range: [0.0000, 0.0079], d_k_M_hat range: [0.8722, 0.9997]
2025-03-11 21:34:23 - Train Iteration 14425: loss: 0.9443, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.0282, 0.9990]
2025-03-11 21:34:23 - Train Iteration 14426: loss: 0.0142, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.8811, 0.9993]
2025-03-11 21:34:24 - Train Iteration 14427: loss: 0.0008, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9715, 0.9995]
2025-03-11 21:34:24 - Train Iteration 14428: loss: 0.0001, d_k_M range: [0.0000, 0.0055], d_k_M_hat range: [0.9919, 0.9999]
2025-03-11 21:34:24 - Train Iteration 14429: loss: 0.0092, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9043, 0.9994]
2025-03-11 21:34:25 - Train Iteration 14430: loss: 0.0236, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.8462, 0.9998]
2025-03-11 21:34:25 - Train Iteration 14431: loss: 0.0003, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9832, 0.9994]
2025-03-11 21:34:26 - Train Iteration 14432: loss: 0.0091, d_k_M range: [0.0000, 0.0284], d_k_M_hat range: [0.9047, 1.0000]
2025-03-11 21:34:26 - Train Iteration 14433: loss: 0.0004, d_k_M range: [0.0000, 0.0176], d_k_M_hat range: [0.9805, 0.9996]
2025-03-11 21:34:27 - Train Iteration 14434: loss: 0.0007, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9737, 0.9999]
2025-03-11 21:34:27 - Train Iteration 14435: loss: 0.0002, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9858, 0.9997]
2025-03-11 21:34:28 - Train Iteration 14436: loss: 0.5250, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.2755, 0.9960]
2025-03-11 21:34:28 - Train Iteration 14437: loss: 0.6469, d_k_M range: [0.0003, 0.8042], d_k_M_hat range: [0.9965, 0.9999]
2025-03-11 21:34:29 - Train Iteration 14438: loss: 0.0205, d_k_M range: [0.0000, 0.0471], d_k_M_hat range: [0.8572, 0.9997]
2025-03-11 21:34:29 - Train Iteration 14439: loss: 0.0051, d_k_M range: [0.0000, 0.0337], d_k_M_hat range: [0.9291, 0.9997]
2025-03-11 21:34:30 - Train Iteration 14440: loss: 0.0177, d_k_M range: [0.0000, 0.1288], d_k_M_hat range: [0.9873, 0.9999]
2025-03-11 21:34:30 - Train Iteration 14441: loss: 0.0007, d_k_M range: [0.0000, 0.0252], d_k_M_hat range: [0.9749, 0.9995]
2025-03-11 21:34:31 - Train Iteration 14442: loss: 0.0004, d_k_M range: [0.0006, 0.0186], d_k_M_hat range: [0.9939, 0.9997]
2025-03-11 21:34:31 - Train Iteration 14443: loss: 0.0096, d_k_M range: [0.0000, 0.0083], d_k_M_hat range: [0.9020, 0.9985]
2025-03-11 21:34:32 - Train Iteration 14444: loss: 0.0008, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.9715, 0.9998]
2025-03-11 21:34:32 - Train Iteration 14445: loss: 0.0043, d_k_M range: [0.0000, 0.0653], d_k_M_hat range: [0.9405, 0.9998]
2025-03-11 21:34:32 - Train Iteration 14446: loss: 0.7659, d_k_M range: [0.0000, 0.8751], d_k_M_hat range: [0.9744, 0.9999]
2025-03-11 21:34:33 - Train Iteration 14447: loss: 0.0008, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9738, 0.9998]
2025-03-11 21:34:33 - Train Iteration 14448: loss: 0.0055, d_k_M range: [0.0000, 0.0337], d_k_M_hat range: [0.9259, 0.9998]
2025-03-11 21:34:34 - Train Iteration 14449: loss: 0.0030, d_k_M range: [0.0001, 0.0509], d_k_M_hat range: [0.9829, 0.9992]
2025-03-11 21:34:34 - Train Iteration 14450: loss: 0.0001, d_k_M range: [0.0000, 0.0078], d_k_M_hat range: [0.9891, 0.9988]
2025-03-11 21:34:35 - Train Iteration 14451: loss: 0.0009, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.9701, 0.9990]
2025-03-11 21:34:35 - Train Iteration 14452: loss: 0.0182, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.8654, 0.9991]
2025-03-11 21:34:35 - Train Iteration 14453: loss: 0.0027, d_k_M range: [0.0000, 0.0424], d_k_M_hat range: [0.9901, 0.9987]
2025-03-11 21:34:36 - Train Iteration 14454: loss: 0.1117, d_k_M range: [0.0000, 0.0602], d_k_M_hat range: [0.6658, 0.9997]
2025-03-11 21:34:36 - Train Iteration 14455: loss: 0.0029, d_k_M range: [0.0012, 0.0524], d_k_M_hat range: [0.9916, 0.9995]
2025-03-11 21:34:37 - Train Iteration 14456: loss: 0.0008, d_k_M range: [0.0000, 0.0276], d_k_M_hat range: [0.9745, 1.0000]
2025-03-11 21:34:37 - Train Iteration 14457: loss: 0.0018, d_k_M range: [0.0000, 0.0157], d_k_M_hat range: [0.9574, 0.9999]
2025-03-11 21:34:38 - Train Iteration 14458: loss: 0.0063, d_k_M range: [0.0000, 0.0055], d_k_M_hat range: [0.9205, 0.9998]
2025-03-11 21:34:38 - Train Iteration 14459: loss: 0.0005, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.9787, 0.9993]
2025-03-11 21:34:39 - Train Iteration 14460: loss: 0.0012, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9660, 0.9993]
2025-03-11 21:34:39 - Train Iteration 14461: loss: 0.0862, d_k_M range: [0.0000, 0.0030], d_k_M_hat range: [0.7064, 0.9974]
2025-03-11 21:34:40 - Train Iteration 14462: loss: 0.0001, d_k_M range: [0.0000, 0.0106], d_k_M_hat range: [0.9925, 0.9996]
2025-03-11 21:34:40 - Train Iteration 14463: loss: 0.0116, d_k_M range: [0.0000, 0.0483], d_k_M_hat range: [0.9408, 0.9990]
2025-03-11 21:34:41 - Train Iteration 14464: loss: 0.0003, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9847, 0.9992]
2025-03-11 21:34:41 - Train Iteration 14465: loss: 0.0006, d_k_M range: [0.0000, 0.0150], d_k_M_hat range: [0.9749, 1.0000]
2025-03-11 21:34:41 - Train Iteration 14466: loss: 0.0005, d_k_M range: [0.0000, 0.0210], d_k_M_hat range: [0.9846, 0.9997]
2025-03-11 21:34:42 - Train Iteration 14467: loss: 0.0861, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.7066, 0.9998]
2025-03-11 21:34:42 - Train Iteration 14468: loss: 0.0002, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.9880, 0.9995]
2025-03-11 21:34:43 - Train Iteration 14469: loss: 0.0014, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9623, 0.9998]
2025-03-11 21:34:43 - Train Iteration 14470: loss: 0.0112, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.8954, 0.9989]
2025-03-11 21:34:44 - Train Iteration 14471: loss: 0.0136, d_k_M range: [0.0001, 0.0347], d_k_M_hat range: [0.8859, 0.9992]
2025-03-11 21:34:44 - Train Iteration 14472: loss: 0.0024, d_k_M range: [0.0000, 0.0065], d_k_M_hat range: [0.9509, 0.9991]
2025-03-11 21:34:45 - Train Iteration 14473: loss: 0.0059, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9232, 0.9984]
2025-03-11 21:34:45 - Train Iteration 14474: loss: 0.2163, d_k_M range: [0.0000, 0.0476], d_k_M_hat range: [0.5472, 0.9998]
2025-03-11 21:34:46 - Train Iteration 14475: loss: 0.0002, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9855, 0.9996]
2025-03-11 21:34:46 - Train Iteration 14476: loss: 0.0002, d_k_M range: [0.0000, 0.0135], d_k_M_hat range: [0.9957, 0.9998]
2025-03-11 21:34:47 - Train Iteration 14477: loss: 0.0004, d_k_M range: [0.0000, 0.0202], d_k_M_hat range: [0.9912, 0.9999]
2025-03-11 21:34:47 - Train Iteration 14478: loss: 0.0026, d_k_M range: [0.0000, 0.0502], d_k_M_hat range: [0.9924, 0.9997]
2025-03-11 21:34:48 - Train Iteration 14479: loss: 0.0003, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9833, 0.9999]
2025-03-11 21:34:48 - Train Iteration 14480: loss: 0.1673, d_k_M range: [0.0001, 0.4087], d_k_M_hat range: [0.9951, 0.9999]
2025-03-11 21:34:49 - Train Iteration 14481: loss: 0.0007, d_k_M range: [0.0002, 0.0253], d_k_M_hat range: [0.9868, 1.0000]
2025-03-11 21:34:49 - Train Iteration 14482: loss: 0.0182, d_k_M range: [0.0000, 0.0159], d_k_M_hat range: [0.8652, 0.9986]
2025-03-11 21:34:49 - Train Iteration 14483: loss: 0.0006, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.9750, 0.9999]
2025-03-11 21:34:50 - Train Iteration 14484: loss: 0.0399, d_k_M range: [0.0000, 0.0479], d_k_M_hat range: [0.8003, 0.9997]
2025-03-11 21:34:50 - Train Iteration 14485: loss: 0.0025, d_k_M range: [0.0000, 0.0139], d_k_M_hat range: [0.9501, 0.9994]
2025-03-11 21:34:51 - Train Iteration 14486: loss: 0.0059, d_k_M range: [0.0000, 0.0048], d_k_M_hat range: [0.9234, 0.9999]
2025-03-11 21:34:51 - Train Iteration 14487: loss: 0.0003, d_k_M range: [0.0001, 0.0008], d_k_M_hat range: [0.9844, 0.9998]
2025-03-11 21:34:52 - Train Iteration 14488: loss: 0.0172, d_k_M range: [0.0001, 0.0225], d_k_M_hat range: [0.8689, 0.9987]
2025-03-11 21:34:52 - Train Iteration 14489: loss: 0.0934, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.6947, 0.9994]
2025-03-11 21:34:53 - Train Iteration 14490: loss: 0.0013, d_k_M range: [0.0001, 0.0120], d_k_M_hat range: [0.9700, 0.9999]
2025-03-11 21:34:53 - Train Iteration 14491: loss: 0.1114, d_k_M range: [0.0000, 0.0732], d_k_M_hat range: [0.6663, 0.9999]
2025-03-11 21:34:54 - Train Iteration 14492: loss: 0.2173, d_k_M range: [0.0000, 0.4634], d_k_M_hat range: [0.9973, 0.9998]
2025-03-11 21:34:54 - Train Iteration 14493: loss: 0.0026, d_k_M range: [0.0000, 0.0099], d_k_M_hat range: [0.9508, 0.9996]
2025-03-11 21:34:54 - Train Iteration 14494: loss: 0.0137, d_k_M range: [0.0000, 0.1169], d_k_M_hat range: [0.9849, 1.0000]
2025-03-11 21:34:55 - Train Iteration 14495: loss: 0.1037, d_k_M range: [0.0000, 0.3220], d_k_M_hat range: [0.9970, 1.0000]
2025-03-11 21:34:55 - Train Iteration 14496: loss: 0.0002, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.9862, 0.9998]
2025-03-11 21:34:56 - Train Iteration 14497: loss: 0.0002, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9903, 0.9995]
2025-03-11 21:34:56 - Train Iteration 14498: loss: 0.1251, d_k_M range: [0.0000, 0.3535], d_k_M_hat range: [0.9835, 0.9997]
2025-03-11 21:34:57 - Train Iteration 14499: loss: 0.0789, d_k_M range: [0.0000, 0.0182], d_k_M_hat range: [0.7191, 0.9998]
2025-03-11 21:34:57 - Train Iteration 14500: loss: 0.0083, d_k_M range: [0.0000, 0.0902], d_k_M_hat range: [0.9858, 0.9998]
2025-03-11 21:34:57 - Train Iteration 14501: loss: 0.0170, d_k_M range: [0.0002, 0.1304], d_k_M_hat range: [0.9349, 0.9999]
2025-03-11 21:34:58 - Train Iteration 14502: loss: 0.0001, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9945, 0.9997]
2025-03-11 21:34:58 - Train Iteration 14503: loss: 0.0387, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.8032, 0.9991]
2025-03-11 21:34:59 - Train Iteration 14504: loss: 0.0501, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.7763, 0.9992]
2025-03-11 21:34:59 - Train Iteration 14505: loss: 0.0049, d_k_M range: [0.0000, 0.0698], d_k_M_hat range: [0.9909, 0.9997]
2025-03-11 21:35:00 - Train Iteration 14506: loss: 0.0189, d_k_M range: [0.0000, 0.1368], d_k_M_hat range: [0.9029, 0.9992]
2025-03-11 21:35:00 - Train Iteration 14507: loss: 0.0062, d_k_M range: [0.0000, 0.0766], d_k_M_hat range: [0.9906, 0.9997]
2025-03-11 21:35:01 - Train Iteration 14508: loss: 0.0098, d_k_M range: [0.0000, 0.0510], d_k_M_hat range: [0.9012, 0.9994]
2025-03-11 21:35:01 - Train Iteration 14509: loss: 0.0002, d_k_M range: [0.0000, 0.0094], d_k_M_hat range: [0.9871, 0.9998]
2025-03-11 21:35:02 - Train Iteration 14510: loss: 0.0113, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.8938, 0.9989]
2025-03-11 21:35:02 - Train Iteration 14511: loss: 0.0102, d_k_M range: [0.0000, 0.1010], d_k_M_hat range: [0.9812, 0.9998]
2025-03-11 21:35:03 - Train Iteration 14512: loss: 0.0032, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9432, 0.9994]
2025-03-11 21:35:03 - Train Iteration 14513: loss: 0.0119, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.8914, 0.9999]
2025-03-11 21:35:03 - Train Iteration 14514: loss: 0.0005, d_k_M range: [0.0000, 0.0070], d_k_M_hat range: [0.9795, 0.9998]
2025-03-11 21:35:04 - Train Iteration 14515: loss: 0.0015, d_k_M range: [0.0000, 0.0345], d_k_M_hat range: [0.9955, 0.9997]
2025-03-11 21:35:04 - Train Iteration 14516: loss: 0.0021, d_k_M range: [0.0000, 0.0364], d_k_M_hat range: [0.9574, 0.9994]
2025-03-11 21:35:05 - Train Iteration 14517: loss: 0.0020, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9555, 0.9993]
2025-03-11 21:35:05 - Train Iteration 14518: loss: 0.0013, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9636, 0.9996]
2025-03-11 21:35:06 - Train Iteration 14519: loss: 0.0000, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9955, 0.9998]
2025-03-11 21:35:06 - Train Iteration 14520: loss: 0.0032, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9443, 0.9999]
2025-03-11 21:35:06 - Train Iteration 14521: loss: 0.0052, d_k_M range: [0.0000, 0.0192], d_k_M_hat range: [0.9304, 1.0000]
2025-03-11 21:35:07 - Train Iteration 14522: loss: 0.0131, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.8854, 0.9996]
2025-03-11 21:35:07 - Train Iteration 14523: loss: 0.0052, d_k_M range: [0.0000, 0.0709], d_k_M_hat range: [0.9922, 1.0000]
2025-03-11 21:35:08 - Train Iteration 14524: loss: 0.0019, d_k_M range: [0.0000, 0.0397], d_k_M_hat range: [0.9958, 1.0000]
2025-03-11 21:35:08 - Train Iteration 14525: loss: 0.0001, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9879, 0.9996]
2025-03-11 21:35:08 - Train Iteration 14526: loss: 0.0001, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9911, 0.9996]
2025-03-11 21:35:09 - Train Iteration 14527: loss: 0.0007, d_k_M range: [0.0000, 0.0154], d_k_M_hat range: [0.9735, 0.9998]
2025-03-11 21:35:09 - Train Iteration 14528: loss: 0.0050, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.9296, 0.9998]
2025-03-11 21:35:10 - Train Iteration 14529: loss: 0.0021, d_k_M range: [0.0000, 0.0123], d_k_M_hat range: [0.9544, 0.9993]
2025-03-11 21:35:10 - Train Iteration 14530: loss: 0.0211, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.8592, 0.9950]
2025-03-11 21:35:11 - Train Iteration 14531: loss: 0.0005, d_k_M range: [0.0000, 0.0048], d_k_M_hat range: [0.9795, 0.9992]
2025-03-11 21:35:11 - Train Iteration 14532: loss: 0.0010, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9683, 0.9998]
2025-03-11 21:35:12 - Train Iteration 14533: loss: 0.0019, d_k_M range: [0.0000, 0.0418], d_k_M_hat range: [0.9654, 0.9999]
2025-03-11 21:35:12 - Train Iteration 14534: loss: 0.0011, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.9666, 0.9997]
2025-03-11 21:35:13 - Train Iteration 14535: loss: 0.0439, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.7905, 0.9986]
2025-03-11 21:35:13 - Train Iteration 14536: loss: 0.0325, d_k_M range: [0.0000, 0.0424], d_k_M_hat range: [0.8197, 0.9989]
2025-03-11 21:35:14 - Train Iteration 14537: loss: 0.0014, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9635, 0.9989]
2025-03-11 21:35:14 - Train Iteration 14538: loss: 0.0388, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.8031, 0.9950]
2025-03-11 21:35:14 - Train Iteration 14539: loss: 0.1308, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.6384, 0.9999]
2025-03-11 21:35:15 - Train Iteration 14540: loss: 0.0009, d_k_M range: [0.0000, 0.0293], d_k_M_hat range: [0.9919, 1.0000]
2025-03-11 21:35:15 - Train Iteration 14541: loss: 0.0081, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.9098, 0.9997]
2025-03-11 21:35:16 - Train Iteration 14542: loss: 0.0054, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9267, 0.9997]
2025-03-11 21:35:16 - Train Iteration 14543: loss: 0.0007, d_k_M range: [0.0001, 0.0169], d_k_M_hat range: [0.9898, 1.0000]
2025-03-11 21:35:17 - Train Iteration 14544: loss: 0.0021, d_k_M range: [0.0000, 0.0445], d_k_M_hat range: [0.9844, 0.9997]
2025-03-11 21:35:17 - Train Iteration 14545: loss: 0.0006, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.9758, 0.9988]
2025-03-11 21:35:17 - Train Iteration 14546: loss: 0.0003, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9818, 0.9996]
2025-03-11 21:35:18 - Train Iteration 14547: loss: 0.0008, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9719, 0.9989]
2025-03-11 21:35:18 - Train Iteration 14548: loss: 0.0003, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9836, 0.9995]
2025-03-11 21:35:19 - Train Iteration 14549: loss: 0.0005, d_k_M range: [0.0000, 0.0230], d_k_M_hat range: [0.9973, 0.9998]
2025-03-11 21:35:19 - Train Iteration 14550: loss: 0.0386, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.8036, 0.9997]
2025-03-11 21:35:19 - Train Iteration 14551: loss: 0.0002, d_k_M range: [0.0007, 0.0147], d_k_M_hat range: [0.9988, 0.9998]
2025-03-11 21:35:20 - Train Iteration 14552: loss: 0.5210, d_k_M range: [0.0000, 0.7214], d_k_M_hat range: [0.9831, 0.9997]
2025-03-11 21:35:20 - Train Iteration 14553: loss: 0.0005, d_k_M range: [0.0000, 0.0216], d_k_M_hat range: [0.9873, 0.9999]
2025-03-11 21:35:21 - Train Iteration 14554: loss: 0.0002, d_k_M range: [0.0000, 0.0139], d_k_M_hat range: [0.9867, 0.9999]
2025-03-11 21:35:21 - Train Iteration 14555: loss: 0.4450, d_k_M range: [0.0000, 0.6669], d_k_M_hat range: [0.9254, 0.9998]
2025-03-11 21:35:22 - Train Iteration 14556: loss: 0.0061, d_k_M range: [0.0000, 0.0236], d_k_M_hat range: [0.9457, 0.9992]
2025-03-11 21:35:22 - Train Iteration 14557: loss: 0.0022, d_k_M range: [0.0000, 0.0349], d_k_M_hat range: [0.9533, 0.9998]
2025-03-11 21:35:22 - Train Iteration 14558: loss: 0.1164, d_k_M range: [0.0000, 0.3392], d_k_M_hat range: [0.9729, 1.0000]
2025-03-11 21:35:23 - Train Iteration 14559: loss: 0.0000, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9943, 0.9998]
2025-03-11 21:35:23 - Train Iteration 14560: loss: 0.0008, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9727, 0.9998]
2025-03-11 21:35:24 - Train Iteration 14561: loss: 0.0018, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.9582, 0.9999]
2025-03-11 21:35:24 - Train Iteration 14562: loss: 0.0224, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.8506, 0.9998]
2025-03-11 21:35:25 - Train Iteration 14563: loss: 0.0014, d_k_M range: [0.0000, 0.0375], d_k_M_hat range: [0.9932, 0.9999]
2025-03-11 21:35:25 - Train Iteration 14564: loss: 0.0156, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.8751, 0.9987]
2025-03-11 21:35:25 - Train Iteration 14565: loss: 0.5459, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.2611, 0.9992]
2025-03-11 21:35:26 - Train Iteration 14566: loss: 0.0129, d_k_M range: [0.0001, 0.1133], d_k_M_hat range: [0.9797, 0.9999]
2025-03-11 21:35:26 - Train Iteration 14567: loss: 0.0043, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9382, 0.9998]
2025-03-11 21:35:27 - Train Iteration 14568: loss: 0.0069, d_k_M range: [0.0001, 0.0584], d_k_M_hat range: [0.9176, 0.9993]
2025-03-11 21:35:27 - Train Iteration 14569: loss: 0.0000, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.9934, 0.9997]
2025-03-11 21:35:27 - Train Iteration 14570: loss: 0.0028, d_k_M range: [0.0001, 0.0530], d_k_M_hat range: [0.9943, 0.9999]
2025-03-11 21:35:28 - Train Iteration 14571: loss: 0.0002, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9877, 0.9995]
2025-03-11 21:35:28 - Train Iteration 14572: loss: 0.0022, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9534, 0.9994]
2025-03-11 21:35:29 - Train Iteration 14573: loss: 0.0077, d_k_M range: [0.0000, 0.0747], d_k_M_hat range: [0.9125, 0.9998]
2025-03-11 21:35:29 - Train Iteration 14574: loss: 0.0101, d_k_M range: [0.0000, 0.0393], d_k_M_hat range: [0.8994, 0.9998]
2025-03-11 21:35:30 - Train Iteration 14575: loss: 0.0686, d_k_M range: [0.0000, 0.2616], d_k_M_hat range: [0.9966, 0.9997]
2025-03-11 21:35:30 - Train Iteration 14576: loss: 0.0024, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.9527, 0.9993]
2025-03-11 21:35:30 - Train Iteration 14577: loss: 0.0006, d_k_M range: [0.0000, 0.0170], d_k_M_hat range: [0.9756, 0.9999]
2025-03-11 21:35:31 - Train Iteration 14578: loss: 0.0846, d_k_M range: [0.0000, 0.2878], d_k_M_hat range: [0.9947, 0.9994]
2025-03-11 21:35:31 - Train Iteration 14579: loss: 0.1771, d_k_M range: [0.0000, 0.4200], d_k_M_hat range: [0.9938, 0.9999]
2025-03-11 21:35:32 - Train Iteration 14580: loss: 0.0005, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9778, 0.9997]
2025-03-11 21:35:32 - Train Iteration 14581: loss: 0.0012, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9654, 0.9996]
2025-03-11 21:35:33 - Train Iteration 14582: loss: 0.0005, d_k_M range: [0.0002, 0.0221], d_k_M_hat range: [0.9790, 1.0000]
2025-03-11 21:35:33 - Train Iteration 14583: loss: 0.0009, d_k_M range: [0.0000, 0.0289], d_k_M_hat range: [0.9987, 0.9999]
2025-03-11 21:35:34 - Train Iteration 14584: loss: 0.0004, d_k_M range: [0.0000, 0.0180], d_k_M_hat range: [0.9953, 0.9999]
2025-03-11 21:35:34 - Train Iteration 14585: loss: 0.0006, d_k_M range: [0.0000, 0.0103], d_k_M_hat range: [0.9753, 0.9999]
2025-03-11 21:35:34 - Train Iteration 14586: loss: 0.0006, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9761, 0.9998]
2025-03-11 21:35:35 - Train Iteration 14587: loss: 0.0001, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.9879, 0.9996]
2025-03-11 21:35:35 - Train Iteration 14588: loss: 0.6979, d_k_M range: [0.0000, 0.8351], d_k_M_hat range: [0.9990, 1.0000]
2025-03-11 21:35:36 - Train Iteration 14589: loss: 0.0017, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9588, 0.9997]
2025-03-11 21:35:36 - Train Iteration 14590: loss: 0.0001, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.9919, 0.9992]
2025-03-11 21:35:37 - Train Iteration 14591: loss: 0.0042, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9350, 0.9999]
2025-03-11 21:35:37 - Train Iteration 14592: loss: 0.1611, d_k_M range: [0.0000, 0.4014], d_k_M_hat range: [0.9652, 1.0000]
2025-03-11 21:35:37 - Train Iteration 14593: loss: 0.0157, d_k_M range: [0.0000, 0.1236], d_k_M_hat range: [0.9940, 1.0000]
2025-03-11 21:35:38 - Train Iteration 14594: loss: 0.0192, d_k_M range: [0.0000, 0.0206], d_k_M_hat range: [0.8613, 0.9999]
2025-03-11 21:35:38 - Train Iteration 14595: loss: 0.0155, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.8756, 0.9998]
2025-03-11 21:35:39 - Train Iteration 14596: loss: 0.5863, d_k_M range: [0.0000, 0.7656], d_k_M_hat range: [0.9886, 0.9999]
2025-03-11 21:35:39 - Train Iteration 14597: loss: 0.0050, d_k_M range: [0.0000, 0.0704], d_k_M_hat range: [0.9960, 0.9999]
2025-03-11 21:35:40 - Train Iteration 14598: loss: 0.0015, d_k_M range: [0.0000, 0.0078], d_k_M_hat range: [0.9608, 0.9995]
2025-03-11 21:35:40 - Train Iteration 14599: loss: 0.0008, d_k_M range: [0.0000, 0.0277], d_k_M_hat range: [0.9793, 0.9998]
2025-03-11 21:35:40 - Train Iteration 14600: loss: 0.0046, d_k_M range: [0.0000, 0.0199], d_k_M_hat range: [0.9323, 0.9997]
2025-03-11 21:35:41 - Train Iteration 14601: loss: 0.0018, d_k_M range: [0.0000, 0.0408], d_k_M_hat range: [0.9892, 0.9995]
2025-03-11 21:35:41 - Train Iteration 14602: loss: 0.0003, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9842, 0.9997]
2025-03-11 21:35:42 - Train Iteration 14603: loss: 0.0001, d_k_M range: [0.0000, 0.0079], d_k_M_hat range: [0.9898, 0.9996]
2025-03-11 21:35:42 - Train Iteration 14604: loss: 0.0001, d_k_M range: [0.0001, 0.0014], d_k_M_hat range: [0.9911, 0.9999]
2025-03-11 21:35:42 - Train Iteration 14605: loss: 0.4474, d_k_M range: [0.0000, 0.6684], d_k_M_hat range: [0.9413, 0.9997]
2025-03-11 21:35:43 - Train Iteration 14606: loss: 0.0057, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9248, 0.9998]
2025-03-11 21:35:43 - Train Iteration 14607: loss: 0.0021, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9540, 0.9996]
2025-03-11 21:35:44 - Train Iteration 14608: loss: 0.0005, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9785, 0.9991]
2025-03-11 21:35:44 - Train Iteration 14609: loss: 0.0009, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9709, 0.9992]
2025-03-11 21:35:45 - Train Iteration 14610: loss: 0.0002, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.9852, 0.9998]
2025-03-11 21:35:45 - Train Iteration 14611: loss: 0.0003, d_k_M range: [0.0000, 0.0154], d_k_M_hat range: [0.9814, 0.9995]
2025-03-11 21:35:45 - Train Iteration 14612: loss: 0.0028, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.9473, 0.9969]
2025-03-11 21:35:46 - Train Iteration 14613: loss: 0.0071, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9159, 0.9998]
2025-03-11 21:35:46 - Train Iteration 14614: loss: 0.0028, d_k_M range: [0.0000, 0.0149], d_k_M_hat range: [0.9479, 0.9986]
2025-03-11 21:35:47 - Train Iteration 14615: loss: 0.0003, d_k_M range: [0.0000, 0.0052], d_k_M_hat range: [0.9835, 0.9997]
2025-03-11 21:35:47 - Train Iteration 14616: loss: 0.0009, d_k_M range: [0.0000, 0.0105], d_k_M_hat range: [0.9692, 0.9973]
2025-03-11 21:35:47 - Train Iteration 14617: loss: 0.0004, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9794, 0.9990]
2025-03-11 21:35:48 - Train Iteration 14618: loss: 0.6513, d_k_M range: [0.0000, 0.8070], d_k_M_hat range: [0.9927, 1.0000]
2025-03-11 21:35:48 - Train Iteration 14619: loss: 0.3102, d_k_M range: [0.0000, 0.0145], d_k_M_hat range: [0.4431, 0.9993]
2025-03-11 21:35:49 - Train Iteration 14620: loss: 0.0004, d_k_M range: [0.0002, 0.0174], d_k_M_hat range: [0.9933, 0.9999]
2025-03-11 21:35:49 - Train Iteration 14621: loss: 0.0003, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9838, 0.9994]
2025-03-11 21:35:50 - Train Iteration 14622: loss: 0.0311, d_k_M range: [0.0000, 0.0077], d_k_M_hat range: [0.8236, 1.0000]
2025-03-11 21:35:50 - Train Iteration 14623: loss: 0.0292, d_k_M range: [0.0000, 0.0150], d_k_M_hat range: [0.8441, 0.9999]
2025-03-11 21:35:50 - Train Iteration 14624: loss: 0.0011, d_k_M range: [0.0001, 0.0325], d_k_M_hat range: [0.9951, 0.9999]
2025-03-11 21:35:51 - Train Iteration 14625: loss: 0.2764, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.4749, 0.9995]
2025-03-11 21:35:51 - Train Iteration 14626: loss: 0.0132, d_k_M range: [0.0000, 0.1131], d_k_M_hat range: [0.9972, 0.9999]
2025-03-11 21:35:52 - Train Iteration 14627: loss: 0.2124, d_k_M range: [0.0000, 0.4606], d_k_M_hat range: [0.9922, 0.9998]
2025-03-11 21:35:52 - Train Iteration 14628: loss: 0.1349, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.6327, 0.9997]
2025-03-11 21:35:52 - Train Iteration 14629: loss: 0.0003, d_k_M range: [0.0000, 0.0138], d_k_M_hat range: [0.9829, 0.9994]
2025-03-11 21:35:53 - Train Iteration 14630: loss: 0.0020, d_k_M range: [0.0000, 0.0431], d_k_M_hat range: [0.9980, 0.9999]
2025-03-11 21:35:53 - Train Iteration 14631: loss: 0.0011, d_k_M range: [0.0004, 0.0335], d_k_M_hat range: [0.9922, 1.0000]
2025-03-11 21:35:54 - Train Iteration 14632: loss: 0.0003, d_k_M range: [0.0001, 0.0122], d_k_M_hat range: [0.9834, 0.9999]
2025-03-11 21:35:54 - Train Iteration 14633: loss: 0.0001, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9923, 0.9999]
2025-03-11 21:35:55 - Train Iteration 14634: loss: 0.0570, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.7615, 0.9986]
2025-03-11 21:35:55 - Train Iteration 14635: loss: 0.0007, d_k_M range: [0.0000, 0.0240], d_k_M_hat range: [0.9892, 0.9999]
2025-03-11 21:35:56 - Train Iteration 14636: loss: 0.0016, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.9596, 0.9999]
2025-03-11 21:35:56 - Train Iteration 14637: loss: 0.0009, d_k_M range: [0.0000, 0.0047], d_k_M_hat range: [0.9695, 0.9994]
2025-03-11 21:35:57 - Train Iteration 14638: loss: 0.0008, d_k_M range: [0.0000, 0.0272], d_k_M_hat range: [0.9796, 0.9998]
2025-03-11 21:35:57 - Train Iteration 14639: loss: 0.0004, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9801, 0.9988]
2025-03-11 21:35:58 - Train Iteration 14640: loss: 0.0074, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.9144, 0.9999]
2025-03-11 21:35:58 - Train Iteration 14641: loss: 0.0009, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.9708, 0.9998]
2025-03-11 21:35:58 - Train Iteration 14642: loss: 0.0004, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9811, 0.9998]
2025-03-11 21:35:59 - Train Iteration 14643: loss: 0.0073, d_k_M range: [0.0000, 0.0601], d_k_M_hat range: [0.9747, 0.9999]
2025-03-11 21:35:59 - Train Iteration 14644: loss: 0.3805, d_k_M range: [0.0000, 0.6167], d_k_M_hat range: [0.9902, 1.0000]
2025-03-11 21:36:00 - Train Iteration 14645: loss: 0.0001, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9943, 0.9999]
2025-03-11 21:36:00 - Train Iteration 14646: loss: 0.0002, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.9856, 0.9998]
2025-03-11 21:36:01 - Train Iteration 14647: loss: 0.0003, d_k_M range: [0.0000, 0.0177], d_k_M_hat range: [0.9878, 0.9999]
2025-03-11 21:36:01 - Train Iteration 14648: loss: 0.2889, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.4625, 0.9965]
2025-03-11 21:36:01 - Train Iteration 14649: loss: 0.4976, d_k_M range: [0.0000, 0.7054], d_k_M_hat range: [0.9845, 1.0000]
2025-03-11 21:36:02 - Train Iteration 14650: loss: 0.0114, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.8933, 0.9988]
2025-03-11 21:36:02 - Train Iteration 14651: loss: 0.0020, d_k_M range: [0.0000, 0.0031], d_k_M_hat range: [0.9580, 0.9998]
2025-03-11 21:36:03 - Train Iteration 14652: loss: 0.0002, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.9847, 0.9999]
2025-03-11 21:36:03 - Train Iteration 14653: loss: 0.0096, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9024, 0.9998]
2025-03-11 21:36:04 - Train Iteration 14654: loss: 0.0002, d_k_M range: [0.0000, 0.0117], d_k_M_hat range: [0.9920, 0.9998]
2025-03-11 21:36:04 - Train Iteration 14655: loss: 0.8185, d_k_M range: [0.0000, 0.9040], d_k_M_hat range: [0.9874, 0.9999]
2025-03-11 21:36:04 - Train Iteration 14656: loss: 0.0165, d_k_M range: [0.0000, 0.1282], d_k_M_hat range: [0.9526, 0.9997]
2025-03-11 21:36:05 - Train Iteration 14657: loss: 0.0019, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9566, 0.9999]
2025-03-11 21:36:05 - Train Iteration 14658: loss: 0.0008, d_k_M range: [0.0000, 0.0275], d_k_M_hat range: [0.9899, 0.9997]
2025-03-11 21:36:06 - Train Iteration 14659: loss: 0.0011, d_k_M range: [0.0000, 0.0337], d_k_M_hat range: [0.9932, 1.0000]
2025-03-11 21:36:06 - Train Iteration 14660: loss: 0.0158, d_k_M range: [0.0000, 0.0154], d_k_M_hat range: [0.8743, 0.9998]
2025-03-11 21:36:06 - Train Iteration 14661: loss: 0.0139, d_k_M range: [0.0000, 0.1175], d_k_M_hat range: [0.9272, 0.9998]
2025-03-11 21:36:07 - Train Iteration 14662: loss: 0.0292, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.8290, 0.9998]
2025-03-11 21:36:07 - Train Iteration 14663: loss: 0.0086, d_k_M range: [0.0000, 0.0114], d_k_M_hat range: [0.9075, 0.9998]
2025-03-11 21:36:08 - Train Iteration 14664: loss: 0.0039, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9383, 0.9988]
2025-03-11 21:36:08 - Train Iteration 14665: loss: 0.0007, d_k_M range: [0.0001, 0.0250], d_k_M_hat range: [0.9966, 0.9999]
2025-03-11 21:36:09 - Train Iteration 14666: loss: 0.0020, d_k_M range: [0.0001, 0.0078], d_k_M_hat range: [0.9550, 0.9999]
2025-03-11 21:36:09 - Train Iteration 14667: loss: 0.0000, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9978, 1.0000]
2025-03-11 21:36:10 - Train Iteration 14668: loss: 0.0089, d_k_M range: [0.0000, 0.0940], d_k_M_hat range: [0.9964, 0.9999]
2025-03-11 21:36:10 - Train Iteration 14669: loss: 0.0006, d_k_M range: [0.0000, 0.0242], d_k_M_hat range: [0.9974, 0.9999]
2025-03-11 21:36:10 - Train Iteration 14670: loss: 0.0002, d_k_M range: [0.0000, 0.0056], d_k_M_hat range: [0.9867, 0.9997]
2025-03-11 21:36:11 - Train Iteration 14671: loss: 0.0001, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9930, 0.9999]
2025-03-11 21:36:11 - Train Iteration 14672: loss: 0.5194, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.2795, 0.9994]
2025-03-11 21:36:12 - Train Iteration 14673: loss: 0.6429, d_k_M range: [0.0000, 0.8015], d_k_M_hat range: [0.9917, 0.9999]
2025-03-11 21:36:12 - Train Iteration 14674: loss: 0.0051, d_k_M range: [0.0000, 0.0109], d_k_M_hat range: [0.9283, 0.9999]
2025-03-11 21:36:12 - Train Iteration 14675: loss: 0.3208, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.4336, 0.9996]
2025-03-11 21:36:13 - Train Iteration 14676: loss: 0.0000, d_k_M range: [0.0001, 0.0030], d_k_M_hat range: [0.9964, 0.9993]
2025-03-11 21:36:13 - Train Iteration 14677: loss: 0.2852, d_k_M range: [0.0000, 0.5338], d_k_M_hat range: [0.9890, 0.9998]
2025-03-11 21:36:14 - Train Iteration 14678: loss: 0.0990, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.6855, 0.9999]
2025-03-11 21:36:14 - Train Iteration 14679: loss: 0.0004, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.9812, 1.0000]
2025-03-11 21:36:15 - Train Iteration 14680: loss: 0.0007, d_k_M range: [0.0000, 0.0209], d_k_M_hat range: [0.9783, 0.9991]
2025-03-11 21:36:15 - Train Iteration 14681: loss: 0.0034, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9416, 0.9999]
2025-03-11 21:36:16 - Train Iteration 14682: loss: 0.0077, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9200, 0.9999]
2025-03-11 21:36:16 - Train Iteration 14683: loss: 0.0001, d_k_M range: [0.0000, 0.0025], d_k_M_hat range: [0.9917, 0.9995]
2025-03-11 21:36:16 - Train Iteration 14684: loss: 0.0618, d_k_M range: [0.0000, 0.2479], d_k_M_hat range: [0.9121, 0.9998]
2025-03-11 21:36:17 - Train Iteration 14685: loss: 0.0002, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9861, 0.9999]
2025-03-11 21:36:17 - Train Iteration 14686: loss: 0.0003, d_k_M range: [0.0000, 0.0127], d_k_M_hat range: [0.9837, 0.9999]
2025-03-11 21:36:18 - Train Iteration 14687: loss: 0.0010, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9692, 0.9997]
2025-03-11 21:36:18 - Train Iteration 14688: loss: 0.0002, d_k_M range: [0.0000, 0.0098], d_k_M_hat range: [0.9843, 0.9998]
2025-03-11 21:36:19 - Train Iteration 14689: loss: 0.1516, d_k_M range: [0.0001, 0.3893], d_k_M_hat range: [0.9908, 1.0000]
2025-03-11 21:36:19 - Train Iteration 14690: loss: 0.0007, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9731, 0.9997]
2025-03-11 21:36:20 - Train Iteration 14691: loss: 0.0824, d_k_M range: [0.0000, 0.0581], d_k_M_hat range: [0.7711, 0.9987]
2025-03-11 21:36:20 - Train Iteration 14692: loss: 0.0014, d_k_M range: [0.0000, 0.0228], d_k_M_hat range: [0.9627, 0.9996]
2025-03-11 21:36:20 - Train Iteration 14693: loss: 0.0549, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.7657, 0.9990]
2025-03-11 21:36:21 - Train Iteration 14694: loss: 0.0003, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9828, 0.9992]
2025-03-11 21:36:21 - Train Iteration 14695: loss: 0.0001, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9887, 0.9998]
2025-03-11 21:36:22 - Train Iteration 14696: loss: 0.0002, d_k_M range: [0.0000, 0.0112], d_k_M_hat range: [0.9849, 0.9998]
2025-03-11 21:36:22 - Train Iteration 14697: loss: 0.0001, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9929, 0.9995]
2025-03-11 21:36:23 - Train Iteration 14698: loss: 0.0004, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9795, 0.9992]
2025-03-11 21:36:23 - Train Iteration 14699: loss: 0.0170, d_k_M range: [0.0000, 0.1176], d_k_M_hat range: [0.9871, 0.9999]
2025-03-11 21:36:23 - Train Iteration 14700: loss: 0.0199, d_k_M range: [0.0001, 0.1409], d_k_M_hat range: [0.9707, 1.0000]
2025-03-11 21:36:24 - Train Iteration 14701: loss: 0.0545, d_k_M range: [0.0001, 0.0355], d_k_M_hat range: [0.7666, 1.0000]
2025-03-11 21:36:24 - Train Iteration 14702: loss: 0.0074, d_k_M range: [0.0001, 0.0845], d_k_M_hat range: [0.9972, 1.0000]
2025-03-11 21:36:25 - Train Iteration 14703: loss: 0.0002, d_k_M range: [0.0000, 0.0121], d_k_M_hat range: [0.9912, 0.9998]
2025-03-11 21:36:25 - Train Iteration 14704: loss: 0.0015, d_k_M range: [0.0000, 0.0388], d_k_M_hat range: [0.9881, 0.9999]
2025-03-11 21:36:26 - Train Iteration 14705: loss: 0.0001, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9881, 0.9999]
2025-03-11 21:36:26 - Train Iteration 14706: loss: 0.0013, d_k_M range: [0.0000, 0.0104], d_k_M_hat range: [0.9643, 0.9993]
2025-03-11 21:36:26 - Train Iteration 14707: loss: 0.0001, d_k_M range: [0.0000, 0.0110], d_k_M_hat range: [0.9976, 0.9999]
2025-03-11 21:36:27 - Train Iteration 14708: loss: 0.0293, d_k_M range: [0.0000, 0.1709], d_k_M_hat range: [0.9945, 0.9999]
2025-03-11 21:36:27 - Train Iteration 14709: loss: 0.0033, d_k_M range: [0.0000, 0.0049], d_k_M_hat range: [0.9433, 1.0000]
2025-03-11 21:36:28 - Train Iteration 14710: loss: 0.1065, d_k_M range: [0.0000, 0.2302], d_k_M_hat range: [0.9039, 0.9993]
2025-03-11 21:36:28 - Train Iteration 14711: loss: 0.0002, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9855, 0.9996]
2025-03-11 21:36:28 - Train Iteration 14712: loss: 0.0135, d_k_M range: [0.0004, 0.0989], d_k_M_hat range: [0.9827, 0.9999]
2025-03-11 21:36:29 - Train Iteration 14713: loss: 0.0007, d_k_M range: [0.0000, 0.0253], d_k_M_hat range: [0.9932, 0.9999]
2025-03-11 21:36:29 - Train Iteration 14714: loss: 0.0000, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9973, 0.9998]
2025-03-11 21:36:30 - Train Iteration 14715: loss: 0.0192, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.8614, 0.9999]
2025-03-11 21:36:30 - Train Iteration 14716: loss: 0.0004, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9805, 0.9998]
2025-03-11 21:36:31 - Train Iteration 14717: loss: 0.0184, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.8645, 0.9990]
2025-03-11 21:36:31 - Train Iteration 14718: loss: 0.0003, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9814, 0.9999]
2025-03-11 21:36:31 - Train Iteration 14719: loss: 0.0021, d_k_M range: [0.0000, 0.0096], d_k_M_hat range: [0.9542, 0.9999]
2025-03-11 21:36:32 - Train Iteration 14720: loss: 0.0001, d_k_M range: [0.0000, 0.0032], d_k_M_hat range: [0.9919, 0.9999]
2025-03-11 21:36:32 - Train Iteration 14721: loss: 0.0011, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.9670, 0.9997]
2025-03-11 21:36:33 - Train Iteration 14722: loss: 0.0009, d_k_M range: [0.0000, 0.0302], d_k_M_hat range: [0.9978, 1.0000]
2025-03-11 21:36:33 - Train Iteration 14723: loss: 0.0030, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.9456, 0.9997]
2025-03-11 21:36:34 - Train Iteration 14724: loss: 0.2509, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.4991, 0.9932]
2025-03-11 21:36:34 - Train Iteration 14725: loss: 0.0052, d_k_M range: [0.0000, 0.0720], d_k_M_hat range: [0.9993, 1.0000]
2025-03-11 21:36:34 - Train Iteration 14726: loss: 0.0001, d_k_M range: [0.0000, 0.0091], d_k_M_hat range: [0.9962, 0.9998]
2025-03-11 21:36:35 - Train Iteration 14727: loss: 0.0019, d_k_M range: [0.0000, 0.0182], d_k_M_hat range: [0.9579, 0.9998]
2025-03-11 21:36:35 - Train Iteration 14728: loss: 0.0711, d_k_M range: [0.0002, 0.2649], d_k_M_hat range: [0.9885, 0.9996]
2025-03-11 21:36:36 - Train Iteration 14729: loss: 0.0001, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9943, 0.9996]
2025-03-11 21:36:36 - Train Iteration 14730: loss: 0.0000, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9977, 0.9998]
2025-03-11 21:36:37 - Train Iteration 14731: loss: 0.0016, d_k_M range: [0.0000, 0.0395], d_k_M_hat range: [0.9774, 0.9998]
2025-03-11 21:36:37 - Train Iteration 14732: loss: 0.0001, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9930, 0.9996]
2025-03-11 21:36:38 - Train Iteration 14733: loss: 0.0006, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9755, 0.9999]
2025-03-11 21:36:38 - Train Iteration 14734: loss: 0.0104, d_k_M range: [0.0000, 0.1021], d_k_M_hat range: [0.9894, 0.9999]
2025-03-11 21:36:38 - Train Iteration 14735: loss: 0.0001, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9878, 0.9998]
2025-03-11 21:36:39 - Train Iteration 14736: loss: 0.0017, d_k_M range: [0.0001, 0.0077], d_k_M_hat range: [0.9597, 0.9992]
2025-03-11 21:36:39 - Train Iteration 14737: loss: 0.0001, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9916, 0.9998]
2025-03-11 21:36:40 - Train Iteration 14738: loss: 0.0086, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9075, 0.9997]
2025-03-11 21:36:40 - Train Iteration 14739: loss: 0.0003, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9823, 0.9972]
2025-03-11 21:36:41 - Train Iteration 14740: loss: 0.0163, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.8723, 0.9999]
2025-03-11 21:36:41 - Train Iteration 14741: loss: 0.0552, d_k_M range: [0.0001, 0.2336], d_k_M_hat range: [0.9964, 0.9998]
2025-03-11 21:36:42 - Train Iteration 14742: loss: 0.0000, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9948, 0.9999]
2025-03-11 21:36:42 - Train Iteration 14743: loss: 0.0049, d_k_M range: [0.0000, 0.0151], d_k_M_hat range: [0.9298, 0.9999]
2025-03-11 21:36:42 - Train Iteration 14744: loss: 0.0032, d_k_M range: [0.0000, 0.0036], d_k_M_hat range: [0.9436, 0.9996]
2025-03-11 21:36:43 - Train Iteration 14745: loss: 0.0002, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9876, 0.9999]
2025-03-11 21:36:43 - Train Iteration 14746: loss: 0.0001, d_k_M range: [0.0000, 0.0019], d_k_M_hat range: [0.9909, 0.9999]
2025-03-11 21:36:44 - Train Iteration 14747: loss: 0.6634, d_k_M range: [0.0000, 0.8144], d_k_M_hat range: [0.9993, 1.0000]
2025-03-11 21:36:44 - Train Iteration 14748: loss: 0.0002, d_k_M range: [0.0000, 0.0092], d_k_M_hat range: [0.9858, 0.9999]
2025-03-11 21:36:45 - Train Iteration 14749: loss: 0.0095, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9046, 0.9999]
2025-03-11 21:36:45 - Train Iteration 14750: loss: 0.0000, d_k_M range: [0.0000, 0.0059], d_k_M_hat range: [0.9978, 0.9999]
2025-03-11 21:36:45 - Train Iteration 14751: loss: 0.0004, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.9791, 0.9996]
2025-03-11 21:36:46 - Train Iteration 14752: loss: 0.0278, d_k_M range: [0.0000, 0.1632], d_k_M_hat range: [0.9877, 1.0000]
2025-03-11 21:36:46 - Train Iteration 14753: loss: 0.0287, d_k_M range: [0.0000, 0.1631], d_k_M_hat range: [0.9701, 0.9993]
2025-03-11 21:36:47 - Train Iteration 14754: loss: 0.0437, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.7925, 0.9996]
2025-03-11 21:36:47 - Train Iteration 14755: loss: 0.0044, d_k_M range: [0.0000, 0.0302], d_k_M_hat range: [0.9338, 0.9998]
2025-03-11 21:36:47 - Train Iteration 14756: loss: 0.0002, d_k_M range: [0.0000, 0.0068], d_k_M_hat range: [0.9863, 0.9999]
2025-03-11 21:36:48 - Train Iteration 14757: loss: 0.0001, d_k_M range: [0.0001, 0.0090], d_k_M_hat range: [0.9962, 0.9998]
2025-03-11 21:36:48 - Train Iteration 14758: loss: 0.0001, d_k_M range: [0.0000, 0.0026], d_k_M_hat range: [0.9912, 0.9997]
2025-03-11 21:36:49 - Train Iteration 14759: loss: 0.0013, d_k_M range: [0.0000, 0.0085], d_k_M_hat range: [0.9654, 0.9999]
2025-03-11 21:36:49 - Train Iteration 14760: loss: 0.0242, d_k_M range: [0.0000, 0.1528], d_k_M_hat range: [0.9855, 0.9997]
2025-03-11 21:36:50 - Train Iteration 14761: loss: 0.0001, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9926, 0.9996]
2025-03-11 21:36:50 - Train Iteration 14762: loss: 0.0000, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.9934, 0.9999]
2025-03-11 21:36:50 - Train Iteration 14763: loss: 0.0678, d_k_M range: [0.0000, 0.2597], d_k_M_hat range: [0.9921, 0.9999]
2025-03-11 21:36:51 - Train Iteration 14764: loss: 0.0041, d_k_M range: [0.0000, 0.0038], d_k_M_hat range: [0.9366, 0.9989]
2025-03-11 21:36:51 - Train Iteration 14765: loss: 0.0037, d_k_M range: [0.0000, 0.0541], d_k_M_hat range: [0.9392, 0.9989]
2025-03-11 21:36:52 - Train Iteration 14766: loss: 0.0003, d_k_M range: [0.0000, 0.0029], d_k_M_hat range: [0.9861, 1.0000]
2025-03-11 21:36:52 - Train Iteration 14767: loss: 0.0004, d_k_M range: [0.0001, 0.0095], d_k_M_hat range: [0.9797, 0.9992]
2025-03-11 21:36:53 - Train Iteration 14768: loss: 0.0004, d_k_M range: [0.0000, 0.0175], d_k_M_hat range: [0.9978, 1.0000]
2025-03-11 21:36:53 - Train Iteration 14769: loss: 0.0011, d_k_M range: [0.0000, 0.0316], d_k_M_hat range: [0.9976, 0.9999]
2025-03-11 21:36:54 - Train Iteration 14770: loss: 0.0000, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.9972, 0.9998]
2025-03-11 21:36:54 - Train Iteration 14771: loss: 0.0002, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.9856, 0.9997]
2025-03-11 21:36:55 - Train Iteration 14772: loss: 0.0012, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9660, 0.9994]
2025-03-11 21:36:55 - Train Iteration 14773: loss: 0.0001, d_k_M range: [0.0000, 0.0082], d_k_M_hat range: [0.9971, 0.9999]
2025-03-11 21:36:55 - Train Iteration 14774: loss: 0.0021, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9538, 0.9998]
2025-03-11 21:36:56 - Train Iteration 14775: loss: 0.0053, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9291, 0.9996]
2025-03-11 21:36:56 - Train Iteration 14776: loss: 0.0019, d_k_M range: [0.0000, 0.0425], d_k_M_hat range: [0.9885, 0.9999]
2025-03-11 21:36:57 - Train Iteration 14777: loss: 0.0020, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9552, 0.9998]
2025-03-11 21:36:57 - Train Iteration 14778: loss: 0.0043, d_k_M range: [0.0000, 0.0037], d_k_M_hat range: [0.9347, 0.9995]
2025-03-11 21:36:58 - Train Iteration 14779: loss: 0.0684, d_k_M range: [0.0000, 0.0267], d_k_M_hat range: [0.7390, 0.9999]
2025-03-11 21:36:58 - Train Iteration 14780: loss: 0.0001, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9885, 0.9999]
2025-03-11 21:36:58 - Train Iteration 14781: loss: 0.0004, d_k_M range: [0.0000, 0.0053], d_k_M_hat range: [0.9801, 0.9998]
2025-03-11 21:36:59 - Train Iteration 14782: loss: 0.0015, d_k_M range: [0.0000, 0.0389], d_k_M_hat range: [0.9825, 0.9998]
2025-03-11 21:36:59 - Train Iteration 14783: loss: 0.0001, d_k_M range: [0.0000, 0.0048], d_k_M_hat range: [0.9895, 1.0000]
2025-03-11 21:37:00 - Train Iteration 14784: loss: 0.0010, d_k_M range: [0.0000, 0.0262], d_k_M_hat range: [0.9859, 0.9999]
2025-03-11 21:37:00 - Train Iteration 14785: loss: 0.0014, d_k_M range: [0.0000, 0.0226], d_k_M_hat range: [0.9679, 0.9999]
2025-03-11 21:37:01 - Train Iteration 14786: loss: 0.0005, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9783, 0.9996]
2025-03-11 21:37:01 - Train Iteration 14787: loss: 0.1181, d_k_M range: [0.0000, 0.0209], d_k_M_hat range: [0.6564, 0.9999]
2025-03-11 21:37:02 - Train Iteration 14788: loss: 0.0003, d_k_M range: [0.0000, 0.0170], d_k_M_hat range: [0.9936, 0.9999]
2025-03-11 21:37:02 - Train Iteration 14789: loss: 0.5299, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.2722, 0.9983]
2025-03-11 21:37:03 - Train Iteration 14790: loss: 0.0008, d_k_M range: [0.0000, 0.0095], d_k_M_hat range: [0.9727, 0.9999]
2025-03-11 21:37:03 - Train Iteration 14791: loss: 0.0257, d_k_M range: [0.0000, 0.1559], d_k_M_hat range: [0.9480, 0.9984]
2025-03-11 21:37:04 - Train Iteration 14792: loss: 0.0945, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.6926, 0.9935]
2025-03-11 21:37:04 - Train Iteration 14793: loss: 0.0024, d_k_M range: [0.0000, 0.0450], d_k_M_hat range: [0.9839, 0.9999]
2025-03-11 21:37:04 - Train Iteration 14794: loss: 0.0001, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.9901, 0.9999]
2025-03-11 21:37:05 - Train Iteration 14795: loss: 0.0771, d_k_M range: [0.0000, 0.2771], d_k_M_hat range: [0.9953, 0.9999]
2025-03-11 21:37:05 - Train Iteration 14796: loss: 0.0002, d_k_M range: [0.0001, 0.0005], d_k_M_hat range: [0.9868, 0.9995]
2025-03-11 21:37:06 - Train Iteration 14797: loss: 0.0001, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9929, 0.9997]
2025-03-11 21:37:06 - Train Iteration 14798: loss: 0.0006, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9746, 0.9998]
2025-03-11 21:37:07 - Train Iteration 14799: loss: 0.0840, d_k_M range: [0.0000, 0.0047], d_k_M_hat range: [0.7102, 0.9999]
2025-03-11 21:37:07 - Train Iteration 14800: loss: 0.0018, d_k_M range: [0.0000, 0.0081], d_k_M_hat range: [0.9587, 0.9992]
2025-03-11 21:37:07 - Train Iteration 14801: loss: 0.0009, d_k_M range: [0.0000, 0.0064], d_k_M_hat range: [0.9736, 1.0000]
2025-03-11 21:37:08 - Train Iteration 14802: loss: 0.0006, d_k_M range: [0.0001, 0.0041], d_k_M_hat range: [0.9765, 1.0000]
2025-03-11 21:37:08 - Train Iteration 14803: loss: 0.0001, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9912, 0.9997]
2025-03-11 21:37:09 - Train Iteration 14804: loss: 0.0000, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9960, 1.0000]
2025-03-11 21:37:09 - Train Iteration 14805: loss: 0.0028, d_k_M range: [0.0000, 0.0092], d_k_M_hat range: [0.9473, 0.9989]
2025-03-11 21:37:10 - Train Iteration 14806: loss: 0.0000, d_k_M range: [0.0001, 0.0009], d_k_M_hat range: [0.9952, 0.9999]
2025-03-11 21:37:10 - Train Iteration 14807: loss: 0.5907, d_k_M range: [0.0000, 0.0189], d_k_M_hat range: [0.2315, 0.9997]
2025-03-11 21:37:10 - Train Iteration 14808: loss: 0.6375, d_k_M range: [0.0001, 0.7983], d_k_M_hat range: [0.9988, 1.0000]
2025-03-11 21:37:11 - Train Iteration 14809: loss: 0.0004, d_k_M range: [0.0000, 0.0161], d_k_M_hat range: [0.9887, 0.9997]
2025-03-11 21:37:11 - Train Iteration 14810: loss: 0.0014, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9632, 1.0000]
2025-03-11 21:37:12 - Train Iteration 14811: loss: 0.0275, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.8344, 0.9992]
2025-03-11 21:37:12 - Train Iteration 14812: loss: 0.0669, d_k_M range: [0.0000, 0.2579], d_k_M_hat range: [0.9526, 0.9993]
2025-03-11 21:37:12 - Train Iteration 14813: loss: 0.0000, d_k_M range: [0.0000, 0.0050], d_k_M_hat range: [0.9936, 1.0000]
2025-03-11 21:37:13 - Train Iteration 14814: loss: 0.0000, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9939, 0.9997]
2025-03-11 21:37:13 - Train Iteration 14815: loss: 0.0536, d_k_M range: [0.0000, 0.0188], d_k_M_hat range: [0.7686, 0.9999]
2025-03-11 21:37:14 - Train Iteration 14816: loss: 0.0003, d_k_M range: [0.0000, 0.0162], d_k_M_hat range: [0.9953, 0.9999]
2025-03-11 21:37:14 - Train Iteration 14817: loss: 0.0002, d_k_M range: [0.0000, 0.0127], d_k_M_hat range: [0.9907, 0.9994]
2025-03-11 21:37:15 - Train Iteration 14818: loss: 0.0120, d_k_M range: [0.0001, 0.1056], d_k_M_hat range: [0.9841, 0.9999]
2025-03-11 21:37:15 - Train Iteration 14819: loss: 0.0011, d_k_M range: [0.0000, 0.0069], d_k_M_hat range: [0.9667, 1.0000]
2025-03-11 21:37:16 - Train Iteration 14820: loss: 0.0037, d_k_M range: [0.0000, 0.0102], d_k_M_hat range: [0.9399, 0.9997]
2025-03-11 21:37:16 - Train Iteration 14821: loss: 0.0017, d_k_M range: [0.0000, 0.0130], d_k_M_hat range: [0.9713, 0.9999]
2025-03-11 21:37:16 - Train Iteration 14822: loss: 0.0001, d_k_M range: [0.0000, 0.0067], d_k_M_hat range: [0.9915, 0.9999]
2025-03-11 21:37:17 - Train Iteration 14823: loss: 0.0031, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9446, 0.9999]
2025-03-11 21:37:17 - Train Iteration 14824: loss: 0.0002, d_k_M range: [0.0000, 0.0089], d_k_M_hat range: [0.9894, 0.9998]
2025-03-11 21:37:18 - Train Iteration 14825: loss: 0.0008, d_k_M range: [0.0000, 0.0064], d_k_M_hat range: [0.9722, 1.0000]
2025-03-11 21:37:18 - Train Iteration 14826: loss: 0.0011, d_k_M range: [0.0000, 0.0054], d_k_M_hat range: [0.9670, 0.9999]
2025-03-11 21:37:19 - Train Iteration 14827: loss: 0.0004, d_k_M range: [0.0000, 0.0206], d_k_M_hat range: [0.9949, 0.9999]
2025-03-11 21:37:19 - Train Iteration 14828: loss: 0.0218, d_k_M range: [0.0000, 0.1471], d_k_M_hat range: [0.9859, 1.0000]
2025-03-11 21:37:19 - Train Iteration 14829: loss: 0.0050, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.9293, 0.9994]
2025-03-11 21:37:20 - Train Iteration 14830: loss: 0.0021, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9548, 0.9997]
2025-03-11 21:37:20 - Train Iteration 14831: loss: 0.0582, d_k_M range: [0.0000, 0.0024], d_k_M_hat range: [0.7588, 0.9993]
2025-03-11 21:37:21 - Train Iteration 14832: loss: 0.7905, d_k_M range: [0.0000, 0.0041], d_k_M_hat range: [0.1109, 1.0000]
2025-03-11 21:37:21 - Train Iteration 14833: loss: 0.0051, d_k_M range: [0.0000, 0.0706], d_k_M_hat range: [0.9952, 1.0000]
2025-03-11 21:37:22 - Train Iteration 14834: loss: 0.0158, d_k_M range: [0.0000, 0.1200], d_k_M_hat range: [0.8742, 1.0000]
2025-03-11 21:37:22 - Train Iteration 14835: loss: 0.0040, d_k_M range: [0.0000, 0.0633], d_k_M_hat range: [0.9835, 0.9999]
2025-03-11 21:37:23 - Train Iteration 14836: loss: 0.0000, d_k_M range: [0.0000, 0.0056], d_k_M_hat range: [0.9971, 1.0000]
2025-03-11 21:37:23 - Train Iteration 14837: loss: 0.0028, d_k_M range: [0.0000, 0.0227], d_k_M_hat range: [0.9471, 0.9998]
2025-03-11 21:37:24 - Train Iteration 14838: loss: 0.0001, d_k_M range: [0.0000, 0.0080], d_k_M_hat range: [0.9887, 0.9996]
2025-03-11 21:37:24 - Train Iteration 14839: loss: 0.0021, d_k_M range: [0.0000, 0.0455], d_k_M_hat range: [0.9642, 0.9999]
2025-03-11 21:37:24 - Train Iteration 14840: loss: 0.0002, d_k_M range: [0.0000, 0.0063], d_k_M_hat range: [0.9855, 1.0000]
2025-03-11 21:37:25 - Train Iteration 14841: loss: 0.0095, d_k_M range: [0.0000, 0.0960], d_k_M_hat range: [0.9945, 0.9998]
2025-03-11 21:37:25 - Train Iteration 14842: loss: 0.0840, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.7102, 0.9995]
2025-03-11 21:37:26 - Train Iteration 14843: loss: 0.0019, d_k_M range: [0.0000, 0.0034], d_k_M_hat range: [0.9565, 0.9991]
2025-03-11 21:37:26 - Train Iteration 14844: loss: 0.1119, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.6655, 0.9997]
2025-03-11 21:37:27 - Train Iteration 14845: loss: 0.0070, d_k_M range: [0.0000, 0.0017], d_k_M_hat range: [0.9165, 0.9995]
2025-03-11 21:37:27 - Train Iteration 14846: loss: 0.0083, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9089, 0.9982]
2025-03-11 21:37:27 - Train Iteration 14847: loss: 0.0003, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9823, 0.9990]
2025-03-11 21:37:28 - Train Iteration 14848: loss: 0.0002, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9869, 0.9993]
2025-03-11 21:37:28 - Train Iteration 14849: loss: 0.0024, d_k_M range: [0.0000, 0.0033], d_k_M_hat range: [0.9512, 0.9993]
2025-03-11 21:37:29 - Train Iteration 14850: loss: 0.0057, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9244, 0.9984]
2025-03-11 21:37:29 - Train Iteration 14851: loss: 0.0333, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.8186, 0.9997]
2025-03-11 21:37:30 - Train Iteration 14852: loss: 0.0004, d_k_M range: [0.0000, 0.0188], d_k_M_hat range: [0.9959, 1.0000]
2025-03-11 21:37:30 - Train Iteration 14853: loss: 0.0001, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9897, 0.9999]
2025-03-11 21:37:30 - Train Iteration 14854: loss: 0.0015, d_k_M range: [0.0000, 0.0137], d_k_M_hat range: [0.9618, 0.9998]
2025-03-11 21:37:31 - Train Iteration 14855: loss: 0.0819, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.7137, 0.9996]
2025-03-11 21:37:31 - Train Iteration 14856: loss: 0.0001, d_k_M range: [0.0000, 0.0055], d_k_M_hat range: [0.9916, 0.9999]
2025-03-11 21:37:32 - Train Iteration 14857: loss: 0.5282, d_k_M range: [0.0000, 0.0015], d_k_M_hat range: [0.2732, 0.9999]
2025-03-11 21:37:33 - Train Iteration 14858: loss: 0.4459, d_k_M range: [0.0001, 0.6677], d_k_M_hat range: [0.9976, 1.0000]
2025-03-11 21:37:33 - Train Iteration 14859: loss: 0.0667, d_k_M range: [0.0000, 0.0074], d_k_M_hat range: [0.7420, 0.9979]
2025-03-11 21:37:33 - Train Iteration 14860: loss: 0.0034, d_k_M range: [0.0000, 0.0044], d_k_M_hat range: [0.9422, 0.9999]
2025-03-11 21:37:34 - Train Iteration 14861: loss: 0.0004, d_k_M range: [0.0000, 0.0197], d_k_M_hat range: [0.9924, 1.0000]
2025-03-11 21:37:34 - Train Iteration 14862: loss: 0.0000, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.9971, 0.9999]
2025-03-11 21:37:35 - Train Iteration 14863: loss: 0.0005, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9779, 0.9997]
2025-03-11 21:37:35 - Train Iteration 14864: loss: 0.0003, d_k_M range: [0.0000, 0.0009], d_k_M_hat range: [0.9839, 0.9998]
2025-03-11 21:37:36 - Train Iteration 14865: loss: 0.0001, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9929, 0.9998]
2025-03-11 21:37:36 - Train Iteration 14866: loss: 0.0002, d_k_M range: [0.0000, 0.0147], d_k_M_hat range: [0.9901, 0.9999]
2025-03-11 21:37:37 - Train Iteration 14867: loss: 0.0435, d_k_M range: [0.0000, 0.0238], d_k_M_hat range: [0.7915, 0.9998]
2025-03-11 21:37:37 - Train Iteration 14868: loss: 0.0112, d_k_M range: [0.0000, 0.1058], d_k_M_hat range: [0.9314, 0.9999]
2025-03-11 21:37:38 - Train Iteration 14869: loss: 0.0055, d_k_M range: [0.0000, 0.0404], d_k_M_hat range: [0.9385, 0.9996]
2025-03-11 21:37:38 - Train Iteration 14870: loss: 0.5879, d_k_M range: [0.0000, 0.7667], d_k_M_hat range: [0.7959, 1.0000]
2025-03-11 21:37:38 - Train Iteration 14871: loss: 0.0008, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.9723, 0.9952]
2025-03-11 21:37:39 - Train Iteration 14872: loss: 0.0002, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9855, 0.9999]
2025-03-11 21:37:39 - Train Iteration 14873: loss: 0.7490, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.1346, 0.9982]
2025-03-11 21:37:40 - Train Iteration 14874: loss: 0.6354, d_k_M range: [0.0001, 0.7971], d_k_M_hat range: [0.9959, 1.0000]
2025-03-11 21:37:40 - Train Iteration 14875: loss: 0.0014, d_k_M range: [0.0004, 0.0342], d_k_M_hat range: [0.9863, 0.9992]
2025-03-11 21:37:41 - Train Iteration 14876: loss: 0.1742, d_k_M range: [0.0001, 0.4172], d_k_M_hat range: [0.9995, 1.0000]
2025-03-11 21:37:41 - Train Iteration 14877: loss: 0.0003, d_k_M range: [0.0000, 0.0172], d_k_M_hat range: [0.9875, 0.9999]
2025-03-11 21:37:41 - Train Iteration 14878: loss: 0.0001, d_k_M range: [0.0000, 0.0085], d_k_M_hat range: [0.9910, 0.9999]
2025-03-11 21:37:42 - Train Iteration 14879: loss: 0.0015, d_k_M range: [0.0000, 0.0035], d_k_M_hat range: [0.9609, 0.9999]
2025-03-11 21:37:42 - Train Iteration 14880: loss: 0.0071, d_k_M range: [0.0000, 0.0840], d_k_M_hat range: [0.9881, 0.9997]
2025-03-11 21:37:43 - Train Iteration 14881: loss: 0.0006, d_k_M range: [0.0000, 0.0021], d_k_M_hat range: [0.9765, 0.9995]
2025-03-11 21:37:43 - Train Iteration 14882: loss: 0.0002, d_k_M range: [0.0000, 0.0113], d_k_M_hat range: [0.9881, 0.9999]
2025-03-11 21:37:44 - Train Iteration 14883: loss: 0.0001, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.9931, 0.9993]
2025-03-11 21:37:44 - Train Iteration 14884: loss: 0.0806, d_k_M range: [0.0000, 0.1512], d_k_M_hat range: [0.7161, 0.9997]
2025-03-11 21:37:45 - Train Iteration 14885: loss: 0.0922, d_k_M range: [0.0000, 0.0043], d_k_M_hat range: [0.6966, 0.9999]
2025-03-11 21:37:45 - Train Iteration 14886: loss: 0.0000, d_k_M range: [0.0000, 0.0039], d_k_M_hat range: [0.9955, 0.9999]
2025-03-11 21:37:45 - Train Iteration 14887: loss: 0.0490, d_k_M range: [0.0000, 0.2207], d_k_M_hat range: [0.9922, 1.0000]
2025-03-11 21:37:46 - Train Iteration 14888: loss: 0.0018, d_k_M range: [0.0000, 0.0422], d_k_M_hat range: [0.9971, 0.9999]
2025-03-11 21:37:46 - Train Iteration 14889: loss: 0.0031, d_k_M range: [0.0000, 0.0561], d_k_M_hat range: [0.9967, 1.0000]
2025-03-11 21:37:47 - Train Iteration 14890: loss: 0.0001, d_k_M range: [0.0000, 0.0101], d_k_M_hat range: [0.9963, 0.9999]
2025-03-11 21:37:47 - Train Iteration 14891: loss: 0.0001, d_k_M range: [0.0000, 0.0120], d_k_M_hat range: [0.9979, 1.0000]
2025-03-11 21:37:48 - Train Iteration 14892: loss: 0.0021, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.9547, 0.9993]
2025-03-11 21:37:48 - Train Iteration 14893: loss: 0.0037, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9394, 0.9994]
2025-03-11 21:37:49 - Train Iteration 14894: loss: 0.0022, d_k_M range: [0.0000, 0.0022], d_k_M_hat range: [0.9533, 0.9998]
2025-03-11 21:37:49 - Train Iteration 14895: loss: 0.0001, d_k_M range: [0.0000, 0.0002], d_k_M_hat range: [0.9904, 0.9993]
2025-03-11 21:37:49 - Train Iteration 14896: loss: 0.0001, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9881, 0.9993]
2025-03-11 21:37:50 - Train Iteration 14897: loss: 0.0453, d_k_M range: [0.0000, 0.0111], d_k_M_hat range: [0.7983, 0.9997]
2025-03-11 21:37:50 - Train Iteration 14898: loss: 0.0022, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9531, 0.9998]
2025-03-11 21:37:51 - Train Iteration 14899: loss: 0.3789, d_k_M range: [0.0000, 0.0010], d_k_M_hat range: [0.3845, 0.9982]
2025-03-11 21:37:51 - Train Iteration 14900: loss: 0.0001, d_k_M range: [0.0000, 0.0108], d_k_M_hat range: [0.9990, 0.9998]
2025-03-11 21:37:52 - Train Iteration 14901: loss: 0.0006, d_k_M range: [0.0000, 0.0232], d_k_M_hat range: [0.9863, 0.9999]
2025-03-11 21:37:52 - Train Iteration 14902: loss: 0.0049, d_k_M range: [0.0000, 0.0012], d_k_M_hat range: [0.9301, 0.9999]
2025-03-11 21:37:53 - Train Iteration 14903: loss: 0.0005, d_k_M range: [0.0000, 0.0003], d_k_M_hat range: [0.9780, 0.9995]
2025-03-11 21:37:53 - Train Iteration 14904: loss: 0.0043, d_k_M range: [0.0000, 0.0066], d_k_M_hat range: [0.9345, 1.0000]
2025-03-11 21:37:54 - Train Iteration 14905: loss: 0.0000, d_k_M range: [0.0000, 0.0011], d_k_M_hat range: [0.9968, 0.9998]
2025-03-11 21:37:54 - Train Iteration 14906: loss: 0.0001, d_k_M range: [0.0000, 0.0046], d_k_M_hat range: [0.9927, 1.0000]
2025-03-11 21:37:55 - Train Iteration 14907: loss: 0.3034, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.4492, 0.9996]
2025-03-11 21:37:55 - Train Iteration 14908: loss: 0.0035, d_k_M range: [0.0001, 0.0589], d_k_M_hat range: [0.9995, 1.0000]
2025-03-11 21:37:56 - Train Iteration 14909: loss: 0.1929, d_k_M range: [0.0000, 0.4392], d_k_M_hat range: [0.9981, 1.0000]
2025-03-11 21:37:56 - Train Iteration 14910: loss: 0.0414, d_k_M range: [0.0000, 0.0078], d_k_M_hat range: [0.7967, 0.9997]
2025-03-11 21:37:56 - Train Iteration 14911: loss: 0.3649, d_k_M range: [0.0000, 0.0013], d_k_M_hat range: [0.3959, 0.9996]
2025-03-11 21:37:57 - Train Iteration 14912: loss: 0.3878, d_k_M range: [0.0000, 0.6227], d_k_M_hat range: [0.9689, 0.9999]
2025-03-11 21:37:57 - Train Iteration 14913: loss: 0.0286, d_k_M range: [0.0000, 0.1685], d_k_M_hat range: [0.9871, 0.9996]
2025-03-11 21:37:58 - Train Iteration 14914: loss: 0.7660, d_k_M range: [0.0000, 0.0064], d_k_M_hat range: [0.1248, 0.9997]
2025-03-11 21:37:58 - Train Iteration 14915: loss: 0.0003, d_k_M range: [0.0000, 0.0143], d_k_M_hat range: [0.9958, 0.9999]
2025-03-11 21:37:58 - Train Iteration 14916: loss: 0.0147, d_k_M range: [0.0000, 0.1207], d_k_M_hat range: [0.9322, 1.0000]
2025-03-11 21:37:59 - Train Iteration 14917: loss: 0.0012, d_k_M range: [0.0000, 0.0007], d_k_M_hat range: [0.9659, 0.9995]
2025-03-11 21:37:59 - Train Iteration 14918: loss: 0.0013, d_k_M range: [0.0000, 0.0060], d_k_M_hat range: [0.9638, 0.9995]
2025-03-11 21:38:00 - Train Iteration 14919: loss: 0.0007, d_k_M range: [0.0000, 0.0061], d_k_M_hat range: [0.9739, 1.0000]
2025-03-11 21:38:00 - Train Iteration 14920: loss: 0.1397, d_k_M range: [0.0000, 0.0439], d_k_M_hat range: [0.6263, 0.9999]
2025-03-11 21:38:01 - Train Iteration 14921: loss: 0.0118, d_k_M range: [0.0001, 0.1086], d_k_M_hat range: [0.9961, 1.0000]
2025-03-11 21:38:01 - Train Iteration 14922: loss: 0.0067, d_k_M range: [0.0000, 0.0818], d_k_M_hat range: [0.9961, 1.0000]
2025-03-11 21:38:02 - Train Iteration 14923: loss: 0.0096, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9027, 0.9998]
2025-03-11 21:38:02 - Train Iteration 14924: loss: 0.0706, d_k_M range: [0.0000, 0.2651], d_k_M_hat range: [0.9695, 0.9996]
2025-03-11 21:38:03 - Train Iteration 14925: loss: 0.1790, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.5770, 0.9991]
2025-03-11 21:38:03 - Train Iteration 14926: loss: 0.3013, d_k_M range: [0.0000, 0.5487], d_k_M_hat range: [0.9487, 0.9999]
2025-03-11 21:38:04 - Train Iteration 14927: loss: 0.0898, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.7004, 0.9996]
2025-03-11 21:38:04 - Train Iteration 14928: loss: 0.0033, d_k_M range: [0.0000, 0.0572], d_k_M_hat range: [0.9946, 1.0000]
2025-03-11 21:38:04 - Train Iteration 14929: loss: 0.0024, d_k_M range: [0.0000, 0.0051], d_k_M_hat range: [0.9506, 0.9998]
2025-03-11 21:38:05 - Train Iteration 14930: loss: 0.0197, d_k_M range: [0.0001, 0.1390], d_k_M_hat range: [0.9961, 0.9997]
2025-03-11 21:38:05 - Train Iteration 14931: loss: 0.0031, d_k_M range: [0.0000, 0.0020], d_k_M_hat range: [0.9446, 0.9962]
2025-03-11 21:38:06 - Train Iteration 14932: loss: 0.0028, d_k_M range: [0.0001, 0.0522], d_k_M_hat range: [0.9709, 0.9997]
2025-03-11 21:38:06 - Train Iteration 14933: loss: 0.0249, d_k_M range: [0.0000, 0.1570], d_k_M_hat range: [0.9833, 0.9997]
2025-03-11 21:38:07 - Train Iteration 14934: loss: 0.0042, d_k_M range: [0.0000, 0.0622], d_k_M_hat range: [0.9837, 0.9998]
2025-03-11 21:38:07 - Train Iteration 14935: loss: 0.0017, d_k_M range: [0.0000, 0.0316], d_k_M_hat range: [0.9906, 1.0000]
2025-03-11 21:38:08 - Train Iteration 14936: loss: 0.0001, d_k_M range: [0.0000, 0.0040], d_k_M_hat range: [0.9900, 0.9997]
2025-03-11 21:38:08 - Train Iteration 14937: loss: 0.0037, d_k_M range: [0.0000, 0.0076], d_k_M_hat range: [0.9398, 0.9997]
2025-03-11 21:38:09 - Train Iteration 14938: loss: 0.0198, d_k_M range: [0.0000, 0.1282], d_k_M_hat range: [0.8593, 0.9996]
2025-03-11 21:38:09 - Train Iteration 14939: loss: 0.0008, d_k_M range: [0.0000, 0.0045], d_k_M_hat range: [0.9711, 0.9998]
2025-03-11 21:38:10 - Train Iteration 14940: loss: 0.9441, d_k_M range: [0.0000, 0.9716], d_k_M_hat range: [0.7077, 1.0000]
2025-03-11 21:38:10 - Train Iteration 14941: loss: 0.0019, d_k_M range: [0.0000, 0.0014], d_k_M_hat range: [0.9559, 0.9999]
2025-03-11 21:38:11 - Train Iteration 14942: loss: 0.0000, d_k_M range: [0.0000, 0.0018], d_k_M_hat range: [0.9970, 0.9998]
2025-03-11 21:38:11 - Train Iteration 14943: loss: 0.0001, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.9914, 0.9996]
2025-03-11 21:38:11 - Train Iteration 14944: loss: 0.0002, d_k_M range: [0.0000, 0.0149], d_k_M_hat range: [0.9978, 0.9999]
2025-03-11 21:38:12 - Train Iteration 14945: loss: 0.0006, d_k_M range: [0.0000, 0.0173], d_k_M_hat range: [0.9930, 1.0000]
2025-03-11 21:38:12 - Train Iteration 14946: loss: 0.0003, d_k_M range: [0.0000, 0.0168], d_k_M_hat range: [0.9896, 1.0000]
2025-03-11 21:38:13 - Train Iteration 14947: loss: 0.0092, d_k_M range: [0.0000, 0.0958], d_k_M_hat range: [0.9870, 0.9999]
2025-03-11 21:38:13 - Train Iteration 14948: loss: 0.0007, d_k_M range: [0.0000, 0.0267], d_k_M_hat range: [0.9909, 1.0000]
2025-03-11 21:38:14 - Train Iteration 14949: loss: 0.0008, d_k_M range: [0.0000, 0.0286], d_k_M_hat range: [0.9946, 1.0000]
2025-03-11 21:38:14 - Train Iteration 14950: loss: 0.0004, d_k_M range: [0.0000, 0.0152], d_k_M_hat range: [0.9884, 1.0000]
2025-03-11 21:38:15 - Train Iteration 14951: loss: 0.0028, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9473, 0.9994]
2025-03-11 21:38:15 - Train Iteration 14952: loss: 0.7261, d_k_M range: [0.0000, 0.0001], d_k_M_hat range: [0.1479, 0.9839]
2025-03-11 21:38:16 - Train Iteration 14953: loss: 0.0050, d_k_M range: [0.0000, 0.0702], d_k_M_hat range: [0.9963, 0.9999]
2025-03-11 21:38:16 - Train Iteration 14954: loss: 0.0001, d_k_M range: [0.0000, 0.0083], d_k_M_hat range: [0.9988, 1.0000]
2025-03-11 21:38:16 - Train Iteration 14955: loss: 0.2062, d_k_M range: [0.0000, 0.4538], d_k_M_hat range: [0.9977, 0.9997]
2025-03-11 21:38:17 - Train Iteration 14956: loss: 0.3660, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.3951, 0.9992]
2025-03-11 21:38:17 - Train Iteration 14957: loss: 0.0012, d_k_M range: [0.0000, 0.0158], d_k_M_hat range: [0.9812, 0.9999]
2025-03-11 21:38:18 - Train Iteration 14958: loss: 0.0006, d_k_M range: [0.0000, 0.0239], d_k_M_hat range: [0.9969, 0.9999]
2025-03-11 21:38:18 - Train Iteration 14959: loss: 0.0094, d_k_M range: [0.0000, 0.0121], d_k_M_hat range: [0.9029, 0.9993]
2025-03-11 21:38:19 - Train Iteration 14960: loss: 0.0837, d_k_M range: [0.0000, 0.0790], d_k_M_hat range: [0.7120, 0.9999]
2025-03-11 21:38:19 - Train Iteration 14961: loss: 0.0073, d_k_M range: [0.0000, 0.0104], d_k_M_hat range: [0.9147, 0.9998]
2025-03-11 21:38:20 - Train Iteration 14962: loss: 0.0366, d_k_M range: [0.0000, 0.1911], d_k_M_hat range: [0.9975, 0.9999]
2025-03-11 21:38:20 - Train Iteration 14963: loss: 0.0712, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.7333, 0.9999]
2025-03-11 21:38:20 - Train Iteration 14964: loss: 0.0013, d_k_M range: [0.0001, 0.0365], d_k_M_hat range: [0.9958, 1.0000]
2025-03-11 21:38:21 - Train Iteration 14965: loss: 0.0000, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9971, 0.9999]
2025-03-11 21:38:21 - Train Iteration 14966: loss: 0.0082, d_k_M range: [0.0000, 0.0902], d_k_M_hat range: [0.9906, 0.9999]
2025-03-11 21:38:22 - Train Iteration 14967: loss: 0.0003, d_k_M range: [0.0000, 0.0159], d_k_M_hat range: [0.9964, 0.9998]
2025-03-11 21:38:22 - Train Iteration 14968: loss: 0.0001, d_k_M range: [0.0000, 0.0023], d_k_M_hat range: [0.9913, 0.9997]
2025-03-11 21:38:23 - Train Iteration 14969: loss: 0.0003, d_k_M range: [0.0000, 0.0183], d_k_M_hat range: [0.9973, 0.9999]
2025-03-11 21:38:23 - Train Iteration 14970: loss: 0.3289, d_k_M range: [0.0000, 0.5723], d_k_M_hat range: [0.9799, 0.9996]
2025-03-11 21:38:23 - Train Iteration 14971: loss: 0.0004, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.9808, 0.9990]
2025-03-11 21:38:24 - Train Iteration 14972: loss: 0.0005, d_k_M range: [0.0000, 0.0008], d_k_M_hat range: [0.9769, 0.9999]
2025-03-11 21:38:24 - Train Iteration 14973: loss: 0.0066, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9188, 0.9998]
2025-03-11 21:38:25 - Train Iteration 14974: loss: 0.0026, d_k_M range: [0.0000, 0.0510], d_k_M_hat range: [0.9916, 1.0000]
2025-03-11 21:38:25 - Train Iteration 14975: loss: 0.0015, d_k_M range: [0.0000, 0.0207], d_k_M_hat range: [0.9825, 0.9999]
2025-03-11 21:38:26 - Train Iteration 14976: loss: 0.0005, d_k_M range: [0.0000, 0.0098], d_k_M_hat range: [0.9782, 0.9998]
2025-03-11 21:38:26 - Train Iteration 14977: loss: 0.0033, d_k_M range: [0.0000, 0.0550], d_k_M_hat range: [0.9845, 0.9997]
2025-03-11 21:38:27 - Train Iteration 14978: loss: 0.0058, d_k_M range: [0.0000, 0.0752], d_k_M_hat range: [0.9931, 1.0000]
2025-03-11 21:38:27 - Train Iteration 14979: loss: 0.0010, d_k_M range: [0.0000, 0.0280], d_k_M_hat range: [0.9887, 0.9998]
2025-03-11 21:38:28 - Train Iteration 14980: loss: 0.1275, d_k_M range: [0.0000, 0.3563], d_k_M_hat range: [0.9980, 0.9999]
2025-03-11 21:38:28 - Train Iteration 14981: loss: 0.0007, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9735, 0.9998]
2025-03-11 21:38:28 - Train Iteration 14982: loss: 0.0045, d_k_M range: [0.0000, 0.0042], d_k_M_hat range: [0.9330, 0.9999]
2025-03-11 21:38:29 - Train Iteration 14983: loss: 0.0068, d_k_M range: [0.0000, 0.0669], d_k_M_hat range: [0.9749, 0.9991]
2025-03-11 21:38:29 - Train Iteration 14984: loss: 0.0012, d_k_M range: [0.0000, 0.0101], d_k_M_hat range: [0.9711, 0.9997]
2025-03-11 21:38:30 - Train Iteration 14985: loss: 0.0001, d_k_M range: [0.0000, 0.0027], d_k_M_hat range: [0.9923, 0.9999]
2025-03-11 21:38:30 - Train Iteration 14986: loss: 0.0004, d_k_M range: [0.0000, 0.0028], d_k_M_hat range: [0.9800, 0.9997]
2025-03-11 21:38:31 - Train Iteration 14987: loss: 0.0007, d_k_M range: [0.0000, 0.0152], d_k_M_hat range: [0.9753, 0.9988]
2025-03-11 21:38:31 - Train Iteration 14988: loss: 0.0071, d_k_M range: [0.0000, 0.0809], d_k_M_hat range: [0.9927, 0.9993]
2025-03-11 21:38:32 - Train Iteration 14989: loss: 0.0184, d_k_M range: [0.0000, 0.0055], d_k_M_hat range: [0.8651, 0.9993]
2025-03-11 21:38:32 - Train Iteration 14990: loss: 0.0003, d_k_M range: [0.0000, 0.0004], d_k_M_hat range: [0.9837, 0.9994]
2025-03-11 21:38:33 - Train Iteration 14991: loss: 0.0024, d_k_M range: [0.0000, 0.0016], d_k_M_hat range: [0.9513, 0.9998]
2025-03-11 21:38:33 - Train Iteration 14992: loss: 0.0045, d_k_M range: [0.0000, 0.0670], d_k_M_hat range: [0.9953, 0.9999]
2025-03-11 21:38:34 - Train Iteration 14993: loss: 0.0692, d_k_M range: [0.0000, 0.0006], d_k_M_hat range: [0.7369, 0.9993]
2025-03-11 21:38:34 - Train Iteration 14994: loss: 0.4292, d_k_M range: [0.0000, 0.0202], d_k_M_hat range: [0.3449, 0.9992]
2025-03-11 21:38:35 - Train Iteration 14995: loss: 0.0376, d_k_M range: [0.0000, 0.1937], d_k_M_hat range: [0.9923, 0.9999]
2025-03-11 21:38:35 - Train Iteration 14996: loss: 0.0016, d_k_M range: [0.0000, 0.0165], d_k_M_hat range: [0.9608, 0.9992]
2025-03-11 21:38:36 - Train Iteration 14997: loss: 0.0028, d_k_M range: [0.0000, 0.0005], d_k_M_hat range: [0.9476, 0.9995]
2025-03-11 21:38:36 - Train Iteration 14998: loss: 0.0009, d_k_M range: [0.0000, 0.0176], d_k_M_hat range: [0.9705, 0.9993]
2025-03-11 21:38:36 - Train Iteration 14999: loss: 0.1170, d_k_M range: [0.0000, 0.3418], d_k_M_hat range: [0.9912, 0.9998]
2025-03-11 21:38:37 - Train Iteration 15000: loss: 0.0000, d_k_M range: [0.0000, 0.0058], d_k_M_hat range: [0.9960, 0.9999]
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:114 [1] NCCL INFO [Service thread] Connection closed by localRank 1
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:113 [3] NCCL INFO [Service thread] Connection closed by localRank 3
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:117 [2] NCCL INFO [Service thread] Connection closed by localRank 2
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:80:550 [3] NCCL INFO comm 0x577004599980 rank 3 nranks 4 cudaDev 3 busId 9000 - Abort COMPLETE
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:78:549 [1] NCCL INFO comm 0x5af2a09a5d40 rank 1 nranks 4 cudaDev 1 busId 7000 - Abort COMPLETE
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:79:551 [2] NCCL INFO comm 0x5b0398c15f10 rank 2 nranks 4 cudaDev 2 busId 8000 - Abort COMPLETE
2025-03-11 21:38:40 - Final models saved at iteration 15000, time_string = 20250311194930239004
2025-03-11 21:38:40 - Training completed.
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/vgg.pth
2025-03-11 21:38:42 - Loading alternative model: ffhq1k
2025-03-11 21:38:42 - Downloading StyleGAN2 model to ffhq1k-paper256-ada.pkl...
  0%|          | 0.00/282M [00:00<?, ?B/s]  0%|          | 768k/282M [00:00<00:38, 7.64MB/s]  4%|         | 11.2M/282M [00:00<00:04, 67.0MB/s]  9%|         | 25.2M/282M [00:00<00:02, 103MB/s]  14%|        | 39.2M/282M [00:00<00:02, 120MB/s] 19%|        | 53.5M/282M [00:00<00:01, 130MB/s] 24%|       | 67.4M/282M [00:00<00:01, 135MB/s] 29%|       | 81.4M/282M [00:00<00:01, 139MB/s] 34%|      | 95.6M/282M [00:00<00:01, 142MB/s] 39%|      | 110M/282M [00:00<00:01, 143MB/s]  44%|     | 124M/282M [00:01<00:01, 144MB/s] 49%|     | 138M/282M [00:01<00:01, 145MB/s] 54%|    | 152M/282M [00:01<00:00, 143MB/s] 59%|    | 166M/282M [00:01<00:00, 145MB/s] 64%|   | 180M/282M [00:01<00:00, 146MB/s] 69%|   | 194M/282M [00:01<00:00, 145MB/s] 74%|  | 208M/282M [00:01<00:00, 143MB/s] 79%|  | 222M/282M [00:01<00:00, 142MB/s] 83%| | 236M/282M [00:01<00:00, 143MB/s] 88%| | 250M/282M [00:01<00:00, 144MB/s] 93%|| 264M/282M [00:02<00:00, 145MB/s] 98%|| 278M/282M [00:02<00:00, 145MB/s]100%|| 282M/282M [00:02<00:00, 136MB/s]
2025-03-11 21:38:45 - Download complete.
2025-03-11 21:38:45 - Loading alternative model: ffhq30k
2025-03-11 21:38:45 - Downloading StyleGAN2 model to ffhq30k-paper256-ada.pkl...
  0%|          | 0.00/282M [00:00<?, ?B/s]  0%|          | 1.00M/282M [00:00<00:28, 10.3MB/s]  3%|         | 8.88M/282M [00:00<00:05, 51.8MB/s]  7%|         | 20.4M/282M [00:00<00:03, 82.4MB/s] 13%|        | 35.4M/282M [00:00<00:02, 112MB/s]  18%|        | 50.6M/282M [00:00<00:01, 129MB/s] 23%|       | 65.9M/282M [00:00<00:01, 139MB/s] 29%|       | 81.1M/282M [00:00<00:01, 146MB/s] 34%|      | 96.4M/282M [00:00<00:01, 150MB/s] 40%|      | 112M/282M [00:00<00:01, 153MB/s]  45%|     | 127M/282M [00:01<00:01, 155MB/s] 50%|     | 142M/282M [00:01<00:00, 156MB/s] 56%|    | 158M/282M [00:01<00:00, 157MB/s] 61%|    | 173M/282M [00:01<00:00, 158MB/s] 67%|   | 188M/282M [00:01<00:00, 158MB/s] 72%|  | 203M/282M [00:01<00:00, 158MB/s] 77%|  | 218M/282M [00:01<00:00, 158MB/s] 83%| | 233M/282M [00:01<00:00, 158MB/s] 88%| | 248M/282M [00:01<00:00, 158MB/s] 94%|| 264M/282M [00:01<00:00, 159MB/s] 99%|| 279M/282M [00:02<00:00, 159MB/s]100%|| 282M/282M [00:02<00:00, 145MB/s]
2025-03-11 21:38:48 - Download complete.
2025-03-11 21:38:48 - Loading alternative model: ffhq70k-bcr
2025-03-11 21:38:48 - Downloading StyleGAN2 model to ffhq70k-paper256-ada-bcr.pkl...
  0%|          | 0.00/282M [00:00<?, ?B/s]  0%|          | 1.00M/282M [00:00<00:28, 10.4MB/s]  5%|         | 14.1M/282M [00:00<00:03, 84.4MB/s] 11%|         | 29.6M/282M [00:00<00:02, 111MB/s]  16%|        | 45.0M/282M [00:00<00:01, 130MB/s] 22%|       | 60.9M/282M [00:00<00:01, 142MB/s] 27%|       | 76.8M/282M [00:00<00:01, 150MB/s] 33%|      | 92.2M/282M [00:00<00:01, 154MB/s] 38%|      | 108M/282M [00:00<00:01, 157MB/s]  44%|     | 124M/282M [00:00<00:01, 159MB/s] 49%|     | 139M/282M [00:01<00:00, 160MB/s] 55%|    | 155M/282M [00:01<00:00, 161MB/s] 60%|    | 171M/282M [00:01<00:00, 162MB/s] 66%|   | 186M/282M [00:01<00:00, 162MB/s] 72%|  | 202M/282M [00:01<00:00, 162MB/s] 77%|  | 217M/282M [00:01<00:00, 162MB/s] 83%| | 233M/282M [00:01<00:00, 161MB/s] 88%| | 248M/282M [00:01<00:00, 161MB/s] 94%|| 264M/282M [00:01<00:00, 162MB/s] 99%|| 280M/282M [00:01<00:00, 162MB/s]100%|| 282M/282M [00:01<00:00, 152MB/s]
2025-03-11 21:38:50 - Download complete.
2025-03-11 21:38:50 - Loading alternative model: ffhq70k-noaug
2025-03-11 21:38:50 - Downloading StyleGAN2 model to ffhq70k-paper256-noaug.pkl...
  0%|          | 0.00/282M [00:00<?, ?B/s]  0%|          | 896k/282M [00:00<00:32, 8.98MB/s]  4%|         | 12.6M/282M [00:00<00:03, 75.5MB/s] 10%|         | 27.0M/282M [00:00<00:02, 110MB/s]  15%|        | 41.6M/282M [00:00<00:01, 127MB/s] 20%|        | 56.4M/282M [00:00<00:01, 137MB/s] 25%|       | 71.0M/282M [00:00<00:01, 142MB/s] 30%|       | 85.8M/282M [00:00<00:01, 146MB/s] 36%|      | 100M/282M [00:00<00:01, 149MB/s]  41%|      | 115M/282M [00:00<00:01, 149MB/s] 46%|     | 130M/282M [00:01<00:01, 150MB/s] 51%|     | 144M/282M [00:01<00:00, 152MB/s] 56%|    | 159M/282M [00:01<00:00, 151MB/s] 62%|   | 174M/282M [00:01<00:00, 152MB/s] 67%|   | 188M/282M [00:01<00:00, 152MB/s] 72%|  | 203M/282M [00:01<00:00, 153MB/s] 77%|  | 218M/282M [00:01<00:00, 153MB/s] 82%| | 232M/282M [00:01<00:00, 153MB/s] 88%| | 247M/282M [00:01<00:00, 153MB/s] 93%|| 262M/282M [00:01<00:00, 154MB/s] 98%|| 277M/282M [00:02<00:00, 153MB/s]100%|| 282M/282M [00:02<00:00, 144MB/s]
2025-03-11 21:38:53 - Download complete.
2025-03-11 21:38:53 - Processing batch 1/125 (8 images)
2025-03-11 21:38:53 - Processing batch 2/125 (8 images)
2025-03-11 21:38:54 - Processing batch 3/125 (8 images)
2025-03-11 21:38:54 - Processing batch 4/125 (8 images)
2025-03-11 21:38:54 - Processing batch 5/125 (8 images)
2025-03-11 21:38:55 - Processing batch 6/125 (8 images)
2025-03-11 21:38:55 - Processing batch 7/125 (8 images)
2025-03-11 21:38:55 - Processing batch 8/125 (8 images)
2025-03-11 21:38:56 - Processing batch 9/125 (8 images)
2025-03-11 21:38:56 - Processing batch 10/125 (8 images)
2025-03-11 21:38:56 - Processing batch 11/125 (8 images)
2025-03-11 21:38:57 - Processing batch 12/125 (8 images)
2025-03-11 21:38:57 - Processing batch 13/125 (8 images)
2025-03-11 21:38:58 - Processing batch 14/125 (8 images)
2025-03-11 21:38:58 - Processing batch 15/125 (8 images)
2025-03-11 21:38:58 - Processing batch 16/125 (8 images)
2025-03-11 21:38:59 - Processing batch 17/125 (8 images)
2025-03-11 21:38:59 - Processing batch 18/125 (8 images)
2025-03-11 21:38:59 - Processing batch 19/125 (8 images)
2025-03-11 21:39:00 - Processing batch 20/125 (8 images)
2025-03-11 21:39:00 - Processing batch 21/125 (8 images)
2025-03-11 21:39:01 - Processing batch 22/125 (8 images)
2025-03-11 21:39:01 - Processing batch 23/125 (8 images)
2025-03-11 21:39:01 - Processing batch 24/125 (8 images)
2025-03-11 21:39:02 - Processing batch 25/125 (8 images)
2025-03-11 21:39:02 - Processing batch 26/125 (8 images)
2025-03-11 21:39:02 - Processing batch 27/125 (8 images)
2025-03-11 21:39:03 - Processing batch 28/125 (8 images)
2025-03-11 21:39:03 - Processing batch 29/125 (8 images)
2025-03-11 21:39:04 - Processing batch 30/125 (8 images)
2025-03-11 21:39:04 - Processing batch 31/125 (8 images)
2025-03-11 21:39:04 - Processing batch 32/125 (8 images)
2025-03-11 21:39:05 - Processing batch 33/125 (8 images)
2025-03-11 21:39:05 - Processing batch 34/125 (8 images)
2025-03-11 21:39:05 - Processing batch 35/125 (8 images)
2025-03-11 21:39:06 - Processing batch 36/125 (8 images)
2025-03-11 21:39:06 - Processing batch 37/125 (8 images)
2025-03-11 21:39:07 - Processing batch 38/125 (8 images)
2025-03-11 21:39:07 - Processing batch 39/125 (8 images)
2025-03-11 21:39:07 - Processing batch 40/125 (8 images)
2025-03-11 21:39:08 - Processing batch 41/125 (8 images)
2025-03-11 21:39:08 - Processing batch 42/125 (8 images)
2025-03-11 21:39:08 - Processing batch 43/125 (8 images)
2025-03-11 21:39:09 - Processing batch 44/125 (8 images)
2025-03-11 21:39:09 - Processing batch 45/125 (8 images)
2025-03-11 21:39:10 - Processing batch 46/125 (8 images)
2025-03-11 21:39:10 - Processing batch 47/125 (8 images)
2025-03-11 21:39:10 - Processing batch 48/125 (8 images)
2025-03-11 21:39:11 - Processing batch 49/125 (8 images)
2025-03-11 21:39:11 - Processing batch 50/125 (8 images)
2025-03-11 21:39:11 - Processing batch 51/125 (8 images)
2025-03-11 21:39:12 - Processing batch 52/125 (8 images)
2025-03-11 21:39:12 - Processing batch 53/125 (8 images)
2025-03-11 21:39:13 - Processing batch 54/125 (8 images)
2025-03-11 21:39:13 - Processing batch 55/125 (8 images)
2025-03-11 21:39:13 - Processing batch 56/125 (8 images)
2025-03-11 21:39:14 - Processing batch 57/125 (8 images)
2025-03-11 21:39:14 - Processing batch 58/125 (8 images)
2025-03-11 21:39:15 - Processing batch 59/125 (8 images)
2025-03-11 21:39:15 - Processing batch 60/125 (8 images)
2025-03-11 21:39:15 - Processing batch 61/125 (8 images)
2025-03-11 21:39:16 - Processing batch 62/125 (8 images)
2025-03-11 21:39:16 - Processing batch 63/125 (8 images)
2025-03-11 21:39:17 - Processing batch 64/125 (8 images)
2025-03-11 21:39:17 - Processing batch 65/125 (8 images)
2025-03-11 21:39:17 - Processing batch 66/125 (8 images)
2025-03-11 21:39:18 - Processing batch 67/125 (8 images)
2025-03-11 21:39:18 - Processing batch 68/125 (8 images)
2025-03-11 21:39:18 - Processing batch 69/125 (8 images)
2025-03-11 21:39:19 - Processing batch 70/125 (8 images)
2025-03-11 21:39:19 - Processing batch 71/125 (8 images)
2025-03-11 21:39:20 - Processing batch 72/125 (8 images)
2025-03-11 21:39:20 - Processing batch 73/125 (8 images)
2025-03-11 21:39:20 - Processing batch 74/125 (8 images)
2025-03-11 21:39:21 - Processing batch 75/125 (8 images)
2025-03-11 21:39:21 - Processing batch 76/125 (8 images)
2025-03-11 21:39:21 - Processing batch 77/125 (8 images)
2025-03-11 21:39:22 - Processing batch 78/125 (8 images)
2025-03-11 21:39:22 - Processing batch 79/125 (8 images)
2025-03-11 21:39:23 - Processing batch 80/125 (8 images)
2025-03-11 21:39:23 - Processing batch 81/125 (8 images)
2025-03-11 21:39:23 - Processing batch 82/125 (8 images)
2025-03-11 21:39:24 - Processing batch 83/125 (8 images)
2025-03-11 21:39:24 - Processing batch 84/125 (8 images)
2025-03-11 21:39:25 - Processing batch 85/125 (8 images)
2025-03-11 21:39:25 - Processing batch 86/125 (8 images)
2025-03-11 21:39:25 - Processing batch 87/125 (8 images)
2025-03-11 21:39:26 - Processing batch 88/125 (8 images)
2025-03-11 21:39:26 - Processing batch 89/125 (8 images)
2025-03-11 21:39:26 - Processing batch 90/125 (8 images)
2025-03-11 21:39:27 - Processing batch 91/125 (8 images)
2025-03-11 21:39:27 - Processing batch 92/125 (8 images)
2025-03-11 21:39:28 - Processing batch 93/125 (8 images)
2025-03-11 21:39:28 - Processing batch 94/125 (8 images)
2025-03-11 21:39:28 - Processing batch 95/125 (8 images)
2025-03-11 21:39:29 - Processing batch 96/125 (8 images)
2025-03-11 21:39:29 - Processing batch 97/125 (8 images)
2025-03-11 21:39:30 - Processing batch 98/125 (8 images)
2025-03-11 21:39:30 - Processing batch 99/125 (8 images)
2025-03-11 21:39:30 - Processing batch 100/125 (8 images)
2025-03-11 21:39:31 - Processing batch 101/125 (8 images)
2025-03-11 21:39:31 - Processing batch 102/125 (8 images)
2025-03-11 21:39:31 - Processing batch 103/125 (8 images)
2025-03-11 21:39:32 - Processing batch 104/125 (8 images)
2025-03-11 21:39:32 - Processing batch 105/125 (8 images)
2025-03-11 21:39:33 - Processing batch 106/125 (8 images)
2025-03-11 21:39:33 - Processing batch 107/125 (8 images)
2025-03-11 21:39:33 - Processing batch 108/125 (8 images)
2025-03-11 21:39:34 - Processing batch 109/125 (8 images)
2025-03-11 21:39:34 - Processing batch 110/125 (8 images)
2025-03-11 21:39:34 - Processing batch 111/125 (8 images)
2025-03-11 21:39:35 - Processing batch 112/125 (8 images)
2025-03-11 21:39:35 - Processing batch 113/125 (8 images)
2025-03-11 21:39:36 - Processing batch 114/125 (8 images)
2025-03-11 21:39:36 - Processing batch 115/125 (8 images)
2025-03-11 21:39:36 - Processing batch 116/125 (8 images)
2025-03-11 21:39:37 - Processing batch 117/125 (8 images)
2025-03-11 21:39:37 - Processing batch 118/125 (8 images)
2025-03-11 21:39:37 - Processing batch 119/125 (8 images)
2025-03-11 21:39:38 - Processing batch 120/125 (8 images)
2025-03-11 21:39:38 - Processing batch 121/125 (8 images)
2025-03-11 21:39:39 - Processing batch 122/125 (8 images)
2025-03-11 21:39:39 - Processing batch 123/125 (8 images)
2025-03-11 21:39:39 - Processing batch 124/125 (8 images)
2025-03-11 21:39:40 - Processing batch 125/125 (8 images)
2025-03-11 21:39:40 - Selected threshold: 0.0000
2025-03-11 21:39:40 - Number of original images: 1000
2025-03-11 21:39:40 - Number of watermarked images: 1000
2025-03-11 21:39:40 - Final evaluation after 15000 iterations:
2025-03-11 21:39:40 - AUC score: 0.9726
2025-03-11 21:39:40 - TPR@1%FPR (watermarked): 0.4800
2025-03-11 21:39:40 - Mean score (watermarked): 0.0050
2025-03-11 21:39:40 - Std score (watermarked): 0.0521
2025-03-11 21:39:40 - TNR@1%FPR (original): 0.9900
2025-03-11 21:39:40 - TNR@1%FPR (random): 0.0000
2025-03-11 21:39:40 - TNR@1%FPR (truncated): 1.0000
2025-03-11 21:39:40 - TNR@1%FPR (quantized): 0.9870
2025-03-11 21:39:40 - TNR@1%FPR (downsampled): 1.0000
2025-03-11 21:39:40 - TNR@1%FPR (compressed): 0.9910
2025-03-11 21:39:40 - TNR@1%FPR (alt_ffhq1k): 0.9810
2025-03-11 21:39:40 - TNR@1%FPR (alt_ffhq30k): 0.9930
2025-03-11 21:39:40 - TNR@1%FPR (alt_ffhq70k-bcr): 0.9940
2025-03-11 21:39:40 - TNR@1%FPR (alt_ffhq70k-noaug): 0.9910
2025-03-11 21:39:40 - Training completed successfully.
[rank0]:[W311 21:39:41.421029410 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:118 [0] NCCL INFO [Service thread] Connection closed by localRank 0
s2470447-infk8s-job-train-rs-on-baseline-from-scratch-0-1-0:77:553 [0] NCCL INFO comm 0x6304621c72d0 rank 0 nranks 4 cudaDev 0 busId 6000 - Abort COMPLETE
Python script finished with exit status 0, sleeping indefinitely
